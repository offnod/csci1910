{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3, Problem 4\n",
    "The goal of this problem is for you to try and classify whether or not an individual is likely to make more or less than 50K per year. Carry out this task. Try at least five general architectures, report precision, recall and f1 score on a test set.\n",
    "\n",
    "For each of the parts, report your preformance in terms not of just numbers but in terms of graphs. When you have training and validation data, please show the curves as the training progresses. You should know when you are overfitting or underfitting. Don't just report bare numbers. You are free to add implmentation or markdown cells to make your notebook clearer!!\n",
    "\n",
    "Data:\n",
    "The following dataset was taken from the first dataset repository: http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "As the original task of the dataset lays out, Please note:\n",
    "\n",
    "the continuous variable fnlwgt represents final weight, which is the number of units in the target population that the responding unit represents.\n",
    "Part 1: Dealing with Missing Values\n",
    "What should you do about dealing with missing values - do you just drop those rows?\n",
    "One of the most common problems we come accross in working with data \"in the wild\" is missing data. Often we will have observations (rows) that have only some of the needed attributes. Different rows will have different attributes missing. There are a number of strategies for dealing with the missing values. Clearly one could be dropping the column (attribute), or row (observation). Unfortuntely if you drop columns you may lose critical information that is helpful for classification and may be present in most (many) of the rows. You can drop rows but if many rows have at least one missing value, you may loose too much data. Do you try to impute (i. e. fill in) the missing data? If so how?\n",
    "\n",
    "Explain why you chose the strategy you did.\n",
    "\n",
    "Hint - '?' denotes a missing value.\n",
    "\n",
    "Some possible strategies for dealing with missing data\n",
    "Whenever there is pleanty of data and very little missing data, you should consider dropping rows and/or columns. This may introduce some bias in the data but again, if the problem is limited to a very few rows or columns, it is easy in training to reproduce.\n",
    "\n",
    "Fill with fixed value using sklearn.impute.SimpleImputer. a. 'constant' 0. Rarely a good idea but sometimes, if we can assume that when it is missing it is basically 0, this might be a good idea. For example a data may list number of house fires in a zip code and a missing value just means none. b. 'mean' if the data is numeric, the mean is meaningfull. c. 'median' may be more sensible if the data is integer or ordered. When the mean and median are very different it is important to understand what a \"typical\" example might mean. When considering \"income\", for example, a few large outliers will mess up the mean. d. \"most_frequent' when you have categorical (nominal) labels, mean and median don't make any sense. Most probable label is what you need to use. This is also known as \"mode\".\n",
    "\n",
    "sklearn.impute.MissingIndicator: Sometimes the fact that a value is missing, is itself an important indicator. One can create a new feature/attribute that indicates a certain attribute is missing. If you later build a classifier by hand you can explicitly wieght each variable using the missing variable weights so that for that example (row) that attribute won't contribute to the classifier. In a deep neural network it is possible that the network can learn to do that automatically.\n",
    "\n",
    "One can use the sklearn.impute.KNNImputer which will look for rows to fill in the data.\n",
    "\n",
    "Fill with sklearn.impute.IterativeImputer scikit-learn provides a sophisticated imputation strategy. You can read up on this in the documentation, but it will fix on of the columns (attributes), and try to use the other features to predict similar to KNN but more sophisticated.\n",
    "\n",
    "Train a classifier: You can build your own classifier using machine learning. This is kind of a problem within a problem but if done correctly, it has the potential to be more accurate than a simpler method. Of course, if done badly it could be worse.\n",
    "\n",
    "Manually impute the missing values. You may know enough about the problem to build an ad-hoc way to fill in the missing values for each column in a way that makes the most sense. This almost always requires a great deal of domain expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def Printthis(df ,idx=False ,elems=5 ,rows=10 ,columns=None ,rand=False ,prtall=False):\n",
    "    if prtall == True:\n",
    "        with pd.option_context('display.max_rows', None\n",
    "                               , 'display.max_columns', None\n",
    "                               ,'display.width', None\n",
    "                              ,'display.max_colwidth', None):\n",
    "            print (df)\n",
    "    else:\n",
    "        size = len(df)\n",
    "\n",
    "        if idx==True:\n",
    "            return idxex\n",
    "        elif rand == False:\n",
    "            with pd.option_context('display.max_rows', rows\n",
    "                                   , 'display.max_columns', columns\n",
    "                                   ,'display.width', None\n",
    "                                  ,'display.max_colwidth', None):\n",
    "                print (df.iloc[:rows])\n",
    "        else:\n",
    "            index = np.random.permutation(size)[:elems]\n",
    "            with pd.option_context('display.max_rows', rows\n",
    "                                   , 'display.max_columns', columns\n",
    "                                   ,'display.width', None\n",
    "                                  ,'display.max_colwidth', None):\n",
    "                print (df.iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add your code for filling in the data here. Please end by using the appropriate pandas method\n",
    "#### to show the amount of missing data (which in the end should not be any since you dropped or filled in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "columns = [\n",
    "    \"age\",\n",
    "    \"work_class\",\n",
    "    \"fnlwgt\",\n",
    "    \"education\",\n",
    "    \"education_num\",\n",
    "    \"marital_status\",\n",
    "    \"occupation\",\n",
    "    \"relationship\",\n",
    "    \"race\",\n",
    "    \"sex\",\n",
    "    \"capital_gain\",\n",
    "    \"capital_loss\",\n",
    "    \"hours_per_week\",\n",
    "    \"native_country\",\n",
    "    \"target\"\n",
    "]\n",
    "df = pd.read_csv(\"/mnt/hgfs/VMsharedFolder/CCNY/csci1910/hw4/adult.data\", names=columns)\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == \"object\":\n",
    "        df[column] = df[column].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   work_class      32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education_num   32561 non-null  int64 \n",
      " 5   marital_status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital_gain    32561 non-null  int64 \n",
      " 11  capital_loss    32561 non-null  int64 \n",
      " 12  hours_per_week  32561 non-null  int64 \n",
      " 13  native_country  32561 non-null  object\n",
      " 14  target          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "[39 50 38 53 28 37 49 52 31 42 30 23 32 40 34 25 43 54 35 59 56 19 20 45\n",
      " 22 48 21 24 57 44 41 29 18 47 46 36 79 27 67 33 76 17 55 61 70 64 71 68\n",
      " 66 51 58 26 60 90 75 65 77 62 63 80 72 74 69 73 81 78 88 82 83 84 85 86\n",
      " 87]\n",
      "work_class\n",
      "['State-gov' 'Self-emp-not-inc' 'Private' 'Federal-gov' 'Local-gov' '?'\n",
      " 'Self-emp-inc' 'Without-pay' 'Never-worked']\n",
      "fnlwgt\n",
      "[ 77516  83311 215646 ...  34066  84661 257302]\n",
      "education\n",
      "['Bachelors' 'HS-grad' '11th' 'Masters' '9th' 'Some-college' 'Assoc-acdm'\n",
      " 'Assoc-voc' '7th-8th' 'Doctorate' 'Prof-school' '5th-6th' '10th'\n",
      " '1st-4th' 'Preschool' '12th']\n",
      "education_num\n",
      "[13  9  7 14  5 10 12 11  4 16 15  3  6  2  1  8]\n",
      "marital_status\n",
      "['Never-married' 'Married-civ-spouse' 'Divorced' 'Married-spouse-absent'\n",
      " 'Separated' 'Married-AF-spouse' 'Widowed']\n",
      "occupation\n",
      "['Adm-clerical' 'Exec-managerial' 'Handlers-cleaners' 'Prof-specialty'\n",
      " 'Other-service' 'Sales' 'Craft-repair' 'Transport-moving'\n",
      " 'Farming-fishing' 'Machine-op-inspct' 'Tech-support' '?'\n",
      " 'Protective-serv' 'Armed-Forces' 'Priv-house-serv']\n",
      "relationship\n",
      "['Not-in-family' 'Husband' 'Wife' 'Own-child' 'Unmarried' 'Other-relative']\n",
      "race\n",
      "['White' 'Black' 'Asian-Pac-Islander' 'Amer-Indian-Eskimo' 'Other']\n",
      "sex\n",
      "['Male' 'Female']\n",
      "capital_gain\n",
      "[ 2174     0 14084  5178  5013  2407 14344 15024  7688 34095  4064  4386\n",
      "  7298  1409  3674  1055  3464  2050  2176   594 20051  6849  4101  1111\n",
      "  8614  3411  2597 25236  4650  9386  2463  3103 10605  2964  3325  2580\n",
      "  3471  4865 99999  6514  1471  2329  2105  2885 25124 10520  2202  2961\n",
      " 27828  6767  2228  1506 13550  2635  5556  4787  3781  3137  3818  3942\n",
      "   914   401  2829  2977  4934  2062  2354  5455 15020  1424  3273 22040\n",
      "  4416  3908 10566   991  4931  1086  7430  6497   114  7896  2346  3418\n",
      "  3432  2907  1151  2414  2290 15831 41310  4508  2538  3456  6418  1848\n",
      "  3887  5721  9562  1455  2036  1831 11678  2936  2993  7443  6360  1797\n",
      "  1173  4687  6723  2009  6097  2653  1639 18481  7978  2387  5060]\n",
      "capital_loss\n",
      "[   0 2042 1408 1902 1573 1887 1719 1762 1564 2179 1816 1980 1977 1876\n",
      " 1340 2206 1741 1485 2339 2415 1380 1721 2051 2377 1669 2352 1672  653\n",
      " 2392 1504 2001 1590 1651 1628 1848 1740 2002 1579 2258 1602  419 2547\n",
      " 2174 2205 1726 2444 1138 2238  625  213 1539  880 1668 1092 1594 3004\n",
      " 2231 1844  810 2824 2559 2057 1974  974 2149 1825 1735 1258 2129 2603\n",
      " 2282  323 4356 2246 1617 1648 2489 3770 1755 3683 2267 2080 2457  155\n",
      " 3900 2201 1944 2467 2163 2754 2472 1411]\n",
      "hours_per_week\n",
      "[40 13 16 45 50 80 30 35 60 20 52 44 15 25 38 43 55 48 58 32 70  2 22 56\n",
      " 41 28 36 24 46 42 12 65  1 10 34 75 98 33 54  8  6 64 19 18 72  5  9 47\n",
      " 37 21 26 14  4 59  7 99 53 39 62 57 78 90 66 11 49 84  3 17 68 27 85 31\n",
      " 51 77 63 23 87 88 73 89 97 94 29 96 67 82 86 91 81 76 92 61 74 95]\n",
      "native_country\n",
      "['United-States' 'Cuba' 'Jamaica' 'India' '?' 'Mexico' 'South'\n",
      " 'Puerto-Rico' 'Honduras' 'England' 'Canada' 'Germany' 'Iran'\n",
      " 'Philippines' 'Italy' 'Poland' 'Columbia' 'Cambodia' 'Thailand' 'Ecuador'\n",
      " 'Laos' 'Taiwan' 'Haiti' 'Portugal' 'Dominican-Republic' 'El-Salvador'\n",
      " 'France' 'Guatemala' 'China' 'Japan' 'Yugoslavia' 'Peru'\n",
      " 'Outlying-US(Guam-USVI-etc)' 'Scotland' 'Trinadad&Tobago' 'Greece'\n",
      " 'Nicaragua' 'Vietnam' 'Hong' 'Ireland' 'Hungary' 'Holand-Netherlands']\n",
      "target\n",
      "['<=50K' '>50K']\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col)\n",
    "    Printthis(df[col].unique() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "36    898\n",
      "31    888\n",
      "34    886\n",
      "23    877\n",
      "35    876\n",
      "33    875\n",
      "28    867\n",
      "30    861\n",
      "37    858\n",
      "25    841\n",
      "27    835\n",
      "32    828\n",
      "38    827\n",
      "39    816\n",
      "29    813\n",
      "41    808\n",
      "24    798\n",
      "40    794\n",
      "26    785\n",
      "42    780\n",
      "43    770\n",
      "22    765\n",
      "20    753\n",
      "46    737\n",
      "45    734\n",
      "44    724\n",
      "21    720\n",
      "19    712\n",
      "47    708\n",
      "50    602\n",
      "51    595\n",
      "49    577\n",
      "18    550\n",
      "48    543\n",
      "52    478\n",
      "53    464\n",
      "55    419\n",
      "54    415\n",
      "17    395\n",
      "58    366\n",
      "56    366\n",
      "57    358\n",
      "59    355\n",
      "60    312\n",
      "61    300\n",
      "62    258\n",
      "63    230\n",
      "64    208\n",
      "65    178\n",
      "67    151\n",
      "66    150\n",
      "68    120\n",
      "69    108\n",
      "70     89\n",
      "71     72\n",
      "72     67\n",
      "73     64\n",
      "74     51\n",
      "76     46\n",
      "75     45\n",
      "90     43\n",
      "77     29\n",
      "78     23\n",
      "80     22\n",
      "79     22\n",
      "81     20\n",
      "82     12\n",
      "84     10\n",
      "83      6\n",
      "85      3\n",
      "88      3\n",
      "87      1\n",
      "86      1\n",
      "Name: age, dtype: int64\n",
      "work_class\n",
      "Private             22696\n",
      "Self-emp-not-inc     2541\n",
      "Local-gov            2093\n",
      "?                    1836\n",
      "State-gov            1298\n",
      "Self-emp-inc         1116\n",
      "Federal-gov           960\n",
      "Without-pay            14\n",
      "Never-worked            7\n",
      "Name: work_class, dtype: int64\n",
      "fnlwgt\n",
      "164190     13\n",
      "203488     13\n",
      "123011     13\n",
      "113364     12\n",
      "121124     12\n",
      "126675     12\n",
      "148995     12\n",
      "123983     11\n",
      "190290     11\n",
      "126569     11\n",
      "155659     11\n",
      "102308     11\n",
      "120277     11\n",
      "241998     11\n",
      "111483     11\n",
      "120131     11\n",
      "188246     11\n",
      "117963     10\n",
      "174789     10\n",
      "112497     10\n",
      "193882     10\n",
      "125933     10\n",
      "216129     10\n",
      "99185      10\n",
      "125461     10\n",
      "155489     10\n",
      "194630     10\n",
      "125892     10\n",
      "119793     10\n",
      "177675     10\n",
      "186934     10\n",
      "124963      9\n",
      "175262      9\n",
      "200471      9\n",
      "116632      9\n",
      "218490      9\n",
      "214542      9\n",
      "194901      9\n",
      "221172      9\n",
      "129573      9\n",
      "202872      9\n",
      "82393       9\n",
      "111567      9\n",
      "118551      9\n",
      "112847      9\n",
      "169104      8\n",
      "176185      8\n",
      "163003      8\n",
      "144949      8\n",
      "104501      8\n",
      "160120      8\n",
      "226443      8\n",
      "130620      8\n",
      "181091      8\n",
      "151089      8\n",
      "119156      8\n",
      "185041      8\n",
      "99146       8\n",
      "340917      8\n",
      "150533      8\n",
      "210781      8\n",
      "132601      8\n",
      "111128      8\n",
      "132879      8\n",
      "113324      8\n",
      "213140      8\n",
      "199058      8\n",
      "185385      8\n",
      "144778      8\n",
      "210736      8\n",
      "138768      8\n",
      "157747      8\n",
      "184655      8\n",
      "202027      8\n",
      "108435      8\n",
      "154374      8\n",
      "168071      8\n",
      "108140      8\n",
      "147258      8\n",
      "176683      8\n",
      "161141      8\n",
      "163665      8\n",
      "172538      8\n",
      "154641      7\n",
      "116358      7\n",
      "143046      7\n",
      "107231      7\n",
      "185057      7\n",
      "188069      7\n",
      "207668      7\n",
      "134737      7\n",
      "103277      7\n",
      "134886      7\n",
      "207685      7\n",
      "252752      7\n",
      "99199       7\n",
      "102771      7\n",
      "109133      7\n",
      "211968      7\n",
      "101593      7\n",
      "143062      7\n",
      "246891      7\n",
      "175232      7\n",
      "127651      7\n",
      "174714      7\n",
      "159755      7\n",
      "117789      7\n",
      "101345      7\n",
      "212894      7\n",
      "114691      7\n",
      "156464      7\n",
      "112115      7\n",
      "381153      7\n",
      "111499      7\n",
      "174533      7\n",
      "217460      7\n",
      "133963      7\n",
      "191342      7\n",
      "162312      7\n",
      "117381      7\n",
      "98361       7\n",
      "329980      7\n",
      "106900      7\n",
      "96062       7\n",
      "123429      7\n",
      "144064      7\n",
      "204235      7\n",
      "198316      7\n",
      "173858      7\n",
      "98350       7\n",
      "113838      7\n",
      "202560      7\n",
      "167482      7\n",
      "107801      7\n",
      "200153      7\n",
      "194636      7\n",
      "120238      7\n",
      "124692      7\n",
      "206609      7\n",
      "145441      7\n",
      "104196      7\n",
      "205100      7\n",
      "103925      7\n",
      "138852      7\n",
      "150057      7\n",
      "115932      7\n",
      "185407      7\n",
      "145409      7\n",
      "61885       7\n",
      "114158      7\n",
      "101709      7\n",
      "143582      7\n",
      "107302      6\n",
      "160724      6\n",
      "193494      6\n",
      "189759      6\n",
      "108293      6\n",
      "153132      6\n",
      "203761      6\n",
      "132686      6\n",
      "104509      6\n",
      "186035      6\n",
      "192779      6\n",
      "163870      6\n",
      "124242      6\n",
      "174575      6\n",
      "142712      6\n",
      "206051      6\n",
      "139391      6\n",
      "347166      6\n",
      "102476      6\n",
      "154410      6\n",
      "184378      6\n",
      "170230      6\n",
      "79586       6\n",
      "122272      6\n",
      "69333       6\n",
      "77146       6\n",
      "155664      6\n",
      "175958      6\n",
      "182117      6\n",
      "127772      6\n",
      "257250      6\n",
      "140644      6\n",
      "140001      6\n",
      "160786      6\n",
      "188436      6\n",
      "281030      6\n",
      "110622      6\n",
      "130126      6\n",
      "214635      6\n",
      "161708      6\n",
      "97723       6\n",
      "145964      6\n",
      "183523      6\n",
      "152810      6\n",
      "139268      6\n",
      "82622       6\n",
      "147989      6\n",
      "86551       6\n",
      "214858      6\n",
      "190350      6\n",
      "349910      6\n",
      "175942      6\n",
      "193524      6\n",
      "160647      6\n",
      "105936      6\n",
      "174461      6\n",
      "341672      6\n",
      "34378       6\n",
      "208358      6\n",
      "115023      6\n",
      "233130      6\n",
      "305597      6\n",
      "175856      6\n",
      "361888      6\n",
      "164488      6\n",
      "182771      6\n",
      "190525      6\n",
      "153486      6\n",
      "125000      6\n",
      "155106      6\n",
      "320451      6\n",
      "227065      6\n",
      "172571      6\n",
      "149943      6\n",
      "72338       6\n",
      "151584      6\n",
      "149640      6\n",
      "251854      6\n",
      "189203      6\n",
      "190895      6\n",
      "174201      6\n",
      "145574      6\n",
      "195124      6\n",
      "170800      6\n",
      "57233       6\n",
      "210945      6\n",
      "197387      6\n",
      "117606      6\n",
      "70240       6\n",
      "176711      6\n",
      "241895      6\n",
      "198841      6\n",
      "109015      6\n",
      "140854      6\n",
      "237943      6\n",
      "153976      6\n",
      "89508       6\n",
      "32950       6\n",
      "287988      6\n",
      "155781      6\n",
      "186824      6\n",
      "191277      6\n",
      "139012      6\n",
      "241885      6\n",
      "33975       6\n",
      "170070      6\n",
      "198660      6\n",
      "154571      6\n",
      "193026      6\n",
      "135339      6\n",
      "80058       6\n",
      "134768      6\n",
      "160035      6\n",
      "32732       6\n",
      "223212      6\n",
      "248990      6\n",
      "238917      6\n",
      "207301      6\n",
      "102359      6\n",
      "22245       6\n",
      "328466      5\n",
      "208302      5\n",
      "189462      5\n",
      "122066      5\n",
      "232475      5\n",
      "80933       5\n",
      "37869       5\n",
      "147653      5\n",
      "173938      5\n",
      "168232      5\n",
      "144351      5\n",
      "103064      5\n",
      "37778       5\n",
      "117849      5\n",
      "133969      5\n",
      "201495      5\n",
      "175127      5\n",
      "195835      5\n",
      "22966       5\n",
      "124137      5\n",
      "195488      5\n",
      "117779      5\n",
      "48087       5\n",
      "259323      5\n",
      "162551      5\n",
      "143604      5\n",
      "171924      5\n",
      "206951      5\n",
      "207578      5\n",
      "146659      5\n",
      "192835      5\n",
      "29810       5\n",
      "160369      5\n",
      "208946      5\n",
      "76860       5\n",
      "103323      5\n",
      "213226      5\n",
      "219591      5\n",
      "230684      5\n",
      "72887       5\n",
      "171968      5\n",
      "177305      5\n",
      "29762       5\n",
      "287658      5\n",
      "190228      5\n",
      "167990      5\n",
      "33798       5\n",
      "117833      5\n",
      "50178       5\n",
      "107218      5\n",
      "286750      5\n",
      "172281      5\n",
      "34180       5\n",
      "221955      5\n",
      "37933       5\n",
      "234663      5\n",
      "180052      5\n",
      "128378      5\n",
      "255004      5\n",
      "193586      5\n",
      "154120      5\n",
      "215990      5\n",
      "109952      5\n",
      "69251       5\n",
      "277488      5\n",
      "104892      5\n",
      "137367      5\n",
      "136986      5\n",
      "133503      5\n",
      "231826      5\n",
      "209317      5\n",
      "139703      5\n",
      "94235       5\n",
      "117210      5\n",
      "106347      5\n",
      "116608      5\n",
      "133373      5\n",
      "33331       5\n",
      "272950      5\n",
      "53833       5\n",
      "105138      5\n",
      "117618      5\n",
      "164526      5\n",
      "409189      5\n",
      "192939      5\n",
      "64292       5\n",
      "204226      5\n",
      "181705      5\n",
      "199590      5\n",
      "177905      5\n",
      "40955       5\n",
      "124827      5\n",
      "218215      5\n",
      "40666       5\n",
      "225193      5\n",
      "154950      5\n",
      "109912      5\n",
      "218184      5\n",
      "202729      5\n",
      "61343       5\n",
      "180060      5\n",
      "356689      5\n",
      "149210      5\n",
      "157131      5\n",
      "85995       5\n",
      "60331       5\n",
      "174102      5\n",
      "186191      5\n",
      "234901      5\n",
      "187322      5\n",
      "193285      5\n",
      "253814      5\n",
      "182460      5\n",
      "226902      5\n",
      "338320      5\n",
      "170850      5\n",
      "83411       5\n",
      "190027      5\n",
      "157332      5\n",
      "423222      5\n",
      "86143       5\n",
      "238959      5\n",
      "19302       5\n",
      "180985      5\n",
      "117496      5\n",
      "239755      5\n",
      "84119       5\n",
      "131230      5\n",
      "161478      5\n",
      "189933      5\n",
      "183800      5\n",
      "162572      5\n",
      "198096      5\n",
      "187046      5\n",
      "120781      5\n",
      "116666      5\n",
      "328216      5\n",
      "185647      5\n",
      "193047      5\n",
      "169583      5\n",
      "173495      5\n",
      "236769      5\n",
      "97883       5\n",
      "179668      5\n",
      "243190      5\n",
      "126613      5\n",
      "224566      5\n",
      "181820      5\n",
      "29814       5\n",
      "227890      5\n",
      "207568      5\n",
      "182342      5\n",
      "142719      5\n",
      "135056      5\n",
      "245090      5\n",
      "161092      5\n",
      "122206      5\n",
      "231043      5\n",
      "192894      5\n",
      "123075      5\n",
      "199763      5\n",
      "214242      5\n",
      "114967      5\n",
      "93225       5\n",
      "168906      5\n",
      "147206      5\n",
      "175935      5\n",
      "217961      5\n",
      "130856      5\n",
      "272944      5\n",
      "410351      5\n",
      "117674      5\n",
      "42044       5\n",
      "182714      5\n",
      "195532      5\n",
      "201699      5\n",
      "174395      5\n",
      "220585      5\n",
      "78529       5\n",
      "134367      5\n",
      "31740       5\n",
      "175339      5\n",
      "168262      5\n",
      "33126       5\n",
      "242984      5\n",
      "265266      5\n",
      "121718      5\n",
      "107882      5\n",
      "159187      5\n",
      "187560      5\n",
      "175925      5\n",
      "201127      5\n",
      "182926      5\n",
      "194096      5\n",
      "155343      5\n",
      "126701      5\n",
      "224361      5\n",
      "235271      5\n",
      "145290      5\n",
      "197332      5\n",
      "176756      5\n",
      "153078      5\n",
      "107682      5\n",
      "32528       5\n",
      "243631      5\n",
      "236391      5\n",
      "193815      5\n",
      "204447      5\n",
      "73514       5\n",
      "88055       5\n",
      "41356       5\n",
      "209538      5\n",
      "206600      5\n",
      "159732      5\n",
      "122493      5\n",
      "30916       5\n",
      "119422      5\n",
      "149102      5\n",
      "96483       5\n",
      "100345      5\n",
      "117767      5\n",
      "34572       5\n",
      "77820       5\n",
      "195897      5\n",
      "191385      5\n",
      "173736      5\n",
      "183765      5\n",
      "409230      5\n",
      "247025      5\n",
      "112271      5\n",
      "159442      5\n",
      "168539      5\n",
      "175674      5\n",
      "127610      5\n",
      "334273      5\n",
      "193720      5\n",
      "173851      5\n",
      "167725      5\n",
      "98776       5\n",
      "192337      5\n",
      "159908      5\n",
      "170562      4\n",
      "163110      4\n",
      "33117       4\n",
      "197997      4\n",
      "230329      4\n",
      "137354      4\n",
      "60726       4\n",
      "226267      4\n",
      "169180      4\n",
      "148254      4\n",
      "174491      4\n",
      "186916      4\n",
      "199713      4\n",
      "156926      4\n",
      "183594      4\n",
      "348960      4\n",
      "204816      4\n",
      "133937      4\n",
      "370119      4\n",
      "110998      4\n",
      "137815      4\n",
      "24008       4\n",
      "291407      4\n",
      "233511      4\n",
      "149949      4\n",
      "191196      4\n",
      "191814      4\n",
      "195994      4\n",
      "142675      4\n",
      "19914       4\n",
      "341204      4\n",
      "33521       4\n",
      "223515      4\n",
      "48093       4\n",
      "110643      4\n",
      "279129      4\n",
      "160910      4\n",
      "162228      4\n",
      "89559       4\n",
      "100135      4\n",
      "59496       4\n",
      "153066      4\n",
      "88564       4\n",
      "115784      4\n",
      "119098      4\n",
      "32185       4\n",
      "202450      4\n",
      "233571      4\n",
      "180303      4\n",
      "124971      4\n",
      "55377       4\n",
      "133861      4\n",
      "102058      4\n",
      "235646      4\n",
      "166961      4\n",
      "284317      4\n",
      "323069      4\n",
      "278130      4\n",
      "208277      4\n",
      "255454      4\n",
      "251905      4\n",
      "103474      4\n",
      "156890      4\n",
      "160187      4\n",
      "45607       4\n",
      "207202      4\n",
      "34616       4\n",
      "185452      4\n",
      "312667      4\n",
      "125417      4\n",
      "220589      4\n",
      "125796      4\n",
      "159726      4\n",
      "213722      4\n",
      "209205      4\n",
      "190511      4\n",
      "216811      4\n",
      "35309       4\n",
      "33487       4\n",
      "313729      4\n",
      "188386      4\n",
      "375313      4\n",
      "209609      4\n",
      "249935      4\n",
      "216181      4\n",
      "295589      4\n",
      "214702      4\n",
      "291979      4\n",
      "190968      4\n",
      "56651       4\n",
      "345705      4\n",
      "98389       4\n",
      "185846      4\n",
      "119199      4\n",
      "66473       4\n",
      "256211      4\n",
      "144071      4\n",
      "417668      4\n",
      "193459      4\n",
      "323790      4\n",
      "107793      4\n",
      "188236      4\n",
      "174040      4\n",
      "178615      4\n",
      "145160      4\n",
      "233777      4\n",
      "190044      4\n",
      "88913       4\n",
      "186909      4\n",
      "201680      4\n",
      "253759      4\n",
      "132222      4\n",
      "156728      4\n",
      "35723       4\n",
      "88126       4\n",
      "196385      4\n",
      "236696      4\n",
      "235853      4\n",
      "298635      4\n",
      "203070      4\n",
      "168191      4\n",
      "165315      4\n",
      "114580      4\n",
      "187847      4\n",
      "35595       4\n",
      "109001      4\n",
      "149507      4\n",
      "31023       4\n",
      "141807      4\n",
      "329426      4\n",
      "101299      4\n",
      "171424      4\n",
      "115066      4\n",
      "137876      4\n",
      "246439      4\n",
      "351161      4\n",
      "269733      4\n",
      "202822      4\n",
      "192323      4\n",
      "193895      4\n",
      "189888      4\n",
      "187702      4\n",
      "112763      4\n",
      "147638      4\n",
      "353012      4\n",
      "191777      4\n",
      "149909      4\n",
      "24106       4\n",
      "284329      4\n",
      "199915      4\n",
      "177937      4\n",
      "268234      4\n",
      "38948       4\n",
      "124111      4\n",
      "169995      4\n",
      "206861      4\n",
      "111363      4\n",
      "184078      4\n",
      "197286      4\n",
      "181307      4\n",
      "177526      4\n",
      "177705      4\n",
      "102828      4\n",
      "286675      4\n",
      "164607      4\n",
      "231638      4\n",
      "99131       4\n",
      "157289      4\n",
      "186420      4\n",
      "125550      4\n",
      "22201       4\n",
      "48343       4\n",
      "190650      4\n",
      "24763       4\n",
      "190115      4\n",
      "77884       4\n",
      "199688      4\n",
      "235894      4\n",
      "312017      4\n",
      "131310      4\n",
      "119411      4\n",
      "164898      4\n",
      "216116      4\n",
      "176321      4\n",
      "184682      4\n",
      "200973      4\n",
      "89041       4\n",
      "167474      4\n",
      "120074      4\n",
      "235124      4\n",
      "211032      4\n",
      "184756      4\n",
      "126754      4\n",
      "28572       4\n",
      "190333      4\n",
      "107411      4\n",
      "245317      4\n",
      "196342      4\n",
      "342709      4\n",
      "194141      4\n",
      "167476      4\n",
      "170108      4\n",
      "347491      4\n",
      "111450      4\n",
      "213887      4\n",
      "129707      4\n",
      "467108      4\n",
      "201865      4\n",
      "97176       4\n",
      "221532      4\n",
      "189346      4\n",
      "331395      4\n",
      "295127      4\n",
      "147655      4\n",
      "137363      4\n",
      "178948      4\n",
      "349148      4\n",
      "53197       4\n",
      "210474      4\n",
      "163237      4\n",
      "181666      4\n",
      "609789      4\n",
      "118693      4\n",
      "188330      4\n",
      "163392      4\n",
      "155818      4\n",
      "33304       4\n",
      "26781       4\n",
      "174308      4\n",
      "320984      4\n",
      "203482      4\n",
      "183898      4\n",
      "148709      4\n",
      "83064       4\n",
      "98155       4\n",
      "308205      4\n",
      "128016      4\n",
      "58343       4\n",
      "148549      4\n",
      "168981      4\n",
      "169496      4\n",
      "332379      4\n",
      "175070      4\n",
      "167159      4\n",
      "210498      4\n",
      "105252      4\n",
      "218542      4\n",
      "168387      4\n",
      "301867      4\n",
      "160261      4\n",
      "129150      4\n",
      "47902       4\n",
      "212864      4\n",
      "216867      4\n",
      "456236      4\n",
      "193090      4\n",
      "43712       4\n",
      "265097      4\n",
      "200235      4\n",
      "287306      4\n",
      "152035      4\n",
      "284166      4\n",
      "176992      4\n",
      "280093      4\n",
      "274363      4\n",
      "81132       4\n",
      "112137      4\n",
      "236543      4\n",
      "179423      4\n",
      "203240      4\n",
      "188540      4\n",
      "155657      4\n",
      "118023      4\n",
      "293091      4\n",
      "100669      4\n",
      "222011      4\n",
      "172175      4\n",
      "339482      4\n",
      "30529       4\n",
      "165695      4\n",
      "205359      4\n",
      "185325      4\n",
      "180551      4\n",
      "301614      4\n",
      "98283       4\n",
      "154210      4\n",
      "70720       4\n",
      "143058      4\n",
      "163215      4\n",
      "63509       4\n",
      "138441      4\n",
      "291755      4\n",
      "59083       4\n",
      "118941      4\n",
      "219546      4\n",
      "188291      4\n",
      "330571      4\n",
      "102130      4\n",
      "64520       4\n",
      "123727      4\n",
      "114459      4\n",
      "100734      4\n",
      "180599      4\n",
      "216563      4\n",
      "150324      4\n",
      "35576       4\n",
      "99357       4\n",
      "73199       4\n",
      "154785      4\n",
      "195576      4\n",
      "54611       4\n",
      "152307      4\n",
      "329144      4\n",
      "163998      4\n",
      "124680      4\n",
      "199303      4\n",
      "297449      4\n",
      "34446       4\n",
      "202683      4\n",
      "228320      4\n",
      "187830      4\n",
      "125159      4\n",
      "240504      4\n",
      "169182      4\n",
      "144361      4\n",
      "30673       4\n",
      "161007      4\n",
      "103948      4\n",
      "244147      4\n",
      "39986       4\n",
      "193260      4\n",
      "154863      4\n",
      "37937       4\n",
      "183735      4\n",
      "165309      4\n",
      "317360      4\n",
      "353824      4\n",
      "194740      4\n",
      "176839      4\n",
      "184018      4\n",
      "138940      4\n",
      "183810      4\n",
      "37088       4\n",
      "173243      4\n",
      "176716      4\n",
      "198183      4\n",
      "224640      4\n",
      "361497      4\n",
      "183611      4\n",
      "150309      4\n",
      "31267       4\n",
      "177907      4\n",
      "172822      4\n",
      "82777       4\n",
      "178983      4\n",
      "29702       4\n",
      "160703      4\n",
      "32616       4\n",
      "80680       4\n",
      "115562      4\n",
      "194259      4\n",
      "130057      4\n",
      "334291      4\n",
      "304570      4\n",
      "182062      4\n",
      "162667      4\n",
      "165815      4\n",
      "413297      4\n",
      "140764      4\n",
      "445382      4\n",
      "341762      4\n",
      "146908      4\n",
      "192251      4\n",
      "197583      4\n",
      "236861      4\n",
      "137192      4\n",
      "278322      4\n",
      "103435      4\n",
      "169324      4\n",
      "226296      4\n",
      "172232      4\n",
      "90934       4\n",
      "216414      4\n",
      "87205       4\n",
      "403671      4\n",
      "49020       4\n",
      "260696      4\n",
      "99270       4\n",
      "306779      4\n",
      "25955       4\n",
      "134890      4\n",
      "289886      4\n",
      "231180      4\n",
      "212120      4\n",
      "165235      4\n",
      "156877      4\n",
      "194360      4\n",
      "203836      4\n",
      "192384      4\n",
      "118793      4\n",
      "222993      4\n",
      "205852      4\n",
      "159179      4\n",
      "282023      4\n",
      "180686      4\n",
      "121313      4\n",
      "121055      4\n",
      "174215      4\n",
      "108945      4\n",
      "27049       4\n",
      "159589      4\n",
      "215395      4\n",
      "183639      4\n",
      "167350      4\n",
      "123681      4\n",
      "91189       4\n",
      "195638      4\n",
      "188950      4\n",
      "421561      4\n",
      "188774      4\n",
      "176814      4\n",
      "152246      4\n",
      "159869      4\n",
      "250038      4\n",
      "121023      4\n",
      "186272      4\n",
      "200246      4\n",
      "200089      4\n",
      "143766      4\n",
      "268022      4\n",
      "177858      4\n",
      "193130      4\n",
      "182074      4\n",
      "171615      4\n",
      "169133      4\n",
      "223433      4\n",
      "225456      4\n",
      "134566      4\n",
      "278924      4\n",
      "167140      4\n",
      "145419      4\n",
      "136331      4\n",
      "222654      4\n",
      "116391      4\n",
      "263561      4\n",
      "154076      4\n",
      "131568      4\n",
      "182177      4\n",
      "33610       4\n",
      "113870      4\n",
      "236021      4\n",
      "50442       4\n",
      "162343      4\n",
      "132320      4\n",
      "245372      4\n",
      "114758      4\n",
      "176101      4\n",
      "343403      4\n",
      "34037       4\n",
      "128272      4\n",
      "138370      4\n",
      "188798      4\n",
      "174995      4\n",
      "303867      4\n",
      "112403      4\n",
      "322674      4\n",
      "198211      4\n",
      "110457      4\n",
      "183096      4\n",
      "198452      4\n",
      "193374      4\n",
      "185099      4\n",
      "356838      4\n",
      "89718       4\n",
      "241951      4\n",
      "271933      4\n",
      "183151      4\n",
      "184659      4\n",
      "149184      4\n",
      "143266      4\n",
      "39615       4\n",
      "209103      4\n",
      "187167      4\n",
      "169785      4\n",
      "150025      4\n",
      "42706       4\n",
      "47907       4\n",
      "176178      4\n",
      "209691      4\n",
      "180342      4\n",
      "410439      4\n",
      "27408       4\n",
      "368561      4\n",
      "35032       4\n",
      "222450      4\n",
      "248584      4\n",
      "196307      4\n",
      "187581      4\n",
      "180758      4\n",
      "481987      4\n",
      "291374      4\n",
      "68729       4\n",
      "35633       4\n",
      "202950      4\n",
      "115289      4\n",
      "184105      4\n",
      "201723      4\n",
      "216256      4\n",
      "81853       4\n",
      "117363      4\n",
      "142766      4\n",
      "216481      4\n",
      "45796       4\n",
      "223267      4\n",
      "124187      4\n",
      "227594      4\n",
      "177287      4\n",
      "180339      4\n",
      "72896       4\n",
      "137658      4\n",
      "187720      4\n",
      "165799      4\n",
      "210525      4\n",
      "38795       4\n",
      "179488      4\n",
      "185127      4\n",
      "87556       4\n",
      "162187      4\n",
      "171114      4\n",
      "248094      4\n",
      "394927      4\n",
      "73585       4\n",
      "79531       4\n",
      "177083      4\n",
      "205152      4\n",
      "410034      4\n",
      "204641      4\n",
      "173730      4\n",
      "179579      4\n",
      "183892      4\n",
      "65278       4\n",
      "108542      4\n",
      "283635      4\n",
      "27242       4\n",
      "31339       4\n",
      "204052      4\n",
      "213019      4\n",
      "191910      4\n",
      "292472      4\n",
      "199539      4\n",
      "20795       4\n",
      "219835      4\n",
      "115215      4\n",
      "316820      3\n",
      "185145      3\n",
      "147284      3\n",
      "350498      3\n",
      "56841       3\n",
      "123053      3\n",
      "167440      3\n",
      "135289      3\n",
      "119033      3\n",
      "165278      3\n",
      "185129      3\n",
      "144608      3\n",
      "157541      3\n",
      "147110      3\n",
      "122999      3\n",
      "117983      3\n",
      "95855       3\n",
      "189265      3\n",
      "92262       3\n",
      "24395       3\n",
      "277647      3\n",
      "190227      3\n",
      "122246      3\n",
      "113466      3\n",
      "151369      3\n",
      "42485       3\n",
      "61778       3\n",
      "192712      3\n",
      "124771      3\n",
      "124052      3\n",
      "165930      3\n",
      "51100       3\n",
      "246974      3\n",
      "139770      3\n",
      "181220      3\n",
      "122346      3\n",
      "174592      3\n",
      "56582       3\n",
      "242552      3\n",
      "167065      3\n",
      "139347      3\n",
      "250967      3\n",
      "154422      3\n",
      "228873      3\n",
      "131982      3\n",
      "59612       3\n",
      "182898      3\n",
      "115851      3\n",
      "102628      3\n",
      "162632      3\n",
      "269722      3\n",
      "30290       3\n",
      "204205      3\n",
      "188503      3\n",
      "195516      3\n",
      "182866      3\n",
      "158294      3\n",
      "54190       3\n",
      "367533      3\n",
      "177211      3\n",
      "192565      3\n",
      "198145      3\n",
      "206862      3\n",
      "195949      3\n",
      "258883      3\n",
      "200192      3\n",
      "173590      3\n",
      "298130      3\n",
      "219021      3\n",
      "187203      3\n",
      "50748       3\n",
      "35644       3\n",
      "381789      3\n",
      "200819      3\n",
      "150154      3\n",
      "108320      3\n",
      "368797      3\n",
      "194772      3\n",
      "153546      3\n",
      "107658      3\n",
      "166549      3\n",
      "192869      3\n",
      "267859      3\n",
      "202565      3\n",
      "244945      3\n",
      "48520       3\n",
      "287681      3\n",
      "249727      3\n",
      "177304      3\n",
      "138192      3\n",
      "242619      3\n",
      "305874      3\n",
      "153805      3\n",
      "146378      3\n",
      "133144      3\n",
      "109282      3\n",
      "32921       3\n",
      "209101      3\n",
      "65624       3\n",
      "177727      3\n",
      "345969      3\n",
      "162327      3\n",
      "319733      3\n",
      "188274      3\n",
      "77634       3\n",
      "322691      3\n",
      "330087      3\n",
      "296453      3\n",
      "291968      3\n",
      "176069      3\n",
      "162945      3\n",
      "141003      3\n",
      "56248       3\n",
      "197918      3\n",
      "420054      3\n",
      "421837      3\n",
      "134130      3\n",
      "196816      3\n",
      "174426      3\n",
      "209057      3\n",
      "43221       3\n",
      "185556      3\n",
      "203776      3\n",
      "266070      3\n",
      "73715       3\n",
      "118376      3\n",
      "83671       3\n",
      "125856      3\n",
      "354104      3\n",
      "297884      3\n",
      "190997      3\n",
      "296158      3\n",
      "227310      3\n",
      "310774      3\n",
      "81145       3\n",
      "324637      3\n",
      "278155      3\n",
      "36480       3\n",
      "240137      3\n",
      "103596      3\n",
      "82161       3\n",
      "224531      3\n",
      "102729      3\n",
      "232719      3\n",
      "69867       3\n",
      "113323      3\n",
      "287031      3\n",
      "187901      3\n",
      "163229      3\n",
      "193855      3\n",
      "181758      3\n",
      "116138      3\n",
      "276087      3\n",
      "423024      3\n",
      "119359      3\n",
      "175083      3\n",
      "193042      3\n",
      "32897       3\n",
      "197731      3\n",
      "161662      3\n",
      "149650      3\n",
      "164707      3\n",
      "209213      3\n",
      "142182      3\n",
      "204322      3\n",
      "193568      3\n",
      "201328      3\n",
      "192776      3\n",
      "176634      3\n",
      "273771      3\n",
      "102942      3\n",
      "236396      3\n",
      "244172      3\n",
      "35945       3\n",
      "105312      3\n",
      "192381      3\n",
      "170846      3\n",
      "28035       3\n",
      "141388      3\n",
      "120914      3\n",
      "176831      3\n",
      "54260       3\n",
      "264052      3\n",
      "248445      3\n",
      "48121       3\n",
      "67728       3\n",
      "45857       3\n",
      "229465      3\n",
      "184710      3\n",
      "290504      3\n",
      "201743      3\n",
      "67433       3\n",
      "278391      3\n",
      "219632      3\n",
      "163985      3\n",
      "177147      3\n",
      "282461      3\n",
      "150570      3\n",
      "218678      3\n",
      "139907      3\n",
      "163921      3\n",
      "89413       3\n",
      "165937      3\n",
      "189762      3\n",
      "116508      3\n",
      "157612      3\n",
      "115040      3\n",
      "247880      3\n",
      "235442      3\n",
      "199753      3\n",
      "158688      3\n",
      "380614      3\n",
      "121287      3\n",
      "548361      3\n",
      "131608      3\n",
      "180096      3\n",
      "70261       3\n",
      "225165      3\n",
      "119565      3\n",
      "182108      3\n",
      "148581      3\n",
      "121471      3\n",
      "33308       3\n",
      "137314      3\n",
      "219266      3\n",
      "102569      3\n",
      "174503      3\n",
      "223019      3\n",
      "235786      3\n",
      "34310       3\n",
      "42900       3\n",
      "336643      3\n",
      "121912      3\n",
      "194995      3\n",
      "111994      3\n",
      "223811      3\n",
      "114937      3\n",
      "194698      3\n",
      "171015      3\n",
      "118710      3\n",
      "43206       3\n",
      "33794       3\n",
      "32372       3\n",
      "113936      3\n",
      "34104       3\n",
      "111415      3\n",
      "75167       3\n",
      "102318      3\n",
      "94413       3\n",
      "228649      3\n",
      "159322      3\n",
      "67716       3\n",
      "178623      3\n",
      "236804      3\n",
      "34845       3\n",
      "114060      3\n",
      "165532      3\n",
      "112362      3\n",
      "200734      3\n",
      "175804      3\n",
      "189924      3\n",
      "355728      3\n",
      "155233      3\n",
      "243165      3\n",
      "160300      3\n",
      "204470      3\n",
      "184306      3\n",
      "283499      3\n",
      "96245       3\n",
      "58683       3\n",
      "208872      3\n",
      "265706      3\n",
      "183778      3\n",
      "135162      3\n",
      "344060      3\n",
      "215479      3\n",
      "148509      3\n",
      "200700      3\n",
      "161691      3\n",
      "66356       3\n",
      "226696      3\n",
      "215047      3\n",
      "143368      3\n",
      "128796      3\n",
      "220460      3\n",
      "188569      3\n",
      "138975      3\n",
      "126501      3\n",
      "241431      3\n",
      "139290      3\n",
      "204527      3\n",
      "180859      3\n",
      "141118      3\n",
      "191188      3\n",
      "242391      3\n",
      "34248       3\n",
      "247043      3\n",
      "198613      3\n",
      "356934      3\n",
      "318822      3\n",
      "330132      3\n",
      "160155      3\n",
      "174283      3\n",
      "137421      3\n",
      "327886      3\n",
      "149726      3\n",
      "161155      3\n",
      "211654      3\n",
      "38251       3\n",
      "169589      3\n",
      "96219       3\n",
      "125155      3\n",
      "206541      3\n",
      "166371      3\n",
      "29887       3\n",
      "268525      3\n",
      "213307      3\n",
      "167651      3\n",
      "183000      3\n",
      "56026       3\n",
      "266529      3\n",
      "141483      3\n",
      "211049      3\n",
      "34173       3\n",
      "147707      3\n",
      "235109      3\n",
      "112754      3\n",
      "141858      3\n",
      "119272      3\n",
      "209320      3\n",
      "133061      3\n",
      "151626      3\n",
      "212888      3\n",
      "150755      3\n",
      "114797      3\n",
      "159888      3\n",
      "152951      3\n",
      "446358      3\n",
      "108699      3\n",
      "222490      3\n",
      "283969      3\n",
      "43953       3\n",
      "164938      3\n",
      "20534       3\n",
      "191856      3\n",
      "105803      3\n",
      "333305      3\n",
      "86745       3\n",
      "280169      3\n",
      "128143      3\n",
      "180477      3\n",
      "143822      3\n",
      "331482      3\n",
      "118500      3\n",
      "101722      3\n",
      "214838      3\n",
      "239409      3\n",
      "42703       3\n",
      "271795      3\n",
      "245628      3\n",
      "331651      3\n",
      "188278      3\n",
      "196456      3\n",
      "261278      3\n",
      "184016      3\n",
      "147340      3\n",
      "170214      3\n",
      "184543      3\n",
      "153489      3\n",
      "257942      3\n",
      "300681      3\n",
      "183710      3\n",
      "196643      3\n",
      "234640      3\n",
      "226883      3\n",
      "34007       3\n",
      "182556      3\n",
      "126060      3\n",
      "200316      3\n",
      "145714      3\n",
      "95654       3\n",
      "341643      3\n",
      "160634      3\n",
      "132749      3\n",
      "192982      3\n",
      "53042       3\n",
      "319280      3\n",
      "212448      3\n",
      "39606       3\n",
      "220754      3\n",
      "169631      3\n",
      "189956      3\n",
      "126822      3\n",
      "209955      3\n",
      "263925      3\n",
      "207940      3\n",
      "170871      3\n",
      "102076      3\n",
      "100029      3\n",
      "207120      3\n",
      "200967      3\n",
      "97688       3\n",
      "95763       3\n",
      "206947      3\n",
      "180138      3\n",
      "184456      3\n",
      "200515      3\n",
      "50341       3\n",
      "116613      3\n",
      "102583      3\n",
      "176063      3\n",
      "182227      3\n",
      "124793      3\n",
      "191834      3\n",
      "147253      3\n",
      "223342      3\n",
      "190385      3\n",
      "102615      3\n",
      "218445      3\n",
      "83893       3\n",
      "206351      3\n",
      "146767      3\n",
      "118212      3\n",
      "115945      3\n",
      "184678      3\n",
      "44064       3\n",
      "116677      3\n",
      "194905      3\n",
      "336007      3\n",
      "182211      3\n",
      "190023      3\n",
      "114032      3\n",
      "111985      3\n",
      "122026      3\n",
      "355856      3\n",
      "128876      3\n",
      "187370      3\n",
      "340880      3\n",
      "211154      3\n",
      "112158      3\n",
      "106705      3\n",
      "224886      3\n",
      "186183      3\n",
      "113635      3\n",
      "99309       3\n",
      "290640      3\n",
      "162494      3\n",
      "81534       3\n",
      "206681      3\n",
      "200511      3\n",
      "190391      3\n",
      "60981       3\n",
      "99156       3\n",
      "30008       3\n",
      "157932      3\n",
      "76625       3\n",
      "166210      3\n",
      "270059      3\n",
      "245487      3\n",
      "213385      3\n",
      "70645       3\n",
      "234108      3\n",
      "269300      3\n",
      "266860      3\n",
      "137076      3\n",
      "176262      3\n",
      "203027      3\n",
      "104996      3\n",
      "57600       3\n",
      "180211      3\n",
      "44216       3\n",
      "308945      3\n",
      "102945      3\n",
      "314007      3\n",
      "221167      3\n",
      "119421      3\n",
      "198759      3\n",
      "267989      3\n",
      "253354      3\n",
      "29261       3\n",
      "221324      3\n",
      "120268      3\n",
      "42924       3\n",
      "146268      3\n",
      "53245       3\n",
      "187802      3\n",
      "163948      3\n",
      "185027      3\n",
      "220019      3\n",
      "191712      3\n",
      "133584      3\n",
      "302406      3\n",
      "301568      3\n",
      "275421      3\n",
      "101338      3\n",
      "105021      3\n",
      "35330       3\n",
      "159549      3\n",
      "100800      3\n",
      "142717      3\n",
      "149347      3\n",
      "212847      3\n",
      "353881      3\n",
      "89040       3\n",
      "258037      3\n",
      "158291      3\n",
      "203828      3\n",
      "204374      3\n",
      "130760      3\n",
      "164309      3\n",
      "150042      3\n",
      "78765       3\n",
      "243569      3\n",
      "203463      3\n",
      "238415      3\n",
      "105813      3\n",
      "262819      3\n",
      "133060      3\n",
      "200681      3\n",
      "27776       3\n",
      "164775      3\n",
      "162282      3\n",
      "314153      3\n",
      "241962      3\n",
      "33068       3\n",
      "178353      3\n",
      "189674      3\n",
      "111625      3\n",
      "175696      3\n",
      "223934      3\n",
      "62165       3\n",
      "168211      3\n",
      "167336      3\n",
      "148294      3\n",
      "26892       3\n",
      "105582      3\n",
      "158420      3\n",
      "143699      3\n",
      "199378      3\n",
      "137142      3\n",
      "203039      3\n",
      "171150      3\n",
      "101320      3\n",
      "151141      3\n",
      "226735      3\n",
      "22494       3\n",
      "226891      3\n",
      "43348       3\n",
      "115323      3\n",
      "165474      3\n",
      "186303      3\n",
      "171807      3\n",
      "164574      3\n",
      "269318      3\n",
      "107762      3\n",
      "213321      3\n",
      "207172      3\n",
      "196328      3\n",
      "127728      3\n",
      "353010      3\n",
      "93930       3\n",
      "78530       3\n",
      "203408      3\n",
      "129177      3\n",
      "48014       3\n",
      "356882      3\n",
      "206253      3\n",
      "166386      3\n",
      "33310       3\n",
      "151382      3\n",
      "80914       3\n",
      "147215      3\n",
      "144322      3\n",
      "107125      3\n",
      "52386       3\n",
      "283122      3\n",
      "145166      3\n",
      "299635      3\n",
      "74883       3\n",
      "456618      3\n",
      "287480      3\n",
      "309620      3\n",
      "205939      3\n",
      "302422      3\n",
      "406641      3\n",
      "301199      3\n",
      "120939      3\n",
      "108907      3\n",
      "33155       3\n",
      "39581       3\n",
      "105592      3\n",
      "333677      3\n",
      "214816      3\n",
      "198813      3\n",
      "212064      3\n",
      "120461      3\n",
      "139364      3\n",
      "232618      3\n",
      "355978      3\n",
      "293196      3\n",
      "309513      3\n",
      "260782      3\n",
      "282604      3\n",
      "255191      3\n",
      "202373      3\n",
      "359001      3\n",
      "166634      3\n",
      "70055       3\n",
      "37997       3\n",
      "193995      3\n",
      "204516      3\n",
      "245378      3\n",
      "302847      3\n",
      "101562      3\n",
      "96129       3\n",
      "189623      3\n",
      "193689      3\n",
      "231413      3\n",
      "203924      3\n",
      "200574      3\n",
      "110171      3\n",
      "188767      3\n",
      "460408      3\n",
      "210029      3\n",
      "218343      3\n",
      "93206       3\n",
      "118001      3\n",
      "506329      3\n",
      "313986      3\n",
      "172991      3\n",
      "204984      3\n",
      "278557      3\n",
      "163047      3\n",
      "162302      3\n",
      "242912      3\n",
      "316211      3\n",
      "144995      3\n",
      "135840      3\n",
      "163595      3\n",
      "228372      3\n",
      "205839      3\n",
      "33863       3\n",
      "225775      3\n",
      "122109      3\n",
      "66686       3\n",
      "163671      3\n",
      "383493      3\n",
      "274451      3\n",
      "138626      3\n",
      "310152      3\n",
      "38950       3\n",
      "163434      3\n",
      "166416      3\n",
      "229826      3\n",
      "173704      3\n",
      "163862      3\n",
      "332355      3\n",
      "100375      3\n",
      "133696      3\n",
      "194723      3\n",
      "139671      3\n",
      "216734      3\n",
      "105010      3\n",
      "166809      3\n",
      "151580      3\n",
      "197038      3\n",
      "372525      3\n",
      "143392      3\n",
      "96798       3\n",
      "109832      3\n",
      "160192      3\n",
      "114357      3\n",
      "167737      3\n",
      "253190      3\n",
      "180667      3\n",
      "197886      3\n",
      "231263      3\n",
      "304602      3\n",
      "227332      3\n",
      "205940      3\n",
      "143030      3\n",
      "189461      3\n",
      "125279      3\n",
      "261241      3\n",
      "28334       3\n",
      "140516      3\n",
      "298871      3\n",
      "53481       3\n",
      "167031      3\n",
      "181265      3\n",
      "197114      3\n",
      "102597      3\n",
      "58582       3\n",
      "287908      3\n",
      "221366      3\n",
      "83444       3\n",
      "158002      3\n",
      "155594      3\n",
      "211678      3\n",
      "84278       3\n",
      "98360       3\n",
      "254211      3\n",
      "240172      3\n",
      "140863      3\n",
      "119471      3\n",
      "127185      3\n",
      "35448       3\n",
      "188644      3\n",
      "59313       3\n",
      "199947      3\n",
      "186009      3\n",
      "96480       3\n",
      "172962      3\n",
      "92215       3\n",
      "222020      3\n",
      "258102      3\n",
      "33105       3\n",
      "251120      3\n",
      "232308      3\n",
      "252327      3\n",
      "298225      3\n",
      "178341      3\n",
      "229272      3\n",
      "202937      3\n",
      "50053       3\n",
      "207677      3\n",
      "50103       3\n",
      "190786      3\n",
      "52267       3\n",
      "60668       3\n",
      "149809      3\n",
      "189590      3\n",
      "218558      3\n",
      "240841      3\n",
      "116103      3\n",
      "150528      3\n",
      "379798      3\n",
      "116878      3\n",
      "210313      3\n",
      "170148      3\n",
      "33124       3\n",
      "170174      3\n",
      "125120      3\n",
      "178255      3\n",
      "205950      3\n",
      "311376      3\n",
      "111939      3\n",
      "254285      3\n",
      "361280      3\n",
      "243178      3\n",
      "115422      3\n",
      "228057      3\n",
      "187563      3\n",
      "31935       3\n",
      "168894      3\n",
      "174242      3\n",
      "79036       3\n",
      "55363       3\n",
      "241350      3\n",
      "152940      3\n",
      "254291      3\n",
      "140752      3\n",
      "127921      3\n",
      "170924      3\n",
      "134152      3\n",
      "261059      3\n",
      "226311      3\n",
      "137547      3\n",
      "188571      3\n",
      "263338      3\n",
      "213412      3\n",
      "343789      3\n",
      "221336      3\n",
      "219902      3\n",
      "191161      3\n",
      "323798      3\n",
      "37546       3\n",
      "125010      3\n",
      "186452      3\n",
      "91711       3\n",
      "147548      3\n",
      "379412      3\n",
      "100999      3\n",
      "200576      3\n",
      "154227      3\n",
      "90363       3\n",
      "199011      3\n",
      "213008      3\n",
      "74784       3\n",
      "97136       3\n",
      "219155      3\n",
      "355918      3\n",
      "170092      3\n",
      "185480      3\n",
      "151053      3\n",
      "211601      3\n",
      "167265      3\n",
      "128538      3\n",
      "101950      3\n",
      "382368      3\n",
      "135803      3\n",
      "189878      3\n",
      "192793      3\n",
      "34862       3\n",
      "188972      3\n",
      "155057      3\n",
      "205337      3\n",
      "94113       3\n",
      "325538      3\n",
      "43479       3\n",
      "107458      3\n",
      "34218       3\n",
      "203003      3\n",
      "98211       3\n",
      "169699      3\n",
      "241185      3\n",
      "367749      3\n",
      "118853      3\n",
      "160968      3\n",
      "222810      3\n",
      "131826      3\n",
      "112840      3\n",
      "203076      3\n",
      "57512       3\n",
      "51961       3\n",
      "203182      3\n",
      "222434      3\n",
      "191858      3\n",
      "199995      3\n",
      "320744      3\n",
      "107812      3\n",
      "241153      3\n",
      "121012      3\n",
      "110713      3\n",
      "30759       3\n",
      "86872       3\n",
      "183173      3\n",
      "157043      3\n",
      "53366       3\n",
      "173611      3\n",
      "111900      3\n",
      "176486      3\n",
      "193755      3\n",
      "168794      3\n",
      "37618       3\n",
      "392812      3\n",
      "239663      3\n",
      "197344      3\n",
      "94081       3\n",
      "144259      3\n",
      "39054       3\n",
      "36989       3\n",
      "141511      3\n",
      "160785      3\n",
      "109089      3\n",
      "198148      3\n",
      "178312      3\n",
      "97005       3\n",
      "252079      3\n",
      "54608       3\n",
      "188563      3\n",
      "473133      3\n",
      "187513      3\n",
      "137898      3\n",
      "230704      3\n",
      "36069       3\n",
      "198068      3\n",
      "344624      3\n",
      "159724      3\n",
      "124953      3\n",
      "217200      3\n",
      "215955      3\n",
      "189219      3\n",
      "162034      3\n",
      "22641       3\n",
      "76487       3\n",
      "146477      3\n",
      "94342       3\n",
      "118230      3\n",
      "146325      3\n",
      "176673      3\n",
      "31621       3\n",
      "350387      3\n",
      "167005      3\n",
      "244605      3\n",
      "189404      3\n",
      "110748      3\n",
      "33658       3\n",
      "138692      3\n",
      "178319      3\n",
      "318331      3\n",
      "256240      3\n",
      "260938      3\n",
      "60267       3\n",
      "189382      3\n",
      "148903      3\n",
      "25429       3\n",
      "97261       3\n",
      "64875       3\n",
      "166744      3\n",
      "193898      3\n",
      "153516      3\n",
      "178037      3\n",
      "25837       3\n",
      "117683      3\n",
      "389713      3\n",
      "175360      3\n",
      "248406      3\n",
      "175943      3\n",
      "176729      3\n",
      "166740      3\n",
      "52028       3\n",
      "176162      3\n",
      "123598      3\n",
      "24504       3\n",
      "182302      3\n",
      "454915      3\n",
      "261382      3\n",
      "120126      3\n",
      "106437      3\n",
      "220066      3\n",
      "166606      3\n",
      "101265      3\n",
      "117583      3\n",
      "154537      3\n",
      "250135      3\n",
      "111891      3\n",
      "237865      3\n",
      "203353      3\n",
      "69132       3\n",
      "106698      3\n",
      "312232      3\n",
      "31577       3\n",
      "46401       3\n",
      "260761      3\n",
      "74660       3\n",
      "98418       3\n",
      "443508      3\n",
      "166153      3\n",
      "189123      3\n",
      "207937      3\n",
      "136419      3\n",
      "50276       3\n",
      "36270       3\n",
      "201122      3\n",
      "30731       3\n",
      "102938      3\n",
      "204752      3\n",
      "211013      3\n",
      "29591       3\n",
      "113543      3\n",
      "119704      3\n",
      "138179      3\n",
      "172496      3\n",
      "244408      3\n",
      "199495      3\n",
      "191982      3\n",
      "107584      3\n",
      "509364      3\n",
      "21698       3\n",
      "103408      3\n",
      "306225      3\n",
      "238913      3\n",
      "70754       3\n",
      "205844      3\n",
      "234807      3\n",
      "189843      3\n",
      "151322      3\n",
      "229773      3\n",
      "29054       3\n",
      "177119      3\n",
      "229148      3\n",
      "143123      3\n",
      "106910      3\n",
      "164866      3\n",
      "29874       3\n",
      "260560      3\n",
      "168138      3\n",
      "92968       3\n",
      "55395       3\n",
      "212954      3\n",
      "32855       3\n",
      "152373      3\n",
      "101684      3\n",
      "164922      3\n",
      "183612      3\n",
      "224658      3\n",
      "115488      3\n",
      "149700      3\n",
      "156015      3\n",
      "210464      3\n",
      "112181      3\n",
      "119904      3\n",
      "326048      3\n",
      "152652      3\n",
      "108658      3\n",
      "175878      3\n",
      "206599      3\n",
      "91964       3\n",
      "173682      3\n",
      "66634       3\n",
      "67065       3\n",
      "203849      3\n",
      "160625      3\n",
      "162238      3\n",
      "34918       3\n",
      "34987       3\n",
      "129460      3\n",
      "191444      3\n",
      "150553      3\n",
      "288825      3\n",
      "135643      3\n",
      "197558      3\n",
      "173005      3\n",
      "243409      3\n",
      "180284      3\n",
      "227856      3\n",
      "130021      3\n",
      "43711       3\n",
      "510072      3\n",
      "176969      3\n",
      "142443      3\n",
      "99894       3\n",
      "76767       3\n",
      "188612      3\n",
      "199198      3\n",
      "95336       3\n",
      "330715      3\n",
      "65372       3\n",
      "225507      3\n",
      "220187      3\n",
      "185336      3\n",
      "209900      3\n",
      "126945      3\n",
      "162003      3\n",
      "192002      3\n",
      "51985       3\n",
      "117222      3\n",
      "174938      3\n",
      "97277       3\n",
      "369678      3\n",
      "280167      3\n",
      "27444       3\n",
      "194690      3\n",
      "162108      3\n",
      "200190      3\n",
      "223548      3\n",
      "69847       3\n",
      "383384      3\n",
      "163911      3\n",
      "213055      3\n",
      "170091      3\n",
      "242521      3\n",
      "152958      3\n",
      "177596      3\n",
      "37672       3\n",
      "303588      3\n",
      "250630      3\n",
      "70282       3\n",
      "42596       3\n",
      "123397      3\n",
      "173613      3\n",
      "81973       3\n",
      "171242      3\n",
      "190072      3\n",
      "82552       3\n",
      "199934      3\n",
      "195744      3\n",
      "89991       3\n",
      "335453      3\n",
      "108116      3\n",
      "102085      3\n",
      "34506       3\n",
      "169672      3\n",
      "174907      3\n",
      "607848      3\n",
      "198965      3\n",
      "96249       3\n",
      "111275      3\n",
      "210165      3\n",
      "210562      3\n",
      "214541      3\n",
      "261725      3\n",
      "169426      3\n",
      "173806      3\n",
      "57916       3\n",
      "208122      3\n",
      "208577      3\n",
      "178841      3\n",
      "222978      3\n",
      "174752      3\n",
      "66278       3\n",
      "178686      3\n",
      "271767      3\n",
      "183279      3\n",
      "72310       3\n",
      "175759      3\n",
      "210844      3\n",
      "190759      3\n",
      "179869      3\n",
      "343476      3\n",
      "283676      3\n",
      "192017      3\n",
      "203894      3\n",
      "166181      3\n",
      "114605      3\n",
      "314525      3\n",
      "192283      3\n",
      "98941       3\n",
      "207201      3\n",
      "215443      3\n",
      "132716      3\n",
      "248059      3\n",
      "336513      3\n",
      "103986      3\n",
      "82488       3\n",
      "202871      3\n",
      "91949       3\n",
      "95469       3\n",
      "181659      3\n",
      "326232      3\n",
      "111252      3\n",
      "265807      3\n",
      "160362      3\n",
      "209547      3\n",
      "202091      3\n",
      "38876       3\n",
      "180609      3\n",
      "62374       3\n",
      "175931      3\n",
      "51744       3\n",
      "120539      3\n",
      "128354      3\n",
      "167835      3\n",
      "374524      3\n",
      "63910       3\n",
      "144928      3\n",
      "285335      3\n",
      "243368      3\n",
      "192203      3\n",
      "283602      3\n",
      "204461      3\n",
      "29145       3\n",
      "206512      3\n",
      "358886      3\n",
      "365739      3\n",
      "220115      3\n",
      "151888      3\n",
      "181363      3\n",
      "178780      3\n",
      "169982      3\n",
      "39630       3\n",
      "89534       3\n",
      "186845      3\n",
      "158948      3\n",
      "170769      3\n",
      "193820      3\n",
      "200117      3\n",
      "206008      3\n",
      "162442      3\n",
      "127306      3\n",
      "211424      3\n",
      "398988      3\n",
      "213296      3\n",
      "51461       3\n",
      "113481      3\n",
      "169628      3\n",
      "167787      3\n",
      "68898       3\n",
      "154342      3\n",
      "315065      3\n",
      "173754      3\n",
      "129513      3\n",
      "329530      3\n",
      "166497      3\n",
      "200318      3\n",
      "349365      3\n",
      "48779       3\n",
      "111746      3\n",
      "216851      3\n",
      "201179      3\n",
      "145886      3\n",
      "376455      3\n",
      "114994      3\n",
      "182752      3\n",
      "195000      3\n",
      "124076      3\n",
      "181372      3\n",
      "244803      3\n",
      "98989       3\n",
      "298215      3\n",
      "141058      3\n",
      "229051      3\n",
      "155509      3\n",
      "214385      3\n",
      "213668      3\n",
      "362883      3\n",
      "188535      3\n",
      "326886      3\n",
      "146091      3\n",
      "239539      3\n",
      "117444      3\n",
      "86808       3\n",
      "171328      3\n",
      "215419      3\n",
      "227886      3\n",
      "226497      3\n",
      "271521      3\n",
      "33983       3\n",
      "191765      3\n",
      "133515      3\n",
      "165484      3\n",
      "209483      3\n",
      "159449      3\n",
      "229737      3\n",
      "171095      3\n",
      "191389      3\n",
      "248612      3\n",
      "258298      3\n",
      "205424      3\n",
      "206889      3\n",
      "148015      3\n",
      "177121      3\n",
      "277700      3\n",
      "191149      3\n",
      "150084      3\n",
      "312477      3\n",
      "208406      3\n",
      "167106      3\n",
      "203067      3\n",
      "349368      3\n",
      "172046      3\n",
      "115677      3\n",
      "178778      3\n",
      "222596      3\n",
      "149337      3\n",
      "206139      3\n",
      "204501      3\n",
      "197919      3\n",
      "181755      3\n",
      "247750      3\n",
      "91666       3\n",
      "165881      3\n",
      "186849      3\n",
      "112650      3\n",
      "198170      3\n",
      "137591      3\n",
      "106014      3\n",
      "175622      3\n",
      "174704      3\n",
      "89172       3\n",
      "271828      3\n",
      "52781       3\n",
      "238685      3\n",
      "168283      3\n",
      "141326      3\n",
      "172047      3\n",
      "443546      3\n",
      "287037      3\n",
      "144844      3\n",
      "108574      3\n",
      "206066      3\n",
      "143385      3\n",
      "201410      3\n",
      "146497      3\n",
      "152629      3\n",
      "254293      3\n",
      "249720      3\n",
      "186172      3\n",
      "408229      3\n",
      "23438       3\n",
      "96635       3\n",
      "151790      3\n",
      "454508      3\n",
      "65390       3\n",
      "51264       3\n",
      "250647      3\n",
      "215392      3\n",
      "347292      3\n",
      "70447       3\n",
      "374116      3\n",
      "190762      3\n",
      "110978      3\n",
      "411950      3\n",
      "176123      3\n",
      "85088       3\n",
      "29235       3\n",
      "138358      3\n",
      "60722       3\n",
      "36228       3\n",
      "23780       3\n",
      "140664      3\n",
      "101017      3\n",
      "199227      3\n",
      "213902      3\n",
      "214413      3\n",
      "90915       3\n",
      "202498      3\n",
      "117312      3\n",
      "106742      3\n",
      "306646      3\n",
      "39236       3\n",
      "241306      3\n",
      "187983      3\n",
      "146919      3\n",
      "182541      3\n",
      "197932      3\n",
      "314310      3\n",
      "183801      3\n",
      "105862      3\n",
      "160662      3\n",
      "146042      3\n",
      "219262      3\n",
      "141944      3\n",
      "114537      3\n",
      "312055      3\n",
      "32276       3\n",
      "201112      3\n",
      "256362      3\n",
      "199067      3\n",
      "148431      3\n",
      "315640      3\n",
      "195258      3\n",
      "195891      3\n",
      "160731      3\n",
      "214896      3\n",
      "169544      3\n",
      "172304      3\n",
      "206878      3\n",
      "125421      3\n",
      "216999      3\n",
      "348739      3\n",
      "187969      3\n",
      "229732      3\n",
      "183627      3\n",
      "111387      3\n",
      "188808      3\n",
      "75742       3\n",
      "196529      3\n",
      "66118       3\n",
      "147098      2\n",
      "116789      2\n",
      "448337      2\n",
      "178815      2\n",
      "339863      2\n",
      "46155       2\n",
      "122215      2\n",
      "146719      2\n",
      "174717      2\n",
      "124993      2\n",
      "234537      2\n",
      "246820      2\n",
      "155961      2\n",
      "274720      2\n",
      "183009      2\n",
      "152328      2\n",
      "109705      2\n",
      "97306       2\n",
      "255847      2\n",
      "278107      2\n",
      "97453       2\n",
      "217826      2\n",
      "46746       2\n",
      "238342      2\n",
      "64922       2\n",
      "206520      2\n",
      "305466      2\n",
      "191841      2\n",
      "180553      2\n",
      "225330      2\n",
      "85708       2\n",
      "109277      2\n",
      "102147      2\n",
      "227943      2\n",
      "148300      2\n",
      "61270       2\n",
      "315291      2\n",
      "182028      2\n",
      "335704      2\n",
      "112683      2\n",
      "57424       2\n",
      "375655      2\n",
      "332727      2\n",
      "148644      2\n",
      "165949      2\n",
      "201138      2\n",
      "152752      2\n",
      "125784      2\n",
      "279968      2\n",
      "176186      2\n",
      "306513      2\n",
      "54152       2\n",
      "114059      2\n",
      "37783       2\n",
      "280362      2\n",
      "343742      2\n",
      "200618      2\n",
      "147372      2\n",
      "338816      2\n",
      "56121       2\n",
      "181762      2\n",
      "68985       2\n",
      "164857      2\n",
      "151474      2\n",
      "189728      2\n",
      "145389      2\n",
      "220531      2\n",
      "189680      2\n",
      "175485      2\n",
      "155433      2\n",
      "167149      2\n",
      "33109       2\n",
      "37092       2\n",
      "252714      2\n",
      "107164      2\n",
      "189664      2\n",
      "353696      2\n",
      "31533       2\n",
      "48347       2\n",
      "337766      2\n",
      "124919      2\n",
      "268281      2\n",
      "253801      2\n",
      "255364      2\n",
      "103710      2\n",
      "47791       2\n",
      "157486      2\n",
      "158993      2\n",
      "310085      2\n",
      "189092      2\n",
      "529216      2\n",
      "183557      2\n",
      "197288      2\n",
      "360743      2\n",
      "171355      2\n",
      "164197      2\n",
      "370502      2\n",
      "102346      2\n",
      "64506       2\n",
      "216907      2\n",
      "255822      2\n",
      "127601      2\n",
      "159567      2\n",
      "159670      2\n",
      "167309      2\n",
      "101697      2\n",
      "203435      2\n",
      "362589      2\n",
      "139057      2\n",
      "55849       2\n",
      "106377      2\n",
      "126950      2\n",
      "299813      2\n",
      "48495       2\n",
      "314645      2\n",
      "54159       2\n",
      "181652      2\n",
      "91733       2\n",
      "191025      2\n",
      "47396       2\n",
      "78707       2\n",
      "126838      2\n",
      "100219      2\n",
      "104094      2\n",
      "82797       2\n",
      "168496      2\n",
      "334039      2\n",
      "171199      2\n",
      "170721      2\n",
      "195453      2\n",
      "88926       2\n",
      "227832      2\n",
      "318647      2\n",
      "72630       2\n",
      "50356       2\n",
      "108495      2\n",
      "133833      2\n",
      "187161      2\n",
      "86643       2\n",
      "61474       2\n",
      "269723      2\n",
      "98061       2\n",
      "132125      2\n",
      "147099      2\n",
      "219619      2\n",
      "123273      2\n",
      "219897      2\n",
      "109869      2\n",
      "182668      2\n",
      "156848      2\n",
      "68781       2\n",
      "114079      2\n",
      "55176       2\n",
      "205246      2\n",
      "187715      2\n",
      "188900      2\n",
      "116554      2\n",
      "49156       2\n",
      "172582      2\n",
      "176452      2\n",
      "115613      2\n",
      "171215      2\n",
      "58222       2\n",
      "109165      2\n",
      "182163      2\n",
      "197836      2\n",
      "109351      2\n",
      "233312      2\n",
      "120130      2\n",
      "270721      2\n",
      "87928       2\n",
      "220563      2\n",
      "202046      2\n",
      "168337      2\n",
      "238188      2\n",
      "144586      2\n",
      "247444      2\n",
      "152182      2\n",
      "208180      2\n",
      "301862      2\n",
      "35865       2\n",
      "185670      2\n",
      "118161      2\n",
      "96586       2\n",
      "36327       2\n",
      "137088      2\n",
      "190964      2\n",
      "176140      2\n",
      "258768      2\n",
      "173542      2\n",
      "154405      2\n",
      "427474      2\n",
      "22428       2\n",
      "404573      2\n",
      "78602       2\n",
      "237868      2\n",
      "54472       2\n",
      "131852      2\n",
      "186791      2\n",
      "273929      2\n",
      "121130      2\n",
      "165468      2\n",
      "300528      2\n",
      "37646       2\n",
      "308334      2\n",
      "219838      2\n",
      "317847      2\n",
      "38772       2\n",
      "347653      2\n",
      "400535      2\n",
      "144067      2\n",
      "185848      2\n",
      "54318       2\n",
      "258498      2\n",
      "179413      2\n",
      "207473      2\n",
      "141040      2\n",
      "72619       2\n",
      "117605      2\n",
      "137951      2\n",
      "208311      2\n",
      "261497      2\n",
      "243636      2\n",
      "63434       2\n",
      "156580      2\n",
      "183013      2\n",
      "306440      2\n",
      "201454      2\n",
      "105817      2\n",
      "41432       2\n",
      "60639       2\n",
      "140474      2\n",
      "311764      2\n",
      "144371      2\n",
      "31137       2\n",
      "216283      2\n",
      "88638       2\n",
      "341797      2\n",
      "124094      2\n",
      "133917      2\n",
      "329993      2\n",
      "290688      2\n",
      "355320      2\n",
      "150683      2\n",
      "184665      2\n",
      "289653      2\n",
      "447346      2\n",
      "177265      2\n",
      "159247      2\n",
      "182629      2\n",
      "287737      2\n",
      "174921      2\n",
      "210452      2\n",
      "109421      2\n",
      "291547      2\n",
      "60358       2\n",
      "89625       2\n",
      "196125      2\n",
      "224799      2\n",
      "141657      2\n",
      "199172      2\n",
      "384508      2\n",
      "193132      2\n",
      "246392      2\n",
      "187577      2\n",
      "117109      2\n",
      "313873      2\n",
      "142519      2\n",
      "378546      2\n",
      "289669      2\n",
      "113035      2\n",
      "182812      2\n",
      "200928      2\n",
      "103111      2\n",
      "194908      2\n",
      "289909      2\n",
      "111268      2\n",
      "138107      2\n",
      "115076      2\n",
      "167501      2\n",
      "64631       2\n",
      "197752      2\n",
      "285865      2\n",
      "152744      2\n",
      "314165      2\n",
      "271160      2\n",
      "81413       2\n",
      "242606      2\n",
      "204209      2\n",
      "121319      2\n",
      "234474      2\n",
      "134120      2\n",
      "149427      2\n",
      "234880      2\n",
      "350759      2\n",
      "187098      2\n",
      "175431      2\n",
      "74194       2\n",
      "191807      2\n",
      "210308      2\n",
      "114053      2\n",
      "136218      2\n",
      "178818      2\n",
      "175069      2\n",
      "214288      2\n",
      "201344      2\n",
      "89182       2\n",
      "181280      2\n",
      "172664      2\n",
      "76313       2\n",
      "224559      2\n",
      "178811      2\n",
      "277695      2\n",
      "33397       2\n",
      "191103      2\n",
      "77143       2\n",
      "179557      2\n",
      "226789      2\n",
      "279173      2\n",
      "220124      2\n",
      "113806      2\n",
      "279914      2\n",
      "85355       2\n",
      "38240       2\n",
      "269323      2\n",
      "203715      2\n",
      "166461      2\n",
      "209934      2\n",
      "139889      2\n",
      "310255      2\n",
      "122442      2\n",
      "207449      2\n",
      "242670      2\n",
      "141663      2\n",
      "252947      2\n",
      "49893       2\n",
      "207853      2\n",
      "33404       2\n",
      "103529      2\n",
      "340458      2\n",
      "203263      2\n",
      "101795      2\n",
      "412316      2\n",
      "107452      2\n",
      "281540      2\n",
      "65738       2\n",
      "85109       2\n",
      "279802      2\n",
      "146391      2\n",
      "313749      2\n",
      "199265      2\n",
      "54953       2\n",
      "168654      2\n",
      "210164      2\n",
      "159297      2\n",
      "85041       2\n",
      "63042       2\n",
      "185394      2\n",
      "298227      2\n",
      "117681      2\n",
      "461337      2\n",
      "164332      2\n",
      "139960      2\n",
      "198050      2\n",
      "173350      2\n",
      "86648       2\n",
      "65716       2\n",
      "289731      2\n",
      "160402      2\n",
      "132636      2\n",
      "195881      2\n",
      "31251       2\n",
      "125457      2\n",
      "327164      2\n",
      "76845       2\n",
      "107160      2\n",
      "207513      2\n",
      "381583      2\n",
      "329733      2\n",
      "172694      2\n",
      "240698      2\n",
      "55929       2\n",
      "176296      2\n",
      "257295      2\n",
      "137578      2\n",
      "301654      2\n",
      "48063       2\n",
      "195411      2\n",
      "184831      2\n",
      "189498      2\n",
      "215943      2\n",
      "133625      2\n",
      "100931      2\n",
      "128700      2\n",
      "187795      2\n",
      "40641       2\n",
      "107276      2\n",
      "89735       2\n",
      "373403      2\n",
      "143003      2\n",
      "109609      2\n",
      "182437      2\n",
      "83253       2\n",
      "275395      2\n",
      "295922      2\n",
      "190625      2\n",
      "188576      2\n",
      "316470      2\n",
      "379883      2\n",
      "416745      2\n",
      "183041      2\n",
      "187999      2\n",
      "106648      2\n",
      "192259      2\n",
      "161097      2\n",
      "244495      2\n",
      "162381      2\n",
      "98524       2\n",
      "294919      2\n",
      "249043      2\n",
      "48123       2\n",
      "123088      2\n",
      "70884       2\n",
      "109053      2\n",
      "37070       2\n",
      "138022      2\n",
      "138285      2\n",
      "67234       2\n",
      "251396      2\n",
      "128230      2\n",
      "159938      2\n",
      "130067      2\n",
      "142573      2\n",
      "338105      2\n",
      "132572      2\n",
      "320510      2\n",
      "87282       2\n",
      "224943      2\n",
      "236497      2\n",
      "411797      2\n",
      "35917       2\n",
      "144084      2\n",
      "43959       2\n",
      "326400      2\n",
      "414994      2\n",
      "179010      2\n",
      "207415      2\n",
      "191921      2\n",
      "32477       2\n",
      "103344      2\n",
      "198587      2\n",
      "190174      2\n",
      "98725       2\n",
      "462294      2\n",
      "35236       2\n",
      "209460      2\n",
      "99452       2\n",
      "138597      2\n",
      "412379      2\n",
      "101283      2\n",
      "358124      2\n",
      "328610      2\n",
      "168030      2\n",
      "174626      2\n",
      "154430      2\n",
      "241367      2\n",
      "363219      2\n",
      "297396      2\n",
      "261203      2\n",
      "279636      2\n",
      "227491      2\n",
      "209034      2\n",
      "212619      2\n",
      "50122       2\n",
      "28367       2\n",
      "141584      2\n",
      "86150       2\n",
      "99064       2\n",
      "166851      2\n",
      "149637      2\n",
      "129597      2\n",
      "219086      2\n",
      "213821      2\n",
      "201664      2\n",
      "117158      2\n",
      "98948       2\n",
      "143482      2\n",
      "345360      2\n",
      "67218       2\n",
      "129762      2\n",
      "103642      2\n",
      "145284      2\n",
      "108083      2\n",
      "197093      2\n",
      "24153       2\n",
      "236415      2\n",
      "128604      2\n",
      "322143      2\n",
      "287008      2\n",
      "197365      2\n",
      "498785      2\n",
      "255582      2\n",
      "164748      2\n",
      "363405      2\n",
      "116662      2\n",
      "179285      2\n",
      "189620      2\n",
      "242586      2\n",
      "176410      2\n",
      "166813      2\n",
      "314177      2\n",
      "43945       2\n",
      "121111      2\n",
      "193366      2\n",
      "364548      2\n",
      "315287      2\n",
      "153160      2\n",
      "24896       2\n",
      "139647      2\n",
      "113823      2\n",
      "162298      2\n",
      "373050      2\n",
      "33355       2\n",
      "256504      2\n",
      "296066      2\n",
      "56483       2\n",
      "224421      2\n",
      "180532      2\n",
      "138847      2\n",
      "133278      2\n",
      "209770      2\n",
      "91262       2\n",
      "93793       2\n",
      "59460       2\n",
      "304710      2\n",
      "203126      2\n",
      "174788      2\n",
      "129591      2\n",
      "233059      2\n",
      "385540      2\n",
      "29254       2\n",
      "134195      2\n",
      "82783       2\n",
      "470663      2\n",
      "188041      2\n",
      "148429      2\n",
      "185554      2\n",
      "186188      2\n",
      "148522      2\n",
      "177114      2\n",
      "154835      2\n",
      "346341      2\n",
      "191256      2\n",
      "82847       2\n",
      "90692       2\n",
      "315984      2\n",
      "252903      2\n",
      "197666      2\n",
      "103456      2\n",
      "420895      2\n",
      "103406      2\n",
      "167882      2\n",
      "91145       2\n",
      "156718      2\n",
      "165064      2\n",
      "71864       2\n",
      "199444      2\n",
      "53727       2\n",
      "281356      2\n",
      "197816      2\n",
      "191776      2\n",
      "205894      2\n",
      "148138      2\n",
      "236731      2\n",
      "32365       2\n",
      "106179      2\n",
      "198258      2\n",
      "278632      2\n",
      "74680       2\n",
      "132053      2\n",
      "208503      2\n",
      "152909      2\n",
      "24185       2\n",
      "394860      2\n",
      "209146      2\n",
      "239865      2\n",
      "183355      2\n",
      "174864      2\n",
      "255386      2\n",
      "137126      2\n",
      "206671      2\n",
      "113597      2\n",
      "19395       2\n",
      "136985      2\n",
      "225544      2\n",
      "340940      2\n",
      "142287      2\n",
      "174924      2\n",
      "228583      2\n",
      "252897      2\n",
      "298834      2\n",
      "259496      2\n",
      "124751      2\n",
      "425804      2\n",
      "210673      2\n",
      "117747      2\n",
      "201531      2\n",
      "172256      2\n",
      "229180      2\n",
      "169841      2\n",
      "113688      2\n",
      "265954      2\n",
      "40295       2\n",
      "125831      2\n",
      "192053      2\n",
      "168827      2\n",
      "405309      2\n",
      "111243      2\n",
      "156566      2\n",
      "31606       2\n",
      "313243      2\n",
      "96844       2\n",
      "84848       2\n",
      "107373      2\n",
      "295791      2\n",
      "138153      2\n",
      "165138      2\n",
      "329603      2\n",
      "163708      2\n",
      "378747      2\n",
      "116539      2\n",
      "447488      2\n",
      "197642      2\n",
      "488720      2\n",
      "84979       2\n",
      "175183      2\n",
      "276229      2\n",
      "100099      2\n",
      "200450      2\n",
      "206487      2\n",
      "320277      2\n",
      "99434       2\n",
      "82388       2\n",
      "144593      2\n",
      "112507      2\n",
      "103179      2\n",
      "198727      2\n",
      "218322      2\n",
      "208068      2\n",
      "97030       2\n",
      "240027      2\n",
      "297335      2\n",
      "199903      2\n",
      "48189       2\n",
      "306982      2\n",
      "41721       2\n",
      "39478       2\n",
      "65324       2\n",
      "167777      2\n",
      "120617      2\n",
      "361817      2\n",
      "345122      2\n",
      "29732       2\n",
      "84737       2\n",
      "165667      2\n",
      "38294       2\n",
      "326857      2\n",
      "238638      2\n",
      "161087      2\n",
      "595000      2\n",
      "199739      2\n",
      "183168      2\n",
      "169853      2\n",
      "115585      2\n",
      "31670       2\n",
      "110150      2\n",
      "82572       2\n",
      "79923       2\n",
      "119986      2\n",
      "187089      2\n",
      "185283      2\n",
      "76417       2\n",
      "220098      2\n",
      "289116      2\n",
      "321577      2\n",
      "177087      2\n",
      "276515      2\n",
      "403489      2\n",
      "222504      2\n",
      "284703      2\n",
      "306108      2\n",
      "161819      2\n",
      "195253      2\n",
      "187346      2\n",
      "59469       2\n",
      "87310       2\n",
      "168038      2\n",
      "90758       2\n",
      "93449       2\n",
      "29962       2\n",
      "163083      2\n",
      "101352      2\n",
      "254949      2\n",
      "175625      2\n",
      "287701      2\n",
      "75024       2\n",
      "125591      2\n",
      "170649      2\n",
      "176796      2\n",
      "122175      2\n",
      "146398      2\n",
      "291529      2\n",
      "114801      2\n",
      "199419      2\n",
      "214955      2\n",
      "383745      2\n",
      "104981      2\n",
      "416577      2\n",
      "23871       2\n",
      "238912      2\n",
      "333530      2\n",
      "176972      2\n",
      "48458       2\n",
      "365465      2\n",
      "253062      2\n",
      "193380      2\n",
      "286789      2\n",
      "49092       2\n",
      "165827      2\n",
      "150861      2\n",
      "258932      2\n",
      "265083      2\n",
      "159662      2\n",
      "311350      2\n",
      "189238      2\n",
      "223215      2\n",
      "172032      2\n",
      "29444       2\n",
      "185267      2\n",
      "314149      2\n",
      "285457      2\n",
      "27415       2\n",
      "218667      2\n",
      "167868      2\n",
      "320294      2\n",
      "34803       2\n",
      "183092      2\n",
      "330664      2\n",
      "197418      2\n",
      "377757      2\n",
      "257337      2\n",
      "176118      2\n",
      "320421      2\n",
      "100067      2\n",
      "408717      2\n",
      "191429      2\n",
      "157240      2\n",
      "122353      2\n",
      "24127       2\n",
      "189511      2\n",
      "198163      2\n",
      "136721      2\n",
      "183811      2\n",
      "128516      2\n",
      "255503      2\n",
      "311671      2\n",
      "237065      2\n",
      "311974      2\n",
      "62932       2\n",
      "87561       2\n",
      "206343      2\n",
      "34307       2\n",
      "407068      2\n",
      "128509      2\n",
      "157778      2\n",
      "493034      2\n",
      "80638       2\n",
      "218948      2\n",
      "63021       2\n",
      "526968      2\n",
      "110015      2\n",
      "220609      2\n",
      "31350       2\n",
      "53147       2\n",
      "176751      2\n",
      "142897      2\n",
      "378322      2\n",
      "194004      2\n",
      "330144      2\n",
      "159191      2\n",
      "79324       2\n",
      "39530       2\n",
      "437727      2\n",
      "331527      2\n",
      "249315      2\n",
      "228860      2\n",
      "183802      2\n",
      "232024      2\n",
      "166662      2\n",
      "190040      2\n",
      "116338      2\n",
      "136824      2\n",
      "265356      2\n",
      "44671       2\n",
      "197080      2\n",
      "198282      2\n",
      "170287      2\n",
      "179951      2\n",
      "80430       2\n",
      "34458       2\n",
      "321709      2\n",
      "206459      2\n",
      "188081      2\n",
      "277022      2\n",
      "175526      2\n",
      "37250       2\n",
      "32552       2\n",
      "202344      2\n",
      "126414      2\n",
      "188694      2\n",
      "108023      2\n",
      "96854       2\n",
      "198186      2\n",
      "230899      2\n",
      "398918      2\n",
      "357962      2\n",
      "154568      2\n",
      "173630      2\n",
      "38353       2\n",
      "159303      2\n",
      "265698      2\n",
      "82497       2\n",
      "340543      2\n",
      "148955      2\n",
      "175697      2\n",
      "232914      2\n",
      "214238      2\n",
      "175017      2\n",
      "209535      2\n",
      "204057      2\n",
      "164441      2\n",
      "160216      2\n",
      "206046      2\n",
      "93415       2\n",
      "116163      2\n",
      "367306      2\n",
      "104097      2\n",
      "398931      2\n",
      "202214      2\n",
      "310525      2\n",
      "148738      2\n",
      "157894      2\n",
      "144063      2\n",
      "338620      2\n",
      "277314      2\n",
      "34292       2\n",
      "149131      2\n",
      "111700      2\n",
      "201435      2\n",
      "146161      2\n",
      "264936      2\n",
      "99065       2\n",
      "278228      2\n",
      "222374      2\n",
      "136913      2\n",
      "161226      2\n",
      "304302      2\n",
      "170730      2\n",
      "190330      2\n",
      "289991      2\n",
      "103980      2\n",
      "271550      2\n",
      "196308      2\n",
      "108765      2\n",
      "167381      2\n",
      "268183      2\n",
      "333505      2\n",
      "169240      2\n",
      "294395      2\n",
      "238474      2\n",
      "149224      2\n",
      "296282      2\n",
      "271710      2\n",
      "216666      2\n",
      "208470      2\n",
      "226989      2\n",
      "179565      2\n",
      "163189      2\n",
      "383603      2\n",
      "179731      2\n",
      "163205      2\n",
      "157639      2\n",
      "230979      2\n",
      "174732      2\n",
      "185744      2\n",
      "171584      2\n",
      "196123      2\n",
      "192236      2\n",
      "115498      2\n",
      "199336      2\n",
      "179715      2\n",
      "54782       2\n",
      "54560       2\n",
      "81540       2\n",
      "431745      2\n",
      "246449      2\n",
      "140590      2\n",
      "390781      2\n",
      "130684      2\n",
      "34419       2\n",
      "306790      2\n",
      "245053      2\n",
      "306495      2\n",
      "122177      2\n",
      "140219      2\n",
      "263498      2\n",
      "220776      2\n",
      "179533      2\n",
      "25864       2\n",
      "262778      2\n",
      "170617      2\n",
      "130438      2\n",
      "138845      2\n",
      "167832      2\n",
      "285295      2\n",
      "150125      2\n",
      "32694       2\n",
      "82540       2\n",
      "167864      2\n",
      "339324      2\n",
      "35429       2\n",
      "177154      2\n",
      "179203      2\n",
      "223763      2\n",
      "257780      2\n",
      "151504      2\n",
      "227931      2\n",
      "88019       2\n",
      "222216      2\n",
      "262038      2\n",
      "51089       2\n",
      "55921       2\n",
      "230020      2\n",
      "225124      2\n",
      "65382       2\n",
      "377017      2\n",
      "31387       2\n",
      "235371      2\n",
      "191129      2\n",
      "130454      2\n",
      "151408      2\n",
      "168515      2\n",
      "336880      2\n",
      "141181      2\n",
      "128460      2\n",
      "338033      2\n",
      "153475      2\n",
      "357954      2\n",
      "138634      2\n",
      "178587      2\n",
      "32146       2\n",
      "100313      2\n",
      "285263      2\n",
      "169323      2\n",
      "119838      2\n",
      "95566       2\n",
      "189765      2\n",
      "244771      2\n",
      "134181      2\n",
      "168470      2\n",
      "33300       2\n",
      "110402      2\n",
      "27187       2\n",
      "272913      2\n",
      "184846      2\n",
      "189749      2\n",
      "159028      2\n",
      "104521      2\n",
      "116830      2\n",
      "184400      2\n",
      "181553      2\n",
      "162347      2\n",
      "115244      2\n",
      "177487      2\n",
      "104443      2\n",
      "112607      2\n",
      "163174      2\n",
      "225291      2\n",
      "87054       2\n",
      "100933      2\n",
      "273425      2\n",
      "240988      2\n",
      "230420      2\n",
      "182677      2\n",
      "98012       2\n",
      "69640       2\n",
      "199426      2\n",
      "32778       2\n",
      "143372      2\n",
      "186385      2\n",
      "224947      2\n",
      "55139       2\n",
      "214881      2\n",
      "95639       2\n",
      "386773      2\n",
      "32406       2\n",
      "134808      2\n",
      "30219       2\n",
      "242482      2\n",
      "100009      2\n",
      "177271      2\n",
      "31659       2\n",
      "181761      2\n",
      "161463      2\n",
      "27433       2\n",
      "138938      2\n",
      "114366      2\n",
      "269095      2\n",
      "22211       2\n",
      "194247      2\n",
      "181020      2\n",
      "177647      2\n",
      "319122      2\n",
      "380560      2\n",
      "169611      2\n",
      "249392      2\n",
      "351810      2\n",
      "103995      2\n",
      "320376      2\n",
      "34377       2\n",
      "365430      2\n",
      "36440       2\n",
      "259351      2\n",
      "216672      2\n",
      "132633      2\n",
      "325159      2\n",
      "359259      2\n",
      "334679      2\n",
      "198265      2\n",
      "230292      2\n",
      "168854      2\n",
      "255621      2\n",
      "165599      2\n",
      "128487      2\n",
      "656036      2\n",
      "200408      2\n",
      "136651      2\n",
      "390657      2\n",
      "317219      2\n",
      "103110      2\n",
      "120243      2\n",
      "271328      2\n",
      "339772      2\n",
      "184723      2\n",
      "309055      2\n",
      "89922       2\n",
      "214387      2\n",
      "225978      2\n",
      "207537      2\n",
      "87891       2\n",
      "29115       2\n",
      "27305       2\n",
      "166565      2\n",
      "160474      2\n",
      "359131      2\n",
      "110028      2\n",
      "278254      2\n",
      "288229      2\n",
      "38619       2\n",
      "143068      2\n",
      "257126      2\n",
      "27385       2\n",
      "221317      2\n",
      "44780       2\n",
      "211699      2\n",
      "190747      2\n",
      "284403      2\n",
      "202203      2\n",
      "187119      2\n",
      "138714      2\n",
      "228075      2\n",
      "94954       2\n",
      "112383      2\n",
      "344572      2\n",
      "206125      2\n",
      "349230      2\n",
      "123382      2\n",
      "157028      2\n",
      "246739      2\n",
      "203943      2\n",
      "368739      2\n",
      "89202       2\n",
      "240063      2\n",
      "142444      2\n",
      "680390      2\n",
      "143331      2\n",
      "340428      2\n",
      "145651      2\n",
      "197113      2\n",
      "239439      2\n",
      "272669      2\n",
      "55717       2\n",
      "140092      2\n",
      "40135       2\n",
      "348430      2\n",
      "348592      2\n",
      "223751      2\n",
      "283806      2\n",
      "201080      2\n",
      "409922      2\n",
      "400416      2\n",
      "42734       2\n",
      "221480      2\n",
      "146574      2\n",
      "192900      2\n",
      "24982       2\n",
      "197552      2\n",
      "321943      2\n",
      "471452      2\n",
      "165001      2\n",
      "182691      2\n",
      "170263      2\n",
      "31141       2\n",
      "60001       2\n",
      "225780      2\n",
      "404998      2\n",
      "99476       2\n",
      "144594      2\n",
      "174655      2\n",
      "131584      2\n",
      "62020       2\n",
      "27207       2\n",
      "165108      2\n",
      "32916       2\n",
      "72953       2\n",
      "121874      2\n",
      "91384       2\n",
      "226875      2\n",
      "270942      2\n",
      "211075      2\n",
      "316000      2\n",
      "121441      2\n",
      "222005      2\n",
      "92775       2\n",
      "62546       2\n",
      "114844      2\n",
      "143932      2\n",
      "166459      2\n",
      "99385       2\n",
      "130206      2\n",
      "410114      2\n",
      "89154       2\n",
      "412156      2\n",
      "112835      2\n",
      "220342      2\n",
      "43535       2\n",
      "561334      2\n",
      "105017      2\n",
      "101432      2\n",
      "197860      2\n",
      "73471       2\n",
      "208862      2\n",
      "117299      2\n",
      "31782       2\n",
      "191524      2\n",
      "103649      2\n",
      "211129      2\n",
      "152046      2\n",
      "386136      2\n",
      "258490      2\n",
      "65706       2\n",
      "163678      2\n",
      "52849       2\n",
      "82098       2\n",
      "72119       2\n",
      "391349      2\n",
      "37302       2\n",
      "360884      2\n",
      "180418      2\n",
      "399088      2\n",
      "344492      2\n",
      "200904      2\n",
      "136819      2\n",
      "217296      2\n",
      "440969      2\n",
      "194773      2\n",
      "55743       2\n",
      "112797      2\n",
      "108993      2\n",
      "182370      2\n",
      "309122      2\n",
      "93476       2\n",
      "29933       2\n",
      "236599      2\n",
      "188888      2\n",
      "318046      2\n",
      "187891      2\n",
      "111058      2\n",
      "233624      2\n",
      "192644      2\n",
      "405644      2\n",
      "139616      2\n",
      "300104      2\n",
      "49298       2\n",
      "146499      2\n",
      "204042      2\n",
      "244974      2\n",
      "193626      2\n",
      "306967      2\n",
      "226535      2\n",
      "549174      2\n",
      "292023      2\n",
      "101509      2\n",
      "210095      2\n",
      "117059      2\n",
      "28996       2\n",
      "308498      2\n",
      "164170      2\n",
      "321865      2\n",
      "97419       2\n",
      "46868       2\n",
      "181388      2\n",
      "195750      2\n",
      "56482       2\n",
      "137527      2\n",
      "67317       2\n",
      "317809      2\n",
      "46987       2\n",
      "155767      2\n",
      "224377      2\n",
      "256263      2\n",
      "102632      2\n",
      "187487      2\n",
      "23778       2\n",
      "59732       2\n",
      "103643      2\n",
      "135416      2\n",
      "161532      2\n",
      "307468      2\n",
      "234460      2\n",
      "141583      2\n",
      "168294      2\n",
      "168216      2\n",
      "133403      2\n",
      "110946      2\n",
      "90668       2\n",
      "215389      2\n",
      "168475      2\n",
      "274111      2\n",
      "45363       2\n",
      "310380      2\n",
      "140915      2\n",
      "119177      2\n",
      "255559      2\n",
      "177277      2\n",
      "194940      2\n",
      "180603      2\n",
      "93318       2\n",
      "156807      2\n",
      "38151       2\n",
      "232586      2\n",
      "175390      2\n",
      "57711       2\n",
      "118847      2\n",
      "193701      2\n",
      "251305      2\n",
      "124071      2\n",
      "34568       2\n",
      "170038      2\n",
      "201105      2\n",
      "55390       2\n",
      "164243      2\n",
      "145214      2\n",
      "339773      2\n",
      "162236      2\n",
      "123959      2\n",
      "186808      2\n",
      "78261       2\n",
      "261943      2\n",
      "98092       2\n",
      "171080      2\n",
      "323627      2\n",
      "114733      2\n",
      "103540      2\n",
      "254367      2\n",
      "176335      2\n",
      "40024       2\n",
      "210013      2\n",
      "174486      2\n",
      "78181       2\n",
      "259846      2\n",
      "247552      2\n",
      "169905      2\n",
      "349986      2\n",
      "115971      2\n",
      "195844      2\n",
      "188505      2\n",
      "160045      2\n",
      "179468      2\n",
      "175374      2\n",
      "140559      2\n",
      "270043      2\n",
      "283921      2\n",
      "52498       2\n",
      "49325       2\n",
      "305446      2\n",
      "143653      2\n",
      "439919      2\n",
      "196899      2\n",
      "231714      2\n",
      "118497      2\n",
      "238831      2\n",
      "227644      2\n",
      "36601       2\n",
      "543922      2\n",
      "162140      2\n",
      "30824       2\n",
      "122048      2\n",
      "230856      2\n",
      "250201      2\n",
      "96330       2\n",
      "231160      2\n",
      "160920      2\n",
      "155983      2\n",
      "114765      2\n",
      "84298       2\n",
      "249585      2\n",
      "173804      2\n",
      "259301      2\n",
      "39232       2\n",
      "114495      2\n",
      "80324       2\n",
      "154949      2\n",
      "265434      2\n",
      "31588       2\n",
      "27494       2\n",
      "99179       2\n",
      "178866      2\n",
      "235847      2\n",
      "80282       2\n",
      "174662      2\n",
      "191628      2\n",
      "202220      2\n",
      "208881      2\n",
      "134026      2\n",
      "35378       2\n",
      "170544      2\n",
      "233369      2\n",
      "334744      2\n",
      "267161      2\n",
      "363418      2\n",
      "155752      2\n",
      "389725      2\n",
      "142158      2\n",
      "199298      2\n",
      "473748      2\n",
      "191118      2\n",
      "108496      2\n",
      "113436      2\n",
      "238367      2\n",
      "220262      2\n",
      "114639      2\n",
      "268145      2\n",
      "221791      2\n",
      "357173      2\n",
      "102345      2\n",
      "102606      2\n",
      "332401      2\n",
      "30682       2\n",
      "49087       2\n",
      "202682      2\n",
      "159737      2\n",
      "22418       2\n",
      "198692      2\n",
      "334368      2\n",
      "184335      2\n",
      "268147      2\n",
      "115880      2\n",
      "178660      2\n",
      "298841      2\n",
      "196971      2\n",
      "325658      2\n",
      "32825       2\n",
      "382802      2\n",
      "178644      2\n",
      "223277      2\n",
      "133586      2\n",
      "202570      2\n",
      "177181      2\n",
      "34632       2\n",
      "315423      2\n",
      "222247      2\n",
      "290661      2\n",
      "31732       2\n",
      "50163       2\n",
      "167523      2\n",
      "92036       2\n",
      "184857      2\n",
      "99127       2\n",
      "118657      2\n",
      "140782      2\n",
      "205759      2\n",
      "202878      2\n",
      "326156      2\n",
      "96102       2\n",
      "615367      2\n",
      "136137      2\n",
      "260106      2\n",
      "60374       2\n",
      "158206      2\n",
      "99307       2\n",
      "229223      2\n",
      "247075      2\n",
      "191782      2\n",
      "125905      2\n",
      "90159       2\n",
      "182314      2\n",
      "172071      2\n",
      "34443       2\n",
      "45093       2\n",
      "141877      2\n",
      "54929       2\n",
      "165922      2\n",
      "214891      2\n",
      "55720       2\n",
      "104089      2\n",
      "218785      2\n",
      "169482      2\n",
      "124420      2\n",
      "468713      2\n",
      "267945      2\n",
      "225515      2\n",
      "346122      2\n",
      "202115      2\n",
      "31478       2\n",
      "344480      2\n",
      "251521      2\n",
      "46807       2\n",
      "455995      2\n",
      "153790      2\n",
      "211028      2\n",
      "137296      2\n",
      "216145      2\n",
      "169383      2\n",
      "134746      2\n",
      "180299      2\n",
      "214627      2\n",
      "149040      2\n",
      "212793      2\n",
      "266439      2\n",
      "704108      2\n",
      "173679      2\n",
      "46144       2\n",
      "247328      2\n",
      "196508      2\n",
      "186376      2\n",
      "175769      2\n",
      "69306       2\n",
      "155408      2\n",
      "163604      2\n",
      "147397      2\n",
      "202521      2\n",
      "112062      2\n",
      "288551      2\n",
      "204584      2\n",
      "137510      2\n",
      "116531      2\n",
      "178100      2\n",
      "102323      2\n",
      "91959       2\n",
      "259510      2\n",
      "24384       2\n",
      "211482      2\n",
      "140426      2\n",
      "114508      2\n",
      "67339       2\n",
      "114591      2\n",
      "192262      2\n",
      "46028       2\n",
      "255476      2\n",
      "188096      2\n",
      "280570      2\n",
      "392668      2\n",
      "36851       2\n",
      "223214      2\n",
      "263899      2\n",
      "272090      2\n",
      "153870      2\n",
      "200426      2\n",
      "311020      2\n",
      "325596      2\n",
      "274964      2\n",
      "190728      2\n",
      "71417       2\n",
      "276221      2\n",
      "51290       2\n",
      "77373       2\n",
      "206399      2\n",
      "237735      2\n",
      "222884      2\n",
      "94429       2\n",
      "413345      2\n",
      "209109      2\n",
      "243842      2\n",
      "248010      2\n",
      "131425      2\n",
      "157886      2\n",
      "106252      2\n",
      "213179      2\n",
      "84154       2\n",
      "106679      2\n",
      "178322      2\n",
      "112820      2\n",
      "175509      2\n",
      "258276      2\n",
      "132728      2\n",
      "271935      2\n",
      "179580      2\n",
      "145636      2\n",
      "270436      2\n",
      "186648      2\n",
      "287927      2\n",
      "149770      2\n",
      "226629      2\n",
      "70985       2\n",
      "252168      2\n",
      "111949      2\n",
      "122612      2\n",
      "324791      2\n",
      "192258      2\n",
      "53373       2\n",
      "355686      2\n",
      "149168      2\n",
      "162028      2\n",
      "184553      2\n",
      "350440      2\n",
      "388725      2\n",
      "116892      2\n",
      "110142      2\n",
      "105614      2\n",
      "192022      2\n",
      "252024      2\n",
      "216657      2\n",
      "364657      2\n",
      "81487       2\n",
      "36425       2\n",
      "220783      2\n",
      "198216      2\n",
      "97863       2\n",
      "182378      2\n",
      "34996       2\n",
      "138514      2\n",
      "325374      2\n",
      "309348      2\n",
      "196707      2\n",
      "266337      2\n",
      "161978      2\n",
      "249362      2\n",
      "147629      2\n",
      "67083       2\n",
      "220656      2\n",
      "237729      2\n",
      "220640      2\n",
      "284129      2\n",
      "369538      2\n",
      "130532      2\n",
      "219288      2\n",
      "342164      2\n",
      "104614      2\n",
      "155775      2\n",
      "223400      2\n",
      "227468      2\n",
      "444554      2\n",
      "99835       2\n",
      "193241      2\n",
      "377018      2\n",
      "257621      2\n",
      "172695      2\n",
      "163787      2\n",
      "391114      2\n",
      "156266      2\n",
      "163396      2\n",
      "403788      2\n",
      "86065       2\n",
      "367329      2\n",
      "153326      2\n",
      "34402       2\n",
      "55360       2\n",
      "31717       2\n",
      "156815      2\n",
      "126094      2\n",
      "190772      2\n",
      "218249      2\n",
      "173854      2\n",
      "177285      2\n",
      "356089      2\n",
      "186110      2\n",
      "160893      2\n",
      "191177      2\n",
      "194580      2\n",
      "169926      2\n",
      "375134      2\n",
      "282579      2\n",
      "136629      2\n",
      "190836      2\n",
      "115057      2\n",
      "171216      2\n",
      "286689      2\n",
      "158926      2\n",
      "237720      2\n",
      "26598       2\n",
      "374764      2\n",
      "186078      2\n",
      "247794      2\n",
      "184307      2\n",
      "109766      2\n",
      "289982      2\n",
      "158451      2\n",
      "109273      2\n",
      "104746      2\n",
      "200453      2\n",
      "505980      2\n",
      "150601      2\n",
      "96452       2\n",
      "163057      2\n",
      "168187      2\n",
      "188615      2\n",
      "202952      2\n",
      "196857      2\n",
      "419691      2\n",
      "344275      2\n",
      "146679      2\n",
      "225065      2\n",
      "196827      2\n",
      "41183       2\n",
      "33001       2\n",
      "100584      2\n",
      "199698      2\n",
      "156687      2\n",
      "191502      2\n",
      "149698      2\n",
      "176317      2\n",
      "236592      2\n",
      "188693      2\n",
      "282753      2\n",
      "450695      2\n",
      "327435      2\n",
      "154728      2\n",
      "247564      2\n",
      "358682      2\n",
      "129172      2\n",
      "380544      2\n",
      "37359       2\n",
      "141580      2\n",
      "56392       2\n",
      "140359      2\n",
      "109638      2\n",
      "160829      2\n",
      "653574      2\n",
      "336951      2\n",
      "123253      2\n",
      "332243      2\n",
      "176079      2\n",
      "230248      2\n",
      "196373      2\n",
      "189775      2\n",
      "262617      2\n",
      "278039      2\n",
      "185673      2\n",
      "162256      2\n",
      "99651       2\n",
      "369825      2\n",
      "65171       2\n",
      "147921      2\n",
      "172493      2\n",
      "98101       2\n",
      "288566      2\n",
      "289405      2\n",
      "106297      2\n",
      "186014      2\n",
      "202033      2\n",
      "96020       2\n",
      "179981      2\n",
      "157446      2\n",
      "279041      2\n",
      "121362      2\n",
      "208591      2\n",
      "194260      2\n",
      "347530      2\n",
      "216941      2\n",
      "152621      2\n",
      "44767       2\n",
      "151267      2\n",
      "329059      2\n",
      "161508      2\n",
      "40681       2\n",
      "205309      2\n",
      "240124      2\n",
      "168443      2\n",
      "367984      2\n",
      "26248       2\n",
      "190916      2\n",
      "220993      2\n",
      "243660      2\n",
      "33887       2\n",
      "109814      2\n",
      "34832       2\n",
      "136224      2\n",
      "178564      2\n",
      "71592       2\n",
      "27886       2\n",
      "173998      2\n",
      "139193      2\n",
      "133050      2\n",
      "34019       2\n",
      "233851      2\n",
      "200783      2\n",
      "348099      2\n",
      "32709       2\n",
      "208249      2\n",
      "226525      2\n",
      "31964       2\n",
      "175710      2\n",
      "227734      2\n",
      "115963      2\n",
      "194404      2\n",
      "223046      2\n",
      "123393      2\n",
      "140583      2\n",
      "104280      2\n",
      "222548      2\n",
      "120672      2\n",
      "216931      2\n",
      "240628      2\n",
      "308995      2\n",
      "100776      2\n",
      "160167      2\n",
      "162160      2\n",
      "187656      2\n",
      "26502       2\n",
      "214716      2\n",
      "413373      2\n",
      "114483      2\n",
      "286967      2\n",
      "432376      2\n",
      "191230      2\n",
      "183066      2\n",
      "68268       2\n",
      "176917      2\n",
      "106541      2\n",
      "173968      2\n",
      "208785      2\n",
      "63526       2\n",
      "162404      2\n",
      "168553      2\n",
      "167728      2\n",
      "186144      2\n",
      "192409      2\n",
      "204829      2\n",
      "105216      2\n",
      "168569      2\n",
      "363130      2\n",
      "81232       2\n",
      "164427      2\n",
      "234057      2\n",
      "184099      2\n",
      "139127      2\n",
      "184833      2\n",
      "239708      2\n",
      "142166      2\n",
      "285200      2\n",
      "424468      2\n",
      "188675      2\n",
      "318280      2\n",
      "172855      2\n",
      "165953      2\n",
      "102953      2\n",
      "116800      2\n",
      "278403      2\n",
      "89419       2\n",
      "90614       2\n",
      "436798      2\n",
      "34722       2\n",
      "189183      2\n",
      "182273      2\n",
      "185177      2\n",
      "139903      2\n",
      "155151      2\n",
      "142494      2\n",
      "115411      2\n",
      "157217      2\n",
      "160445      2\n",
      "373469      2\n",
      "59380       2\n",
      "31460       2\n",
      "70377       2\n",
      "68330       2\n",
      "339905      2\n",
      "98995       2\n",
      "199346      2\n",
      "168625      2\n",
      "210926      2\n",
      "217769      2\n",
      "49923       2\n",
      "108540      2\n",
      "148171      2\n",
      "157624      2\n",
      "240358      2\n",
      "285432      2\n",
      "169662      2\n",
      "211596      2\n",
      "104660      2\n",
      "201901      2\n",
      "289430      2\n",
      "108464      2\n",
      "401690      2\n",
      "90752       2\n",
      "403468      2\n",
      "152140      2\n",
      "262153      2\n",
      "264874      2\n",
      "226013      2\n",
      "231348      2\n",
      "45781       2\n",
      "132986      2\n",
      "148315      2\n",
      "169092      2\n",
      "110417      2\n",
      "309580      2\n",
      "97521       2\n",
      "237903      2\n",
      "170154      2\n",
      "84306       2\n",
      "198824      2\n",
      "159911      2\n",
      "194726      2\n",
      "216010      2\n",
      "227146      2\n",
      "284834      2\n",
      "387430      2\n",
      "149324      2\n",
      "76142       2\n",
      "165017      2\n",
      "162164      2\n",
      "245482      2\n",
      "168107      2\n",
      "123207      2\n",
      "225605      2\n",
      "353263      2\n",
      "71898       2\n",
      "28887       2\n",
      "47310       2\n",
      "173047      2\n",
      "55568       2\n",
      "235722      2\n",
      "136873      2\n",
      "250051      2\n",
      "94391       2\n",
      "188711      2\n",
      "176319      2\n",
      "44006       2\n",
      "370990      2\n",
      "177125      2\n",
      "88368       2\n",
      "51506       2\n",
      "297906      2\n",
      "119721      2\n",
      "49249       2\n",
      "194710      2\n",
      "82049       2\n",
      "231866      2\n",
      "172479      2\n",
      "84610       2\n",
      "77665       2\n",
      "225399      2\n",
      "321990      2\n",
      "199114      2\n",
      "469454      2\n",
      "180656      2\n",
      "170456      2\n",
      "376483      2\n",
      "285750      2\n",
      "139743      2\n",
      "184801      2\n",
      "141420      2\n",
      "119281      2\n",
      "99203       2\n",
      "74631       2\n",
      "194848      2\n",
      "228238      2\n",
      "170376      2\n",
      "207782      2\n",
      "174478      2\n",
      "134997      2\n",
      "385077      2\n",
      "91039       2\n",
      "188823      2\n",
      "94041       2\n",
      "127111      2\n",
      "449432      2\n",
      "504725      2\n",
      "211860      2\n",
      "196745      2\n",
      "101266      2\n",
      "37289       2\n",
      "136081      2\n",
      "105787      2\n",
      "140108      2\n",
      "52596       2\n",
      "186346      2\n",
      "183479      2\n",
      "233923      2\n",
      "191335      2\n",
      "153312      2\n",
      "65535       2\n",
      "342642      2\n",
      "287647      2\n",
      "174419      2\n",
      "250541      2\n",
      "145917      2\n",
      "187052      2\n",
      "355571      2\n",
      "87284       2\n",
      "295591      2\n",
      "290660      2\n",
      "159603      2\n",
      "120068      2\n",
      "135845      2\n",
      "258761      2\n",
      "77313       2\n",
      "149218      2\n",
      "381645      2\n",
      "431245      2\n",
      "186410      2\n",
      "181382      2\n",
      "287315      2\n",
      "342752      2\n",
      "185053      2\n",
      "221915      2\n",
      "34848       2\n",
      "94937       2\n",
      "194590      2\n",
      "124956      2\n",
      "351381      2\n",
      "337050      2\n",
      "335005      2\n",
      "321851      2\n",
      "222615      2\n",
      "208043      2\n",
      "178134      2\n",
      "40915       2\n",
      "101094      2\n",
      "241174      2\n",
      "352139      2\n",
      "220517      2\n",
      "107123      2\n",
      "42346       2\n",
      "176753      2\n",
      "322931      2\n",
      "341368      2\n",
      "149368      2\n",
      "286452      2\n",
      "174754      2\n",
      "167793      2\n",
      "185732      2\n",
      "195176      2\n",
      "19847       2\n",
      "51048       2\n",
      "33678       2\n",
      "195985      2\n",
      "211345      2\n",
      "324960      2\n",
      "182655      2\n",
      "186815      2\n",
      "200593      2\n",
      "216824      2\n",
      "179481      2\n",
      "66173       2\n",
      "187502      2\n",
      "230039      2\n",
      "78859       2\n",
      "26987       2\n",
      "134447      2\n",
      "320818      2\n",
      "346766      2\n",
      "188331      2\n",
      "130369      2\n",
      "400004      2\n",
      "190482      2\n",
      "51838       2\n",
      "152189      2\n",
      "289147      2\n",
      "234213      2\n",
      "199143      2\n",
      "185195      2\n",
      "222162      2\n",
      "180446      2\n",
      "244665      2\n",
      "270517      2\n",
      "377798      2\n",
      "179008      2\n",
      "574271      2\n",
      "70604       2\n",
      "50295       2\n",
      "49595       2\n",
      "29696       2\n",
      "115439      2\n",
      "260254      2\n",
      "184556      2\n",
      "60567       2\n",
      "176279      2\n",
      "178417      2\n",
      "327825      2\n",
      "209912      2\n",
      "323055      2\n",
      "304386      2\n",
      "133974      2\n",
      "127833      2\n",
      "109419      2\n",
      "170861      2\n",
      "375680      2\n",
      "127215      2\n",
      "146949      2\n",
      "197495      2\n",
      "292570      2\n",
      "266467      2\n",
      "45937       2\n",
      "205706      2\n",
      "129246      2\n",
      "210765      2\n",
      "328606      2\n",
      "198197      2\n",
      "75673       2\n",
      "308136      2\n",
      "149704      2\n",
      "133336      2\n",
      "243580      2\n",
      "342768      2\n",
      "142411      2\n",
      "80145       2\n",
      "262241      2\n",
      "168212      2\n",
      "26716       2\n",
      "169124      2\n",
      "68358       2\n",
      "212041      2\n",
      "269060      2\n",
      "213842      2\n",
      "254202      2\n",
      "230478      2\n",
      "265295      2\n",
      "170066      2\n",
      "176897      2\n",
      "129305      2\n",
      "155930      2\n",
      "83046       2\n",
      "271466      2\n",
      "379959      2\n",
      "51471       2\n",
      "111377      2\n",
      "218164      2\n",
      "187397      2\n",
      "1033222     2\n",
      "314375      2\n",
      "170114      2\n",
      "113440      2\n",
      "183319      2\n",
      "273435      2\n",
      "187164      2\n",
      "149624      2\n",
      "147265      2\n",
      "206964      2\n",
      "37932       2\n",
      "137018      2\n",
      "99374       2\n",
      "137733      2\n",
      "153869      2\n",
      "93235       2\n",
      "424494      2\n",
      "196001      2\n",
      "346478      2\n",
      "128736      2\n",
      "51662       2\n",
      "122348      2\n",
      "122850      2\n",
      "89813       2\n",
      "280278      2\n",
      "140985      2\n",
      "246207      2\n",
      "23037       2\n",
      "23789       2\n",
      "117166      2\n",
      "356067      2\n",
      "77009       2\n",
      "341638      2\n",
      "163455      2\n",
      "74163       2\n",
      "292592      2\n",
      "198223      2\n",
      "85625       2\n",
      "91842       2\n",
      "423616      2\n",
      "226871      2\n",
      "108196      2\n",
      "112264      2\n",
      "184813      2\n",
      "73411       2\n",
      "98791       2\n",
      "54932       2\n",
      "86492       2\n",
      "112432      2\n",
      "91836       2\n",
      "319163      2\n",
      "28119       2\n",
      "153064      2\n",
      "343721      2\n",
      "121308      2\n",
      "102884      2\n",
      "326104      2\n",
      "89942       2\n",
      "39380       2\n",
      "342448      2\n",
      "110331      2\n",
      "28291       2\n",
      "117295      2\n",
      "199046      2\n",
      "141698      2\n",
      "110977      2\n",
      "57898       2\n",
      "188245      2\n",
      "38434       2\n",
      "36385       2\n",
      "99872       2\n",
      "133299      2\n",
      "102821      2\n",
      "39477       2\n",
      "37237       2\n",
      "243560      2\n",
      "204653      2\n",
      "230054      2\n",
      "61299       2\n",
      "101978      2\n",
      "356015      2\n",
      "131463      2\n",
      "175669      2\n",
      "191380      2\n",
      "124924      2\n",
      "259840      2\n",
      "28419       2\n",
      "122390      2\n",
      "260617      2\n",
      "304906      2\n",
      "300812      2\n",
      "210534      2\n",
      "200289      2\n",
      "193565      2\n",
      "178383      2\n",
      "162651      2\n",
      "20057       2\n",
      "283037      2\n",
      "130849      2\n",
      "199191      2\n",
      "194352      2\n",
      "85815       2\n",
      "216711      2\n",
      "222756      2\n",
      "215873      2\n",
      "186539      2\n",
      "216889      2\n",
      "177974      2\n",
      "117310      2\n",
      "123306      2\n",
      "255474      2\n",
      "93997       2\n",
      "223020      2\n",
      "83446       2\n",
      "298860      2\n",
      "150062      2\n",
      "27051       2\n",
      "174515      2\n",
      "155141      2\n",
      "116230      2\n",
      "225053      2\n",
      "25005       2\n",
      "223004      2\n",
      "138765      2\n",
      "189922      2\n",
      "150999      2\n",
      "178469      2\n",
      "231232      2\n",
      "166295      2\n",
      "94809       2\n",
      "197207      2\n",
      "36271       2\n",
      "179641      2\n",
      "182687      2\n",
      "857532      2\n",
      "143953      2\n",
      "95680       2\n",
      "163265      2\n",
      "189890      2\n",
      "182862      2\n",
      "191446      2\n",
      "386877      2\n",
      "258633      2\n",
      "164423      2\n",
      "237379      2\n",
      "134671      2\n",
      "152109      2\n",
      "198270      2\n",
      "43475       2\n",
      "215503      2\n",
      "196193      2\n",
      "202466      2\n",
      "69345       2\n",
      "131588      2\n",
      "132832      2\n",
      "310889      2\n",
      "159008      2\n",
      "204397      2\n",
      "212759      2\n",
      "70100       2\n",
      "52953       2\n",
      "220789      2\n",
      "104917      2\n",
      "110677      2\n",
      "264663      2\n",
      "356824      2\n",
      "211440      2\n",
      "305781      2\n",
      "208613      2\n",
      "112358      2\n",
      "83542       2\n",
      "239130      2\n",
      "175643      2\n",
      "296478      2\n",
      "220939      2\n",
      "172579      2\n",
      "221626      2\n",
      "209344      2\n",
      "227070      2\n",
      "218676      2\n",
      "166343      2\n",
      "40151       2\n",
      "83704       2\n",
      "335421      2\n",
      "280134      2\n",
      "256522      2\n",
      "292590      2\n",
      "328199      2\n",
      "274679      2\n",
      "209768      2\n",
      "168837      2\n",
      "99543       2\n",
      "88842       2\n",
      "95465       2\n",
      "211804      2\n",
      "374905      2\n",
      "52187       2\n",
      "120029      2\n",
      "113398      2\n",
      "224474      2\n",
      "172186      2\n",
      "193231      2\n",
      "46645       2\n",
      "187749      2\n",
      "25803       2\n",
      "226505      2\n",
      "99527       2\n",
      "309974      2\n",
      "109762      2\n",
      "254146      2\n",
      "384236      2\n",
      "77760       2\n",
      "22463       2\n",
      "90046       2\n",
      "328518      2\n",
      "176967      2\n",
      "141085      2\n",
      "142022      2\n",
      "157617      2\n",
      "442274      2\n",
      "219962      2\n",
      "124020      2\n",
      "102460      2\n",
      "177072      2\n",
      "210867      2\n",
      "279337      2\n",
      "191260      2\n",
      "241752      2\n",
      "150296      2\n",
      "275223      2\n",
      "184964      2\n",
      "183486      2\n",
      "147654      2\n",
      "190483      2\n",
      "307496      2\n",
      "153583      2\n",
      "141297      2\n",
      "78104       2\n",
      "227359      2\n",
      "127647      2\n",
      "289436      2\n",
      "27802       2\n",
      "167062      2\n",
      "412296      2\n",
      "255675      2\n",
      "395567      2\n",
      "190457      2\n",
      "256636      2\n",
      "316027      2\n",
      "129345      2\n",
      "55621       2\n",
      "138944      2\n",
      "430084      2\n",
      "50567       2\n",
      "228406      2\n",
      "135436      2\n",
      "84231       2\n",
      "31438       2\n",
      "253116      2\n",
      "344278      2\n",
      "43716       2\n",
      "135388      2\n",
      "327902      2\n",
      "94432       2\n",
      "151780      2\n",
      "182237      2\n",
      "103605      2\n",
      "189528      2\n",
      "195262      2\n",
      "178147      2\n",
      "20956       2\n",
      "69884       2\n",
      "207540      2\n",
      "330416      2\n",
      "449354      2\n",
      "74581       2\n",
      "89622       2\n",
      "66935       2\n",
      "216924      2\n",
      "60783       2\n",
      "214399      2\n",
      "183678      2\n",
      "266084      2\n",
      "179666      2\n",
      "185291      2\n",
      "115178      2\n",
      "36214       2\n",
      "173945      2\n",
      "137063      2\n",
      "31143       2\n",
      "268127      2\n",
      "96099       2\n",
      "213945      2\n",
      "183224      2\n",
      "83311       2\n",
      "52590       2\n",
      "193787      2\n",
      "190273      2\n",
      "259931      2\n",
      "240612      2\n",
      "100109      2\n",
      "193961      2\n",
      "476334      2\n",
      "24342       2\n",
      "300871      2\n",
      "38309       2\n",
      "222205      2\n",
      "216908      2\n",
      "115705      2\n",
      "175912      2\n",
      "35824       2\n",
      "204590      2\n",
      "44434       2\n",
      "169815      2\n",
      "61272       2\n",
      "48102       2\n",
      "47818       2\n",
      "199600      2\n",
      "205733      2\n",
      "211798      2\n",
      "186359      2\n",
      "340885      2\n",
      "214925      2\n",
      "224108      2\n",
      "129624      2\n",
      "154940      2\n",
      "112262      2\n",
      "341995      2\n",
      "163826      2\n",
      "358199      2\n",
      "46442       2\n",
      "278522      2\n",
      "228190      2\n",
      "155574      2\n",
      "46385       2\n",
      "194561      2\n",
      "175642      2\n",
      "120837      2\n",
      "187226      2\n",
      "170866      2\n",
      "174964      2\n",
      "116707      2\n",
      "214689      2\n",
      "99233       2\n",
      "133166      2\n",
      "29599       2\n",
      "55191       2\n",
      "265275      2\n",
      "146326      2\n",
      "338836      2\n",
      "176684      2\n",
      "204742      2\n",
      "212304      2\n",
      "151476      2\n",
      "215944      2\n",
      "146310      2\n",
      "201603      2\n",
      "222539      2\n",
      "427965      2\n",
      "62793       2\n",
      "198663      2\n",
      "262478      2\n",
      "194897      2\n",
      "187356      2\n",
      "289148      2\n",
      "58305       2\n",
      "229394      2\n",
      "105444      2\n",
      "184428      2\n",
      "114798      2\n",
      "475324      2\n",
      "283613      2\n",
      "373432      2\n",
      "35551       2\n",
      "176240      2\n",
      "127961      2\n",
      "144002      2\n",
      "53956       2\n",
      "177989      2\n",
      "312271      2\n",
      "252250      2\n",
      "209040      2\n",
      "187711      2\n",
      "163942      2\n",
      "240283      2\n",
      "591711      2\n",
      "223660      2\n",
      "78247       2\n",
      "113062      2\n",
      "67671       2\n",
      "166527      2\n",
      "29312       2\n",
      "149912      2\n",
      "283268      2\n",
      "173800      2\n",
      "82566       2\n",
      "745768      2\n",
      "137618      2\n",
      "274528      2\n",
      "72333       2\n",
      "158092      2\n",
      "121836      2\n",
      "248754      2\n",
      "306114      2\n",
      "348491      2\n",
      "123218      2\n",
      "152461      2\n",
      "151835      2\n",
      "360527      2\n",
      "149784      2\n",
      "236436      2\n",
      "196348      2\n",
      "28856       2\n",
      "254221      2\n",
      "71269       2\n",
      "186634      2\n",
      "383306      2\n",
      "359249      2\n",
      "193537      2\n",
      "215895      2\n",
      "263614      2\n",
      "136028      2\n",
      "138077      2\n",
      "168195      2\n",
      "376302      2\n",
      "170165      2\n",
      "107306      2\n",
      "346034      2\n",
      "36489       2\n",
      "141459      2\n",
      "227489      2\n",
      "213750      2\n",
      "112139      2\n",
      "244473      2\n",
      "109307      2\n",
      "101119      2\n",
      "154373      2\n",
      "176904      2\n",
      "71467       2\n",
      "99086       2\n",
      "121772      2\n",
      "377622      2\n",
      "172826      2\n",
      "213024      2\n",
      "154033      2\n",
      "162593      2\n",
      "266324      2\n",
      "174163      2\n",
      "221661      2\n",
      "207938      2\n",
      "137645      2\n",
      "245790      2\n",
      "63921       2\n",
      "172581      2\n",
      "225823      2\n",
      "35910       2\n",
      "137253      2\n",
      "197054      2\n",
      "248344      2\n",
      "444304      2\n",
      "296999      2\n",
      "215495      2\n",
      "290856      2\n",
      "41493       2\n",
      "214284      2\n",
      "122922      2\n",
      "283092      2\n",
      "369114      2\n",
      "29231       2\n",
      "60313       2\n",
      "141876      2\n",
      "307767      2\n",
      "282964      2\n",
      "420986      2\n",
      "64632       2\n",
      "195437      2\n",
      "190682      2\n",
      "283757      2\n",
      "96862       2\n",
      "158284      2\n",
      "240738      2\n",
      "176520      2\n",
      "183390      2\n",
      "71701       2\n",
      "137613      2\n",
      "351324      2\n",
      "221757      2\n",
      "391585      2\n",
      "188834      2\n",
      "35295       2\n",
      "37379       2\n",
      "419146      2\n",
      "211497      2\n",
      "125491      2\n",
      "154165      2\n",
      "343579      2\n",
      "236564      2\n",
      "158156      2\n",
      "231495      2\n",
      "159816      2\n",
      "119992      2\n",
      "188861      2\n",
      "172618      2\n",
      "86459       2\n",
      "168524      2\n",
      "49593       2\n",
      "381965      2\n",
      "137814      2\n",
      "152148      2\n",
      "190539      2\n",
      "196678      2\n",
      "341187      2\n",
      "236596      2\n",
      "168403      2\n",
      "113129      2\n",
      "310320      2\n",
      "111095      2\n",
      "299507      2\n",
      "54317       2\n",
      "133616      2\n",
      "270842      2\n",
      "235379      2\n",
      "258170      2\n",
      "30244       2\n",
      "233955      2\n",
      "174603      2\n",
      "191027      2\n",
      "209432      2\n",
      "158746      2\n",
      "170525      2\n",
      "195105      2\n",
      "210438      2\n",
      "67072       2\n",
      "79627       2\n",
      "165622      2\n",
      "36882       2\n",
      "207875      2\n",
      "201732      2\n",
      "150726      2\n",
      "205218      2\n",
      "120572      2\n",
      "394447      2\n",
      "249046      2\n",
      "197200      2\n",
      "28497       2\n",
      "136413      2\n",
      "357540      2\n",
      "195808      2\n",
      "379919      2\n",
      "211527      2\n",
      "208106      2\n",
      "201965      2\n",
      "197871      2\n",
      "237317      2\n",
      "132870      2\n",
      "214014      2\n",
      "169186      2\n",
      "309895      2\n",
      "141957      2\n",
      "236684      2\n",
      "134286      2\n",
      "185832      2\n",
      "72257       2\n",
      "156819      2\n",
      "199655      2\n",
      "170411      2\n",
      "216214      2\n",
      "110355      2\n",
      "267252      2\n",
      "253799      2\n",
      "389254      2\n",
      "57101       2\n",
      "232356      2\n",
      "59146       2\n",
      "358975      2\n",
      "113530      2\n",
      "253060      2\n",
      "302149      2\n",
      "23892       2\n",
      "171088      2\n",
      "123291      2\n",
      "248895      2\n",
      "169652      2\n",
      "177216      2\n",
      "242150      2\n",
      "187748      2\n",
      "219611      2\n",
      "122116      2\n",
      "230767      2\n",
      "197702      2\n",
      "363591      2\n",
      "427686      2\n",
      "138917      2\n",
      "273230      2\n",
      "195023      2\n",
      "110243      2\n",
      "232782      2\n",
      "108247      2\n",
      "313022      2\n",
      "55465       2\n",
      "174645      2\n",
      "376072      2\n",
      "173090      2\n",
      "32016       2\n",
      "185621      2\n",
      "78374       2\n",
      "160808      2\n",
      "182344      2\n",
      "126592      2\n",
      "154669      2\n",
      "140849      2\n",
      "228424      2\n",
      "281647      2\n",
      "388811      2\n",
      "38918       2\n",
      "65225       2\n",
      "231053      2\n",
      "378460      2\n",
      "207611      2\n",
      "348618      2\n",
      "357118      2\n",
      "201490      2\n",
      "102106      2\n",
      "391016      2\n",
      "58124       2\n",
      "108386      2\n",
      "81761       2\n",
      "66304       2\n",
      "76371       2\n",
      "308144      2\n",
      "349116      2\n",
      "275190      2\n",
      "204629      2\n",
      "216070      2\n",
      "139126      2\n",
      "218956      2\n",
      "35854       2\n",
      "257042      2\n",
      "56340       2\n",
      "142922      2\n",
      "213975      2\n",
      "299810      2\n",
      "250821      2\n",
      "193416      2\n",
      "153484      2\n",
      "389857      2\n",
      "586657      2\n",
      "209808      2\n",
      "28791       2\n",
      "209833      2\n",
      "107410      2\n",
      "112512      2\n",
      "183081      2\n",
      "275385      2\n",
      "122749      2\n",
      "37821       2\n",
      "170786      2\n",
      "195520      2\n",
      "95128       2\n",
      "89028       2\n",
      "107236      2\n",
      "242713      2\n",
      "152540      2\n",
      "275094      2\n",
      "138332      2\n",
      "132191      2\n",
      "95329       2\n",
      "275110      2\n",
      "227800      2\n",
      "261929      2\n",
      "160728      2\n",
      "236242      2\n",
      "261232      2\n",
      "193246      2\n",
      "91251       2\n",
      "110371      2\n",
      "166545      2\n",
      "234190      2\n",
      "40060       2\n",
      "143486      2\n",
      "160398      2\n",
      "191117      2\n",
      "39803       2\n",
      "99679       2\n",
      "169037      2\n",
      "140363      2\n",
      "213081      2\n",
      "189148      2\n",
      "99359       2\n",
      "231238      2\n",
      "224849      2\n",
      "98116       2\n",
      "52262       2\n",
      "293936      2\n",
      "330695      2\n",
      "150217      2\n",
      "180195      2\n",
      "339002      2\n",
      "131776      2\n",
      "167735      2\n",
      "180920      2\n",
      "209993      2\n",
      "207946      2\n",
      "285131      2\n",
      "37314       2\n",
      "315971      2\n",
      "204021      2\n",
      "268292      2\n",
      "608184      2\n",
      "33811       2\n",
      "120629      2\n",
      "192654      2\n",
      "304955      2\n",
      "170720      2\n",
      "248919      2\n",
      "177896      2\n",
      "182217      2\n",
      "110426      2\n",
      "245880      2\n",
      "326334      2\n",
      "103860      2\n",
      "170099      2\n",
      "201988      2\n",
      "376936      2\n",
      "94754       2\n",
      "30497       2\n",
      "166330      2\n",
      "108438      2\n",
      "235683      2\n",
      "167415      2\n",
      "102610      2\n",
      "204277      2\n",
      "144592      2\n",
      "212465      2\n",
      "244566      2\n",
      "136077      2\n",
      "210648      2\n",
      "143098      2\n",
      "34278       2\n",
      "247006      2\n",
      "157443      2\n",
      "186117      2\n",
      "169188      2\n",
      "157941      2\n",
      "212760      2\n",
      "177945      2\n",
      "212856      2\n",
      "232871      2\n",
      "198259      2\n",
      "46400       2\n",
      "190403      2\n",
      "55237       2\n",
      "261023      2\n",
      "182313      2\n",
      "178215      2\n",
      "161745      2\n",
      "397346      2\n",
      "174043      2\n",
      "250679      2\n",
      "52738       2\n",
      "171482      2\n",
      "131088      2\n",
      "75755       2\n",
      "386378      2\n",
      "337778      2\n",
      "36924       2\n",
      "122166      2\n",
      "305147      2\n",
      "252646      2\n",
      "135102      2\n",
      "178449      2\n",
      "208826      2\n",
      "192386      2\n",
      "371987      2\n",
      "103700      2\n",
      "116825      2\n",
      "227626      2\n",
      "133201      2\n",
      "229456      2\n",
      "104333      2\n",
      "190541      2\n",
      "232855      2\n",
      "73796       2\n",
      "267556      2\n",
      "51111       2\n",
      "138497      2\n",
      "190387      2\n",
      "124569      2\n",
      "187693      2\n",
      "247294      2\n",
      "334999      2\n",
      "62865       2\n",
      "169469      2\n",
      "161950      2\n",
      "50814       2\n",
      "37931       2\n",
      "70034       2\n",
      "491000      2\n",
      "108933      2\n",
      "220269      2\n",
      "40444       2\n",
      "294400      2\n",
      "129298      2\n",
      "168322      2\n",
      "186314      2\n",
      "304651      2\n",
      "46704       2\n",
      "165848      2\n",
      "211319      2\n",
      "380127      2\n",
      "229744      2\n",
      "162825      2\n",
      "151910      2\n",
      "120691      2\n",
      "136836      2\n",
      "220237      2\n",
      "246862      2\n",
      "535978      2\n",
      "194200      2\n",
      "84409       2\n",
      "259505      2\n",
      "290226      2\n",
      "40021       2\n",
      "29859       2\n",
      "189530      2\n",
      "191935      2\n",
      "213416      2\n",
      "46537       2\n",
      "36302       2\n",
      "165510      2\n",
      "327120      2\n",
      "191954      2\n",
      "192878      2\n",
      "256916      2\n",
      "263871      2\n",
      "67841       2\n",
      "117017      2\n",
      "60949       2\n",
      "230951      2\n",
      "174887      2\n",
      "138892      2\n",
      "253101      2\n",
      "275632      2\n",
      "151105      2\n",
      "174325      2\n",
      "231777      2\n",
      "54595       2\n",
      "390817      2\n",
      "288419      2\n",
      "129263      2\n",
      "219371      2\n",
      "138504      2\n",
      "181943      2\n",
      "433669      2\n",
      "227615      2\n",
      "174373      2\n",
      "292465      2\n",
      "104045      2\n",
      "230959      2\n",
      "98656       2\n",
      "196029      2\n",
      "219483      2\n",
      "26543       2\n",
      "124483      2\n",
      "194895      2\n",
      "168521      2\n",
      "197184      2\n",
      "134727      2\n",
      "149833      2\n",
      "34374       2\n",
      "219122      2\n",
      "208451      2\n",
      "205970      2\n",
      "183083      2\n",
      "37170       2\n",
      "160574      2\n",
      "162623      2\n",
      "209801      2\n",
      "187053      2\n",
      "154891      2\n",
      "129232      2\n",
      "173316      2\n",
      "137428      2\n",
      "211160      2\n",
      "261375      2\n",
      "149734      2\n",
      "198992      2\n",
      "177398      2\n",
      "104748      2\n",
      "160440      2\n",
      "174330      2\n",
      "237819      2\n",
      "154087      2\n",
      "188432      2\n",
      "201954      2\n",
      "554206      2\n",
      "159929      2\n",
      "202956      2\n",
      "119751      2\n",
      "116934      2\n",
      "129240      2\n",
      "215190      2\n",
      "171315      2\n",
      "379118      2\n",
      "73883       2\n",
      "362654      2\n",
      "204172      2\n",
      "321770      2\n",
      "168109      2\n",
      "34080       2\n",
      "274657      2\n",
      "250037      2\n",
      "314649      2\n",
      "151773      2\n",
      "155118      2\n",
      "277783      2\n",
      "30912       2\n",
      "26842       2\n",
      "196791      2\n",
      "111129      2\n",
      "52537       2\n",
      "406662      2\n",
      "299050      2\n",
      "154779      2\n",
      "178478      2\n",
      "285060      2\n",
      "92298       2\n",
      "280966      2\n",
      "195385      2\n",
      "118909      2\n",
      "116143      2\n",
      "132304      2\n",
      "331126      2\n",
      "30840       2\n",
      "47857       2\n",
      "198774      2\n",
      "232577      2\n",
      "135285      2\n",
      "97778       2\n",
      "189564      2\n",
      "27939       2\n",
      "27821       2\n",
      "159897      2\n",
      "313702      2\n",
      "141490      2\n",
      "240323      2\n",
      "428350      2\n",
      "33087       2\n",
      "237731      2\n",
      "268620      2\n",
      "133454      2\n",
      "196943      2\n",
      "61777       2\n",
      "117528      2\n",
      "243872      2\n",
      "168660      2\n",
      "305498      2\n",
      "35166       2\n",
      "32533       2\n",
      "156003      2\n",
      "86373       2\n",
      "175413      2\n",
      "41099       2\n",
      "113544      2\n",
      "155963      2\n",
      "112584      2\n",
      "80165       2\n",
      "101825      2\n",
      "104423      2\n",
      "238162      2\n",
      "501172      2\n",
      "108506      2\n",
      "119101      2\n",
      "159715      2\n",
      "415913      2\n",
      "155621      2\n",
      "205410      2\n",
      "365986      2\n",
      "62278       2\n",
      "174386      2\n",
      "451996      2\n",
      "55284       2\n",
      "216473      2\n",
      "196545      2\n",
      "285004      2\n",
      "217421      2\n",
      "115443      2\n",
      "209472      2\n",
      "344415      2\n",
      "35305       2\n",
      "285020      2\n",
      "59474       2\n",
      "120724      2\n",
      "176027      2\n",
      "202652      2\n",
      "26669       2\n",
      "128478      2\n",
      "90021       2\n",
      "191965      2\n",
      "189916      2\n",
      "56795       2\n",
      "275691      2\n",
      "179671      2\n",
      "234962      2\n",
      "263568      2\n",
      "33616       2\n",
      "355645      2\n",
      "269786      2\n",
      "294991      2\n",
      "27997       2\n",
      "29320       2\n",
      "36177       2\n",
      "359759      2\n",
      "249957      2\n",
      "205499      2\n",
      "200949      2\n",
      "127089      2\n",
      "282951      2\n",
      "215384      2\n",
      "108557      2\n",
      "407672      2\n",
      "431426      2\n",
      "118889      2\n",
      "321666      2\n",
      "211184      2\n",
      "58972       2\n",
      "339372      2\n",
      "111232      2\n",
      "123147      2\n",
      "215310      2\n",
      "434467      2\n",
      "92178       2\n",
      "238980      2\n",
      "73091       2\n",
      "313146      2\n",
      "200733      2\n",
      "198686      2\n",
      "190591      2\n",
      "219420      2\n",
      "188738      2\n",
      "87418       2\n",
      "190514      2\n",
      "289403      2\n",
      "303155      2\n",
      "202812      2\n",
      "233533      2\n",
      "172307      2\n",
      "21626       2\n",
      "135924      2\n",
      "203078      2\n",
      "308118      2\n",
      "290763      2\n",
      "197462      2\n",
      "85341       2\n",
      "187124      2\n",
      "84726       2\n",
      "293791      2\n",
      "99212       2\n",
      "140027      2\n",
      "105363      2\n",
      "230246      2\n",
      "158555      2\n",
      "30289       2\n",
      "420749      2\n",
      "33551       2\n",
      "162576      2\n",
      "212800      2\n",
      "160062      2\n",
      "181015      2\n",
      "140011      2\n",
      "174826      2\n",
      "345831      2\n",
      "185061      2\n",
      "289741      2\n",
      "95989       2\n",
      "29361       2\n",
      "153588      2\n",
      "87510       2\n",
      "164678      2\n",
      "129865      2\n",
      "54202       2\n",
      "175029      2\n",
      "316101      2\n",
      "174794      2\n",
      "272338      2\n",
      "213719      2\n",
      "303954      2\n",
      "240467      2\n",
      "123160      2\n",
      "146343      2\n",
      "80896       2\n",
      "199949      2\n",
      "103538      2\n",
      "461678      2\n",
      "344920      2\n",
      "260960      2\n",
      "256866      2\n",
      "130557      2\n",
      "266135      2\n",
      "179048      2\n",
      "230224      2\n",
      "203628      2\n",
      "51579       2\n",
      "410240      2\n",
      "315303      2\n",
      "184207      2\n",
      "265086      2\n",
      "162688      2\n",
      "35649       2\n",
      "221947      2\n",
      "148207      2\n",
      "152453      2\n",
      "150361      2\n",
      "346014      2\n",
      "191355      2\n",
      "265038      2\n",
      "84774       2\n",
      "150393      2\n",
      "144169      2\n",
      "273194      2\n",
      "224858      2\n",
      "86837       2\n",
      "84790       2\n",
      "113464      2\n",
      "194472      2\n",
      "217962      2\n",
      "125762      2\n",
      "314182      2\n",
      "297847      2\n",
      "131699      2\n",
      "176998      2\n",
      "109413      2\n",
      "267085      2\n",
      "172865      2\n",
      "117567      2\n",
      "199326      2\n",
      "191529      2\n",
      "315877      2\n",
      "279015      2\n",
      "304212      2\n",
      "171091      2\n",
      "169042      2\n",
      "118861      2\n",
      "96524       2\n",
      "136787      2\n",
      "165754      2\n",
      "201682      2\n",
      "143865      2\n",
      "26698       2\n",
      "225504      2\n",
      "51262       2\n",
      "125442      2\n",
      "192569      2\n",
      "109621      2\n",
      "75826       2\n",
      "57827       2\n",
      "137300      2\n",
      "135645      2\n",
      "297735      2\n",
      "218311      2\n",
      "182246      2\n",
      "88500       2\n",
      "151989      2\n",
      "278576      2\n",
      "113080      2\n",
      "30509       2\n",
      "172475      2\n",
      "170428      2\n",
      "37380       2\n",
      "330174      2\n",
      "426431      2\n",
      "54012       2\n",
      "178272      2\n",
      "197728      2\n",
      "180695      2\n",
      "143833      2\n",
      "127768      2\n",
      "113176      2\n",
      "319854      2\n",
      "254547      2\n",
      "397317      2\n",
      "189027      2\n",
      "240629      2\n",
      "203763      2\n",
      "37332       2\n",
      "64112       2\n",
      "239397      2\n",
      "133758      2\n",
      "280618      2\n",
      "162432      2\n",
      "29662       2\n",
      "53893       2\n",
      "180871      2\n",
      "158685      2\n",
      "182254      2\n",
      "117721      2\n",
      "224059      2\n",
      "154297      2\n",
      "180239      2\n",
      "205339      2\n",
      "35406       2\n",
      "254746      2\n",
      "205860      2\n",
      "31264       2\n",
      "170020      2\n",
      "263200      2\n",
      "242460      2\n",
      "572751      2\n",
      "186932      2\n",
      "166929      2\n",
      "242464      2\n",
      "27661       2\n",
      "195136      2\n",
      "56331       2\n",
      "248841      2\n",
      "180807      2\n",
      "391192      2\n",
      "175109      2\n",
      "96459       2\n",
      "80771       2\n",
      "100960      2\n",
      "148645      2\n",
      "183884      2\n",
      "95435       2\n",
      "155066      2\n",
      "475322      2\n",
      "79303       2\n",
      "404616      2\n",
      "155372      2\n",
      "37072       2\n",
      "105598      2\n",
      "190709      2\n",
      "431861      2\n",
      "126954      2\n",
      "341051      2\n",
      "105938      2\n",
      "167670      2\n",
      "157887      2\n",
      "251421      2\n",
      "207066      2\n",
      "169071      2\n",
      "61178       2\n",
      "83517       2\n",
      "146538      2\n",
      "47707       2\n",
      "151294      2\n",
      "30267       2\n",
      "132529      2\n",
      "340091      2\n",
      "177543      2\n",
      "157403      2\n",
      "117477      2\n",
      "182187      2\n",
      "107737      2\n",
      "129525      2\n",
      "134854      2\n",
      "177331      2\n",
      "27856       2\n",
      "216472      2\n",
      "67187       2\n",
      "343242      2\n",
      "147280      2\n",
      "345277      2\n",
      "87239       2\n",
      "83141       2\n",
      "289984      2\n",
      "176356      2\n",
      "181721      2\n",
      "95647       2\n",
      "142756      2\n",
      "246965      2\n",
      "131298      2\n",
      "257200      2\n",
      "102102      2\n",
      "36012       2\n",
      "151810      2\n",
      "295289      2\n",
      "38455       2\n",
      "433330      2\n",
      "132661      2\n",
      "234743      2\n",
      "99373       2\n",
      "67804       2\n",
      "205865      2\n",
      "130840      2\n",
      "31778       2\n",
      "63503       2\n",
      "178309      2\n",
      "306908      2\n",
      "209131      2\n",
      "347934      2\n",
      "330466      2\n",
      "135296      2\n",
      "219137      2\n",
      "195602      2\n",
      "79649       2\n",
      "290290      2\n",
      "184498      2\n",
      "405284      2\n",
      "295949      2\n",
      "187652      2\n",
      "317702      2\n",
      "56322       2\n",
      "123703      2\n",
      "70655       2\n",
      "65038       2\n",
      "207064      2\n",
      "120985      2\n",
      "267763      2\n",
      "119665      2\n",
      "194791      2\n",
      "275943      2\n",
      "127139      2\n",
      "222289      2\n",
      "194031      2\n",
      "166988      2\n",
      "340148      2\n",
      "50397       2\n",
      "219318      2\n",
      "53903       2\n",
      "181317      2\n",
      "198146      2\n",
      "282398      2\n",
      "464103      2\n",
      "85548       2\n",
      "259307      2\n",
      "60288       2\n",
      "30457       2\n",
      "278736      2\n",
      "146674      2\n",
      "185399      2\n",
      "100605      2\n",
      "158712      2\n",
      "96509       2\n",
      "106935      2\n",
      "154874      2\n",
      "163278      2\n",
      "372020      2\n",
      "211391      2\n",
      "204751      2\n",
      "154966      2\n",
      "259705      2\n",
      "227282      2\n",
      "267431      2\n",
      "208630      2\n",
      "184277      2\n",
      "391121      2\n",
      "182609      2\n",
      "38223       2\n",
      "96226       2\n",
      "172364      2\n",
      "673764      2\n",
      "34113       2\n",
      "103260      2\n",
      "174056      2\n",
      "204098      2\n",
      "202051      2\n",
      "183620      2\n",
      "296253      2\n",
      "286026      2\n",
      "212114      2\n",
      "161075      2\n",
      "233421      2\n",
      "344394      2\n",
      "200960      2\n",
      "409200      2\n",
      "130302      2\n",
      "318886      2\n",
      "108887      2\n",
      "181776      2\n",
      "178517      2\n",
      "38312       2\n",
      "188343      2\n",
      "244087      2\n",
      "197905      2\n",
      "109684      2\n",
      "362835      2\n",
      "376416      2\n",
      "98639       2\n",
      "179594      2\n",
      "130714      2\n",
      "177531      2\n",
      "268222      2\n",
      "127895      2\n",
      "594187      2\n",
      "221966      2\n",
      "185203      2\n",
      "111979      2\n",
      "256861      2\n",
      "44392       2\n",
      "37210       2\n",
      "215014      2\n",
      "174391      2\n",
      "211253      2\n",
      "35211       2\n",
      "362787      2\n",
      "50837       2\n",
      "334113      2\n",
      "188171      2\n",
      "283945      2\n",
      "31848       2\n",
      "145434      2\n",
      "167967      2\n",
      "73434       2\n",
      "452640      2\n",
      "163204      2\n",
      "340110      2\n",
      "162424      2\n",
      "145711      2\n",
      "227597      2\n",
      "213258      2\n",
      "306784      2\n",
      "266287      2\n",
      "200374      2\n",
      "196280      2\n",
      "127315      2\n",
      "110554      2\n",
      "224424      2\n",
      "198953      2\n",
      "224954      2\n",
      "290321      2\n",
      "42251       2\n",
      "161027      2\n",
      "406811      2\n",
      "228686      2\n",
      "20469       2\n",
      "162678      2\n",
      "145041      2\n",
      "165201      2\n",
      "70995       2\n",
      "190767      2\n",
      "136823      2\n",
      "259363      2\n",
      "155972      2\n",
      "136343      2\n",
      "190107      2\n",
      "209214      2\n",
      "386397      2\n",
      "455361      2\n",
      "204046      2\n",
      "51499       2\n",
      "144182      2\n",
      "97411       2\n",
      "111883      2\n",
      "289944      2\n",
      "198668      2\n",
      "173321      2\n",
      "251243      2\n",
      "178551      2\n",
      "230961      2\n",
      "204338      2\n",
      "30447       2\n",
      "254304      2\n",
      "213477      2\n",
      "193051      2\n",
      "116442      2\n",
      "118712      2\n",
      "180150      2\n",
      "424034      2\n",
      "81654       2\n",
      "199832      2\n",
      "482732      2\n",
      "161334      2\n",
      "485117      2\n",
      "216508      2\n",
      "158416      2\n",
      "177927      2\n",
      "342730      2\n",
      "118536      2\n",
      "50953       2\n",
      "157595      2\n",
      "175456      2\n",
      "171841      2\n",
      "124685      2\n",
      "198069      2\n",
      "101812      2\n",
      "375482      2\n",
      "178922      2\n",
      "152676      2\n",
      "146706      2\n",
      "210991      2\n",
      "342458      2\n",
      "43909       2\n",
      "329425      2\n",
      "335570      2\n",
      "190429      2\n",
      "392286      2\n",
      "548256      2\n",
      "227778      2\n",
      "368700      2\n",
      "338376      2\n",
      "145111      2\n",
      "197069      2\n",
      "137678      2\n",
      "169031      2\n",
      "223696      2\n",
      "407495      2\n",
      "44368       2\n",
      "202467      2\n",
      "257910      2\n",
      "210259      2\n",
      "204935      2\n",
      "111067      2\n",
      "284395      2\n",
      "111563      2\n",
      "100828      2\n",
      "25265       2\n",
      "38819       2\n",
      "44464       2\n",
      "210275      2\n",
      "270194      2\n",
      "317443      2\n",
      "56964       2\n",
      "216479      2\n",
      "30575       2\n",
      "374163      2\n",
      "153451      2\n",
      "182543      2\n",
      "191088      2\n",
      "328301      2\n",
      "146834      2\n",
      "257416      2\n",
      "175972      2\n",
      "203783      2\n",
      "253770      2\n",
      "218955      2\n",
      "333651      2\n",
      "262749      2\n",
      "160594      2\n",
      "236110      2\n",
      "169973      2\n",
      "159580      2\n",
      "24790       2\n",
      "273792      2\n",
      "90705       2\n",
      "159548      2\n",
      "191024      2\n",
      "87867       2\n",
      "255885      2\n",
      "211450      2\n",
      "181677      2\n",
      "402089      2\n",
      "188186      2\n",
      "251675      2\n",
      "216984      2\n",
      "123992      2\n",
      "127491      2\n",
      "135839      2\n",
      "294936      2\n",
      "243665      2\n",
      "124265      2\n",
      "174051      2\n",
      "204756      2\n",
      "109080      2\n",
      "80410       2\n",
      "334366      2\n",
      "158352      2\n",
      "165681      2\n",
      "217054      2\n",
      "270889      2\n",
      "49797       2\n",
      "52636       2\n",
      "277034      2\n",
      "222221      2\n",
      "118686      2\n",
      "186269      2\n",
      "204402      2\n",
      "196674      2\n",
      "308764      2\n",
      "182401      2\n",
      "440129      2\n",
      "114746      2\n",
      "282680      2\n",
      "178506      2\n",
      "206903      2\n",
      "180032      2\n",
      "225892      2\n",
      "340939      2\n",
      "147719      2\n",
      "237713      2\n",
      "255635      2\n",
      "214617      2\n",
      "33725       2\n",
      "96073       2\n",
      "354351      2\n",
      "277434      2\n",
      "402361      2\n",
      "124747      2\n",
      "152503      2\n",
      "60641       2\n",
      "257644      2\n",
      "37215       2\n",
      "231491      2\n",
      "346406      2\n",
      "127678      2\n",
      "189721      2\n",
      "213152      2\n",
      "150516      2\n",
      "149049      2\n",
      "45156       2\n",
      "295010      2\n",
      "145333      2\n",
      "418405      2\n",
      "176286      2\n",
      "168223      2\n",
      "321824      2\n",
      "169549      2\n",
      "197613      2\n",
      "215115      2\n",
      "236879      2\n",
      "184466      2\n",
      "170217      2\n",
      "173585      2\n",
      "196690      2\n",
      "204596      2\n",
      "195554      2\n",
      "58337       2\n",
      "184779      2\n",
      "141453      2\n",
      "192936      2\n",
      "104334      2\n",
      "163322      2\n",
      "397280      2\n",
      "35724       2\n",
      "267955      2\n",
      "114678      2\n",
      "64322       2\n",
      "339956      2\n",
      "308027      2\n",
      "462832      2\n",
      "223648      2\n",
      "399022      2\n",
      "311184      2\n",
      "251579      2\n",
      "320305      2\n",
      "51620       2\n",
      "237993      2\n",
      "97933       2\n",
      "167380      2\n",
      "308691      2\n",
      "234271      2\n",
      "236318      2\n",
      "265099      2\n",
      "196504      2\n",
      "100321      2\n",
      "321435      2\n",
      "272411      2\n",
      "153291      2\n",
      "184759      2\n",
      "34973       2\n",
      "188300      2\n",
      "348152      2\n",
      "24961       2\n",
      "171876      2\n",
      "62339       2\n",
      "174189      2\n",
      "168782      2\n",
      "460835      2\n",
      "164733      2\n",
      "170017      2\n",
      "149531      2\n",
      "371064      2\n",
      "96359       2\n",
      "192614      2\n",
      "254817      2\n",
      "166585      2\n",
      "256864      2\n",
      "140121      2\n",
      "247819      2\n",
      "173987      2\n",
      "213002      2\n",
      "187870      2\n",
      "77698       2\n",
      "107233      2\n",
      "244554      2\n",
      "157145      2\n",
      "55291       2\n",
      "207213      2\n",
      "79443       2\n",
      "47541       2\n",
      "177351      2\n",
      "312500      2\n",
      "102180      2\n",
      "413557      2\n",
      "177955      2\n",
      "123833      2\n",
      "85572       2\n",
      "74949       2\n",
      "185039      2\n",
      "300687      2\n",
      "252986      2\n",
      "40767       2\n",
      "121966      2\n",
      "157249      2\n",
      "235071      2\n",
      "104945      2\n",
      "91857       2\n",
      "192208      2\n",
      "230545      2\n",
      "282062      2\n",
      "36032       2\n",
      "215504      2\n",
      "141841      2\n",
      "95423       2\n",
      "44566       2\n",
      "54744       2\n",
      "199883      2\n",
      "240979      2\n",
      "173093      2\n",
      "121602      2\n",
      "264627      2\n",
      "184117      2\n",
      "403911      2\n",
      "286342      2\n",
      "206297      2\n",
      "102858      2\n",
      "152795      2\n",
      "187411      2\n",
      "191978      2\n",
      "178356      2\n",
      "207277      2\n",
      "242080      2\n",
      "191957      2\n",
      "119170      2\n",
      "161240      2\n",
      "196975      2\n",
      "306183      2\n",
      "158924      2\n",
      "136951      2\n",
      "267717      2\n",
      "220362      2\n",
      "241360      2\n",
      "143774      2\n",
      "89226       2\n",
      "336793      2\n",
      "192321      2\n",
      "289980      2\n",
      "187821      2\n",
      "202239      2\n",
      "198103      2\n",
      "201799      2\n",
      "187454      2\n",
      "376474      2\n",
      "160943      2\n",
      "57924       2\n",
      "288273      2\n",
      "284343      2\n",
      "269474      2\n",
      "288433      2\n",
      "81578       2\n",
      "112283      2\n",
      "281768      2\n",
      "116960      2\n",
      "49626       2\n",
      "26145       2\n",
      "77336       2\n",
      "140117      2\n",
      "160784      2\n",
      "208725      2\n",
      "52900       2\n",
      "421633      2\n",
      "163352      2\n",
      "204074      2\n",
      "511289      2\n",
      "135568      2\n",
      "46561       2\n",
      "195767      2\n",
      "236586      2\n",
      "28160       2\n",
      "74275       2\n",
      "239161      2\n",
      "483822      2\n",
      "98010       2\n",
      "83033       2\n",
      "71344       2\n",
      "77266       2\n",
      "149220      2\n",
      "37274       2\n",
      "199555      2\n",
      "247445      2\n",
      "127388      2\n",
      "214169      2\n",
      "175586      2\n",
      "97842       2\n",
      "194290      2\n",
      "302146      2\n",
      "57758       2\n",
      "106255      2\n",
      "318982      2\n",
      "144483      2\n",
      "206521      2\n",
      "51973       2\n",
      "128715      2\n",
      "27153       2\n",
      "171550      2\n",
      "190911      2\n",
      "303462      2\n",
      "169758      2\n",
      "365683      2\n",
      "224238      2\n",
      "352628      2\n",
      "48358       2\n",
      "35969       2\n",
      "105908      2\n",
      "176077      2\n",
      "325372      2\n",
      "103651      2\n",
      "370585      2\n",
      "105586      2\n",
      "332249      2\n",
      "117201      2\n",
      "280344      2\n",
      "139183      2\n",
      "509629      2\n",
      "288353      2\n",
      "22422       2\n",
      "225724      2\n",
      "231037      2\n",
      "208640      2\n",
      "93272       2\n",
      "62507       2\n",
      "277946      2\n",
      "77905       2\n",
      "138575      2\n",
      "68684       2\n",
      "214781      2\n",
      "190885      2\n",
      "145178      2\n",
      "198341      2\n",
      "317175      2\n",
      "183870      2\n",
      "231196      2\n",
      "116207      2\n",
      "31095       2\n",
      "190257      2\n",
      "153031      2\n",
      "218782      2\n",
      "132717      2\n",
      "177787      2\n",
      "528616      2\n",
      "369522      2\n",
      "37232       2\n",
      "149396      2\n",
      "146454      2\n",
      "226947      2\n",
      "236770      2\n",
      "29020       2\n",
      "29658       2\n",
      "266091      2\n",
      "106982      2\n",
      "185132      1\n",
      "197077      1\n",
      "162601      1\n",
      "234854      1\n",
      "108402      1\n",
      "173593      1\n",
      "224984      1\n",
      "263970      1\n",
      "330535      1\n",
      "159032      1\n",
      "199251      1\n",
      "183597      1\n",
      "130304      1\n",
      "176931      1\n",
      "295912      1\n",
      "142624      1\n",
      "197988      1\n",
      "106306      1\n",
      "87006       1\n",
      "366796      1\n",
      "103751      1\n",
      "66838       1\n",
      "127930      1\n",
      "56424       1\n",
      "198393      1\n",
      "150812      1\n",
      "25124       1\n",
      "218724      1\n",
      "308064      1\n",
      "25386       1\n",
      "359193      1\n",
      "97562       1\n",
      "405386      1\n",
      "122159      1\n",
      "251167      1\n",
      "341346      1\n",
      "175424      1\n",
      "345405      1\n",
      "242994      1\n",
      "148226      1\n",
      "154398      1\n",
      "326587      1\n",
      "394612      1\n",
      "101460      1\n",
      "187327      1\n",
      "346975      1\n",
      "140592      1\n",
      "387844      1\n",
      "58744       1\n",
      "477983      1\n",
      "46990       1\n",
      "332657      1\n",
      "361493      1\n",
      "177522      1\n",
      "293297      1\n",
      "267044      1\n",
      "142579      1\n",
      "142555      1\n",
      "269687      1\n",
      "357691      1\n",
      "169204      1\n",
      "205601      1\n",
      "148844      1\n",
      "41762       1\n",
      "152878      1\n",
      "91209       1\n",
      "221977      1\n",
      "166626      1\n",
      "296317      1\n",
      "183824      1\n",
      "217274      1\n",
      "152351      1\n",
      "242960      1\n",
      "207841      1\n",
      "86185       1\n",
      "123838      1\n",
      "271379      1\n",
      "184542      1\n",
      "86860       1\n",
      "265116      1\n",
      "142673      1\n",
      "340787      1\n",
      "275778      1\n",
      "181196      1\n",
      "249087      1\n",
      "95255       1\n",
      "512828      1\n",
      "183248      1\n",
      "463072      1\n",
      "44774       1\n",
      "302945      1\n",
      "171351      1\n",
      "72998       1\n",
      "74334       1\n",
      "142657      1\n",
      "88909       1\n",
      "181070      1\n",
      "156616      1\n",
      "197429      1\n",
      "66326       1\n",
      "173296      1\n",
      "201498      1\n",
      "281565      1\n",
      "343609      1\n",
      "161016      1\n",
      "195833      1\n",
      "41777       1\n",
      "189468      1\n",
      "258888      1\n",
      "238802      1\n",
      "283400      1\n",
      "70982       1\n",
      "171335      1\n",
      "261418      1\n",
      "159049      1\n",
      "218062      1\n",
      "181580      1\n",
      "41794       1\n",
      "229287      1\n",
      "150980      1\n",
      "159016      1\n",
      "142874      1\n",
      "211762      1\n",
      "54377       1\n",
      "175057      1\n",
      "181054      1\n",
      "433170      1\n",
      "201686      1\n",
      "377869      1\n",
      "189225      1\n",
      "236341      1\n",
      "299828      1\n",
      "175120      1\n",
      "220511      1\n",
      "191288      1\n",
      "105431      1\n",
      "236805      1\n",
      "238386      1\n",
      "191276      1\n",
      "224217      1\n",
      "189241      1\n",
      "243941      1\n",
      "159773      1\n",
      "75104       1\n",
      "297186      1\n",
      "298786      1\n",
      "142689      1\n",
      "104361      1\n",
      "357338      1\n",
      "109414      1\n",
      "138557      1\n",
      "148444      1\n",
      "173314      1\n",
      "35459       1\n",
      "69056       1\n",
      "201556      1\n",
      "342865      1\n",
      "294398      1\n",
      "32059       1\n",
      "324922      1\n",
      "109872      1\n",
      "146540      1\n",
      "104737      1\n",
      "203233      1\n",
      "271665      1\n",
      "185359      1\n",
      "208802      1\n",
      "478346      1\n",
      "353219      1\n",
      "179013      1\n",
      "299831      1\n",
      "161765      1\n",
      "177408      1\n",
      "258872      1\n",
      "216413      1\n",
      "95280       1\n",
      "99126       1\n",
      "31428       1\n",
      "306467      1\n",
      "234519      1\n",
      "267588      1\n",
      "47577       1\n",
      "647882      1\n",
      "160456      1\n",
      "169435      1\n",
      "64874       1\n",
      "333270      1\n",
      "204247      1\n",
      "248876      1\n",
      "113555      1\n",
      "182975      1\n",
      "266134      1\n",
      "258339      1\n",
      "37591       1\n",
      "128363      1\n",
      "236246      1\n",
      "187069      1\n",
      "204049      1\n",
      "146586      1\n",
      "87518       1\n",
      "378221      1\n",
      "195394      1\n",
      "165082      1\n",
      "294701      1\n",
      "191291      1\n",
      "306563      1\n",
      "351711      1\n",
      "110490      1\n",
      "246829      1\n",
      "154941      1\n",
      "88781       1\n",
      "31007       1\n",
      "67725       1\n",
      "202182      1\n",
      "161572      1\n",
      "396270      1\n",
      "195739      1\n",
      "279452      1\n",
      "232151      1\n",
      "284871      1\n",
      "272856      1\n",
      "324506      1\n",
      "462180      1\n",
      "204085      1\n",
      "148940      1\n",
      "176867      1\n",
      "34102       1\n",
      "268598      1\n",
      "270228      1\n",
      "120270      1\n",
      "318891      1\n",
      "581071      1\n",
      "105830      1\n",
      "236262      1\n",
      "191803      1\n",
      "251196      1\n",
      "57329       1\n",
      "247514      1\n",
      "108683      1\n",
      "241121      1\n",
      "259352      1\n",
      "401508      1\n",
      "244770      1\n",
      "208534      1\n",
      "62346       1\n",
      "201117      1\n",
      "119432      1\n",
      "125833      1\n",
      "738812      1\n",
      "62155       1\n",
      "205474      1\n",
      "144032      1\n",
      "162506      1\n",
      "517000      1\n",
      "39815       1\n",
      "166789      1\n",
      "223944      1\n",
      "27979       1\n",
      "301229      1\n",
      "150175      1\n",
      "409604      1\n",
      "87372       1\n",
      "343377      1\n",
      "295621      1\n",
      "318975      1\n",
      "306515      1\n",
      "115358      1\n",
      "154604      1\n",
      "55965       1\n",
      "195467      1\n",
      "390472      1\n",
      "189944      1\n",
      "247276      1\n",
      "112130      1\n",
      "203445      1\n",
      "338611      1\n",
      "140176      1\n",
      "172722      1\n",
      "187279      1\n",
      "165505      1\n",
      "188957      1\n",
      "189098      1\n",
      "271393      1\n",
      "155093      1\n",
      "355954      1\n",
      "183789      1\n",
      "167284      1\n",
      "322873      1\n",
      "268965      1\n",
      "295763      1\n",
      "120302      1\n",
      "117273      1\n",
      "370160      1\n",
      "682947      1\n",
      "217807      1\n",
      "273905      1\n",
      "181132      1\n",
      "128348      1\n",
      "232139      1\n",
      "94936       1\n",
      "165316      1\n",
      "250782      1\n",
      "406978      1\n",
      "191243      1\n",
      "250639      1\n",
      "243776      1\n",
      "98076       1\n",
      "144354      1\n",
      "195337      1\n",
      "195914      1\n",
      "312653      1\n",
      "187311      1\n",
      "109969      1\n",
      "311907      1\n",
      "267012      1\n",
      "62539       1\n",
      "761006      1\n",
      "253262      1\n",
      "117503      1\n",
      "148222      1\n",
      "171301      1\n",
      "178344      1\n",
      "394534      1\n",
      "150941      1\n",
      "36135       1\n",
      "183356      1\n",
      "306593      1\n",
      "115813      1\n",
      "86958       1\n",
      "19899       1\n",
      "98980       1\n",
      "224584      1\n",
      "41745       1\n",
      "130329      1\n",
      "159299      1\n",
      "598802      1\n",
      "224185      1\n",
      "254904      1\n",
      "91534       1\n",
      "180283      1\n",
      "220543      1\n",
      "117760      1\n",
      "93208       1\n",
      "261062      1\n",
      "46466       1\n",
      "134069      1\n",
      "410446      1\n",
      "85389       1\n",
      "119344      1\n",
      "205580      1\n",
      "184948      1\n",
      "203542      1\n",
      "230165      1\n",
      "258049      1\n",
      "311931      1\n",
      "121102      1\n",
      "71046       1\n",
      "189832      1\n",
      "340755      1\n",
      "150080      1\n",
      "183213      1\n",
      "128059      1\n",
      "66309       1\n",
      "465974      1\n",
      "304032      1\n",
      "173601      1\n",
      "170302      1\n",
      "70037       1\n",
      "25322       1\n",
      "133876      1\n",
      "340723      1\n",
      "69045       1\n",
      "47858       1\n",
      "48433       1\n",
      "106544      1\n",
      "161210      1\n",
      "185695      1\n",
      "153549      1\n",
      "318190      1\n",
      "411068      1\n",
      "164582      1\n",
      "144723      1\n",
      "249277      1\n",
      "333108      1\n",
      "105189      1\n",
      "56236       1\n",
      "244523      1\n",
      "117471      1\n",
      "100881      1\n",
      "88991       1\n",
      "240049      1\n",
      "469921      1\n",
      "341410      1\n",
      "107265      1\n",
      "359678      1\n",
      "38310       1\n",
      "236907      1\n",
      "124975      1\n",
      "272166      1\n",
      "207375      1\n",
      "156410      1\n",
      "173050      1\n",
      "97017       1\n",
      "146178      1\n",
      "191544      1\n",
      "287476      1\n",
      "91048       1\n",
      "118108      1\n",
      "269654      1\n",
      "202071      1\n",
      "564135      1\n",
      "279980      1\n",
      "267174      1\n",
      "38079       1\n",
      "195322      1\n",
      "113571      1\n",
      "173488      1\n",
      "209826      1\n",
      "301814      1\n",
      "175537      1\n",
      "89325       1\n",
      "148524      1\n",
      "172898      1\n",
      "108467      1\n",
      "277635      1\n",
      "263300      1\n",
      "183845      1\n",
      "285854      1\n",
      "208019      1\n",
      "241607      1\n",
      "343059      1\n",
      "224393      1\n",
      "270075      1\n",
      "293802      1\n",
      "261799      1\n",
      "54684       1\n",
      "185503      1\n",
      "218124      1\n",
      "279661      1\n",
      "139324      1\n",
      "216730      1\n",
      "99478       1\n",
      "78866       1\n",
      "109611      1\n",
      "256173      1\n",
      "167063      1\n",
      "42984       1\n",
      "248973      1\n",
      "139161      1\n",
      "423064      1\n",
      "25139       1\n",
      "267284      1\n",
      "193451      1\n",
      "183410      1\n",
      "98695       1\n",
      "179135      1\n",
      "101524      1\n",
      "256062      1\n",
      "174120      1\n",
      "311194      1\n",
      "175024      1\n",
      "119918      1\n",
      "306289      1\n",
      "169532      1\n",
      "197748      1\n",
      "140478      1\n",
      "60355       1\n",
      "85566       1\n",
      "252292      1\n",
      "242720      1\n",
      "183327      1\n",
      "187424      1\n",
      "50093       1\n",
      "180220      1\n",
      "322585      1\n",
      "179314      1\n",
      "95256       1\n",
      "286372      1\n",
      "111589      1\n",
      "220101      1\n",
      "361494      1\n",
      "105493      1\n",
      "53304       1\n",
      "58522       1\n",
      "44000       1\n",
      "172828      1\n",
      "79980       1\n",
      "306352      1\n",
      "29675       1\n",
      "121821      1\n",
      "168693      1\n",
      "25497       1\n",
      "187551      1\n",
      "165030      1\n",
      "273569      1\n",
      "179378      1\n",
      "318351      1\n",
      "222868      1\n",
      "359828      1\n",
      "232628      1\n",
      "191451      1\n",
      "1097453     1\n",
      "403037      1\n",
      "198459      1\n",
      "72886       1\n",
      "122244      1\n",
      "199572      1\n",
      "260669      1\n",
      "507086      1\n",
      "97449       1\n",
      "301024      1\n",
      "337286      1\n",
      "255161      1\n",
      "195562      1\n",
      "93193       1\n",
      "349340      1\n",
      "50349       1\n",
      "148492      1\n",
      "154781      1\n",
      "116641      1\n",
      "183404      1\n",
      "146579      1\n",
      "195595      1\n",
      "199170      1\n",
      "194304      1\n",
      "298133      1\n",
      "342946      1\n",
      "81057       1\n",
      "171159      1\n",
      "271346      1\n",
      "244721      1\n",
      "353432      1\n",
      "259226      1\n",
      "276568      1\n",
      "154432      1\n",
      "48010       1\n",
      "107425      1\n",
      "164198      1\n",
      "218015      1\n",
      "108510      1\n",
      "154526      1\n",
      "478380      1\n",
      "103588      1\n",
      "177120      1\n",
      "230373      1\n",
      "193672      1\n",
      "177027      1\n",
      "288568      1\n",
      "148590      1\n",
      "115806      1\n",
      "174545      1\n",
      "185436      1\n",
      "299223      1\n",
      "425049      1\n",
      "275522      1\n",
      "179313      1\n",
      "314770      1\n",
      "367655      1\n",
      "198546      1\n",
      "252406      1\n",
      "332884      1\n",
      "136262      1\n",
      "404416      1\n",
      "185279      1\n",
      "252862      1\n",
      "203910      1\n",
      "343121      1\n",
      "42435       1\n",
      "201766      1\n",
      "267399      1\n",
      "78928       1\n",
      "401134      1\n",
      "178002      1\n",
      "60552       1\n",
      "279485      1\n",
      "48271       1\n",
      "365511      1\n",
      "371827      1\n",
      "144515      1\n",
      "164966      1\n",
      "60367       1\n",
      "207824      1\n",
      "58898       1\n",
      "228395      1\n",
      "158827      1\n",
      "209970      1\n",
      "273084      1\n",
      "109667      1\n",
      "238721      1\n",
      "177107      1\n",
      "33374       1\n",
      "298037      1\n",
      "119493      1\n",
      "365516      1\n",
      "169759      1\n",
      "228411      1\n",
      "117313      1\n",
      "259019      1\n",
      "54334       1\n",
      "54440       1\n",
      "231688      1\n",
      "29819       1\n",
      "234096      1\n",
      "236338      1\n",
      "222248      1\n",
      "189385      1\n",
      "234143      1\n",
      "52156       1\n",
      "162923      1\n",
      "121998      1\n",
      "31801       1\n",
      "199735      1\n",
      "148606      1\n",
      "177075      1\n",
      "437281      1\n",
      "66614       1\n",
      "349151      1\n",
      "240771      1\n",
      "138293      1\n",
      "319371      1\n",
      "257277      1\n",
      "207923      1\n",
      "280798      1\n",
      "107665      1\n",
      "279580      1\n",
      "80945       1\n",
      "408498      1\n",
      "242736      1\n",
      "398843      1\n",
      "197732      1\n",
      "267396      1\n",
      "144531      1\n",
      "171111      1\n",
      "257849      1\n",
      "148526      1\n",
      "99462       1\n",
      "93227       1\n",
      "357750      1\n",
      "230168      1\n",
      "156809      1\n",
      "273604      1\n",
      "212617      1\n",
      "87497       1\n",
      "201844      1\n",
      "225970      1\n",
      "162954      1\n",
      "105838      1\n",
      "186788      1\n",
      "244395      1\n",
      "154017      1\n",
      "285775      1\n",
      "46162       1\n",
      "234699      1\n",
      "48211       1\n",
      "255098      1\n",
      "202106      1\n",
      "230484      1\n",
      "157991      1\n",
      "199765      1\n",
      "404547      1\n",
      "99364       1\n",
      "207817      1\n",
      "87164       1\n",
      "33717       1\n",
      "416829      1\n",
      "152636      1\n",
      "89054       1\n",
      "191547      1\n",
      "195545      1\n",
      "195770      1\n",
      "136198      1\n",
      "109921      1\n",
      "112860      1\n",
      "142547      1\n",
      "70868       1\n",
      "210053      1\n",
      "195418      1\n",
      "225516      1\n",
      "97318       1\n",
      "226129      1\n",
      "254809      1\n",
      "85244       1\n",
      "377836      1\n",
      "350853      1\n",
      "234327      1\n",
      "378916      1\n",
      "359696      1\n",
      "312588      1\n",
      "249101      1\n",
      "548664      1\n",
      "203653      1\n",
      "398212      1\n",
      "164693      1\n",
      "122127      1\n",
      "327766      1\n",
      "26911       1\n",
      "81154       1\n",
      "200559      1\n",
      "205649      1\n",
      "400630      1\n",
      "23646       1\n",
      "113099      1\n",
      "313946      1\n",
      "149044      1\n",
      "195481      1\n",
      "199925      1\n",
      "111843      1\n",
      "187618      1\n",
      "34021       1\n",
      "158200      1\n",
      "425161      1\n",
      "183532      1\n",
      "161018      1\n",
      "181485      1\n",
      "272063      1\n",
      "168807      1\n",
      "334741      1\n",
      "74593       1\n",
      "83196       1\n",
      "469907      1\n",
      "156874      1\n",
      "239321      1\n",
      "140544      1\n",
      "115549      1\n",
      "220109      1\n",
      "125684      1\n",
      "265477      1\n",
      "312206      1\n",
      "252813      1\n",
      "158603      1\n",
      "177426      1\n",
      "210714      1\n",
      "52963       1\n",
      "29928       1\n",
      "414991      1\n",
      "203637      1\n",
      "160472      1\n",
      "479611      1\n",
      "265509      1\n",
      "169047      1\n",
      "303986      1\n",
      "232421      1\n",
      "164790      1\n",
      "143949      1\n",
      "45891       1\n",
      "294121      1\n",
      "282664      1\n",
      "328981      1\n",
      "175465      1\n",
      "87771       1\n",
      "195433      1\n",
      "190340      1\n",
      "166759      1\n",
      "238401      1\n",
      "161066      1\n",
      "48099       1\n",
      "174912      1\n",
      "334693      1\n",
      "32779       1\n",
      "142581      1\n",
      "122038      1\n",
      "140576      1\n",
      "170983      1\n",
      "347132      1\n",
      "316702      1\n",
      "145983      1\n",
      "149875      1\n",
      "138502      1\n",
      "107746      1\n",
      "263444      1\n",
      "117917      1\n",
      "200207      1\n",
      "175331      1\n",
      "159001      1\n",
      "136455      1\n",
      "255193      1\n",
      "159854      1\n",
      "511068      1\n",
      "171964      1\n",
      "102193      1\n",
      "159522      1\n",
      "186569      1\n",
      "154493      1\n",
      "32280       1\n",
      "189257      1\n",
      "588905      1\n",
      "132326      1\n",
      "125768      1\n",
      "101607      1\n",
      "247053      1\n",
      "113770      1\n",
      "138054      1\n",
      "102270      1\n",
      "120590      1\n",
      "257216      1\n",
      "206002      1\n",
      "339123      1\n",
      "112627      1\n",
      "224203      1\n",
      "201908      1\n",
      "251180      1\n",
      "484298      1\n",
      "205024      1\n",
      "215948      1\n",
      "54261       1\n",
      "123785      1\n",
      "166083      1\n",
      "119409      1\n",
      "36876       1\n",
      "198202      1\n",
      "496743      1\n",
      "185551      1\n",
      "170939      1\n",
      "203717      1\n",
      "421065      1\n",
      "257310      1\n",
      "113601      1\n",
      "208908      1\n",
      "122412      1\n",
      "33669       1\n",
      "81107       1\n",
      "208109      1\n",
      "150463      1\n",
      "173248      1\n",
      "218302      1\n",
      "111520      1\n",
      "150717      1\n",
      "156842      1\n",
      "706026      1\n",
      "128170      1\n",
      "56510       1\n",
      "464536      1\n",
      "216237      1\n",
      "191659      1\n",
      "312353      1\n",
      "140242      1\n",
      "133736      1\n",
      "252127      1\n",
      "142528      1\n",
      "244689      1\n",
      "318639      1\n",
      "345121      1\n",
      "375698      1\n",
      "273575      1\n",
      "238481      1\n",
      "238768      1\n",
      "240817      1\n",
      "121838      1\n",
      "478829      1\n",
      "144579      1\n",
      "56269       1\n",
      "115457      1\n",
      "95108       1\n",
      "257609      1\n",
      "318452      1\n",
      "189656      1\n",
      "117827      1\n",
      "95450       1\n",
      "208067      1\n",
      "209629      1\n",
      "216284      1\n",
      "201924      1\n",
      "103654      1\n",
      "126868      1\n",
      "167658      1\n",
      "148398      1\n",
      "35829       1\n",
      "283743      1\n",
      "185582      1\n",
      "26671       1\n",
      "289707      1\n",
      "228265      1\n",
      "36039       1\n",
      "95432       1\n",
      "199591      1\n",
      "87263       1\n",
      "245196      1\n",
      "368949      1\n",
      "339168      1\n",
      "44273       1\n",
      "240496      1\n",
      "207779      1\n",
      "211873      1\n",
      "439592      1\n",
      "101364      1\n",
      "248186      1\n",
      "107617      1\n",
      "28790       1\n",
      "107744      1\n",
      "105686      1\n",
      "124194      1\n",
      "46402       1\n",
      "95226       1\n",
      "129426      1\n",
      "60409       1\n",
      "328581      1\n",
      "386040      1\n",
      "156889      1\n",
      "138342      1\n",
      "39927       1\n",
      "355259      1\n",
      "124090      1\n",
      "98228       1\n",
      "152915      1\n",
      "119679      1\n",
      "377725      1\n",
      "179186      1\n",
      "348771      1\n",
      "44257       1\n",
      "117628      1\n",
      "373952      1\n",
      "146625      1\n",
      "99254       1\n",
      "228570      1\n",
      "165726      1\n",
      "253310      1\n",
      "210381      1\n",
      "221850      1\n",
      "460437      1\n",
      "61708       1\n",
      "115085      1\n",
      "180318      1\n",
      "165918      1\n",
      "104438      1\n",
      "75409       1\n",
      "69621       1\n",
      "36699       1\n",
      "440417      1\n",
      "208528      1\n",
      "284303      1\n",
      "307786      1\n",
      "373367      1\n",
      "27032       1\n",
      "186350      1\n",
      "186130      1\n",
      "32763       1\n",
      "167893      1\n",
      "189666      1\n",
      "219754      1\n",
      "188280      1\n",
      "430471      1\n",
      "241667      1\n",
      "232022      1\n",
      "548510      1\n",
      "194954      1\n",
      "137301      1\n",
      "81220       1\n",
      "79874       1\n",
      "190105      1\n",
      "55294       1\n",
      "391257      1\n",
      "125019      1\n",
      "86108       1\n",
      "181901      1\n",
      "117148      1\n",
      "215304      1\n",
      "196234      1\n",
      "106118      1\n",
      "131002      1\n",
      "34437       1\n",
      "32126       1\n",
      "51164       1\n",
      "196571      1\n",
      "34935       1\n",
      "483450      1\n",
      "190015      1\n",
      "210563      1\n",
      "323545      1\n",
      "30664       1\n",
      "41090       1\n",
      "295046      1\n",
      "231559      1\n",
      "69748       1\n",
      "75891       1\n",
      "172146      1\n",
      "256278      1\n",
      "554986      1\n",
      "108960      1\n",
      "118149      1\n",
      "341102      1\n",
      "120959      1\n",
      "231972      1\n",
      "93169       1\n",
      "184620      1\n",
      "169958      1\n",
      "303521      1\n",
      "200677      1\n",
      "34788       1\n",
      "507875      1\n",
      "45613       1\n",
      "169990      1\n",
      "173832      1\n",
      "296613      1\n",
      "106546      1\n",
      "76144       1\n",
      "172401      1\n",
      "163530      1\n",
      "175491      1\n",
      "231166      1\n",
      "234504      1\n",
      "27466       1\n",
      "346159      1\n",
      "237601      1\n",
      "83930       1\n",
      "174112      1\n",
      "192200      1\n",
      "143731      1\n",
      "374833      1\n",
      "38599       1\n",
      "184687      1\n",
      "299047      1\n",
      "82285       1\n",
      "116620      1\n",
      "210875      1\n",
      "307555      1\n",
      "289039      1\n",
      "243762      1\n",
      "118831      1\n",
      "244830      1\n",
      "375827      1\n",
      "654141      1\n",
      "321896      1\n",
      "92682       1\n",
      "182303      1\n",
      "160107      1\n",
      "215404      1\n",
      "229414      1\n",
      "204486      1\n",
      "141363      1\n",
      "137606      1\n",
      "266707      1\n",
      "86399       1\n",
      "216697      1\n",
      "153614      1\n",
      "71351       1\n",
      "239683      1\n",
      "332703      1\n",
      "430283      1\n",
      "172220      1\n",
      "274096      1\n",
      "309634      1\n",
      "212534      1\n",
      "196266      1\n",
      "30793       1\n",
      "169639      1\n",
      "201613      1\n",
      "139576      1\n",
      "215219      1\n",
      "178241      1\n",
      "530454      1\n",
      "163894      1\n",
      "339142      1\n",
      "329783      1\n",
      "388496      1\n",
      "102423      1\n",
      "188793      1\n",
      "446140      1\n",
      "160123      1\n",
      "322171      1\n",
      "45054       1\n",
      "204817      1\n",
      "239632      1\n",
      "124987      1\n",
      "280639      1\n",
      "219277      1\n",
      "113550      1\n",
      "326297      1\n",
      "121694      1\n",
      "385242      1\n",
      "161930      1\n",
      "125147      1\n",
      "119004      1\n",
      "188303      1\n",
      "251487      1\n",
      "249741      1\n",
      "186830      1\n",
      "149388      1\n",
      "196491      1\n",
      "283087      1\n",
      "117473      1\n",
      "106961      1\n",
      "305379      1\n",
      "30602       1\n",
      "227545      1\n",
      "317019      1\n",
      "225707      1\n",
      "171889      1\n",
      "278114      1\n",
      "119522      1\n",
      "187717      1\n",
      "188618      1\n",
      "86220       1\n",
      "121037      1\n",
      "337505      1\n",
      "215247      1\n",
      "36383       1\n",
      "178385      1\n",
      "270546      1\n",
      "169878      1\n",
      "235733      1\n",
      "42017       1\n",
      "69525       1\n",
      "391744      1\n",
      "124808      1\n",
      "252058      1\n",
      "668362      1\n",
      "311534      1\n",
      "307440      1\n",
      "172274      1\n",
      "301526      1\n",
      "210802      1\n",
      "201175      1\n",
      "175985      1\n",
      "214143      1\n",
      "106748      1\n",
      "243904      1\n",
      "272240      1\n",
      "93655       1\n",
      "157947      1\n",
      "127451      1\n",
      "116991      1\n",
      "100820      1\n",
      "169846      1\n",
      "329301      1\n",
      "178050      1\n",
      "95835       1\n",
      "131302      1\n",
      "132996      1\n",
      "47570       1\n",
      "156294      1\n",
      "78291       1\n",
      "75648       1\n",
      "124792      1\n",
      "120902      1\n",
      "156606      1\n",
      "221418      1\n",
      "247676      1\n",
      "35210       1\n",
      "194426      1\n",
      "459463      1\n",
      "161690      1\n",
      "134756      1\n",
      "136687      1\n",
      "113443      1\n",
      "183973      1\n",
      "37028       1\n",
      "276241      1\n",
      "81859       1\n",
      "502837      1\n",
      "313925      1\n",
      "196396      1\n",
      "488706      1\n",
      "270551      1\n",
      "87247       1\n",
      "153534      1\n",
      "118717      1\n",
      "157305      1\n",
      "166715      1\n",
      "509048      1\n",
      "157640      1\n",
      "119215      1\n",
      "192664      1\n",
      "264148      1\n",
      "128645      1\n",
      "243666      1\n",
      "224854      1\n",
      "46712       1\n",
      "166039      1\n",
      "140456      1\n",
      "435469      1\n",
      "352207      1\n",
      "213421      1\n",
      "285102      1\n",
      "284758      1\n",
      "219293      1\n",
      "245918      1\n",
      "459189      1\n",
      "268726      1\n",
      "258379      1\n",
      "164711      1\n",
      "139452      1\n",
      "116927      1\n",
      "190057      1\n",
      "126568      1\n",
      "307392      1\n",
      "53930       1\n",
      "232985      1\n",
      "118701      1\n",
      "168656      1\n",
      "33221       1\n",
      "171438      1\n",
      "185619      1\n",
      "180505      1\n",
      "33323       1\n",
      "228472      1\n",
      "143281      1\n",
      "210866      1\n",
      "460214      1\n",
      "358585      1\n",
      "180272      1\n",
      "201292      1\n",
      "156089      1\n",
      "210547      1\n",
      "117357      1\n",
      "221157      1\n",
      "194490      1\n",
      "37745       1\n",
      "118972      1\n",
      "401335      1\n",
      "205249      1\n",
      "430005      1\n",
      "183916      1\n",
      "288398      1\n",
      "264244      1\n",
      "159768      1\n",
      "178530      1\n",
      "35092       1\n",
      "149686      1\n",
      "238305      1\n",
      "170262      1\n",
      "69911       1\n",
      "216972      1\n",
      "325802      1\n",
      "200468      1\n",
      "168103      1\n",
      "92440       1\n",
      "196773      1\n",
      "766115      1\n",
      "243743      1\n",
      "298661      1\n",
      "143516      1\n",
      "70668       1\n",
      "32650       1\n",
      "68552       1\n",
      "295799      1\n",
      "419721      1\n",
      "153471      1\n",
      "241843      1\n",
      "62124       1\n",
      "356619      1\n",
      "182540      1\n",
      "152420      1\n",
      "331556      1\n",
      "141185      1\n",
      "81794       1\n",
      "405765      1\n",
      "43280       1\n",
      "588003      1\n",
      "243587      1\n",
      "243986      1\n",
      "135044      1\n",
      "48214       1\n",
      "79050       1\n",
      "478205      1\n",
      "53407       1\n",
      "149405      1\n",
      "174224      1\n",
      "50096       1\n",
      "116493      1\n",
      "69927       1\n",
      "617898      1\n",
      "252046      1\n",
      "438176      1\n",
      "337825      1\n",
      "90409       1\n",
      "96554       1\n",
      "30475       1\n",
      "163594      1\n",
      "376973      1\n",
      "137250      1\n",
      "262042      1\n",
      "89870       1\n",
      "36936       1\n",
      "632593      1\n",
      "114973      1\n",
      "213149      1\n",
      "174368      1\n",
      "216691      1\n",
      "169879      1\n",
      "557349      1\n",
      "208656      1\n",
      "354201      1\n",
      "358554      1\n",
      "28568       1\n",
      "222989      1\n",
      "229525      1\n",
      "166036      1\n",
      "274579      1\n",
      "90377       1\n",
      "104858      1\n",
      "118652      1\n",
      "356555      1\n",
      "270577      1\n",
      "241021      1\n",
      "132917      1\n",
      "40822       1\n",
      "135874      1\n",
      "104662      1\n",
      "264436      1\n",
      "115511      1\n",
      "301302      1\n",
      "190297      1\n",
      "200500      1\n",
      "143152      1\n",
      "239824      1\n",
      "186159      1\n",
      "121038      1\n",
      "272209      1\n",
      "456922      1\n",
      "98106       1\n",
      "362309      1\n",
      "126104      1\n",
      "181974      1\n",
      "151518      1\n",
      "132565      1\n",
      "116541      1\n",
      "102631      1\n",
      "121070      1\n",
      "127195      1\n",
      "297188      1\n",
      "333990      1\n",
      "106721      1\n",
      "288585      1\n",
      "110396      1\n",
      "283004      1\n",
      "122672      1\n",
      "313181      1\n",
      "556652      1\n",
      "352094      1\n",
      "493443      1\n",
      "214695      1\n",
      "147314      1\n",
      "284078      1\n",
      "159931      1\n",
      "135028      1\n",
      "67006       1\n",
      "106143      1\n",
      "204662      1\n",
      "129350      1\n",
      "170166      1\n",
      "25690       1\n",
      "161563      1\n",
      "175891      1\n",
      "270565      1\n",
      "29324       1\n",
      "213349      1\n",
      "106753      1\n",
      "399386      1\n",
      "452808      1\n",
      "293114      1\n",
      "105794      1\n",
      "249644      1\n",
      "171814      1\n",
      "196805      1\n",
      "329924      1\n",
      "197353      1\n",
      "67365       1\n",
      "149756      1\n",
      "28520       1\n",
      "255849      1\n",
      "143583      1\n",
      "208570      1\n",
      "106406      1\n",
      "210959      1\n",
      "194475      1\n",
      "167652      1\n",
      "204518      1\n",
      "339952      1\n",
      "116812      1\n",
      "158177      1\n",
      "114674      1\n",
      "223671      1\n",
      "231141      1\n",
      "256514      1\n",
      "102471      1\n",
      "102388      1\n",
      "172022      1\n",
      "198996      1\n",
      "104439      1\n",
      "32837       1\n",
      "356344      1\n",
      "475028      1\n",
      "188398      1\n",
      "120910      1\n",
      "462820      1\n",
      "305053      1\n",
      "106282      1\n",
      "160049      1\n",
      "209906      1\n",
      "69727       1\n",
      "242700      1\n",
      "225750      1\n",
      "182131      1\n",
      "301031      1\n",
      "325355      1\n",
      "28648       1\n",
      "73809       1\n",
      "291147      1\n",
      "124905      1\n",
      "234286      1\n",
      "338316      1\n",
      "236938      1\n",
      "172368      1\n",
      "286730      1\n",
      "46514       1\n",
      "53260       1\n",
      "213341      1\n",
      "116751      1\n",
      "227791      1\n",
      "83998       1\n",
      "172050      1\n",
      "102420      1\n",
      "187643      1\n",
      "420779      1\n",
      "138966      1\n",
      "331831      1\n",
      "205153      1\n",
      "34122       1\n",
      "211948      1\n",
      "425622      1\n",
      "159782      1\n",
      "172034      1\n",
      "289960      1\n",
      "289636      1\n",
      "47170       1\n",
      "143360      1\n",
      "214985      1\n",
      "469056      1\n",
      "259803      1\n",
      "227386      1\n",
      "104790      1\n",
      "158040      1\n",
      "311357      1\n",
      "182332      1\n",
      "745817      1\n",
      "225339      1\n",
      "204788      1\n",
      "233799      1\n",
      "100569      1\n",
      "73670       1\n",
      "79619       1\n",
      "39222       1\n",
      "137223      1\n",
      "485496      1\n",
      "168055      1\n",
      "167424      1\n",
      "196725      1\n",
      "188842      1\n",
      "180162      1\n",
      "503923      1\n",
      "147202      1\n",
      "217663      1\n",
      "222853      1\n",
      "50483       1\n",
      "357814      1\n",
      "194682      1\n",
      "166290      1\n",
      "165637      1\n",
      "434102      1\n",
      "110723      1\n",
      "55215       1\n",
      "143280      1\n",
      "186959      1\n",
      "237873      1\n",
      "198581      1\n",
      "181282      1\n",
      "28729       1\n",
      "26553       1\n",
      "65466       1\n",
      "114813      1\n",
      "348092      1\n",
      "164570      1\n",
      "59145       1\n",
      "268661      1\n",
      "182380      1\n",
      "109445      1\n",
      "410543      1\n",
      "79827       1\n",
      "344157      1\n",
      "233428      1\n",
      "239074      1\n",
      "49218       1\n",
      "115005      1\n",
      "153918      1\n",
      "48882       1\n",
      "96346       1\n",
      "162096      1\n",
      "305472      1\n",
      "206577      1\n",
      "152880      1\n",
      "41281       1\n",
      "170310      1\n",
      "49401       1\n",
      "153551      1\n",
      "346382      1\n",
      "214989      1\n",
      "190776      1\n",
      "163578      1\n",
      "196554      1\n",
      "266343      1\n",
      "39014       1\n",
      "279243      1\n",
      "262245      1\n",
      "66008       1\n",
      "214069      1\n",
      "143459      1\n",
      "172129      1\n",
      "124665      1\n",
      "403552      1\n",
      "129338      1\n",
      "218990      1\n",
      "20333       1\n",
      "108211      1\n",
      "28281       1\n",
      "92792       1\n",
      "361324      1\n",
      "389755      1\n",
      "150031      1\n",
      "464502      1\n",
      "331381      1\n",
      "117372      1\n",
      "41490       1\n",
      "165492      1\n",
      "174640      1\n",
      "70164       1\n",
      "334357      1\n",
      "201599      1\n",
      "46706       1\n",
      "94744       1\n",
      "219661      1\n",
      "216411      1\n",
      "224953      1\n",
      "94606       1\n",
      "194186      1\n",
      "171655      1\n",
      "118337      1\n",
      "208513      1\n",
      "204241      1\n",
      "104965      1\n",
      "351871      1\n",
      "233882      1\n",
      "262285      1\n",
      "343506      1\n",
      "38472       1\n",
      "149116      1\n",
      "211570      1\n",
      "190987      1\n",
      "105808      1\n",
      "221722      1\n",
      "247245      1\n",
      "29866       1\n",
      "377374      1\n",
      "306785      1\n",
      "323016      1\n",
      "173664      1\n",
      "186925      1\n",
      "150876      1\n",
      "227128      1\n",
      "54878       1\n",
      "233371      1\n",
      "232900      1\n",
      "675421      1\n",
      "47619       1\n",
      "220323      1\n",
      "239303      1\n",
      "285858      1\n",
      "141875      1\n",
      "240837      1\n",
      "407138      1\n",
      "270079      1\n",
      "226922      1\n",
      "113185      1\n",
      "216685      1\n",
      "41506       1\n",
      "130667      1\n",
      "159910      1\n",
      "194049      1\n",
      "135716      1\n",
      "188661      1\n",
      "189897      1\n",
      "124520      1\n",
      "203301      1\n",
      "458549      1\n",
      "137862      1\n",
      "198244      1\n",
      "263637      1\n",
      "130832      1\n",
      "285294      1\n",
      "82521       1\n",
      "42857       1\n",
      "288154      1\n",
      "232591      1\n",
      "308285      1\n",
      "49436       1\n",
      "97963       1\n",
      "204405      1\n",
      "195805      1\n",
      "106151      1\n",
      "209507      1\n",
      "169638      1\n",
      "134821      1\n",
      "176580      1\n",
      "141795      1\n",
      "179875      1\n",
      "152159      1\n",
      "161510      1\n",
      "108001      1\n",
      "167396      1\n",
      "73190       1\n",
      "102069      1\n",
      "230885      1\n",
      "329026      1\n",
      "442035      1\n",
      "200641      1\n",
      "110257      1\n",
      "353352      1\n",
      "129497      1\n",
      "79331       1\n",
      "219742      1\n",
      "328570      1\n",
      "48610       1\n",
      "186030      1\n",
      "175777      1\n",
      "199268      1\n",
      "41474       1\n",
      "165745      1\n",
      "389843      1\n",
      "34452       1\n",
      "127595      1\n",
      "343699      1\n",
      "162297      1\n",
      "175761      1\n",
      "340341      1\n",
      "56975       1\n",
      "196467      1\n",
      "116365      1\n",
      "164569      1\n",
      "109600      1\n",
      "20109       1\n",
      "215468      1\n",
      "203055      1\n",
      "362999      1\n",
      "201204      1\n",
      "318610      1\n",
      "266855      1\n",
      "35303       1\n",
      "123582      1\n",
      "163290      1\n",
      "173728      1\n",
      "225768      1\n",
      "275232      1\n",
      "118429      1\n",
      "209392      1\n",
      "279901      1\n",
      "283116      1\n",
      "181916      1\n",
      "154093      1\n",
      "327323      1\n",
      "162410      1\n",
      "201268      1\n",
      "194138      1\n",
      "395831      1\n",
      "355865      1\n",
      "217775      1\n",
      "193144      1\n",
      "206891      1\n",
      "260729      1\n",
      "238257      1\n",
      "348796      1\n",
      "476573      1\n",
      "244402      1\n",
      "350845      1\n",
      "153151      1\n",
      "111283      1\n",
      "102663      1\n",
      "156649      1\n",
      "511517      1\n",
      "351350      1\n",
      "49837       1\n",
      "138744      1\n",
      "34340       1\n",
      "50402       1\n",
      "337456      1\n",
      "234151      1\n",
      "289448      1\n",
      "437851      1\n",
      "116797      1\n",
      "165148      1\n",
      "106023      1\n",
      "316606      1\n",
      "29059       1\n",
      "42401       1\n",
      "139890      1\n",
      "135796      1\n",
      "467611      1\n",
      "241056      1\n",
      "139906      1\n",
      "99870       1\n",
      "90730       1\n",
      "351187      1\n",
      "161290      1\n",
      "115389      1\n",
      "195978      1\n",
      "93705       1\n",
      "286734      1\n",
      "37482       1\n",
      "59829       1\n",
      "171398      1\n",
      "109530      1\n",
      "498325      1\n",
      "193434      1\n",
      "81282       1\n",
      "228480      1\n",
      "157525      1\n",
      "144898      1\n",
      "207791      1\n",
      "130571      1\n",
      "131275      1\n",
      "35001       1\n",
      "367237      1\n",
      "164870      1\n",
      "270151      1\n",
      "129673      1\n",
      "37023       1\n",
      "267798      1\n",
      "91545       1\n",
      "259873      1\n",
      "339473      1\n",
      "221881      1\n",
      "129972      1\n",
      "173584      1\n",
      "187919      1\n",
      "377486      1\n",
      "158315      1\n",
      "156608      1\n",
      "175552      1\n",
      "69757       1\n",
      "182136      1\n",
      "183885      1\n",
      "214604      1\n",
      "199316      1\n",
      "228939      1\n",
      "33429       1\n",
      "421449      1\n",
      "183751      1\n",
      "144761      1\n",
      "184440      1\n",
      "45487       1\n",
      "293926      1\n",
      "162988      1\n",
      "288185      1\n",
      "394820      1\n",
      "39493       1\n",
      "266820      1\n",
      "76432       1\n",
      "125499      1\n",
      "29240       1\n",
      "284095      1\n",
      "188986      1\n",
      "204375      1\n",
      "260954      1\n",
      "63734       1\n",
      "311949      1\n",
      "163258      1\n",
      "212563      1\n",
      "55950       1\n",
      "150079      1\n",
      "107909      1\n",
      "350783      1\n",
      "43587       1\n",
      "103063      1\n",
      "227994      1\n",
      "138662      1\n",
      "210355      1\n",
      "47713       1\n",
      "806316      1\n",
      "183869      1\n",
      "224680      1\n",
      "127184      1\n",
      "371299      1\n",
      "595088      1\n",
      "89652       1\n",
      "237051      1\n",
      "131686      1\n",
      "127592      1\n",
      "227945      1\n",
      "198196      1\n",
      "224198      1\n",
      "234919      1\n",
      "373344      1\n",
      "215647      1\n",
      "271936      1\n",
      "174675      1\n",
      "230229      1\n",
      "88653       1\n",
      "109428      1\n",
      "150095      1\n",
      "337130      1\n",
      "192344      1\n",
      "110145      1\n",
      "154205      1\n",
      "166546      1\n",
      "295510      1\n",
      "175732      1\n",
      "258648      1\n",
      "195161      1\n",
      "217692      1\n",
      "104118      1\n",
      "90415       1\n",
      "227178      1\n",
      "203525      1\n",
      "28473       1\n",
      "144947      1\n",
      "172370      1\n",
      "223752      1\n",
      "168276      1\n",
      "177951      1\n",
      "14878       1\n",
      "146117      1\n",
      "131414      1\n",
      "110128      1\n",
      "181716      1\n",
      "94552       1\n",
      "162137      1\n",
      "260425      1\n",
      "282972      1\n",
      "179508      1\n",
      "31807       1\n",
      "303637      1\n",
      "56630       1\n",
      "81054       1\n",
      "211265      1\n",
      "139586      1\n",
      "212803      1\n",
      "171419      1\n",
      "233796      1\n",
      "98630       1\n",
      "397831      1\n",
      "79682       1\n",
      "96585       1\n",
      "304960      1\n",
      "57674       1\n",
      "156797      1\n",
      "251710      1\n",
      "174295      1\n",
      "249686      1\n",
      "168015      1\n",
      "91689       1\n",
      "20511       1\n",
      "69413       1\n",
      "186733      1\n",
      "168293      1\n",
      "274800      1\n",
      "205570      1\n",
      "107112      1\n",
      "33142       1\n",
      "170104      1\n",
      "349431      1\n",
      "341695      1\n",
      "133043      1\n",
      "291355      1\n",
      "182836      1\n",
      "206369      1\n",
      "199031      1\n",
      "93518       1\n",
      "227689      1\n",
      "98837       1\n",
      "144798      1\n",
      "203289      1\n",
      "340260      1\n",
      "296485      1\n",
      "250238      1\n",
      "103524      1\n",
      "83756       1\n",
      "87369       1\n",
      "341539      1\n",
      "344414      1\n",
      "309778      1\n",
      "280927      1\n",
      "106850      1\n",
      "200878      1\n",
      "76131       1\n",
      "212163      1\n",
      "167749      1\n",
      "338260      1\n",
      "209184      1\n",
      "340567      1\n",
      "235079      1\n",
      "400966      1\n",
      "99604       1\n",
      "261979      1\n",
      "317535      1\n",
      "423770      1\n",
      "346532      1\n",
      "335533      1\n",
      "310850      1\n",
      "108097      1\n",
      "188905      1\n",
      "291096      1\n",
      "142912      1\n",
      "192588      1\n",
      "174355      1\n",
      "319054      1\n",
      "184120      1\n",
      "188682      1\n",
      "212562      1\n",
      "207107      1\n",
      "235781      1\n",
      "249214      1\n",
      "94057       1\n",
      "164102      1\n",
      "92008       1\n",
      "94892       1\n",
      "157331      1\n",
      "167781      1\n",
      "119052      1\n",
      "173649      1\n",
      "289046      1\n",
      "153167      1\n",
      "50474       1\n",
      "145697      1\n",
      "156025      1\n",
      "73559       1\n",
      "32587       1\n",
      "334133      1\n",
      "164877      1\n",
      "159561      1\n",
      "124744      1\n",
      "216636      1\n",
      "313852      1\n",
      "264503      1\n",
      "28984       1\n",
      "31033       1\n",
      "180733      1\n",
      "151868      1\n",
      "156516      1\n",
      "149823      1\n",
      "200825      1\n",
      "233780      1\n",
      "118605      1\n",
      "155198      1\n",
      "338416      1\n",
      "78090       1\n",
      "500002      1\n",
      "170277      1\n",
      "162189      1\n",
      "123178      1\n",
      "526164      1\n",
      "190763      1\n",
      "63437       1\n",
      "348460      1\n",
      "145234      1\n",
      "409902      1\n",
      "143664      1\n",
      "112945      1\n",
      "131573      1\n",
      "291192      1\n",
      "91928       1\n",
      "204567      1\n",
      "293305      1\n",
      "206560      1\n",
      "262352      1\n",
      "301638      1\n",
      "130779      1\n",
      "128730      1\n",
      "57929       1\n",
      "167428      1\n",
      "216858      1\n",
      "112131      1\n",
      "73431       1\n",
      "432565      1\n",
      "41553       1\n",
      "133420      1\n",
      "121865      1\n",
      "199095      1\n",
      "238002      1\n",
      "339681      1\n",
      "50411       1\n",
      "272960      1\n",
      "155150      1\n",
      "119762      1\n",
      "181773      1\n",
      "167281      1\n",
      "263908      1\n",
      "147171      1\n",
      "74305       1\n",
      "197290      1\n",
      "143939      1\n",
      "197189      1\n",
      "194059      1\n",
      "184975      1\n",
      "348588      1\n",
      "219565      1\n",
      "75472       1\n",
      "113234      1\n",
      "354024      1\n",
      "27067       1\n",
      "105974      1\n",
      "329205      1\n",
      "139730      1\n",
      "126011      1\n",
      "36340       1\n",
      "191581      1\n",
      "189017      1\n",
      "234220      1\n",
      "87535       1\n",
      "24046       1\n",
      "476653      1\n",
      "275859      1\n",
      "252419      1\n",
      "254439      1\n",
      "229846      1\n",
      "319768      1\n",
      "183804      1\n",
      "106183      1\n",
      "320084      1\n",
      "33365       1\n",
      "75235       1\n",
      "270587      1\n",
      "65866       1\n",
      "134699      1\n",
      "234263      1\n",
      "253438      1\n",
      "196630      1\n",
      "162249      1\n",
      "453067      1\n",
      "365390      1\n",
      "176723      1\n",
      "267198      1\n",
      "161482      1\n",
      "111238      1\n",
      "335168      1\n",
      "175648      1\n",
      "109039      1\n",
      "240160      1\n",
      "235909      1\n",
      "94600       1\n",
      "292379      1\n",
      "172577      1\n",
      "386585      1\n",
      "231604      1\n",
      "168009      1\n",
      "406051      1\n",
      "264740      1\n",
      "232666      1\n",
      "108947      1\n",
      "168340      1\n",
      "192973      1\n",
      "415578      1\n",
      "186126      1\n",
      "126233      1\n",
      "220943      1\n",
      "296724      1\n",
      "53628       1\n",
      "206974      1\n",
      "136982      1\n",
      "87583       1\n",
      "200469      1\n",
      "115070      1\n",
      "187934      1\n",
      "162094      1\n",
      "209280      1\n",
      "383518      1\n",
      "442131      1\n",
      "177773      1\n",
      "208657      1\n",
      "287986      1\n",
      "301606      1\n",
      "59944       1\n",
      "98726       1\n",
      "175873      1\n",
      "243442      1\n",
      "195661      1\n",
      "57071       1\n",
      "343014      1\n",
      "313546      1\n",
      "90230       1\n",
      "184045      1\n",
      "216937      1\n",
      "219775      1\n",
      "207267      1\n",
      "119254      1\n",
      "31290       1\n",
      "63210       1\n",
      "203173      1\n",
      "150076      1\n",
      "41521       1\n",
      "217647      1\n",
      "245491      1\n",
      "315804      1\n",
      "337664      1\n",
      "127384      1\n",
      "189399      1\n",
      "302347      1\n",
      "268952      1\n",
      "138999      1\n",
      "121245      1\n",
      "176544      1\n",
      "182661      1\n",
      "325179      1\n",
      "182828      1\n",
      "344621      1\n",
      "198388      1\n",
      "55854       1\n",
      "110884      1\n",
      "73161       1\n",
      "126513      1\n",
      "148489      1\n",
      "46087       1\n",
      "304133      1\n",
      "62463       1\n",
      "162814      1\n",
      "60412       1\n",
      "178140      1\n",
      "113654      1\n",
      "41973       1\n",
      "241857      1\n",
      "113929      1\n",
      "164849      1\n",
      "156653      1\n",
      "125932      1\n",
      "381931      1\n",
      "84977       1\n",
      "103395      1\n",
      "166880      1\n",
      "361742      1\n",
      "414683      1\n",
      "213977      1\n",
      "150488      1\n",
      "116903      1\n",
      "39890       1\n",
      "424478      1\n",
      "82889       1\n",
      "248776      1\n",
      "175044      1\n",
      "373606      1\n",
      "353213      1\n",
      "183304      1\n",
      "152587      1\n",
      "242615      1\n",
      "254989      1\n",
      "245029      1\n",
      "141545      1\n",
      "123965      1\n",
      "388156      1\n",
      "210082      1\n",
      "246841      1\n",
      "117816      1\n",
      "308279      1\n",
      "101452      1\n",
      "130813      1\n",
      "37939       1\n",
      "134192      1\n",
      "160815      1\n",
      "257068      1\n",
      "123157      1\n",
      "541737      1\n",
      "150568      1\n",
      "95917       1\n",
      "242089      1\n",
      "240676      1\n",
      "201763      1\n",
      "197665      1\n",
      "180439      1\n",
      "119835      1\n",
      "105748      1\n",
      "150264      1\n",
      "232997      1\n",
      "230417      1\n",
      "259087      1\n",
      "256956      1\n",
      "289190      1\n",
      "352712      1\n",
      "308087      1\n",
      "385901      1\n",
      "154474      1\n",
      "253841      1\n",
      "566117      1\n",
      "371556      1\n",
      "267107      1\n",
      "203492      1\n",
      "282389      1\n",
      "324011      1\n",
      "189277      1\n",
      "191324      1\n",
      "136244      1\n",
      "281432      1\n",
      "502752      1\n",
      "240468      1\n",
      "213249      1\n",
      "197457      1\n",
      "254797      1\n",
      "217077      1\n",
      "241616      1\n",
      "181065      1\n",
      "84808       1\n",
      "80710       1\n",
      "219307      1\n",
      "76612       1\n",
      "155021      1\n",
      "254781      1\n",
      "115513      1\n",
      "375606      1\n",
      "160623      1\n",
      "379768      1\n",
      "246183      1\n",
      "410489      1\n",
      "115700      1\n",
      "197553      1\n",
      "188856      1\n",
      "110563      1\n",
      "239833      1\n",
      "154538      1\n",
      "209831      1\n",
      "210443      1\n",
      "201635      1\n",
      "100651      1\n",
      "134048      1\n",
      "195486      1\n",
      "91037       1\n",
      "381851      1\n",
      "312242      1\n",
      "84888       1\n",
      "121634      1\n",
      "172949      1\n",
      "103315      1\n",
      "72594       1\n",
      "129934      1\n",
      "256908      1\n",
      "129674      1\n",
      "254500      1\n",
      "269186      1\n",
      "164737      1\n",
      "124942      1\n",
      "123773      1\n",
      "283515      1\n",
      "232512      1\n",
      "146244      1\n",
      "200947      1\n",
      "140581      1\n",
      "159048      1\n",
      "279833      1\n",
      "85272       1\n",
      "111895      1\n",
      "172960      1\n",
      "44308       1\n",
      "236818      1\n",
      "421132      1\n",
      "220426      1\n",
      "249096      1\n",
      "179462      1\n",
      "123092      1\n",
      "240900      1\n",
      "234755      1\n",
      "230657      1\n",
      "276075      1\n",
      "126204      1\n",
      "447739      1\n",
      "275703      1\n",
      "179446      1\n",
      "664821      1\n",
      "169203      1\n",
      "118565      1\n",
      "348986      1\n",
      "68848       1\n",
      "131620      1\n",
      "419053      1\n",
      "158956      1\n",
      "54507       1\n",
      "226198      1\n",
      "19752       1\n",
      "281832      1\n",
      "217864      1\n",
      "111959      1\n",
      "215251      1\n",
      "304469      1\n",
      "175444      1\n",
      "232784      1\n",
      "292175      1\n",
      "290124      1\n",
      "415051      1\n",
      "279881      1\n",
      "118088      1\n",
      "144711      1\n",
      "245062      1\n",
      "175428      1\n",
      "183345      1\n",
      "95551       1\n",
      "64830       1\n",
      "484669      1\n",
      "126268      1\n",
      "181561      1\n",
      "183608      1\n",
      "81206       1\n",
      "167334      1\n",
      "204082      1\n",
      "357679      1\n",
      "261422      1\n",
      "296516      1\n",
      "212185      1\n",
      "152875      1\n",
      "201631      1\n",
      "86701       1\n",
      "360491      1\n",
      "173125      1\n",
      "115849      1\n",
      "259612      1\n",
      "247156      1\n",
      "126076      1\n",
      "159759      1\n",
      "504951      1\n",
      "369781      1\n",
      "207988      1\n",
      "192812      1\n",
      "161415      1\n",
      "29807       1\n",
      "261230      1\n",
      "100479      1\n",
      "152683      1\n",
      "109209      1\n",
      "281704      1\n",
      "195946      1\n",
      "268832      1\n",
      "76900       1\n",
      "37987       1\n",
      "334946      1\n",
      "31838       1\n",
      "447579      1\n",
      "183384      1\n",
      "113750      1\n",
      "42069       1\n",
      "44116       1\n",
      "171090      1\n",
      "227466      1\n",
      "213431      1\n",
      "212102      1\n",
      "287598      1\n",
      "503012      1\n",
      "355468      1\n",
      "217743      1\n",
      "232672      1\n",
      "137229      1\n",
      "106103      1\n",
      "77927       1\n",
      "326862      1\n",
      "347336      1\n",
      "441542      1\n",
      "76996       1\n",
      "169155      1\n",
      "111795      1\n",
      "141323      1\n",
      "122042      1\n",
      "153536      1\n",
      "117944      1\n",
      "438139      1\n",
      "199856      1\n",
      "279721      1\n",
      "46247       1\n",
      "285367      1\n",
      "195329      1\n",
      "53135       1\n",
      "105119      1\n",
      "388252      1\n",
      "220314      1\n",
      "196858      1\n",
      "386331      1\n",
      "156805      1\n",
      "82077       1\n",
      "338740      1\n",
      "463667      1\n",
      "203570      1\n",
      "276934      1\n",
      "88506       1\n",
      "248248      1\n",
      "438711      1\n",
      "207284      1\n",
      "135603      1\n",
      "306164      1\n",
      "223257      1\n",
      "63918       1\n",
      "310014      1\n",
      "157308      1\n",
      "383402      1\n",
      "41381       1\n",
      "76196       1\n",
      "233891      1\n",
      "75855       1\n",
      "166304      1\n",
      "61855       1\n",
      "31842       1\n",
      "248978      1\n",
      "294009      1\n",
      "403860      1\n",
      "131473      1\n",
      "133520      1\n",
      "160143      1\n",
      "46786       1\n",
      "285066      1\n",
      "57426       1\n",
      "211334      1\n",
      "104834      1\n",
      "31166       1\n",
      "221166      1\n",
      "184699      1\n",
      "53707       1\n",
      "188941      1\n",
      "186890      1\n",
      "115209      1\n",
      "182792      1\n",
      "176647      1\n",
      "33373       1\n",
      "175653      1\n",
      "188925      1\n",
      "88570       1\n",
      "49657       1\n",
      "244214      1\n",
      "170482      1\n",
      "100168      1\n",
      "293358      1\n",
      "188909      1\n",
      "204900      1\n",
      "76281       1\n",
      "137698      1\n",
      "166368      1\n",
      "127455      1\n",
      "549341      1\n",
      "219535      1\n",
      "145308      1\n",
      "570562      1\n",
      "235986      1\n",
      "98769       1\n",
      "52138       1\n",
      "96718       1\n",
      "254413      1\n",
      "31102       1\n",
      "55674       1\n",
      "166704      1\n",
      "381741      1\n",
      "205109      1\n",
      "52647       1\n",
      "233779      1\n",
      "137522      1\n",
      "61743       1\n",
      "150768      1\n",
      "208266      1\n",
      "65481       1\n",
      "252202      1\n",
      "637222      1\n",
      "338212      1\n",
      "137506      1\n",
      "297248      1\n",
      "155933      1\n",
      "92444       1\n",
      "178207      1\n",
      "114969      1\n",
      "110871      1\n",
      "211222      1\n",
      "380633      1\n",
      "164113      1\n",
      "162030      1\n",
      "106330      1\n",
      "344329      1\n",
      "84232       1\n",
      "239876      1\n",
      "188669      1\n",
      "315643      1\n",
      "71823       1\n",
      "96460       1\n",
      "119099      1\n",
      "82297       1\n",
      "452924      1\n",
      "170354      1\n",
      "229745      1\n",
      "184416      1\n",
      "210750      1\n",
      "53611       1\n",
      "55658       1\n",
      "344425      1\n",
      "47462       1\n",
      "270693      1\n",
      "422013      1\n",
      "229729      1\n",
      "264544      1\n",
      "94559       1\n",
      "221533      1\n",
      "223580      1\n",
      "182616      1\n",
      "244054      1\n",
      "37203       1\n",
      "137554      1\n",
      "196945      1\n",
      "297296      1\n",
      "194894      1\n",
      "155981      1\n",
      "159876      1\n",
      "102723      1\n",
      "39234       1\n",
      "359327      1\n",
      "225599      1\n",
      "107108      1\n",
      "245199      1\n",
      "141272      1\n",
      "390867      1\n",
      "115433      1\n",
      "176871      1\n",
      "240356      1\n",
      "168675      1\n",
      "295649      1\n",
      "150566      1\n",
      "82649       1\n",
      "139989      1\n",
      "66872       1\n",
      "234195      1\n",
      "367314      1\n",
      "193166      1\n",
      "289484      1\n",
      "545483      1\n",
      "398019      1\n",
      "301762      1\n",
      "131777      1\n",
      "35520       1\n",
      "29375       1\n",
      "108256      1\n",
      "289468      1\n",
      "185019      1\n",
      "470368      1\n",
      "148153      1\n",
      "244406      1\n",
      "205493      1\n",
      "164529      1\n",
      "193199      1\n",
      "225860      1\n",
      "82601       1\n",
      "51944       1\n",
      "333296      1\n",
      "176663      1\n",
      "75890       1\n",
      "165304      1\n",
      "162606      1\n",
      "254765      1\n",
      "158508      1\n",
      "281384      1\n",
      "78631       1\n",
      "153127      1\n",
      "203554      1\n",
      "363296      1\n",
      "123677      1\n",
      "375574      1\n",
      "384651      1\n",
      "168723      1\n",
      "295697      1\n",
      "194746      1\n",
      "137646      1\n",
      "74501       1\n",
      "147884      1\n",
      "114150      1\n",
      "262642      1\n",
      "379525      1\n",
      "156413      1\n",
      "256764      1\n",
      "41809       1\n",
      "294064      1\n",
      "43764       1\n",
      "398067      1\n",
      "269042      1\n",
      "101104      1\n",
      "84648       1\n",
      "172709      1\n",
      "196107      1\n",
      "39586       1\n",
      "35424       1\n",
      "74538       1\n",
      "283227      1\n",
      "252506      1\n",
      "412248      1\n",
      "176727      1\n",
      "201299      1\n",
      "282394      1\n",
      "53835       1\n",
      "186954      1\n",
      "49737       1\n",
      "215624      1\n",
      "47686       1\n",
      "80167       1\n",
      "98881       1\n",
      "24344       1\n",
      "377401      1\n",
      "231991      1\n",
      "266803      1\n",
      "195118      1\n",
      "287277      1\n",
      "59948       1\n",
      "82473       1\n",
      "211494      1\n",
      "206325      1\n",
      "254493      1\n",
      "59932       1\n",
      "121370      1\n",
      "29306       1\n",
      "131681      1\n",
      "277471      1\n",
      "234083      1\n",
      "117651      1\n",
      "695411      1\n",
      "264864      1\n",
      "157673      1\n",
      "111066      1\n",
      "318106      1\n",
      "148121      1\n",
      "275095      1\n",
      "189368      1\n",
      "293941      1\n",
      "491862      1\n",
      "316043      1\n",
      "124648      1\n",
      "43652       1\n",
      "244372      1\n",
      "192670      1\n",
      "213625      1\n",
      "331875      1\n",
      "45687       1\n",
      "211574      1\n",
      "371316      1\n",
      "98929       1\n",
      "130795      1\n",
      "182907      1\n",
      "256620      1\n",
      "152171      1\n",
      "285290      1\n",
      "279145      1\n",
      "51816       1\n",
      "116057      1\n",
      "185691      1\n",
      "44694       1\n",
      "333953      1\n",
      "35065       1\n",
      "182395      1\n",
      "186489      1\n",
      "282744      1\n",
      "110213      1\n",
      "407669      1\n",
      "176244      1\n",
      "166003      1\n",
      "141838      1\n",
      "90222       1\n",
      "250585      1\n",
      "186473      1\n",
      "184424      1\n",
      "237670      1\n",
      "100451      1\n",
      "36960       1\n",
      "223327      1\n",
      "319582      1\n",
      "30813       1\n",
      "223237      1\n",
      "145493      1\n",
      "170065      1\n",
      "150874      1\n",
      "190543      1\n",
      "39844       1\n",
      "258124      1\n",
      "172152      1\n",
      "106566      1\n",
      "145477      1\n",
      "311446      1\n",
      "266598      1\n",
      "358461      1\n",
      "177465      1\n",
      "127918      1\n",
      "164018      1\n",
      "39089       1\n",
      "60890       1\n",
      "419554      1\n",
      "194733      1\n",
      "192684      1\n",
      "208321      1\n",
      "183110      1\n",
      "88233       1\n",
      "305319      1\n",
      "270502      1\n",
      "235307      1\n",
      "210008      1\n",
      "98466       1\n",
      "122745      1\n",
      "199452      1\n",
      "90270       1\n",
      "94364       1\n",
      "177057      1\n",
      "73773       1\n",
      "325461      1\n",
      "99891       1\n",
      "86332       1\n",
      "135312      1\n",
      "387215      1\n",
      "61580       1\n",
      "180362      1\n",
      "206983      1\n",
      "66434       1\n",
      "192572      1\n",
      "306460      1\n",
      "92141       1\n",
      "57322       1\n",
      "313321      1\n",
      "278502      1\n",
      "169955      1\n",
      "253914      1\n",
      "345285      1\n",
      "538583      1\n",
      "186784      1\n",
      "159641      1\n",
      "171986      1\n",
      "231377      1\n",
      "255949      1\n",
      "94156       1\n",
      "340475      1\n",
      "809585      1\n",
      "141253      1\n",
      "77764       1\n",
      "366531      1\n",
      "434114      1\n",
      "155259      1\n",
      "261646      1\n",
      "92093       1\n",
      "257980      1\n",
      "30908       1\n",
      "147251      1\n",
      "262062      1\n",
      "267426      1\n",
      "316298      1\n",
      "118696      1\n",
      "284651      1\n",
      "129007      1\n",
      "51259       1\n",
      "303090      1\n",
      "112693      1\n",
      "163890      1\n",
      "464945      1\n",
      "659504      1\n",
      "240458      1\n",
      "154083      1\n",
      "159788      1\n",
      "345780      1\n",
      "49194       1\n",
      "337693      1\n",
      "370727      1\n",
      "204838      1\n",
      "43003       1\n",
      "124959      1\n",
      "120857      1\n",
      "544792      1\n",
      "196626      1\n",
      "184581      1\n",
      "215039      1\n",
      "358631      1\n",
      "138816      1\n",
      "118792      1\n",
      "127117      1\n",
      "196610      1\n",
      "235521      1\n",
      "331776      1\n",
      "312446      1\n",
      "210935      1\n",
      "141301      1\n",
      "112821      1\n",
      "172214      1\n",
      "151736      1\n",
      "262872      1\n",
      "221550      1\n",
      "29036       1\n",
      "213354      1\n",
      "207207      1\n",
      "322238      1\n",
      "143716      1\n",
      "122075      1\n",
      "168288      1\n",
      "352606      1\n",
      "31069       1\n",
      "280923      1\n",
      "348504      1\n",
      "303446      1\n",
      "209236      1\n",
      "98642       1\n",
      "366929      1\n",
      "218361      1\n",
      "256335      1\n",
      "90446       1\n",
      "31053       1\n",
      "179915      1\n",
      "189565      1\n",
      "251923      1\n",
      "38645       1\n",
      "74054       1\n",
      "47429       1\n",
      "100675      1\n",
      "171429      1\n",
      "137537      1\n",
      "33138       1\n",
      "110964      1\n",
      "114874      1\n",
      "184787      1\n",
      "170458      1\n",
      "45508       1\n",
      "166339      1\n",
      "197058      1\n",
      "182715      1\n",
      "70387       1\n",
      "186809      1\n",
      "30565       1\n",
      "98738       1\n",
      "212780      1\n",
      "110669      1\n",
      "27243       1\n",
      "99388       1\n",
      "33186       1\n",
      "203169      1\n",
      "352196      1\n",
      "278938      1\n",
      "303510      1\n",
      "211349      1\n",
      "212125      1\n",
      "104849      1\n",
      "193818      1\n",
      "18827       1\n",
      "104661      1\n",
      "59231       1\n",
      "196994      1\n",
      "233856      1\n",
      "225660      1\n",
      "68461       1\n",
      "254270      1\n",
      "436361      1\n",
      "393673      1\n",
      "129775      1\n",
      "314240      1\n",
      "104413      1\n",
      "125167      1\n",
      "260333      1\n",
      "291052      1\n",
      "186601      1\n",
      "54257       1\n",
      "108775      1\n",
      "145637      1\n",
      "100579      1\n",
      "33423       1\n",
      "456062      1\n",
      "192732      1\n",
      "357933      1\n",
      "1038553     1\n",
      "217304      1\n",
      "172246      1\n",
      "78036       1\n",
      "198867      1\n",
      "164050      1\n",
      "124604      1\n",
      "215243      1\n",
      "88265       1\n",
      "172230      1\n",
      "203061      1\n",
      "231619      1\n",
      "65730       1\n",
      "57534       1\n",
      "161981      1\n",
      "178421      1\n",
      "217802      1\n",
      "252153      1\n",
      "354591      1\n",
      "151864      1\n",
      "172342      1\n",
      "261504      1\n",
      "90414       1\n",
      "194861      1\n",
      "225580      1\n",
      "180522      1\n",
      "207140      1\n",
      "188154      1\n",
      "375077      1\n",
      "274724      1\n",
      "61435       1\n",
      "200992      1\n",
      "352542      1\n",
      "197875      1\n",
      "149787      1\n",
      "114648      1\n",
      "495888      1\n",
      "92431       1\n",
      "225548      1\n",
      "182539      1\n",
      "174343      1\n",
      "48935       1\n",
      "217404      1\n",
      "31725       1\n",
      "268545      1\n",
      "190719      1\n",
      "385278      1\n",
      "141221      1\n",
      "199908      1\n",
      "289257      1\n",
      "194095      1\n",
      "247337      1\n",
      "108069      1\n",
      "175652      1\n",
      "161311      1\n",
      "196126      1\n",
      "24090       1\n",
      "247321      1\n",
      "249368      1\n",
      "206357      1\n",
      "77332       1\n",
      "273536      1\n",
      "344742      1\n",
      "176648      1\n",
      "660870      1\n",
      "248476      1\n",
      "161279      1\n",
      "224541      1\n",
      "484861      1\n",
      "93955       1\n",
      "349691      1\n",
      "158963      1\n",
      "214521      1\n",
      "127003      1\n",
      "216552      1\n",
      "402306      1\n",
      "34273       1\n",
      "85767       1\n",
      "211880      1\n",
      "257500      1\n",
      "153131      1\n",
      "240183      1\n",
      "297531      1\n",
      "157786      1\n",
      "117253      1\n",
      "452205      1\n",
      "119176      1\n",
      "212582      1\n",
      "197163      1\n",
      "139850      1\n",
      "132705      1\n",
      "321117      1\n",
      "87643       1\n",
      "89690       1\n",
      "29571       1\n",
      "110164      1\n",
      "67153       1\n",
      "128591      1\n",
      "196174      1\n",
      "191062      1\n",
      "286282      1\n",
      "68658       1\n",
      "347720      1\n",
      "140869      1\n",
      "208452      1\n",
      "104003      1\n",
      "466498      1\n",
      "165441      1\n",
      "30271       1\n",
      "91709       1\n",
      "192060      1\n",
      "351802      1\n",
      "80511       1\n",
      "120283      1\n",
      "148953      1\n",
      "223133      1\n",
      "345497      1\n",
      "215288      1\n",
      "188736      1\n",
      "437666      1\n",
      "325007      1\n",
      "157069      1\n",
      "181641      1\n",
      "85384       1\n",
      "81286       1\n",
      "271749      1\n",
      "404868      1\n",
      "359796      1\n",
      "132481      1\n",
      "179761      1\n",
      "164920      1\n",
      "294270      1\n",
      "122234      1\n",
      "473171      1\n",
      "269455      1\n",
      "210295      1\n",
      "179574      1\n",
      "181822      1\n",
      "205528      1\n",
      "99697       1\n",
      "167280      1\n",
      "128367      1\n",
      "340599      1\n",
      "91501       1\n",
      "73986       1\n",
      "138594      1\n",
      "187450      1\n",
      "54683       1\n",
      "277974      1\n",
      "60828       1\n",
      "273876      1\n",
      "198097      1\n",
      "151801      1\n",
      "292303      1\n",
      "352005      1\n",
      "191948      1\n",
      "191893      1\n",
      "259585      1\n",
      "140741      1\n",
      "28952       1\n",
      "239723      1\n",
      "193769      1\n",
      "157117      1\n",
      "218555      1\n",
      "279183      1\n",
      "191722      1\n",
      "179638      1\n",
      "175540      1\n",
      "223206      1\n",
      "175820      1\n",
      "205829      1\n",
      "379418      1\n",
      "355756      1\n",
      "83580       1\n",
      "376230      1\n",
      "206199      1\n",
      "38307       1\n",
      "298400      1\n",
      "82578       1\n",
      "201022      1\n",
      "267891      1\n",
      "142964      1\n",
      "118600      1\n",
      "212806      1\n",
      "171231      1\n",
      "225779      1\n",
      "128831      1\n",
      "458558      1\n",
      "137952      1\n",
      "118261      1\n",
      "118584      1\n",
      "31532       1\n",
      "75573       1\n",
      "274228      1\n",
      "399155      1\n",
      "130413      1\n",
      "134960      1\n",
      "155434      1\n",
      "204123      1\n",
      "272165      1\n",
      "241444      1\n",
      "331552      1\n",
      "292639      1\n",
      "117700      1\n",
      "89737       1\n",
      "156501      1\n",
      "276247      1\n",
      "36885       1\n",
      "268051      1\n",
      "219841      1\n",
      "328776      1\n",
      "251659      1\n",
      "210338      1\n",
      "182089      1\n",
      "165466      1\n",
      "313835      1\n",
      "157236      1\n",
      "25631       1\n",
      "243607      1\n",
      "110714      1\n",
      "296849      1\n",
      "163726      1\n",
      "35224       1\n",
      "149385      1\n",
      "216968      1\n",
      "106538      1\n",
      "61308       1\n",
      "267967      1\n",
      "83439       1\n",
      "145271      1\n",
      "206049      1\n",
      "38771       1\n",
      "243030      1\n",
      "200560      1\n",
      "212838      1\n",
      "239461      1\n",
      "137059      1\n",
      "70623       1\n",
      "266080      1\n",
      "30559       1\n",
      "327518      1\n",
      "186203      1\n",
      "35373       1\n",
      "1226583     1\n",
      "226374      1\n",
      "372484      1\n",
      "79539       1\n",
      "117802      1\n",
      "345789      1\n",
      "306868      1\n",
      "302770      1\n",
      "280960      1\n",
      "456367      1\n",
      "124589      1\n",
      "357437      1\n",
      "382635      1\n",
      "319146      1\n",
      "149161      1\n",
      "38563       1\n",
      "192237      1\n",
      "200352      1\n",
      "226975      1\n",
      "355996      1\n",
      "120475      1\n",
      "56986       1\n",
      "52888       1\n",
      "42645       1\n",
      "247779      1\n",
      "128086      1\n",
      "97934       1\n",
      "22155       1\n",
      "411273      1\n",
      "234500      1\n",
      "112263      1\n",
      "339588      1\n",
      "132737      1\n",
      "226943      1\n",
      "192201      1\n",
      "651396      1\n",
      "332666      1\n",
      "444089      1\n",
      "278230      1\n",
      "204577      1\n",
      "315128      1\n",
      "40690       1\n",
      "198385      1\n",
      "36592       1\n",
      "218729      1\n",
      "57066       1\n",
      "472807      1\n",
      "206565      1\n",
      "377283      1\n",
      "102112      1\n",
      "390879      1\n",
      "258735      1\n",
      "71379       1\n",
      "93884       1\n",
      "102096      1\n",
      "456399      1\n",
      "284120      1\n",
      "222925      1\n",
      "388812      1\n",
      "253642      1\n",
      "332194      1\n",
      "303291      1\n",
      "272069      1\n",
      "231105      1\n",
      "101260      1\n",
      "32446       1\n",
      "172684      1\n",
      "169679      1\n",
      "202994      1\n",
      "144301      1\n",
      "265077      1\n",
      "195327      1\n",
      "58108       1\n",
      "279288      1\n",
      "271092      1\n",
      "369387      1\n",
      "260847      1\n",
      "291566      1\n",
      "355053      1\n",
      "187115      1\n",
      "279272      1\n",
      "242406      1\n",
      "236008      1\n",
      "219867      1\n",
      "213720      1\n",
      "172756      1\n",
      "102889      1\n",
      "175587      1\n",
      "101073      1\n",
      "96975       1\n",
      "148952      1\n",
      "134113      1\n",
      "283338      1\n",
      "212407      1\n",
      "172740      1\n",
      "291518      1\n",
      "287420      1\n",
      "146103      1\n",
      "137907      1\n",
      "68273       1\n",
      "204018      1\n",
      "74500       1\n",
      "246440      1\n",
      "240389      1\n",
      "401451      1\n",
      "287548      1\n",
      "21306       1\n",
      "29828       1\n",
      "72812       1\n",
      "201522      1\n",
      "197424      1\n",
      "176189      1\n",
      "154411      1\n",
      "220860      1\n",
      "181032      1\n",
      "111398      1\n",
      "126142      1\n",
      "205604      1\n",
      "236323      1\n",
      "387335      1\n",
      "52052       1\n",
      "110538      1\n",
      "119578      1\n",
      "117529      1\n",
      "312088      1\n",
      "188729      1\n",
      "207637      1\n",
      "401333      1\n",
      "199441      1\n",
      "424719      1\n",
      "219814      1\n",
      "115464      1\n",
      "178951      1\n",
      "152234      1\n",
      "47783       1\n",
      "209423      1\n",
      "150121      1\n",
      "174693      1\n",
      "191497      1\n",
      "465507      1\n",
      "126117      1\n",
      "295520      1\n",
      "191069      1\n",
      "290609      1\n",
      "53850       1\n",
      "313945      1\n",
      "251694      1\n",
      "54411       1\n",
      "170579      1\n",
      "280699      1\n",
      "166481      1\n",
      "402367      1\n",
      "396482      1\n",
      "84553       1\n",
      "82504       1\n",
      "172612      1\n",
      "170563      1\n",
      "168514      1\n",
      "27620       1\n",
      "295488      1\n",
      "617021      1\n",
      "154171      1\n",
      "340534      1\n",
      "270147      1\n",
      "129583      1\n",
      "92717       1\n",
      "410216      1\n",
      "447882      1\n",
      "271012      1\n",
      "141745      1\n",
      "72355       1\n",
      "239954      1\n",
      "293535      1\n",
      "324254      1\n",
      "184986      1\n",
      "76437       1\n",
      "259882      1\n",
      "367251      1\n",
      "299399      1\n",
      "55508       1\n",
      "156300      1\n",
      "424884      1\n",
      "115336      1\n",
      "537222      1\n",
      "126845      1\n",
      "300404      1\n",
      "31359       1\n",
      "461715      1\n",
      "158333      1\n",
      "320124      1\n",
      "154235      1\n",
      "265917      1\n",
      "281209      1\n",
      "295991      1\n",
      "404085      1\n",
      "205428      1\n",
      "137843      1\n",
      "199281      1\n",
      "272471      1\n",
      "195690      1\n",
      "88449       1\n",
      "98545       1\n",
      "324654      1\n",
      "154667      1\n",
      "343079      1\n",
      "176795      1\n",
      "136226      1\n",
      "93213       1\n",
      "209942      1\n",
      "116044      1\n",
      "42004       1\n",
      "105491      1\n",
      "340899      1\n",
      "157473      1\n",
      "185354      1\n",
      "242147      1\n",
      "173674      1\n",
      "472070      1\n",
      "334105      1\n",
      "234328      1\n",
      "122971      1\n",
      "264526      1\n",
      "261119      1\n",
      "388093      1\n",
      "113094      1\n",
      "89083       1\n",
      "214008      1\n",
      "340982      1\n",
      "113987      1\n",
      "43235       1\n",
      "199665      1\n",
      "92733       1\n",
      "297054      1\n",
      "228399      1\n",
      "209894      1\n",
      "279608      1\n",
      "55636       1\n",
      "117865      1\n",
      "214120      1\n",
      "472166      1\n",
      "76901       1\n",
      "107620      1\n",
      "167009      1\n",
      "130143      1\n",
      "257117      1\n",
      "156764      1\n",
      "285787      1\n",
      "69151       1\n",
      "228921      1\n",
      "94477       1\n",
      "97165       1\n",
      "33394       1\n",
      "202226      1\n",
      "322789      1\n",
      "253003      1\n",
      "179271      1\n",
      "565313      1\n",
      "214117      1\n",
      "182470      1\n",
      "99392       1\n",
      "32312       1\n",
      "193598      1\n",
      "56004       1\n",
      "123964      1\n",
      "300783      1\n",
      "183273      1\n",
      "404453      1\n",
      "208478      1\n",
      "95462       1\n",
      "97167       1\n",
      "29582       1\n",
      "217994      1\n",
      "187873      1\n",
      "29083       1\n",
      "174981      1\n",
      "140164      1\n",
      "267138      1\n",
      "53588       1\n",
      "162687      1\n",
      "191357      1\n",
      "199499      1\n",
      "109532      1\n",
      "209782      1\n",
      "203635      1\n",
      "101233      1\n",
      "263024      1\n",
      "60269       1\n",
      "153788      1\n",
      "116218      1\n",
      "108815      1\n",
      "120773      1\n",
      "133985      1\n",
      "166502      1\n",
      "93021       1\n",
      "165479      1\n",
      "241745      1\n",
      "230816      1\n",
      "201554      1\n",
      "234386      1\n",
      "363425      1\n",
      "170979      1\n",
      "70562       1\n",
      "136162      1\n",
      "64479       1\n",
      "187355      1\n",
      "50136       1\n",
      "373718      1\n",
      "308373      1\n",
      "97231       1\n",
      "183241      1\n",
      "112795      1\n",
      "111558      1\n",
      "404421      1\n",
      "107460      1\n",
      "404601      1\n",
      "97215       1\n",
      "189610      1\n",
      "186266      1\n",
      "126677      1\n",
      "48055       1\n",
      "471990      1\n",
      "105694      1\n",
      "99248       1\n",
      "41400       1\n",
      "95150       1\n",
      "293809      1\n",
      "68006       1\n",
      "119722      1\n",
      "150441      1\n",
      "317083      1\n",
      "170915      1\n",
      "221740      1\n",
      "301911      1\n",
      "342567      1\n",
      "192702      1\n",
      "184506      1\n",
      "51385       1\n",
      "147640      1\n",
      "176227      1\n",
      "143542      1\n",
      "268392      1\n",
      "84661       1\n",
      "225454      1\n",
      "125101      1\n",
      "284843      1\n",
      "143526      1\n",
      "239781      1\n",
      "168098      1\n",
      "393376      1\n",
      "94366       1\n",
      "118938      1\n",
      "112791      1\n",
      "95864       1\n",
      "370837      1\n",
      "41108       1\n",
      "231569      1\n",
      "393360      1\n",
      "424079      1\n",
      "256141      1\n",
      "344200      1\n",
      "238184      1\n",
      "196736      1\n",
      "129151      1\n",
      "94334       1\n",
      "118947      1\n",
      "96824       1\n",
      "217210      1\n",
      "193871      1\n",
      "523067      1\n",
      "182521      1\n",
      "140673      1\n",
      "100593      1\n",
      "105779      1\n",
      "703067      1\n",
      "125165      1\n",
      "123116      1\n",
      "35015       1\n",
      "112871      1\n",
      "174309      1\n",
      "182643      1\n",
      "129387      1\n",
      "227551      1\n",
      "148392      1\n",
      "201319      1\n",
      "225317      1\n",
      "311512      1\n",
      "309463      1\n",
      "368852      1\n",
      "67793       1\n",
      "207246      1\n",
      "157901      1\n",
      "123084      1\n",
      "49352       1\n",
      "374983      1\n",
      "78022       1\n",
      "108741      1\n",
      "235829      1\n",
      "69758       1\n",
      "178295      1\n",
      "265192      1\n",
      "195508      1\n",
      "145463      1\n",
      "237620      1\n",
      "224472      1\n",
      "189719      1\n",
      "133169      1\n",
      "393264      1\n",
      "124973      1\n",
      "121265      1\n",
      "540712      1\n",
      "96080       1\n",
      "170019      1\n",
      "395297      1\n",
      "393248      1\n",
      "30751       1\n",
      "155676      1\n",
      "231357      1\n",
      "477209      1\n",
      "120163      1\n",
      "172052      1\n",
      "333843      1\n",
      "233490      1\n",
      "225394      1\n",
      "260111      1\n",
      "225294      1\n",
      "288781      1\n",
      "221196      1\n",
      "251915      1\n",
      "176134      1\n",
      "208174      1\n",
      "180280      1\n",
      "34626       1\n",
      "436341      1\n",
      "188476      1\n",
      "434292      1\n",
      "200818      1\n",
      "198769      1\n",
      "154981      1\n",
      "94318       1\n",
      "286732      1\n",
      "57452       1\n",
      "217194      1\n",
      "321856      1\n",
      "35662       1\n",
      "282721      1\n",
      "174181      1\n",
      "200802      1\n",
      "179484      1\n",
      "321629      1\n",
      "284763      1\n",
      "344152      1\n",
      "240951      1\n",
      "91608       1\n",
      "299090      1\n",
      "159822      1\n",
      "141706      1\n",
      "219211      1\n",
      "180296      1\n",
      "274502      1\n",
      "217902      1\n",
      "329793      1\n",
      "262208      1\n",
      "487486      1\n",
      "57596       1\n",
      "192766      1\n",
      "43269       1\n",
      "44503       1\n",
      "145879      1\n",
      "106964      1\n",
      "136935      1\n",
      "164593      1\n",
      "39363       1\n",
      "133569      1\n",
      "98752       1\n",
      "260543      1\n",
      "190909      1\n",
      "350651      1\n",
      "315834      1\n",
      "307638      1\n",
      "210142      1\n",
      "137651      1\n",
      "168370      1\n",
      "352640      1\n",
      "94638       1\n",
      "27053       1\n",
      "385452      1\n",
      "342494      1\n",
      "68001       1\n",
      "160158      1\n",
      "27037       1\n",
      "60688       1\n",
      "188545      1\n",
      "180632      1\n",
      "175441      1\n",
      "207253      1\n",
      "205204      1\n",
      "227669      1\n",
      "125405      1\n",
      "156229      1\n",
      "131552      1\n",
      "334787      1\n",
      "262688      1\n",
      "289309      1\n",
      "182809      1\n",
      "113175      1\n",
      "336404      1\n",
      "37394       1\n",
      "157593      1\n",
      "172407      1\n",
      "215862      1\n",
      "38352       1\n",
      "174597      1\n",
      "361341      1\n",
      "276369      1\n",
      "233472      1\n",
      "393728      1\n",
      "168355      1\n",
      "217424      1\n",
      "440607      1\n",
      "248313      1\n",
      "187770      1\n",
      "238068      1\n",
      "170483      1\n",
      "30619       1\n",
      "53738       1\n",
      "115176      1\n",
      "276967      1\n",
      "141797      1\n",
      "201186      1\n",
      "133327      1\n",
      "61838       1\n",
      "350603      1\n",
      "53642       1\n",
      "108390      1\n",
      "39324       1\n",
      "104359      1\n",
      "33088       1\n",
      "487742      1\n",
      "416059      1\n",
      "196025      1\n",
      "178487      1\n",
      "45366       1\n",
      "207157      1\n",
      "291665      1\n",
      "166193      1\n",
      "196912      1\n",
      "190765      1\n",
      "113106      1\n",
      "211239      1\n",
      "266530      1\n",
      "106957      1\n",
      "252187      1\n",
      "86298       1\n",
      "238384      1\n",
      "45334       1\n",
      "43285       1\n",
      "235795      1\n",
      "314347      1\n",
      "193748      1\n",
      "354573      1\n",
      "483596      1\n",
      "149769      1\n",
      "141637      1\n",
      "112967      1\n",
      "217418      1\n",
      "450924      1\n",
      "197050      1\n",
      "209286      1\n",
      "205188      1\n",
      "65920       1\n",
      "387468      1\n",
      "223613      1\n",
      "22907       1\n",
      "184698      1\n",
      "129853      1\n",
      "145011      1\n",
      "86483       1\n",
      "235891      1\n",
      "231793      1\n",
      "153963      1\n",
      "153931      1\n",
      "149865      1\n",
      "248834      1\n",
      "192862      1\n",
      "26973       1\n",
      "356823      1\n",
      "246104      1\n",
      "102350      1\n",
      "116165      1\n",
      "174421      1\n",
      "242769      1\n",
      "37202       1\n",
      "231573      1\n",
      "195519      1\n",
      "156780      1\n",
      "420973      1\n",
      "352612      1\n",
      "110517      1\n",
      "139187      1\n",
      "273051      1\n",
      "166051      1\n",
      "83880       1\n",
      "183580      1\n",
      "316672      1\n",
      "192413      1\n",
      "215110      1\n",
      "219034      1\n",
      "118681      1\n",
      "119939      1\n",
      "202642      1\n",
      "130959      1\n",
      "227214      1\n",
      "251786      1\n",
      "178054      1\n",
      "230912      1\n",
      "200577      1\n",
      "354923      1\n",
      "32639       1\n",
      "386940      1\n",
      "57211       1\n",
      "30270       1\n",
      "370548      1\n",
      "142506      1\n",
      "126829      1\n",
      "184169      1\n",
      "115418      1\n",
      "173924      1\n",
      "108468      1\n",
      "182200      1\n",
      "266081      1\n",
      "315321      1\n",
      "442359      1\n",
      "176117      1\n",
      "337908      1\n",
      "202738      1\n",
      "200689      1\n",
      "225927      1\n",
      "98287       1\n",
      "168796      1\n",
      "208869      1\n",
      "71650       1\n",
      "128990      1\n",
      "159709      1\n",
      "258561      1\n",
      "143868      1\n",
      "415706      1\n",
      "53209       1\n",
      "311255      1\n",
      "103713      1\n",
      "301010      1\n",
      "167889      1\n",
      "799281      1\n",
      "260046      1\n",
      "247752      1\n",
      "145638      1\n",
      "284086      1\n",
      "135105      1\n",
      "96190       1\n",
      "314627      1\n",
      "366900      1\n",
      "126566      1\n",
      "558944      1\n",
      "175800      1\n",
      "190088      1\n",
      "353281      1\n",
      "215323      1\n",
      "294671      1\n",
      "325390      1\n",
      "216137      1\n",
      "249609      1\n",
      "133655      1\n",
      "198362      1\n",
      "191731      1\n",
      "198400      1\n",
      "143032      1\n",
      "341835      1\n",
      "26904       1\n",
      "216825      1\n",
      "286166      1\n",
      "201769      1\n",
      "214787      1\n",
      "108276      1\n",
      "230429      1\n",
      "208049      1\n",
      "57067       1\n",
      "181992      1\n",
      "173796      1\n",
      "233626      1\n",
      "193868      1\n",
      "125324      1\n",
      "20728       1\n",
      "173780      1\n",
      "104146      1\n",
      "511331      1\n",
      "122651      1\n",
      "32607       1\n",
      "128798      1\n",
      "323421      1\n",
      "91996       1\n",
      "153434      1\n",
      "216921      1\n",
      "83800       1\n",
      "276310      1\n",
      "143189      1\n",
      "597843      1\n",
      "137042      1\n",
      "167761      1\n",
      "34640       1\n",
      "509866      1\n",
      "257869      1\n",
      "31391       1\n",
      "198087      1\n",
      "376647      1\n",
      "85413       1\n",
      "173291      1\n",
      "345403      1\n",
      "195201      1\n",
      "132912      1\n",
      "128814      1\n",
      "136862      1\n",
      "116520      1\n",
      "343847      1\n",
      "110373      1\n",
      "71458       1\n",
      "298785      1\n",
      "420691      1\n",
      "62535       1\n",
      "210610      1\n",
      "317434      1\n",
      "450580      1\n",
      "168221      1\n",
      "202930      1\n",
      "229553      1\n",
      "152569      1\n",
      "127151      1\n",
      "190636      1\n",
      "84136       1\n",
      "174182      1\n",
      "399522      1\n",
      "313786      1\n",
      "123037      1\n",
      "223637      1\n",
      "120986      1\n",
      "280728      1\n",
      "178326      1\n",
      "135315      1\n",
      "170130      1\n",
      "188557      1\n",
      "229566      1\n",
      "120970      1\n",
      "216626      1\n",
      "374918      1\n",
      "172165      1\n",
      "305846      1\n",
      "200835      1\n",
      "133248      1\n",
      "134480      1\n",
      "356567      1\n",
      "236627      1\n",
      "321959      1\n",
      "247992      1\n",
      "26620       1\n",
      "110931      1\n",
      "249870      1\n",
      "293984      1\n",
      "290521      1\n",
      "250091      1\n",
      "116968      1\n",
      "122011      1\n",
      "268514      1\n",
      "164065      1\n",
      "67808       1\n",
      "317425      1\n",
      "151771      1\n",
      "182985      1\n",
      "213209      1\n",
      "116952      1\n",
      "112854      1\n",
      "303317      1\n",
      "184271      1\n",
      "133328      1\n",
      "157900      1\n",
      "188610      1\n",
      "311497      1\n",
      "110791      1\n",
      "538822      1\n",
      "353512      1\n",
      "174276      1\n",
      "268482      1\n",
      "526528      1\n",
      "170994      1\n",
      "101077      1\n",
      "374969      1\n",
      "79990       1\n",
      "368757      1\n",
      "39026       1\n",
      "231472      1\n",
      "61487       1\n",
      "161838      1\n",
      "190508      1\n",
      "265638      1\n",
      "153408      1\n",
      "110594      1\n",
      "266275      1\n",
      "403072      1\n",
      "426017      1\n",
      "347434      1\n",
      "20507       1\n",
      "187221      1\n",
      "208919      1\n",
      "115426      1\n",
      "106517      1\n",
      "337940      1\n",
      "167955      1\n",
      "426001      1\n",
      "133136      1\n",
      "126991      1\n",
      "124940      1\n",
      "344073      1\n",
      "374790      1\n",
      "114870      1\n",
      "167939      1\n",
      "294913      1\n",
      "34816       1\n",
      "556902      1\n",
      "383269      1\n",
      "167987      1\n",
      "174132      1\n",
      "165968      1\n",
      "52152       1\n",
      "236069      1\n",
      "405684      1\n",
      "101977      1\n",
      "208999      1\n",
      "211046      1\n",
      "335973      1\n",
      "206948      1\n",
      "194654      1\n",
      "182360      1\n",
      "55481       1\n",
      "270421      1\n",
      "233555      1\n",
      "192591      1\n",
      "30111       1\n",
      "194638      1\n",
      "90189       1\n",
      "223308      1\n",
      "151627      1\n",
      "114761      1\n",
      "110663      1\n",
      "206916      1\n",
      "170050      1\n",
      "196673      1\n",
      "329792      1\n",
      "28735       1\n",
      "115326      1\n",
      "215096      1\n",
      "106548      1\n",
      "436770      1\n",
      "175221      1\n",
      "103762      1\n",
      "278073      1\n",
      "81223       1\n",
      "46406       1\n",
      "232769      1\n",
      "34112       1\n",
      "202125      1\n",
      "101061      1\n",
      "169122      1\n",
      "159021      1\n",
      "189740      1\n",
      "318763      1\n",
      "216361      1\n",
      "113959      1\n",
      "273701      1\n",
      "398626      1\n",
      "255252      1\n",
      "291196      1\n",
      "181528      1\n",
      "163113      1\n",
      "240917      1\n",
      "140564      1\n",
      "197904      1\n",
      "292110      1\n",
      "118025      1\n",
      "136450      1\n",
      "158301      1\n",
      "247082      1\n",
      "166056      1\n",
      "306710      1\n",
      "25932       1\n",
      "433491      1\n",
      "478457      1\n",
      "79190       1\n",
      "96176       1\n",
      "24728       1\n",
      "116104      1\n",
      "114055      1\n",
      "142725      1\n",
      "103810      1\n",
      "101761      1\n",
      "263552      1\n",
      "130431      1\n",
      "128382      1\n",
      "257405      1\n",
      "64667       1\n",
      "347513      1\n",
      "241013      1\n",
      "238964      1\n",
      "138611      1\n",
      "165232      1\n",
      "64879       1\n",
      "360252      1\n",
      "222572      1\n",
      "183155      1\n",
      "183657      1\n",
      "181608      1\n",
      "210278      1\n",
      "136546      1\n",
      "163167      1\n",
      "353628      1\n",
      "387068      1\n",
      "212311      1\n",
      "233724      1\n",
      "378104      1\n",
      "349898      1\n",
      "191822      1\n",
      "226297      1\n",
      "160942      1\n",
      "148182      1\n",
      "249571      1\n",
      "244903      1\n",
      "152044      1\n",
      "142501      1\n",
      "103586      1\n",
      "228608      1\n",
      "64671       1\n",
      "583755      1\n",
      "246936      1\n",
      "171831      1\n",
      "40083       1\n",
      "114185      1\n",
      "195727      1\n",
      "182614      1\n",
      "85129       1\n",
      "197689      1\n",
      "146567      1\n",
      "306309      1\n",
      "304260      1\n",
      "40067       1\n",
      "136322      1\n",
      "180771      1\n",
      "117881      1\n",
      "148600      1\n",
      "179319      1\n",
      "123436      1\n",
      "298161      1\n",
      "127084      1\n",
      "441591      1\n",
      "404661      1\n",
      "109813      1\n",
      "82910       1\n",
      "236977      1\n",
      "425199      1\n",
      "48788       1\n",
      "212232      1\n",
      "256674      1\n",
      "210150      1\n",
      "240869      1\n",
      "72931       1\n",
      "230624      1\n",
      "163039      1\n",
      "154843      1\n",
      "183513      1\n",
      "177366      1\n",
      "106316      1\n",
      "271572      1\n",
      "103634      1\n",
      "128206      1\n",
      "82635       1\n",
      "115912      1\n",
      "374367      1\n",
      "234690      1\n",
      "85690       1\n",
      "230592      1\n",
      "226494      1\n",
      "126141      1\n",
      "347321      1\n",
      "115896      1\n",
      "276552      1\n",
      "171411      1\n",
      "435604      1\n",
      "116360      1\n",
      "192256      1\n",
      "69249       1\n",
      "188027      1\n",
      "415354      1\n",
      "173382      1\n",
      "103121      1\n",
      "181096      1\n",
      "245310      1\n",
      "171635      1\n",
      "167537      1\n",
      "816750      1\n",
      "190060      1\n",
      "120426      1\n",
      "165472      1\n",
      "97823       1\n",
      "114263      1\n",
      "202322      1\n",
      "31993       1\n",
      "213745      1\n",
      "24139       1\n",
      "178665      1\n",
      "147015      1\n",
      "106153      1\n",
      "206298      1\n",
      "108100      1\n",
      "335427      1\n",
      "34368       1\n",
      "97855       1\n",
      "95806       1\n",
      "44677       1\n",
      "183945      1\n",
      "109973      1\n",
      "22154       1\n",
      "282313      1\n",
      "71489       1\n",
      "206532      1\n",
      "167617      1\n",
      "329408      1\n",
      "341395      1\n",
      "136767      1\n",
      "58602       1\n",
      "112310      1\n",
      "239284      1\n",
      "272656      1\n",
      "198320      1\n",
      "95918       1\n",
      "487085      1\n",
      "22186       1\n",
      "231183      1\n",
      "425627      1\n",
      "210064      1\n",
      "136866      1\n",
      "161438      1\n",
      "323229      1\n",
      "257588      1\n",
      "158751      1\n",
      "128676      1\n",
      "117073      1\n",
      "76720       1\n",
      "173716      1\n",
      "130703      1\n",
      "417419      1\n",
      "28221       1\n",
      "164493      1\n",
      "140852      1\n",
      "29526       1\n",
      "83066       1\n",
      "50648       1\n",
      "57206       1\n",
      "298449      1\n",
      "355789      1\n",
      "249289      1\n",
      "709445      1\n",
      "77253       1\n",
      "159165      1\n",
      "83348       1\n",
      "162322      1\n",
      "144822      1\n",
      "105907      1\n",
      "261897      1\n",
      "509500      1\n",
      "314773      1\n",
      "340408      1\n",
      "456110      1\n",
      "191917      1\n",
      "122283      1\n",
      "65160       1\n",
      "156526      1\n",
      "243283      1\n",
      "142757      1\n",
      "173476      1\n",
      "28061       1\n",
      "389856      1\n",
      "148888      1\n",
      "343447      1\n",
      "98588       1\n",
      "202210      1\n",
      "181063      1\n",
      "216827      1\n",
      "263728      1\n",
      "587310      1\n",
      "54826       1\n",
      "282153      1\n",
      "343591      1\n",
      "224232      1\n",
      "305673      1\n",
      "32287       1\n",
      "22042       1\n",
      "280088      1\n",
      "179735      1\n",
      "169683      1\n",
      "208405      1\n",
      "32271       1\n",
      "357870      1\n",
      "129804      1\n",
      "236040      1\n",
      "318987      1\n",
      "185866      1\n",
      "202242      1\n",
      "184965      1\n",
      "153082      1\n",
      "350379      1\n",
      "73203       1\n",
      "366066      1\n",
      "232945      1\n",
      "165360      1\n",
      "32239       1\n",
      "74182       1\n",
      "27044       1\n",
      "246652      1\n",
      "324173      1\n",
      "32172       1\n",
      "181675      1\n",
      "118186      1\n",
      "185769      1\n",
      "67386       1\n",
      "140711      1\n",
      "200098      1\n",
      "43952       1\n",
      "193949      1\n",
      "186813      1\n",
      "52634       1\n",
      "218521      1\n",
      "165267      1\n",
      "356238      1\n",
      "236944      1\n",
      "163212      1\n",
      "378251      1\n",
      "120201      1\n",
      "118799      1\n",
      "206215      1\n",
      "69328       1\n",
      "275845      1\n",
      "198019      1\n",
      "167298      1\n",
      "103809      1\n",
      "204160      1\n",
      "208703      1\n",
      "32124       1\n",
      "152953      1\n",
      "95661       1\n",
      "396722      1\n",
      "107895      1\n",
      "205072      1\n",
      "212468      1\n",
      "167410      1\n",
      "366065      1\n",
      "222703      1\n",
      "290286      1\n",
      "96282       1\n",
      "211517      1\n",
      "255424      1\n",
      "183786      1\n",
      "308709      1\n",
      "48612       1\n",
      "93662       1\n",
      "128477      1\n",
      "32220       1\n",
      "107991      1\n",
      "276840      1\n",
      "132563      1\n",
      "255439      1\n",
      "196044      1\n",
      "42476       1\n",
      "200603      1\n",
      "570821      1\n",
      "236992      1\n",
      "96678       1\n",
      "323006      1\n",
      "181691      1\n",
      "83401       1\n",
      "155064      1\n",
      "190367      1\n",
      "191417      1\n",
      "198003      1\n",
      "306678      1\n",
      "199039      1\n",
      "181547      1\n",
      "120508      1\n",
      "103218      1\n",
      "158162      1\n",
      "175398      1\n",
      "239098      1\n",
      "402998      1\n",
      "197923      1\n",
      "398625      1\n",
      "124191      1\n",
      "98765       1\n",
      "195868      1\n",
      "50459       1\n",
      "172970      1\n",
      "374450      1\n",
      "441620      1\n",
      "34067       1\n",
      "68882       1\n",
      "228620      1\n",
      "193952      1\n",
      "283913      1\n",
      "177413      1\n",
      "29557       1\n",
      "167170      1\n",
      "267521      1\n",
      "335104      1\n",
      "199472      1\n",
      "120057      1\n",
      "384248      1\n",
      "193583      1\n",
      "255279      1\n",
      "169329      1\n",
      "466224      1\n",
      "451951      1\n",
      "279231      1\n",
      "131224      1\n",
      "358636      1\n",
      "146788      1\n",
      "71009       1\n",
      "64860       1\n",
      "282611      1\n",
      "400356      1\n",
      "169388      1\n",
      "111957      1\n",
      "170421      1\n",
      "42293       1\n",
      "265554      1\n",
      "171344      1\n",
      "368140      1\n",
      "554317      1\n",
      "247115      1\n",
      "56648       1\n",
      "179524      1\n",
      "175412      1\n",
      "130364      1\n",
      "27956       1\n",
      "120121      1\n",
      "89400       1\n",
      "142646      1\n",
      "212276      1\n",
      "316471      1\n",
      "414812      1\n",
      "366198      1\n",
      "235691      1\n",
      "115387      1\n",
      "34127       1\n",
      "190143      1\n",
      "257726      1\n",
      "163516      1\n",
      "247483      1\n",
      "347834      1\n",
      "155320      1\n",
      "190568      1\n",
      "212660      1\n",
      "138907      1\n",
      "73392       1\n",
      "124591      1\n",
      "30381       1\n",
      "151210      1\n",
      "220840      1\n",
      "388625      1\n",
      "276133      1\n",
      "170086      1\n",
      "255647      1\n",
      "126622      1\n",
      "194205      1\n",
      "116379      1\n",
      "96100       1\n",
      "304791      1\n",
      "110230      1\n",
      "47086       1\n",
      "114324      1\n",
      "132755      1\n",
      "209867      1\n",
      "157327      1\n",
      "106176      1\n",
      "343748      1\n",
      "95885       1\n",
      "206535      1\n",
      "122616      1\n",
      "152617      1\n",
      "119124      1\n",
      "114420      1\n",
      "138992      1\n",
      "196332      1\n",
      "118506      1\n",
      "188136      1\n",
      "337639      1\n",
      "126021      1\n",
      "141028      1\n",
      "124639      1\n",
      "257758      1\n",
      "130780      1\n",
      "149211      1\n",
      "184026      1\n",
      "122584      1\n",
      "173783      1\n",
      "472789      1\n",
      "132819      1\n",
      "331474      1\n",
      "401104      1\n",
      "157391      1\n",
      "28366       1\n",
      "95949       1\n",
      "214731      1\n",
      "118474      1\n",
      "321758      1\n",
      "24264       1\n",
      "224910      1\n",
      "93557       1\n",
      "349689      1\n",
      "110134      1\n",
      "156800      1\n",
      "389932      1\n",
      "359543      1\n",
      "248851      1\n",
      "255817      1\n",
      "78786       1\n",
      "183850      1\n",
      "54825       1\n",
      "319016      1\n",
      "173607      1\n",
      "142886      1\n",
      "203777      1\n",
      "146980      1\n",
      "34339       1\n",
      "136841      1\n",
      "388594      1\n",
      "181413      1\n",
      "126494      1\n",
      "30237       1\n",
      "214555      1\n",
      "175149      1\n",
      "218649      1\n",
      "220696      1\n",
      "206359      1\n",
      "244315      1\n",
      "42938       1\n",
      "177669      1\n",
      "101890      1\n",
      "100292      1\n",
      "114228      1\n",
      "138991      1\n",
      "75012       1\n",
      "118330      1\n",
      "175750      1\n",
      "257557      1\n",
      "224894      1\n",
      "183930      1\n",
      "155256      1\n",
      "114292      1\n",
      "93806       1\n",
      "239880      1\n",
      "165475      1\n",
      "94529       1\n",
      "73312       1\n",
      "130652      1\n",
      "214619      1\n",
      "56920       1\n",
      "79445       1\n",
      "409172      1\n",
      "65743       1\n",
      "73296       1\n",
      "119592      1\n",
      "264593      1\n",
      "56904       1\n",
      "108103      1\n",
      "175686      1\n",
      "177733      1\n",
      "152150      1\n",
      "104001      1\n",
      "126668      1\n",
      "357949      1\n",
      "247355      1\n",
      "179444      1\n",
      "165107      1\n",
      "123329      1\n",
      "258973      1\n",
      "306459      1\n",
      "99219       1\n",
      "39824       1\n",
      "23813       1\n",
      "352465      1\n",
      "152457      1\n",
      "43910       1\n",
      "124259      1\n",
      "62333       1\n",
      "359292      1\n",
      "115579      1\n",
      "183162      1\n",
      "92486       1\n",
      "369527      1\n",
      "109430      1\n",
      "168817      1\n",
      "269168      1\n",
      "39092       1\n",
      "264961      1\n",
      "187240      1\n",
      "247600      1\n",
      "70767       1\n",
      "201569      1\n",
      "519006      1\n",
      "324445      1\n",
      "490332      1\n",
      "440647      1\n",
      "467799      1\n",
      "242517      1\n",
      "218009      1\n",
      "105376      1\n",
      "136017      1\n",
      "351869      1\n",
      "164835      1\n",
      "220631      1\n",
      "98756       1\n",
      "508891      1\n",
      "183258      1\n",
      "205011      1\n",
      "52921       1\n",
      "107479      1\n",
      "212895      1\n",
      "303212      1\n",
      "233499      1\n",
      "156623      1\n",
      "54042       1\n",
      "201764      1\n",
      "187336      1\n",
      "205767      1\n",
      "337721      1\n",
      "277444      1\n",
      "366618      1\n",
      "36209       1\n",
      "95165       1\n",
      "129980      1\n",
      "93885       1\n",
      "214637      1\n",
      "103345      1\n",
      "95149       1\n",
      "121768      1\n",
      "205735      1\n",
      "242597      1\n",
      "33619       1\n",
      "95902       1\n",
      "103759      1\n",
      "208407      1\n",
      "185097      1\n",
      "56072       1\n",
      "223367      1\n",
      "296892      1\n",
      "29437       1\n",
      "265618      1\n",
      "183034      1\n",
      "119545      1\n",
      "240374      1\n",
      "165798      1\n",
      "131827      1\n",
      "103153      1\n",
      "105200      1\n",
      "187112      1\n",
      "238311      1\n",
      "187625      1\n",
      "131811      1\n",
      "163053      1\n",
      "109462      1\n",
      "91468       1\n",
      "148187      1\n",
      "205527      1\n",
      "142038      1\n",
      "211668      1\n",
      "162613      1\n",
      "190450      1\n",
      "83237       1\n",
      "160776      1\n",
      "199362      1\n",
      "213771      1\n",
      "353039      1\n",
      "143312      1\n",
      "248739      1\n",
      "315977      1\n",
      "578377      1\n",
      "176965      1\n",
      "342852      1\n",
      "103233      1\n",
      "82041       1\n",
      "127805      1\n",
      "344891      1\n",
      "318264      1\n",
      "273206      1\n",
      "176949      1\n",
      "288437      1\n",
      "262402      1\n",
      "133938      1\n",
      "254767      1\n",
      "162604      1\n",
      "443179      1\n",
      "205607      1\n",
      "190889      1\n",
      "144165      1\n",
      "224258      1\n",
      "30796       1\n",
      "228124      1\n",
      "316185      1\n",
      "187160      1\n",
      "107287      1\n",
      "146196      1\n",
      "133122      1\n",
      "133906      1\n",
      "238567      1\n",
      "121832      1\n",
      "216042      1\n",
      "94196       1\n",
      "138416      1\n",
      "206823      1\n",
      "345259      1\n",
      "218281      1\n",
      "178510      1\n",
      "99491       1\n",
      "169121      1\n",
      "181597      1\n",
      "479621      1\n",
      "53942       1\n",
      "261276      1\n",
      "185497      1\n",
      "205975      1\n",
      "175254      1\n",
      "144533      1\n",
      "33939       1\n",
      "234641      1\n",
      "105616      1\n",
      "62605       1\n",
      "92463       1\n",
      "117898      1\n",
      "44861       1\n",
      "142470      1\n",
      "142075      1\n",
      "181929      1\n",
      "156799      1\n",
      "158846      1\n",
      "228476      1\n",
      "358701      1\n",
      "177895      1\n",
      "147700      1\n",
      "83601       1\n",
      "111797      1\n",
      "236784      1\n",
      "287983      1\n",
      "163052      1\n",
      "247019      1\n",
      "120041      1\n",
      "142566      1\n",
      "179428      1\n",
      "167138      1\n",
      "234721      1\n",
      "386370      1\n",
      "214235      1\n",
      "303176      1\n",
      "218329      1\n",
      "56536       1\n",
      "173271      1\n",
      "44246       1\n",
      "111829      1\n",
      "408788      1\n",
      "91343       1\n",
      "193741      1\n",
      "243878      1\n",
      "85194       1\n",
      "382153      1\n",
      "56520       1\n",
      "173255      1\n",
      "275653      1\n",
      "197827      1\n",
      "327434      1\n",
      "144937      1\n",
      "185465      1\n",
      "173175      1\n",
      "222405      1\n",
      "197747      1\n",
      "85434       1\n",
      "648223      1\n",
      "424988      1\n",
      "85018       1\n",
      "185369      1\n",
      "184135      1\n",
      "74775       1\n",
      "497486      1\n",
      "260093      1\n",
      "197651      1\n",
      "39952       1\n",
      "390157      1\n",
      "293900      1\n",
      "56328       1\n",
      "119474      1\n",
      "33795       1\n",
      "36999       1\n",
      "201729      1\n",
      "60414       1\n",
      "231620      1\n",
      "50171       1\n",
      "250873      1\n",
      "142326      1\n",
      "275445      1\n",
      "54850       1\n",
      "230387      1\n",
      "136177      1\n",
      "158702      1\n",
      "281668      1\n",
      "592930      1\n",
      "113700      1\n",
      "177189      1\n",
      "277588      1\n",
      "38001       1\n",
      "138352      1\n",
      "189551      1\n",
      "145504      1\n",
      "162924      1\n",
      "119913      1\n",
      "427422      1\n",
      "122307      1\n",
      "265314      1\n",
      "326624      1\n",
      "115803      1\n",
      "31627       1\n",
      "242773      1\n",
      "63665       1\n",
      "74791       1\n",
      "377931      1\n",
      "360131      1\n",
      "230467      1\n",
      "40000       1\n",
      "83003       1\n",
      "319666      1\n",
      "237630      1\n",
      "197683      1\n",
      "189487      1\n",
      "102640      1\n",
      "198870      1\n",
      "181291      1\n",
      "449576      1\n",
      "247547      1\n",
      "98044       1\n",
      "95997       1\n",
      "196084      1\n",
      "198422      1\n",
      "96779       1\n",
      "163015      1\n",
      "97870       1\n",
      "378009      1\n",
      "313853      1\n",
      "372181      1\n",
      "127482      1\n",
      "392100      1\n",
      "123384      1\n",
      "233974      1\n",
      "45554       1\n",
      "205296      1\n",
      "268861      1\n",
      "240081      1\n",
      "254440      1\n",
      "299494      1\n",
      "197618      1\n",
      "106976      1\n",
      "184176      1\n",
      "152030      1\n",
      "149981      1\n",
      "31195       1\n",
      "170455      1\n",
      "266710      1\n",
      "230136      1\n",
      "109009      1\n",
      "186831      1\n",
      "348521      1\n",
      "97969       1\n",
      "236055      1\n",
      "188872      1\n",
      "123416      1\n",
      "51789       1\n",
      "298113      1\n",
      "227915      1\n",
      "62026       1\n",
      "289353      1\n",
      "123464      1\n",
      "114345      1\n",
      "66755       1\n",
      "112819      1\n",
      "186943      1\n",
      "216402      1\n",
      "96827       1\n",
      "291386      1\n",
      "387641      1\n",
      "203319      1\n",
      "365110      1\n",
      "212437      1\n",
      "113203      1\n",
      "176690      1\n",
      "150061      1\n",
      "98675       1\n",
      "242987      1\n",
      "75333       1\n",
      "133669      1\n",
      "197156      1\n",
      "41504       1\n",
      "83622       1\n",
      "92863       1\n",
      "191001      1\n",
      "61898       1\n",
      "417941      1\n",
      "213308      1\n",
      "37238       1\n",
      "276851      1\n",
      "143730      1\n",
      "108913      1\n",
      "293227      1\n",
      "199471      1\n",
      "156008      1\n",
      "312966      1\n",
      "231781      1\n",
      "211299      1\n",
      "53598       1\n",
      "180572      1\n",
      "129371      1\n",
      "111836      1\n",
      "133461      1\n",
      "229716      1\n",
      "204304      1\n",
      "104052      1\n",
      "207185      1\n",
      "208291      1\n",
      "318918      1\n",
      "215373      1\n",
      "78567       1\n",
      "194891      1\n",
      "155976      1\n",
      "301383      1\n",
      "102726      1\n",
      "112963      1\n",
      "156430      1\n",
      "398904      1\n",
      "199029      1\n",
      "297991      1\n",
      "68037       1\n",
      "184702      1\n",
      "197060      1\n",
      "118253      1\n",
      "185437      1\n",
      "281021      1\n",
      "297380      1\n",
      "68021       1\n",
      "78258       1\n",
      "207281      1\n",
      "74160       1\n",
      "459248      1\n",
      "316235      1\n",
      "194987      1\n",
      "258474      1\n",
      "242082      1\n",
      "63899       1\n",
      "61850       1\n",
      "77247       1\n",
      "221592      1\n",
      "197012      1\n",
      "244115      1\n",
      "201393      1\n",
      "49308       1\n",
      "119182      1\n",
      "290614      1\n",
      "520586      1\n",
      "125321      1\n",
      "231813      1\n",
      "181031      1\n",
      "219519      1\n",
      "53838       1\n",
      "80467       1\n",
      "287320      1\n",
      "189240      1\n",
      "375603      1\n",
      "207665      1\n",
      "318255      1\n",
      "42003       1\n",
      "117549      1\n",
      "279340      1\n",
      "175796      1\n",
      "364958      1\n",
      "111394      1\n",
      "381357      1\n",
      "217886      1\n",
      "346909      1\n",
      "30063       1\n",
      "320280      1\n",
      "146195      1\n",
      "174865      1\n",
      "205584      1\n",
      "109856      1\n",
      "271431      1\n",
      "193290      1\n",
      "197380      1\n",
      "134088      1\n",
      "56063       1\n",
      "45801       1\n",
      "180988      1\n",
      "291578      1\n",
      "280603      1\n",
      "209650      1\n",
      "107248      1\n",
      "498079      1\n",
      "226106      1\n",
      "455379      1\n",
      "97083       1\n",
      "64379       1\n",
      "68469       1\n",
      "197492      1\n",
      "179059      1\n",
      "27432       1\n",
      "211301      1\n",
      "215917      1\n",
      "50028       1\n",
      "224105      1\n",
      "174351      1\n",
      "185528      1\n",
      "176616      1\n",
      "277347      1\n",
      "439263      1\n",
      "76641       1\n",
      "349022      1\n",
      "281437      1\n",
      "148316      1\n",
      "168790      1\n",
      "113491      1\n",
      "126003      1\n",
      "187215      1\n",
      "248653      1\n",
      "49996       1\n",
      "160586      1\n",
      "224073      1\n",
      "184198      1\n",
      "146243      1\n",
      "219967      1\n",
      "217838      1\n",
      "66006       1\n",
      "323811      1\n",
      "263600      1\n",
      "83610       1\n",
      "416415      1\n",
      "279196      1\n",
      "243841      1\n",
      "25240       1\n",
      "168598      1\n",
      "178835      1\n",
      "570002      1\n",
      "207505      1\n",
      "213644      1\n",
      "326283      1\n",
      "256649      1\n",
      "221832      1\n",
      "100997      1\n",
      "703107      1\n",
      "207489      1\n",
      "246396      1\n",
      "335065      1\n",
      "236136      1\n",
      "111218      1\n",
      "36251       1\n",
      "184942      1\n",
      "168740      1\n",
      "201318      1\n",
      "119539      1\n",
      "106967      1\n",
      "22328       1\n",
      "315998      1\n",
      "379485      1\n",
      "375170      1\n",
      "103078      1\n",
      "137895      1\n",
      "187087      1\n",
      "261816      1\n",
      "178915      1\n",
      "188923      1\n",
      "86750       1\n",
      "87250       1\n",
      "49884       1\n",
      "239120      1\n",
      "221912      1\n",
      "269015      1\n",
      "89299       1\n",
      "199381      1\n",
      "100818      1\n",
      "347692      1\n",
      "283342      1\n",
      "201398      1\n",
      "345489      1\n",
      "293579      1\n",
      "27337       1\n",
      "123592      1\n",
      "166597      1\n",
      "309955      1\n",
      "469697      1\n",
      "205504      1\n",
      "267790      1\n",
      "213692      1\n",
      "391867      1\n",
      "420537      1\n",
      "484024      1\n",
      "53566       1\n",
      "423297      1\n",
      "257790      1\n",
      "180212      1\n",
      "218630      1\n",
      "337895      1\n",
      "147428      1\n",
      "135138      1\n",
      "169953      1\n",
      "65876       1\n",
      "94174       1\n",
      "39411       1\n",
      "235237      1\n",
      "297152      1\n",
      "272343      1\n",
      "272531      1\n",
      "69586       1\n",
      "194024      1\n",
      "163788      1\n",
      "220168      1\n",
      "30653       1\n",
      "327612      1\n",
      "13769       1\n",
      "370615      1\n",
      "79797       1\n",
      "231347      1\n",
      "202673      1\n",
      "92079       1\n",
      "282538      1\n",
      "184007      1\n",
      "501671      1\n",
      "80312       1\n",
      "177212      1\n",
      "282602      1\n",
      "352248      1\n",
      "204704      1\n",
      "26683       1\n",
      "118259      1\n",
      "247869      1\n",
      "260997      1\n",
      "100405      1\n",
      "262196      1\n",
      "174394      1\n",
      "255921      1\n",
      "251951      1\n",
      "84013       1\n",
      "38973       1\n",
      "96299       1\n",
      "109067      1\n",
      "139296      1\n",
      "71683       1\n",
      "262802      1\n",
      "135190      1\n",
      "247733      1\n",
      "159269      1\n",
      "315406      1\n",
      "176017      1\n",
      "48915       1\n",
      "104455      1\n",
      "232894      1\n",
      "342019      1\n",
      "223231      1\n",
      "126974      1\n",
      "227325      1\n",
      "163836      1\n",
      "380922      1\n",
      "172511      1\n",
      "157599      1\n",
      "190777      1\n",
      "225772      1\n",
      "245572      1\n",
      "461929      1\n",
      "38721       1\n",
      "171840      1\n",
      "159550      1\n",
      "221447      1\n",
      "352056      1\n",
      "26490       1\n",
      "199546      1\n",
      "362165      1\n",
      "493363      1\n",
      "354095      1\n",
      "192302      1\n",
      "210794      1\n",
      "145189      1\n",
      "102178      1\n",
      "192286      1\n",
      "120601      1\n",
      "189269      1\n",
      "225541      1\n",
      "274198      1\n",
      "212300      1\n",
      "245524      1\n",
      "362259      1\n",
      "169745      1\n",
      "372967      1\n",
      "148143      1\n",
      "212210      1\n",
      "205838      1\n",
      "112453      1\n",
      "225102      1\n",
      "32668       1\n",
      "169809      1\n",
      "166971      1\n",
      "243605      1\n",
      "167826      1\n",
      "54310       1\n",
      "520078      1\n",
      "145704      1\n",
      "188009      1\n",
      "112517      1\n",
      "331650      1\n",
      "235393      1\n",
      "76212       1\n",
      "162745      1\n",
      "175990      1\n",
      "200017      1\n",
      "329587      1\n",
      "167794      1\n",
      "171888      1\n",
      "190319      1\n",
      "182123      1\n",
      "249706      1\n",
      "173927      1\n",
      "339814      1\n",
      "132963      1\n",
      "204640      1\n",
      "190303      1\n",
      "151386      1\n",
      "253784      1\n",
      "278404      1\n",
      "230095      1\n",
      "102470      1\n",
      "71751       1\n",
      "319560      1\n",
      "105266      1\n",
      "123945      1\n",
      "198901      1\n",
      "76017       1\n",
      "118399      1\n",
      "203258      1\n",
      "227610      1\n",
      "292673      1\n",
      "141537      1\n",
      "119006      1\n",
      "115922      1\n",
      "157913      1\n",
      "95929       1\n",
      "104663      1\n",
      "163199      1\n",
      "252662      1\n",
      "243923      1\n",
      "143570      1\n",
      "270544      1\n",
      "317647      1\n",
      "282830      1\n",
      "215245      1\n",
      "129227      1\n",
      "188616      1\n",
      "170183      1\n",
      "217921      1\n",
      "295108      1\n",
      "143554      1\n",
      "370881      1\n",
      "303296      1\n",
      "24824       1\n",
      "217342      1\n",
      "698363      1\n",
      "237824      1\n",
      "261561      1\n",
      "117915      1\n",
      "139568      1\n",
      "121135      1\n",
      "86318       1\n",
      "117037      1\n",
      "114988      1\n",
      "39539       1\n",
      "190761      1\n",
      "39207       1\n",
      "123403      1\n",
      "80163       1\n",
      "84253       1\n",
      "213276      1\n",
      "321817      1\n",
      "188696      1\n",
      "144056      1\n",
      "110866      1\n",
      "174353      1\n",
      "233954      1\n",
      "213260      1\n",
      "194827      1\n",
      "190729      1\n",
      "32896       1\n",
      "203015      1\n",
      "233734      1\n",
      "166149      1\n",
      "229636      1\n",
      "274690      1\n",
      "446654      1\n",
      "245948      1\n",
      "157881      1\n",
      "202856      1\n",
      "331902      1\n",
      "323706      1\n",
      "235639      1\n",
      "331894      1\n",
      "85874       1\n",
      "217198      1\n",
      "61387       1\n",
      "290922      1\n",
      "286824      1\n",
      "101198      1\n",
      "100453      1\n",
      "262244      1\n",
      "209482      1\n",
      "208994      1\n",
      "141409      1\n",
      "31600       1\n",
      "254134      1\n",
      "211531      1\n",
      "90557       1\n",
      "171067      1\n",
      "54732       1\n",
      "200790      1\n",
      "379779      1\n",
      "218640      1\n",
      "208978      1\n",
      "145212      1\n",
      "139344      1\n",
      "365411      1\n",
      "174474      1\n",
      "39827       1\n",
      "284799      1\n",
      "204928      1\n",
      "60735       1\n",
      "196788      1\n",
      "211123      1\n",
      "143538      1\n",
      "207025      1\n",
      "151726      1\n",
      "247981      1\n",
      "85918       1\n",
      "37030       1\n",
      "264357      1\n",
      "205726      1\n",
      "173128      1\n",
      "127809      1\n",
      "312678      1\n",
      "256191      1\n",
      "174209      1\n",
      "216149      1\n",
      "749636      1\n",
      "34965       1\n",
      "1161363     1\n",
      "104272      1\n",
      "277390      1\n",
      "98637       1\n",
      "346253      1\n",
      "147596      1\n",
      "39460       1\n",
      "24712       1\n",
      "98436       1\n",
      "274562      1\n",
      "266945      1\n",
      "152249      1\n",
      "102864      1\n",
      "165106      1\n",
      "323726      1\n",
      "195821      1\n",
      "357612      1\n",
      "100462      1\n",
      "44915       1\n",
      "195066      1\n",
      "134945      1\n",
      "208103      1\n",
      "206054      1\n",
      "260052      1\n",
      "177380      1\n",
      "101603      1\n",
      "99554       1\n",
      "169184      1\n",
      "120190      1\n",
      "128220      1\n",
      "181466      1\n",
      "74966       1\n",
      "145628      1\n",
      "24108       1\n",
      "163021      1\n",
      "226508      1\n",
      "285897      1\n",
      "142535      1\n",
      "212165      1\n",
      "135606      1\n",
      "404062      1\n",
      "147140      1\n",
      "795830      1\n",
      "232145      1\n",
      "202662      1\n",
      "197810      1\n",
      "283896      1\n",
      "142647      1\n",
      "179509      1\n",
      "34098       1\n",
      "73009       1\n",
      "181546      1\n",
      "154921      1\n",
      "441637      1\n",
      "68899       1\n",
      "136480      1\n",
      "58654       1\n",
      "163101      1\n",
      "83783       1\n",
      "212245      1\n",
      "167187      1\n",
      "99602       1\n",
      "138513      1\n",
      "112564      1\n",
      "189710      1\n",
      "163085      1\n",
      "95500       1\n",
      "199288      1\n",
      "238859      1\n",
      "333158      1\n",
      "192065      1\n",
      "204033      1\n",
      "136448      1\n",
      "269354      1\n",
      "163069      1\n",
      "34545       1\n",
      "396467      1\n",
      "203953      1\n",
      "99220       1\n",
      "478315      1\n",
      "185908      1\n",
      "123151      1\n",
      "43738       1\n",
      "101475      1\n",
      "154600      1\n",
      "226396      1\n",
      "154713      1\n",
      "144688      1\n",
      "271446      1\n",
      "142227      1\n",
      "132178      1\n",
      "200525      1\n",
      "353358      1\n",
      "130125      1\n",
      "180117      1\n",
      "201375      1\n",
      "78870       1\n",
      "375049      1\n",
      "140462      1\n",
      "320014      1\n",
      "910398      1\n",
      "321187      1\n",
      "171393      1\n",
      "36325       1\n",
      "76855       1\n",
      "173110      1\n",
      "33842       1\n",
      "191535      1\n",
      "60661       1\n",
      "50282       1\n",
      "72844       1\n",
      "444607      1\n",
      "105585      1\n",
      "261293      1\n",
      "390316      1\n",
      "314539      1\n",
      "115882      1\n",
      "109735      1\n",
      "115306      1\n",
      "562336      1\n",
      "162973      1\n",
      "155603      1\n",
      "286970      1\n",
      "175255      1\n",
      "221252      1\n",
      "137795      1\n",
      "133164      1\n",
      "201872      1\n",
      "228493      1\n",
      "423052      1\n",
      "281739      1\n",
      "83082       1\n",
      "121993      1\n",
      "238726      1\n",
      "146565      1\n",
      "78980       1\n",
      "158847      1\n",
      "181370      1\n",
      "349304      1\n",
      "404599      1\n",
      "304246      1\n",
      "75759       1\n",
      "215891      1\n",
      "419134      1\n",
      "67090       1\n",
      "296450      1\n",
      "267776      1\n",
      "189950      1\n",
      "62972       1\n",
      "118267      1\n",
      "140790      1\n",
      "310773      1\n",
      "69107       1\n",
      "232713      1\n",
      "191983      1\n",
      "116202      1\n",
      "187881      1\n",
      "87528       1\n",
      "101859      1\n",
      "165346      1\n",
      "234976      1\n",
      "196061      1\n",
      "95708       1\n",
      "129447      1\n",
      "482927      1\n",
      "153048      1\n",
      "77271       1\n",
      "173944      1\n",
      "376277      1\n",
      "138705      1\n",
      "234960      1\n",
      "140300      1\n",
      "97741       1\n",
      "259532      1\n",
      "318921      1\n",
      "433665      1\n",
      "472580      1\n",
      "44921       1\n",
      "255927      1\n",
      "110151      1\n",
      "364099      1\n",
      "263746      1\n",
      "102766      1\n",
      "321086      1\n",
      "211177      1\n",
      "52795       1\n",
      "185912      1\n",
      "329266      1\n",
      "499249      1\n",
      "103984      1\n",
      "126511      1\n",
      "416338      1\n",
      "105717      1\n",
      "282155      1\n",
      "163725      1\n",
      "112164      1\n",
      "200227      1\n",
      "247731      1\n",
      "499233      1\n",
      "63004       1\n",
      "78388       1\n",
      "149018      1\n",
      "142871      1\n",
      "296466      1\n",
      "412435      1\n",
      "49469       1\n",
      "164518      1\n",
      "87560       1\n",
      "185800      1\n",
      "114117      1\n",
      "73025       1\n",
      "302465      1\n",
      "239523      1\n",
      "52603       1\n",
      "220537      1\n",
      "175479      1\n",
      "238966      1\n",
      "255406      1\n",
      "115496      1\n",
      "204145      1\n",
      "126319      1\n",
      "120707      1\n",
      "106760      1\n",
      "104719      1\n",
      "80743       1\n",
      "363875      1\n",
      "99682       1\n",
      "269665      1\n",
      "93535       1\n",
      "130397      1\n",
      "193884      1\n",
      "544091      1\n",
      "258862      1\n",
      "60751       1\n",
      "58702       1\n",
      "113200      1\n",
      "217715      1\n",
      "249787      1\n",
      "107846      1\n",
      "376133      1\n",
      "165186      1\n",
      "28031       1\n",
      "34178       1\n",
      "429507      1\n",
      "127314      1\n",
      "236993      1\n",
      "126399      1\n",
      "286853      1\n",
      "138251      1\n",
      "183739      1\n",
      "125280      1\n",
      "435638      1\n",
      "245173      1\n",
      "36275       1\n",
      "145522      1\n",
      "60847       1\n",
      "58798       1\n",
      "196013      1\n",
      "186415      1\n",
      "103840      1\n",
      "357788      1\n",
      "216475      1\n",
      "122265      1\n",
      "77207       1\n",
      "36243       1\n",
      "153183      1\n",
      "171409      1\n",
      "103824      1\n",
      "189838      1\n",
      "195981      1\n",
      "148874      1\n",
      "513416      1\n",
      "175495      1\n",
      "107910      1\n",
      "216342      1\n",
      "185384      1\n",
      "306215      1\n",
      "250536      1\n",
      "238246      1\n",
      "101027      1\n",
      "223881      1\n",
      "259300      1\n",
      "266912      1\n",
      "256671      1\n",
      "31389       1\n",
      "122889      1\n",
      "306567      1\n",
      "113301      1\n",
      "66194       1\n",
      "258700      1\n",
      "84619       1\n",
      "249541      1\n",
      "250504      1\n",
      "352614      1\n",
      "131714      1\n",
      "203393      1\n",
      "154587      1\n",
      "129661      1\n",
      "51835       1\n",
      "128485      1\n",
      "174711      1\n",
      "244341      1\n",
      "184839      1\n",
      "158319      1\n",
      "385646      1\n",
      "293485      1\n",
      "84587       1\n",
      "196742      1\n",
      "477867      1\n",
      "240231      1\n",
      "225964      1\n",
      "449257      1\n",
      "104647      1\n",
      "262882      1\n",
      "168672      1\n",
      "190748      1\n",
      "210827      1\n",
      "187097      1\n",
      "316120      1\n",
      "336598      1\n",
      "205440      1\n",
      "529104      1\n",
      "604380      1\n",
      "56009       1\n",
      "122094      1\n",
      "176836      1\n",
      "35523       1\n",
      "321787      1\n",
      "131309      1\n",
      "179824      1\n",
      "279615      1\n",
      "260797      1\n",
      "182971      1\n",
      "340332      1\n",
      "283320      1\n",
      "107190      1\n",
      "213214      1\n",
      "35507       1\n",
      "361138      1\n",
      "156334      1\n",
      "311914      1\n",
      "113253      1\n",
      "270872      1\n",
      "269182      1\n",
      "207383      1\n",
      "434710      1\n",
      "178709      1\n",
      "209428      1\n",
      "166419      1\n",
      "188942      1\n",
      "193036      1\n",
      "93834       1\n",
      "355551      1\n",
      "207367      1\n",
      "420351      1\n",
      "162301      1\n",
      "148409      1\n",
      "126540      1\n",
      "33266       1\n",
      "358893      1\n",
      "117227      1\n",
      "246250      1\n",
      "154089      1\n",
      "274916      1\n",
      "297767      1\n",
      "433906      1\n",
      "160220      1\n",
      "139734      1\n",
      "272800      1\n",
      "143828      1\n",
      "428499      1\n",
      "229842      1\n",
      "137681      1\n",
      "243829      1\n",
      "133902      1\n",
      "307812      1\n",
      "104993      1\n",
      "113198      1\n",
      "197218      1\n",
      "162397      1\n",
      "193116      1\n",
      "291951      1\n",
      "23494       1\n",
      "176724      1\n",
      "35411       1\n",
      "197202      1\n",
      "207391      1\n",
      "410186      1\n",
      "143791      1\n",
      "86600       1\n",
      "426562      1\n",
      "262656      1\n",
      "102976      1\n",
      "115258      1\n",
      "219705      1\n",
      "348728      1\n",
      "41526       1\n",
      "328242      1\n",
      "329088      1\n",
      "59951       1\n",
      "64045       1\n",
      "180778      1\n",
      "184872      1\n",
      "45604       1\n",
      "71768       1\n",
      "164386      1\n",
      "192443      1\n",
      "78855       1\n",
      "39665       1\n",
      "236481      1\n",
      "62396       1\n",
      "204425      1\n",
      "244661      1\n",
      "209844      1\n",
      "47771       1\n",
      "200418      1\n",
      "379819      1\n",
      "68493       1\n",
      "275364      1\n",
      "138145      1\n",
      "37792       1\n",
      "51498       1\n",
      "228253      1\n",
      "377754      1\n",
      "154521      1\n",
      "109463      1\n",
      "242580      1\n",
      "109570      1\n",
      "197522      1\n",
      "72593       1\n",
      "211128      1\n",
      "418702      1\n",
      "29580       1\n",
      "494784      1\n",
      "181130      1\n",
      "56201       1\n",
      "273287      1\n",
      "242564      1\n",
      "346847      1\n",
      "222142      1\n",
      "406468      1\n",
      "57781       1\n",
      "109511      1\n",
      "281627      1\n",
      "218136      1\n",
      "343061      1\n",
      "269329      1\n",
      "103440      1\n",
      "191503      1\n",
      "31757       1\n",
      "95244       1\n",
      "156745      1\n",
      "52465       1\n",
      "73541       1\n",
      "185106      1\n",
      "192290      1\n",
      "214010      1\n",
      "23545       1\n",
      "273399      1\n",
      "238582      1\n",
      "103580      1\n",
      "369648      1\n",
      "207847      1\n",
      "334221      1\n",
      "192652      1\n",
      "248795      1\n",
      "440456      1\n",
      "716066      1\n",
      "401198      1\n",
      "224207      1\n",
      "168730      1\n",
      "52171       1\n",
      "157466      1\n",
      "156542      1\n",
      "117627      1\n",
      "318329      1\n",
      "199193      1\n",
      "226092      1\n",
      "248619      1\n",
      "148266      1\n",
      "143547      1\n",
      "181598      1\n",
      "275236      1\n",
      "236321      1\n",
      "267040      1\n",
      "387871      1\n",
      "181970      1\n",
      "344858      1\n",
      "174871      1\n",
      "35603       1\n",
      "58126       1\n",
      "94988       1\n",
      "84747       1\n",
      "35245       1\n",
      "174855      1\n",
      "146181      1\n",
      "176900      1\n",
      "109526      1\n",
      "347322      1\n",
      "223999      1\n",
      "288992      1\n",
      "300275      1\n",
      "41718       1\n",
      "113397      1\n",
      "144116      1\n",
      "201520      1\n",
      "164658      1\n",
      "281403      1\n",
      "310101      1\n",
      "303990      1\n",
      "192771      1\n",
      "270886      1\n",
      "149386      1\n",
      "201519      1\n",
      "41806       1\n",
      "238438      1\n",
      "437909      1\n",
      "400225      1\n",
      "423217      1\n",
      "193372      1\n",
      "117595      1\n",
      "82778       1\n",
      "97789       1\n",
      "160572      1\n",
      "262994      1\n",
      "352812      1\n",
      "234320      1\n",
      "93853       1\n",
      "177720      1\n",
      "148298      1\n",
      "149568      1\n",
      "303942      1\n",
      "396099      1\n",
      "262978      1\n",
      "105281      1\n",
      "191295      1\n",
      "228157      1\n",
      "157262      1\n",
      "112212      1\n",
      "140886      1\n",
      "45381       1\n",
      "160061      1\n",
      "237879      1\n",
      "85374       1\n",
      "131379      1\n",
      "264498      1\n",
      "198863      1\n",
      "274969      1\n",
      "172037      1\n",
      "391468      1\n",
      "147755      1\n",
      "172327      1\n",
      "170272      1\n",
      "321822      1\n",
      "454941      1\n",
      "114971      1\n",
      "117018      1\n",
      "141590      1\n",
      "243988      1\n",
      "229651      1\n",
      "292915      1\n",
      "155919      1\n",
      "92430       1\n",
      "198654      1\n",
      "358668      1\n",
      "114955      1\n",
      "250121      1\n",
      "45317       1\n",
      "112900      1\n",
      "198914      1\n",
      "334224      1\n",
      "403782      1\n",
      "104704      1\n",
      "303431      1\n",
      "110965      1\n",
      "262515      1\n",
      "100722      1\n",
      "364913      1\n",
      "26990       1\n",
      "356717      1\n",
      "194924      1\n",
      "82283       1\n",
      "379242      1\n",
      "250217      1\n",
      "205830      1\n",
      "551962      1\n",
      "196963      1\n",
      "166242      1\n",
      "233825      1\n",
      "170336      1\n",
      "158046      1\n",
      "175128      1\n",
      "225267      1\n",
      "303918      1\n",
      "172375      1\n",
      "115064      1\n",
      "176469      1\n",
      "561489      1\n",
      "170320      1\n",
      "544268      1\n",
      "454989      1\n",
      "20809       1\n",
      "186696      1\n",
      "238806      1\n",
      "322658      1\n",
      "273803      1\n",
      "339346      1\n",
      "348751      1\n",
      "38707       1\n",
      "254127      1\n",
      "127149      1\n",
      "161964      1\n",
      "147627      1\n",
      "247978      1\n",
      "125487      1\n",
      "314052      1\n",
      "325033      1\n",
      "176293      1\n",
      "90042       1\n",
      "196771      1\n",
      "184632      1\n",
      "221343      1\n",
      "119832      1\n",
      "553405      1\n",
      "206998      1\n",
      "340117      1\n",
      "229523      1\n",
      "755858      1\n",
      "299153      1\n",
      "327779      1\n",
      "86153       1\n",
      "407684      1\n",
      "231554      1\n",
      "104576      1\n",
      "145874      1\n",
      "213115      1\n",
      "164019      1\n",
      "108726      1\n",
      "223486      1\n",
      "194748      1\n",
      "94461       1\n",
      "456956      1\n",
      "116986      1\n",
      "53497       1\n",
      "205047      1\n",
      "141558      1\n",
      "181087      1\n",
      "235862      1\n",
      "278763      1\n",
      "143589      1\n",
      "688355      1\n",
      "108681      1\n",
      "219553      1\n",
      "120046      1\n",
      "155293      1\n",
      "401623      1\n",
      "98515       1\n",
      "161815      1\n",
      "233681      1\n",
      "334032      1\n",
      "179896      1\n",
      "120155      1\n",
      "161674      1\n",
      "213195      1\n",
      "479482      1\n",
      "203505      1\n",
      "297154      1\n",
      "286911      1\n",
      "323773      1\n",
      "37331       1\n",
      "214865      1\n",
      "61735       1\n",
      "44822       1\n",
      "87745       1\n",
      "199266      1\n",
      "367200      1\n",
      "84570       1\n",
      "217689      1\n",
      "111189      1\n",
      "133359      1\n",
      "33363       1\n",
      "137225      1\n",
      "158286      1\n",
      "195148      1\n",
      "313930      1\n",
      "506436      1\n",
      "134004      1\n",
      "236096      1\n",
      "194514      1\n",
      "187033      1\n",
      "184889      1\n",
      "37676       1\n",
      "320047      1\n",
      "132704      1\n",
      "180779      1\n",
      "182826      1\n",
      "270887      1\n",
      "240166      1\n",
      "178724      1\n",
      "33315       1\n",
      "264738      1\n",
      "65308       1\n",
      "206833      1\n",
      "197975      1\n",
      "276868      1\n",
      "213611      1\n",
      "371382      1\n",
      "80564       1\n",
      "569930      1\n",
      "105617      1\n",
      "205479      1\n",
      "242341      1\n",
      "166425      1\n",
      "235826      1\n",
      "73023       1\n",
      "65545       1\n",
      "86681       1\n",
      "580248      1\n",
      "276548      1\n",
      "275093      1\n",
      "230035      1\n",
      "199314      1\n",
      "193165      1\n",
      "195212      1\n",
      "213643      1\n",
      "346762      1\n",
      "28053       1\n",
      "109190      1\n",
      "437825      1\n",
      "203392      1\n",
      "981628      1\n",
      "41591       1\n",
      "29302       1\n",
      "241126      1\n",
      "81038       1\n",
      "27166       1\n",
      "258589      1\n",
      "189885      1\n",
      "100882      1\n",
      "289230      1\n",
      "258509      1\n",
      "293324      1\n",
      "213451      1\n",
      "220284      1\n",
      "106951      1\n",
      "78277       1\n",
      "135617      1\n",
      "104896      1\n",
      "223678      1\n",
      "543162      1\n",
      "119225      1\n",
      "145844      1\n",
      "100147      1\n",
      "160173      1\n",
      "117162      1\n",
      "151977      1\n",
      "186792      1\n",
      "76198       1\n",
      "178596      1\n",
      "283033      1\n",
      "121240      1\n",
      "209301      1\n",
      "113044      1\n",
      "137616      1\n",
      "188815      1\n",
      "236272      1\n",
      "254627      1\n",
      "110981      1\n",
      "123343      1\n",
      "191367      1\n",
      "229843      1\n",
      "393715      1\n",
      "113511      1\n",
      "72208       1\n",
      "256526      1\n",
      "26009       1\n",
      "152073      1\n",
      "186888      1\n",
      "238087      1\n",
      "272902      1\n",
      "99888       1\n",
      "201217      1\n",
      "63996       1\n",
      "215546      1\n",
      "209397      1\n",
      "299505      1\n",
      "279763      1\n",
      "219883      1\n",
      "225334      1\n",
      "96748       1\n",
      "86505       1\n",
      "252392      1\n",
      "274917      1\n",
      "426467      1\n",
      "133602      1\n",
      "37345       1\n",
      "190942      1\n",
      "149528      1\n",
      "20953       1\n",
      "350680      1\n",
      "249977      1\n",
      "71792       1\n",
      "323309      1\n",
      "240686      1\n",
      "106273      1\n",
      "354078      1\n",
      "98077       1\n",
      "85787       1\n",
      "182042      1\n",
      "122649      1\n",
      "243476      1\n",
      "331539      1\n",
      "395026      1\n",
      "106257      1\n",
      "300816      1\n",
      "124686      1\n",
      "456460      1\n",
      "446219      1\n",
      "197284      1\n",
      "179973      1\n",
      "112388      1\n",
      "202496      1\n",
      "721712      1\n",
      "128764      1\n",
      "118523      1\n",
      "269527      1\n",
      "293726      1\n",
      "110327      1\n",
      "48885       1\n",
      "202480      1\n",
      "280298      1\n",
      "27484       1\n",
      "203674      1\n",
      "296738      1\n",
      "292058      1\n",
      "280282      1\n",
      "436006      1\n",
      "48997       1\n",
      "266083      1\n",
      "333664      1\n",
      "250182      1\n",
      "161599      1\n",
      "118619      1\n",
      "142977      1\n",
      "252231      1\n",
      "499197      1\n",
      "298035      1\n",
      "530099      1\n",
      "366416      1\n",
      "96076       1\n",
      "481096      1\n",
      "208711      1\n",
      "147269      1\n",
      "132930      1\n",
      "227244      1\n",
      "257855      1\n",
      "363134      1\n",
      "352057      1\n",
      "241463      1\n",
      "272182      1\n",
      "374580      1\n",
      "211585      1\n",
      "200939      1\n",
      "231948      1\n",
      "99761       1\n",
      "715938      1\n",
      "347867      1\n",
      "183965      1\n",
      "38238       1\n",
      "427744      1\n",
      "177633      1\n",
      "298643      1\n",
      "122952      1\n",
      "238433      1\n",
      "96468       1\n",
      "321166      1\n",
      "204556      1\n",
      "226956      1\n",
      "193344      1\n",
      "206470      1\n",
      "200323      1\n",
      "99970       1\n",
      "106113      1\n",
      "169600      1\n",
      "190078      1\n",
      "49278       1\n",
      "64885       1\n",
      "147344      1\n",
      "36467       1\n",
      "253899      1\n",
      "183915      1\n",
      "122473      1\n",
      "317032      1\n",
      "77415       1\n",
      "201986      1\n",
      "175558      1\n",
      "294493      1\n",
      "118363      1\n",
      "732102      1\n",
      "253593      1\n",
      "347803      1\n",
      "339671      1\n",
      "92811       1\n",
      "75478       1\n",
      "177810      1\n",
      "204497      1\n",
      "213646      1\n",
      "183585      1\n",
      "194252      1\n",
      "171928      1\n",
      "83451       1\n",
      "110279      1\n",
      "337606      1\n",
      "46788       1\n",
      "352768      1\n",
      "52221       1\n",
      "202721      1\n",
      "130749      1\n",
      "151227      1\n",
      "274103      1\n",
      "243380      1\n",
      "104112      1\n",
      "124590      1\n",
      "196269      1\n",
      "116394      1\n",
      "188073      1\n",
      "132805      1\n",
      "108198      1\n",
      "179877      1\n",
      "177828      1\n",
      "298659      1\n",
      "235168      1\n",
      "346053      1\n",
      "65389       1\n",
      "188335      1\n",
      "88120       1\n",
      "209449      1\n",
      "329778      1\n",
      "223669      1\n",
      "190469      1\n",
      "194604      1\n",
      "152452      1\n",
      "309284      1\n",
      "207789      1\n",
      "118058      1\n",
      "49179       1\n",
      "315417      1\n",
      "77845       1\n",
      "112660      1\n",
      "131091      1\n",
      "264210      1\n",
      "137232      1\n",
      "90127       1\n",
      "256014      1\n",
      "96268       1\n",
      "110597      1\n",
      "67586       1\n",
      "202752      1\n",
      "225279      1\n",
      "129020      1\n",
      "118779      1\n",
      "188409      1\n",
      "215572      1\n",
      "162943      1\n",
      "210932      1\n",
      "106551      1\n",
      "216856      1\n",
      "69491       1\n",
      "182675      1\n",
      "127085      1\n",
      "63596       1\n",
      "188864      1\n",
      "184425      1\n",
      "219240      1\n",
      "188038      1\n",
      "196763      1\n",
      "241765      1\n",
      "122975      1\n",
      "28765       1\n",
      "194652      1\n",
      "49243       1\n",
      "104542      1\n",
      "317528      1\n",
      "368727      1\n",
      "143445      1\n",
      "486332      1\n",
      "50791       1\n",
      "57423       1\n",
      "192589      1\n",
      "179813      1\n",
      "217161      1\n",
      "41031       1\n",
      "165517      1\n",
      "208965      1\n",
      "178244      1\n",
      "196675      1\n",
      "126208      1\n",
      "168001      1\n",
      "362482      1\n",
      "293690      1\n",
      "324231      1\n",
      "421871      1\n",
      "130060      1\n",
      "139455      1\n",
      "249771      1\n",
      "182186      1\n",
      "108454      1\n",
      "395170      1\n",
      "335777      1\n",
      "456604      1\n",
      "24473       1\n",
      "34161       1\n",
      "127273      1\n",
      "343957      1\n",
      "285621      1\n",
      "34706       1\n",
      "136306      1\n",
      "192399      1\n",
      "130957      1\n",
      "161676      1\n",
      "230113      1\n",
      "83850       1\n",
      "293440      1\n",
      "75654       1\n",
      "309124      1\n",
      "100226      1\n",
      "146460      1\n",
      "65087       1\n",
      "456572      1\n",
      "417657      1\n",
      "343925      1\n",
      "341227      1\n",
      "147821      1\n",
      "344916      1\n",
      "430035      1\n",
      "92845       1\n",
      "55272       1\n",
      "108366      1\n",
      "194293      1\n",
      "24292       1\n",
      "202720      1\n",
      "121253      1\n",
      "229341      1\n",
      "188377      1\n",
      "187794      1\n",
      "231672      1\n",
      "108502      1\n",
      "376789      1\n",
      "277541      1\n",
      "108470      1\n",
      "252842      1\n",
      "59342       1\n",
      "182218      1\n",
      "221129      1\n",
      "284616      1\n",
      "229531      1\n",
      "249322      1\n",
      "318082      1\n",
      "38848       1\n",
      "183709      1\n",
      "255934      1\n",
      "217019      1\n",
      "120760      1\n",
      "365908      1\n",
      "229939      1\n",
      "170984      1\n",
      "218886      1\n",
      "263932      1\n",
      "365289      1\n",
      "124672      1\n",
      "161538      1\n",
      "98051       1\n",
      "129845      1\n",
      "145162      1\n",
      "44793       1\n",
      "151364      1\n",
      "71438       1\n",
      "192273      1\n",
      "207022      1\n",
      "216853      1\n",
      "286487      1\n",
      "276218      1\n",
      "304595      1\n",
      "309098      1\n",
      "234373      1\n",
      "403910      1\n",
      "294431      1\n",
      "149204      1\n",
      "188119      1\n",
      "145114      1\n",
      "48859       1\n",
      "192225      1\n",
      "116468      1\n",
      "85733       1\n",
      "304872      1\n",
      "44777       1\n",
      "34540       1\n",
      "388849      1\n",
      "129528      1\n",
      "143129      1\n",
      "290593      1\n",
      "101096      1\n",
      "182100      1\n",
      "440138      1\n",
      "118736      1\n",
      "264012      1\n",
      "364365      1\n",
      "288592      1\n",
      "227154      1\n",
      "100188      1\n",
      "294691      1\n",
      "171871      1\n",
      "288608      1\n",
      "129764      1\n",
      "358242      1\n",
      "116580      1\n",
      "165226      1\n",
      "222107      1\n",
      "151365      1\n",
      "156980      1\n",
      "202558      1\n",
      "164515      1\n",
      "45834       1\n",
      "337720      1\n",
      "196403      1\n",
      "117555      1\n",
      "159537      1\n",
      "59184       1\n",
      "407338      1\n",
      "306985      1\n",
      "108328      1\n",
      "188199      1\n",
      "184101      1\n",
      "83748       1\n",
      "38606       1\n",
      "233165      1\n",
      "178771      1\n",
      "310907      1\n",
      "179137      1\n",
      "341610      1\n",
      "52536       1\n",
      "386672      1\n",
      "198815      1\n",
      "95519       1\n",
      "202366      1\n",
      "231052      1\n",
      "204415      1\n",
      "222848      1\n",
      "196227      1\n",
      "706180      1\n",
      "20101       1\n",
      "274057      1\n",
      "397467      1\n",
      "280164      1\n",
      "120408      1\n",
      "217577      1\n",
      "34100       1\n",
      "185942      1\n",
      "183893      1\n",
      "152667      1\n",
      "159313      1\n",
      "222800      1\n",
      "257302      1\n",
      "156493      1\n",
      "99971       1\n",
      "114251      1\n",
      "175689      1\n",
      "148113      1\n",
      "219987      1\n",
      "308874      1\n",
      "134797      1\n",
      "147147      1\n",
      "200381      1\n",
      "356017      1\n",
      "259762      1\n",
      "293287      1\n",
      "286391      1\n",
      "405177      1\n",
      "377140      1\n",
      "106175      1\n",
      "585361      1\n",
      "32451       1\n",
      "184005      1\n",
      "120518      1\n",
      "220871      1\n",
      "357596      1\n",
      "138157      1\n",
      "40623       1\n",
      "136878      1\n",
      "278187      1\n",
      "63676       1\n",
      "153254      1\n",
      "73746       1\n",
      "32509       1\n",
      "192161      1\n",
      "134813      1\n",
      "120251      1\n",
      "133025      1\n",
      "24215       1\n",
      "317078      1\n",
      "275051      1\n",
      "116372      1\n",
      "97939       1\n",
      "215211      1\n",
      "337768      1\n",
      "376683      1\n",
      "448026      1\n",
      "41017       1\n",
      "188465      1\n",
      "192563      1\n",
      "116788      1\n",
      "199416      1\n",
      "181810      1\n",
      "124487      1\n",
      "32801       1\n",
      "131117      1\n",
      "167999      1\n",
      "270522      1\n",
      "243786      1\n",
      "340043      1\n",
      "89598       1\n",
      "129956      1\n",
      "107597      1\n",
      "158218      1\n",
      "132972      1\n",
      "182590      1\n",
      "196621      1\n",
      "301070      1\n",
      "266255      1\n",
      "245274      1\n",
      "129042      1\n",
      "236570      1\n",
      "53271       1\n",
      "274475      1\n",
      "243773      1\n",
      "165916      1\n",
      "323619      1\n",
      "182308      1\n",
      "197369      1\n",
      "206888      1\n",
      "102479      1\n",
      "161874      1\n",
      "116820      1\n",
      "255348      1\n",
      "53367       1\n",
      "247162      1\n",
      "329852      1\n",
      "163965      1\n",
      "92288       1\n",
      "161922      1\n",
      "147589      1\n",
      "180309      1\n",
      "174216      1\n",
      "253583      1\n",
      "252565      1\n",
      "393357      1\n",
      "181657      1\n",
      "210851      1\n",
      "153718      1\n",
      "284250      1\n",
      "116852      1\n",
      "225395      1\n",
      "155761      1\n",
      "134787      1\n",
      "398001      1\n",
      "261720      1\n",
      "264300      1\n",
      "512103      1\n",
      "248346      1\n",
      "292962      1\n",
      "339954      1\n",
      "430175      1\n",
      "137310      1\n",
      "372500      1\n",
      "186454      1\n",
      "305160      1\n",
      "282631      1\n",
      "182276      1\n",
      "208809      1\n",
      "180123      1\n",
      "169886      1\n",
      "190368      1\n",
      "284582      1\n",
      "221095      1\n",
      "173992      1\n",
      "112554      1\n",
      "186294      1\n",
      "165804      1\n",
      "242923      1\n",
      "255830      1\n",
      "96178       1\n",
      "378114      1\n",
      "280500      1\n",
      "178074      1\n",
      "122775      1\n",
      "60562       1\n",
      "26857       1\n",
      "237455      1\n",
      "399246      1\n",
      "147339      1\n",
      "173960      1\n",
      "216965      1\n",
      "304949      1\n",
      "96130       1\n",
      "126849      1\n",
      "229967      1\n",
      "37741       1\n",
      "272248      1\n",
      "32627       1\n",
      "251411      1\n",
      "282549      1\n",
      "281982      1\n",
      "192515      1\n",
      "129010      1\n",
      "157686      1\n",
      "219110      1\n",
      "48280       1\n",
      "34796       1\n",
      "255667      1\n",
      "94193       1\n",
      "269417      1\n",
      "339897      1\n",
      "319685      1\n",
      "272376      1\n",
      "264188      1\n",
      "145548      1\n",
      "270335      1\n",
      "256000      1\n",
      "100316      1\n",
      "49115       1\n",
      "210906      1\n",
      "344172      1\n",
      "26803       1\n",
      "92112       1\n",
      "71630       1\n",
      "176073      1\n",
      "153542      1\n",
      "118725      1\n",
      "227968      1\n",
      "65475       1\n",
      "227266      1\n",
      "550848      1\n",
      "236913      1\n",
      "145269      1\n",
      "309178      1\n",
      "181828      1\n",
      "34364       1\n",
      "175081      1\n",
      "196388      1\n",
      "150693      1\n",
      "152742      1\n",
      "337064      1\n",
      "175273      1\n",
      "146603      1\n",
      "263340      1\n",
      "126129      1\n",
      "451744      1\n",
      "163108      1\n",
      "271544      1\n",
      "341178      1\n",
      "247187      1\n",
      "189632      1\n",
      "191681      1\n",
      "179949      1\n",
      "413227      1\n",
      "38158       1\n",
      "101517      1\n",
      "469572      1\n",
      "125926      1\n",
      "193666      1\n",
      "162947      1\n",
      "509060      1\n",
      "173192      1\n",
      "236687      1\n",
      "363677      1\n",
      "258120      1\n",
      "345236      1\n",
      "183445      1\n",
      "173208      1\n",
      "373914      1\n",
      "165020      1\n",
      "160962      1\n",
      "195779      1\n",
      "308489      1\n",
      "89389       1\n",
      "70894       1\n",
      "355569      1\n",
      "226546      1\n",
      "148724      1\n",
      "146154      1\n",
      "227471      1\n",
      "171050      1\n",
      "176602      1\n",
      "58624       1\n",
      "28225       1\n",
      "181508      1\n",
      "206088      1\n",
      "208137      1\n",
      "212235      1\n",
      "34028       1\n",
      "310396      1\n",
      "242922      1\n",
      "222584      1\n",
      "278581      1\n",
      "167347      1\n",
      "290560      1\n",
      "433375      1\n",
      "101597      1\n",
      "197714      1\n",
      "171852      1\n",
      "163027      1\n",
      "126161      1\n",
      "136398      1\n",
      "232653      1\n",
      "217226      1\n",
      "201273      1\n",
      "145868      1\n",
      "192978      1\n",
      "212091      1\n",
      "43702       1\n",
      "374262      1\n",
      "185366      1\n",
      "187415      1\n",
      "262233      1\n",
      "37918       1\n",
      "121144      1\n",
      "97759       1\n",
      "306233      1\n",
      "326691      1\n",
      "214052      1\n",
      "498216      1\n",
      "234542      1\n",
      "195635      1\n",
      "214068      1\n",
      "158737      1\n",
      "123920      1\n",
      "201742      1\n",
      "218178      1\n",
      "164876      1\n",
      "58441       1\n",
      "173064      1\n",
      "349190      1\n",
      "128002      1\n",
      "251239      1\n",
      "271352      1\n",
      "183285      1\n",
      "248145      1\n",
      "98611       1\n",
      "224241      1\n",
      "158734      1\n",
      "166893      1\n",
      "238648      1\n",
      "123174      1\n",
      "112941      1\n",
      "107624      1\n",
      "179291      1\n",
      "33884       1\n",
      "201822      1\n",
      "203871      1\n",
      "152023      1\n",
      "162915      1\n",
      "210026      1\n",
      "164924      1\n",
      "132204      1\n",
      "235556      1\n",
      "123374      1\n",
      "95283       1\n",
      "87158       1\n",
      "142457      1\n",
      "44121       1\n",
      "238680      1\n",
      "187479      1\n",
      "85077       1\n",
      "29778       1\n",
      "303455      1\n",
      "123984      1\n",
      "367695      1\n",
      "164940      1\n",
      "177226      1\n",
      "205896      1\n",
      "272476      1\n",
      "54342       1\n",
      "208598      1\n",
      "156736      1\n",
      "103024      1\n",
      "199741      1\n",
      "238944      1\n",
      "269583      1\n",
      "245307      1\n",
      "202206      1\n",
      "149620      1\n",
      "148948      1\n",
      "185814      1\n",
      "141029      1\n",
      "245211      1\n",
      "192964      1\n",
      "349169      1\n",
      "282609      1\n",
      "220647      1\n",
      "198124      1\n",
      "167405      1\n",
      "28145       1\n",
      "178472      1\n",
      "294387      1\n",
      "103886      1\n",
      "179659      1\n",
      "101618      1\n",
      "263612      1\n",
      "118197      1\n",
      "218550      1\n",
      "132300      1\n",
      "491421      1\n",
      "245626      1\n",
      "311269      1\n",
      "265661      1\n",
      "112074      1\n",
      "187308      1\n",
      "249716      1\n",
      "380357      1\n",
      "185798      1\n",
      "206280      1\n",
      "258579      1\n",
      "151029      1\n",
      "75256       1\n",
      "170916      1\n",
      "400943      1\n",
      "187589      1\n",
      "152734      1\n",
      "233168      1\n",
      "132652      1\n",
      "55890       1\n",
      "133239      1\n",
      "749105      1\n",
      "119429      1\n",
      "176046      1\n",
      "83508       1\n",
      "131899      1\n",
      "162834      1\n",
      "161942      1\n",
      "177722      1\n",
      "27624       1\n",
      "83492       1\n",
      "32291       1\n",
      "110820      1\n",
      "103966      1\n",
      "245275      1\n",
      "243226      1\n",
      "175641      1\n",
      "183829      1\n",
      "32275       1\n",
      "30226       1\n",
      "353808      1\n",
      "518030      1\n",
      "103950      1\n",
      "308746      1\n",
      "65027       1\n",
      "58880       1\n",
      "333230      1\n",
      "200109      1\n",
      "219183      1\n",
      "177482      1\n",
      "132412      1\n",
      "298301      1\n",
      "171327      1\n",
      "83879       1\n",
      "181572      1\n",
      "227392      1\n",
      "113995      1\n",
      "167261      1\n",
      "324568      1\n",
      "335183      1\n",
      "423250      1\n",
      "52565       1\n",
      "28443       1\n",
      "108837      1\n",
      "109881      1\n",
      "154935      1\n",
      "197764      1\n",
      "190205      1\n",
      "129836      1\n",
      "156976      1\n",
      "406826      1\n",
      "306473      1\n",
      "235924      1\n",
      "54566       1\n",
      "183589      1\n",
      "50468       1\n",
      "27937       1\n",
      "176552      1\n",
      "36423       1\n",
      "109849      1\n",
      "110226      1\n",
      "114011      1\n",
      "202416      1\n",
      "179627      1\n",
      "175202      1\n",
      "236943      1\n",
      "95634       1\n",
      "183701      1\n",
      "501144      1\n",
      "77209       1\n",
      "245147      1\n",
      "308901      1\n",
      "189792      1\n",
      "148900      1\n",
      "52645       1\n",
      "168324      1\n",
      "41938       1\n",
      "241065      1\n",
      "177578      1\n",
      "216453      1\n",
      "107303      1\n",
      "146711      1\n",
      "189824      1\n",
      "40319       1\n",
      "562558      1\n",
      "200061      1\n",
      "339321      1\n",
      "116084      1\n",
      "228723      1\n",
      "153323      1\n",
      "134509      1\n",
      "362302      1\n",
      "275818      1\n",
      "241001      1\n",
      "205288      1\n",
      "410980      1\n",
      "24721       1\n",
      "149652      1\n",
      "305304      1\n",
      "246677      1\n",
      "113546      1\n",
      "164749      1\n",
      "187653      1\n",
      "270278      1\n",
      "203072      1\n",
      "48972       1\n",
      "107417      1\n",
      "388023      1\n",
      "239045      1\n",
      "138142      1\n",
      "168863      1\n",
      "25505       1\n",
      "31650       1\n",
      "142424      1\n",
      "41865       1\n",
      "312197      1\n",
      "230397      1\n",
      "111467      1\n",
      "263005      1\n",
      "193379      1\n",
      "215908      1\n",
      "377701      1\n",
      "469864      1\n",
      "232337      1\n",
      "618191      1\n",
      "248708      1\n",
      "250743      1\n",
      "244602      1\n",
      "204163      1\n",
      "136063      1\n",
      "158592      1\n",
      "172148      1\n",
      "279461      1\n",
      "250791      1\n",
      "107433      1\n",
      "506858      1\n",
      "242651      1\n",
      "328669      1\n",
      "105438      1\n",
      "165134      1\n",
      "183146      1\n",
      "207848      1\n",
      "209899      1\n",
      "205422      1\n",
      "103407      1\n",
      "158704      1\n",
      "172928      1\n",
      "156033      1\n",
      "121846      1\n",
      "107513      1\n",
      "23510       1\n",
      "422275      1\n",
      "251701      1\n",
      "228306      1\n",
      "234447      1\n",
      "105422      1\n",
      "278476      1\n",
      "90653       1\n",
      "89030       1\n",
      "215833      1\n",
      "158656      1\n",
      "203710      1\n",
      "265148      1\n",
      "142264      1\n",
      "248249      1\n",
      "186239      1\n",
      "188391      1\n",
      "275291      1\n",
      "56150       1\n",
      "345504      1\n",
      "303860      1\n",
      "185063      1\n",
      "174824      1\n",
      "105339      1\n",
      "166636      1\n",
      "393965      1\n",
      "125680      1\n",
      "352834      1\n",
      "156417      1\n",
      "132680      1\n",
      "121590      1\n",
      "185079      1\n",
      "238329      1\n",
      "373499      1\n",
      "118119      1\n",
      "197757      1\n",
      "195298      1\n",
      "34532       1\n",
      "37599       1\n",
      "170718      1\n",
      "264924      1\n",
      "251091      1\n",
      "135567      1\n",
      "316119      1\n",
      "94931       1\n",
      "167544      1\n",
      "58065       1\n",
      "297676      1\n",
      "192455      1\n",
      "303817      1\n",
      "338632      1\n",
      "193219      1\n",
      "203518      1\n",
      "258819      1\n",
      "346964      1\n",
      "254247      1\n",
      "230922      1\n",
      "117556      1\n",
      "213813      1\n",
      "152375      1\n",
      "174904      1\n",
      "158528      1\n",
      "223464      1\n",
      "28455       1\n",
      "109959      1\n",
      "361838      1\n",
      "328525      1\n",
      "208326      1\n",
      "125776      1\n",
      "127827      1\n",
      "244522      1\n",
      "194231      1\n",
      "148261      1\n",
      "174196      1\n",
      "131869      1\n",
      "97355       1\n",
      "113434      1\n",
      "181896      1\n",
      "316183      1\n",
      "187158      1\n",
      "129882      1\n",
      "84756       1\n",
      "90897       1\n",
      "137214      1\n",
      "101132      1\n",
      "292370      1\n",
      "174856      1\n",
      "113658      1\n",
      "485710      1\n",
      "438427      1\n",
      "97474       1\n",
      "83511       1\n",
      "251063      1\n",
      "396745      1\n",
      "296125      1\n",
      "128063      1\n",
      "58098       1\n",
      "175304      1\n",
      "292019      1\n",
      "199884      1\n",
      "40142       1\n",
      "267471      1\n",
      "97490       1\n",
      "422718      1\n",
      "326330      1\n",
      "177035      1\n",
      "229393      1\n",
      "320513      1\n",
      "173051      1\n",
      "414871      1\n",
      "81965       1\n",
      "177307      1\n",
      "251603      1\n",
      "348854      1\n",
      "394503      1\n",
      "350254      1\n",
      "27653       1\n",
      "87605       1\n",
      "47151       1\n",
      "76968       1\n",
      "157974      1\n",
      "41374       1\n",
      "79019       1\n",
      "199900      1\n",
      "99549       1\n",
      "233107      1\n",
      "27920       1\n",
      "145155      1\n",
      "173351      1\n",
      "224512      1\n",
      "319271      1\n",
      "254303      1\n",
      "185607      1\n",
      "163090      1\n",
      "156897      1\n",
      "83242       1\n",
      "115989      1\n",
      "152855      1\n",
      "142616      1\n",
      "204062      1\n",
      "119129      1\n",
      "197565      1\n",
      "376058      1\n",
      "240888      1\n",
      "316663      1\n",
      "384246      1\n",
      "19700       1\n",
      "357619      1\n",
      "24266       1\n",
      "34029       1\n",
      "364862      1\n",
      "177387      1\n",
      "152237      1\n",
      "306496      1\n",
      "273640      1\n",
      "122086      1\n",
      "216292      1\n",
      "160995      1\n",
      "384150      1\n",
      "246933      1\n",
      "52372       1\n",
      "249147      1\n",
      "35884       1\n",
      "212622      1\n",
      "25649       1\n",
      "226355      1\n",
      "318518      1\n",
      "252529      1\n",
      "695136      1\n",
      "303485      1\n",
      "101436      1\n",
      "94392       1\n",
      "302142      1\n",
      "169023      1\n",
      "158784      1\n",
      "162882      1\n",
      "379940      1\n",
      "158752      1\n",
      "138270      1\n",
      "78875       1\n",
      "277530      1\n",
      "115364      1\n",
      "111971      1\n",
      "50197       1\n",
      "150548      1\n",
      "140571      1\n",
      "388112      1\n",
      "177163      1\n",
      "165412      1\n",
      "160646      1\n",
      "115717      1\n",
      "216068      1\n",
      "660461      1\n",
      "95299       1\n",
      "187462      1\n",
      "418961      1\n",
      "101500      1\n",
      "162930      1\n",
      "101771      1\n",
      "69182       1\n",
      "235167      1\n",
      "283767      1\n",
      "99502       1\n",
      "45522       1\n",
      "223131      1\n",
      "291981      1\n",
      "232614      1\n",
      "218039      1\n",
      "152711      1\n",
      "68748       1\n",
      "201871      1\n",
      "296045      1\n",
      "177639      1\n",
      "121958      1\n",
      "83045       1\n",
      "117860      1\n",
      "44791       1\n",
      "101468      1\n",
      "80986       1\n",
      "121942      1\n",
      "257933      1\n",
      "31826       1\n",
      "158800      1\n",
      "286634      1\n",
      "84657       1\n",
      "406603      1\n",
      "204389      1\n",
      "336969      1\n",
      "391874      1\n",
      "387776      1\n",
      "134888      1\n",
      "51151       1\n",
      "153926      1\n",
      "119111      1\n",
      "216035      1\n",
      "209227      1\n",
      "166220      1\n",
      "221452      1\n",
      "162130      1\n",
      "57665       1\n",
      "128714      1\n",
      "153942      1\n",
      "153890      1\n",
      "67217       1\n",
      "205145      1\n",
      "604506      1\n",
      "260953      1\n",
      "190784      1\n",
      "105150      1\n",
      "98605       1\n",
      "117028      1\n",
      "153894      1\n",
      "119079      1\n",
      "30269       1\n",
      "211242      1\n",
      "274731      1\n",
      "188328      1\n",
      "133436      1\n",
      "162098      1\n",
      "543028      1\n",
      "121142      1\n",
      "201657      1\n",
      "110610      1\n",
      "283305      1\n",
      "78171       1\n",
      "206129      1\n",
      "248164      1\n",
      "225859      1\n",
      "172425      1\n",
      "170382      1\n",
      "266639      1\n",
      "319889      1\n",
      "194962      1\n",
      "29075       1\n",
      "194431      1\n",
      "246117      1\n",
      "250263      1\n",
      "194951      1\n",
      "244122      1\n",
      "143771      1\n",
      "100764      1\n",
      "366219      1\n",
      "39386       1\n",
      "147845      1\n",
      "127363      1\n",
      "227714      1\n",
      "174150      1\n",
      "104830      1\n",
      "23776       1\n",
      "135001      1\n",
      "407930      1\n",
      "446839      1\n",
      "219510      1\n",
      "239577      1\n",
      "122575      1\n",
      "170350      1\n",
      "229741      1\n",
      "478994      1\n",
      "165097      1\n",
      "194850      1\n",
      "195096      1\n",
      "260082      1\n",
      "305352      1\n",
      "241851      1\n",
      "136094      1\n",
      "196797      1\n",
      "159939      1\n",
      "57145       1\n",
      "53447       1\n",
      "41161       1\n",
      "171926      1\n",
      "193479      1\n",
      "295117      1\n",
      "102607      1\n",
      "26832       1\n",
      "319697      1\n",
      "162002      1\n",
      "368825      1\n",
      "207032      1\n",
      "201734      1\n",
      "283531      1\n",
      "208726      1\n",
      "268083      1\n",
      "137390      1\n",
      "307371      1\n",
      "387839      1\n",
      "113915      1\n",
      "161954      1\n",
      "90273       1\n",
      "354464      1\n",
      "200863      1\n",
      "170142      1\n",
      "229533      1\n",
      "100508      1\n",
      "88278       1\n",
      "211162      1\n",
      "176761      1\n",
      "67852       1\n",
      "208391      1\n",
      "155905      1\n",
      "26109       1\n",
      "43272       1\n",
      "237833      1\n",
      "112906      1\n",
      "39182       1\n",
      "405723      1\n",
      "135439      1\n",
      "338355      1\n",
      "227602      1\n",
      "117012      1\n",
      "215620      1\n",
      "211226      1\n",
      "274683      1\n",
      "151799      1\n",
      "326379      1\n",
      "192755      1\n",
      "516337      1\n",
      "233711      1\n",
      "39150       1\n",
      "229613      1\n",
      "166124      1\n",
      "76008       1\n",
      "160951      1\n",
      "377061      1\n",
      "41013       1\n",
      "227554      1\n",
      "321760      1\n",
      "266463      1\n",
      "327901      1\n",
      "169303      1\n",
      "55718       1\n",
      "119207      1\n",
      "176731      1\n",
      "160339      1\n",
      "84564       1\n",
      "49749       1\n",
      "86615       1\n",
      "229009      1\n",
      "454843      1\n",
      "366757      1\n",
      "21095       1\n",
      "663394      1\n",
      "79637       1\n",
      "156257      1\n",
      "472604      1\n",
      "87209       1\n",
      "148069      1\n",
      "186213      1\n",
      "250552      1\n",
      "199244      1\n",
      "379393      1\n",
      "141896      1\n",
      "186950      1\n",
      "180805      1\n",
      "160323      1\n",
      "73051       1\n",
      "133692      1\n",
      "143931      1\n",
      "76344       1\n",
      "158545      1\n",
      "221745      1\n",
      "201263      1\n",
      "207400      1\n",
      "248356      1\n",
      "186982      1\n",
      "238185      1\n",
      "95078       1\n",
      "25249       1\n",
      "154100      1\n",
      "254973      1\n",
      "174744      1\n",
      "208506      1\n",
      "101020      1\n",
      "322208      1\n",
      "96930       1\n",
      "233382      1\n",
      "152231      1\n",
      "174760      1\n",
      "113322      1\n",
      "160131      1\n",
      "102986      1\n",
      "153501      1\n",
      "227986      1\n",
      "340171      1\n",
      "259583      1\n",
      "113290      1\n",
      "270985      1\n",
      "212600      1\n",
      "154246      1\n",
      "156953      1\n",
      "31362       1\n",
      "301694      1\n",
      "133756      1\n",
      "143995      1\n",
      "150132      1\n",
      "258675      1\n",
      "721161      1\n",
      "189041      1\n",
      "205730      1\n",
      "188961      1\n",
      "168479      1\n",
      "98733       1\n",
      "640383      1\n",
      "336329      1\n",
      "285127      1\n",
      "199116      1\n",
      "57914       1\n",
      "227794      1\n",
      "182740      1\n",
      "86805       1\n",
      "556688      1\n",
      "112942      1\n",
      "239375      1\n",
      "238192      1\n",
      "135647      1\n",
      "98667       1\n",
      "216804      1\n",
      "198801      1\n",
      "56645       1\n",
      "390348      1\n",
      "192963      1\n",
      "483777      1\n",
      "190912      1\n",
      "219718      1\n",
      "170430      1\n",
      "33213       1\n",
      "307643      1\n",
      "176357      1\n",
      "345006      1\n",
      "246197      1\n",
      "291251      1\n",
      "335625      1\n",
      "109938      1\n",
      "465326      1\n",
      "260578      1\n",
      "121318      1\n",
      "33309       1\n",
      "211466      1\n",
      "81513       1\n",
      "211731      1\n",
      "93099       1\n",
      "186886      1\n",
      "152071      1\n",
      "91839       1\n",
      "35340       1\n",
      "321763      1\n",
      "98829       1\n",
      "301582      1\n",
      "191565      1\n",
      "227858      1\n",
      "193043      1\n",
      "231964      1\n",
      "287233      1\n",
      "142169      1\n",
      "143867      1\n",
      "156040      1\n",
      "76280       1\n",
      "184823      1\n",
      "88566       1\n",
      "279029      1\n",
      "117236      1\n",
      "260594      1\n",
      "222882      1\n",
      "387568      1\n",
      "102895      1\n",
      "195199      1\n",
      "199998      1\n",
      "429897      1\n",
      "529223      1\n",
      "343019      1\n",
      "150262      1\n",
      "357720      1\n",
      "189975      1\n",
      "161285      1\n",
      "171598      1\n",
      "138760      1\n",
      "366089      1\n",
      "87569       1\n",
      "196116      1\n",
      "260754      1\n",
      "316929      1\n",
      "293385      1\n",
      "81436       1\n",
      "48404       1\n",
      "402975      1\n",
      "252253      1\n",
      "71860       1\n",
      "163332      1\n",
      "175614      1\n",
      "216690      1\n",
      "374253      1\n",
      "112093      1\n",
      "216013      1\n",
      "173535      1\n",
      "112160      1\n",
      "243678      1\n",
      "230891      1\n",
      "208366      1\n",
      "242095      1\n",
      "116635      1\n",
      "116211      1\n",
      "32244       1\n",
      "225307      1\n",
      "124407      1\n",
      "205895      1\n",
      "90338       1\n",
      "257574      1\n",
      "408773      1\n",
      "172755      1\n",
      "238049      1\n",
      "173647      1\n",
      "113913      1\n",
      "247379      1\n",
      "126550      1\n",
      "255575      1\n",
      "155232      1\n",
      "205581      1\n",
      "73587       1\n",
      "32356       1\n",
      "224870      1\n",
      "157287      1\n",
      "108808      1\n",
      "145005      1\n",
      "223745      1\n",
      "35890       1\n",
      "421446      1\n",
      "226885      1\n",
      "196164      1\n",
      "116133      1\n",
      "54849       1\n",
      "405155      1\n",
      "671292      1\n",
      "198203      1\n",
      "466502      1\n",
      "452452      1\n",
      "248911      1\n",
      "89648       1\n",
      "219141      1\n",
      "230955      1\n",
      "71209       1\n",
      "230875      1\n",
      "200775      1\n",
      "48751       1\n",
      "130436      1\n",
      "195956      1\n",
      "187505      1\n",
      "213654      1\n",
      "36218       1\n",
      "263224      1\n",
      "174926      1\n",
      "166018      1\n",
      "294292      1\n",
      "191878      1\n",
      "127366      1\n",
      "175502      1\n",
      "167915      1\n",
      "407759      1\n",
      "150930      1\n",
      "83315       1\n",
      "417136      1\n",
      "386175      1\n",
      "98719       1\n",
      "39239       1\n",
      "73064       1\n",
      "288103      1\n",
      "316769      1\n",
      "27678       1\n",
      "262885      1\n",
      "234841      1\n",
      "302424      1\n",
      "358783      1\n",
      "285747      1\n",
      "497280      1\n",
      "187728      1\n",
      "304463      1\n",
      "181651      1\n",
      "357781      1\n",
      "189911      1\n",
      "128453      1\n",
      "67482       1\n",
      "188976      1\n",
      "271807      1\n",
      "349633      1\n",
      "246011      1\n",
      "312771      1\n",
      "157127      1\n",
      "157079      1\n",
      "123612      1\n",
      "234953      1\n",
      "48588       1\n",
      "112077      1\n",
      "282066      1\n",
      "32212       1\n",
      "121559      1\n",
      "143943      1\n",
      "263374      1\n",
      "316849      1\n",
      "122288      1\n",
      "193075      1\n",
      "232874      1\n",
      "202153      1\n",
      "105896      1\n",
      "84402       1\n",
      "224716      1\n",
      "228772      1\n",
      "181667      1\n",
      "178934      1\n",
      "339358      1\n",
      "123430      1\n",
      "431513      1\n",
      "43739       1\n",
      "218916      1\n",
      "311495      1\n",
      "102202      1\n",
      "274222      1\n",
      "350001      1\n",
      "294708      1\n",
      "263836      1\n",
      "159542      1\n",
      "204600      1\n",
      "195892      1\n",
      "394176      1\n",
      "22978       1\n",
      "222966      1\n",
      "196420      1\n",
      "109815      1\n",
      "49069       1\n",
      "229700      1\n",
      "328949      1\n",
      "220819      1\n",
      "556660      1\n",
      "143118      1\n",
      "380674      1\n",
      "411395      1\n",
      "91911       1\n",
      "148460      1\n",
      "212748      1\n",
      "349041      1\n",
      "173839      1\n",
      "163620      1\n",
      "187073      1\n",
      "194325      1\n",
      "190231      1\n",
      "200474      1\n",
      "324120      1\n",
      "213866      1\n",
      "155472      1\n",
      "378707      1\n",
      "390997      1\n",
      "104329      1\n",
      "405374      1\n",
      "366662      1\n",
      "57216       1\n",
      "379066      1\n",
      "327589      1\n",
      "192390      1\n",
      "70657       1\n",
      "167770      1\n",
      "67467       1\n",
      "604045      1\n",
      "176014      1\n",
      "108431      1\n",
      "221072      1\n",
      "223127      1\n",
      "263094      1\n",
      "370888      1\n",
      "237432      1\n",
      "325493      1\n",
      "229236      1\n",
      "83827       1\n",
      "236328      1\n",
      "173935      1\n",
      "210797      1\n",
      "137065      1\n",
      "40808       1\n",
      "156192      1\n",
      "378723      1\n",
      "87905       1\n",
      "75214       1\n",
      "99184       1\n",
      "112706      1\n",
      "134906      1\n",
      "204536      1\n",
      "434894      1\n",
      "220832      1\n",
      "194197      1\n",
      "192150      1\n",
      "141649      1\n",
      "117387      1\n",
      "110238      1\n",
      "401762      1\n",
      "183970      1\n",
      "29617       1\n",
      "189502      1\n",
      "130724      1\n",
      "95909       1\n",
      "224934      1\n",
      "370552      1\n",
      "243373      1\n",
      "82946       1\n",
      "315026      1\n",
      "188048      1\n",
      "306830      1\n",
      "57640       1\n",
      "81548       1\n",
      "71305       1\n",
      "176341      1\n",
      "353927      1\n",
      "240809      1\n",
      "226949      1\n",
      "20098       1\n",
      "515712      1\n",
      "121136      1\n",
      "308861      1\n",
      "212900      1\n",
      "157303      1\n",
      "256019      1\n",
      "182656      1\n",
      "81400       1\n",
      "270056      1\n",
      "376540      1\n",
      "196243      1\n",
      "317153      1\n",
      "31703       1\n",
      "917220      1\n",
      "192230      1\n",
      "300777      1\n",
      "423605      1\n",
      "341741      1\n",
      "274158      1\n",
      "173807      1\n",
      "347890      1\n",
      "280307      1\n",
      "128757      1\n",
      "257750      1\n",
      "73895       1\n",
      "247507      1\n",
      "351952      1\n",
      "341709      1\n",
      "278220      1\n",
      "489085      1\n",
      "173062      1\n",
      "698418      1\n",
      "114362      1\n",
      "165152      1\n",
      "251585      1\n",
      "337599      1\n",
      "521400      1\n",
      "212668      1\n",
      "157367      1\n",
      "192182      1\n",
      "146764      1\n",
      "115360      1\n",
      "279524      1\n",
      "301168      1\n",
      "82646       1\n",
      "213955      1\n",
      "293828      1\n",
      "193477      1\n",
      "158662      1\n",
      "138184      1\n",
      "152529      1\n",
      "136121      1\n",
      "314322      1\n",
      "142081      1\n",
      "254935      1\n",
      "70617       1\n",
      "57698       1\n",
      "152545      1\n",
      "250034      1\n",
      "236472      1\n",
      "70697       1\n",
      "168873      1\n",
      "260199      1\n",
      "275357      1\n",
      "240542      1\n",
      "282678      1\n",
      "385959      1\n",
      "138152      1\n",
      "101290      1\n",
      "164229      1\n",
      "230315      1\n",
      "277420      1\n",
      "287160      1\n",
      "99316       1\n",
      "543042      1\n",
      "106039      1\n",
      "181219      1\n",
      "236520      1\n",
      "66917       1\n",
      "37913       1\n",
      "99339       1\n",
      "343052      1\n",
      "144397      1\n",
      "422149      1\n",
      "117778      1\n",
      "324629      1\n",
      "313573      1\n",
      "146412      1\n",
      "131068      1\n",
      "343068      1\n",
      "140319      1\n",
      "56352       1\n",
      "162852      1\n",
      "259109      1\n",
      "201737      1\n",
      "203784      1\n",
      "125031      1\n",
      "359428      1\n",
      "168941      1\n",
      "414721      1\n",
      "187392      1\n",
      "295919      1\n",
      "39212       1\n",
      "199674      1\n",
      "302072      1\n",
      "58359       1\n",
      "150106      1\n",
      "117746      1\n",
      "187376      1\n",
      "323810      1\n",
      "120920      1\n",
      "125846      1\n",
      "161387      1\n",
      "261012      1\n",
      "45869       1\n",
      "267706      1\n",
      "379682      1\n",
      "93202       1\n",
      "596776      1\n",
      "233280      1\n",
      "35626       1\n",
      "272615      1\n",
      "107327      1\n",
      "183575      1\n",
      "213811      1\n",
      "38622       1\n",
      "275995      1\n",
      "186386      1\n",
      "527162      1\n",
      "75313       1\n",
      "151402      1\n",
      "101146      1\n",
      "88470       1\n",
      "269080      1\n",
      "279315      1\n",
      "216164      1\n",
      "172815      1\n",
      "240398      1\n",
      "351278      1\n",
      "166666      1\n",
      "177728      1\n",
      "156423      1\n",
      "60166       1\n",
      "127749      1\n",
      "387779      1\n",
      "106889      1\n",
      "47932       1\n",
      "351040      1\n",
      "181139      1\n",
      "117634      1\n",
      "324469      1\n",
      "389479      1\n",
      "202473      1\n",
      "172927      1\n",
      "187264      1\n",
      "202483      1\n",
      "226181      1\n",
      "457402      1\n",
      "286230      1\n",
      "29927       1\n",
      "633742      1\n",
      "238479      1\n",
      "191411      1\n",
      "52114       1\n",
      "121712      1\n",
      "111469      1\n",
      "346978      1\n",
      "217953      1\n",
      "238431      1\n",
      "361307      1\n",
      "103257      1\n",
      "105304      1\n",
      "191318      1\n",
      "258666      1\n",
      "414545      1\n",
      "310290      1\n",
      "284680      1\n",
      "184784      1\n",
      "175897      1\n",
      "148291      1\n",
      "117570      1\n",
      "72744       1\n",
      "238530      1\n",
      "159046      1\n",
      "180039      1\n",
      "173279      1\n",
      "220384      1\n",
      "85218       1\n",
      "97508       1\n",
      "91367       1\n",
      "400616      1\n",
      "134378      1\n",
      "328923      1\n",
      "197867      1\n",
      "179436      1\n",
      "93056       1\n",
      "410867      1\n",
      "188515      1\n",
      "171256      1\n",
      "376028      1\n",
      "36058       1\n",
      "144429      1\n",
      "269512      1\n",
      "229504      1\n",
      "312131      1\n",
      "184568      1\n",
      "92061       1\n",
      "157165      1\n",
      "322999      1\n",
      "297155      1\n",
      "203992      1\n",
      "113868      1\n",
      "242893      1\n",
      "427781      1\n",
      "271567      1\n",
      "214227      1\n",
      "29909       1\n",
      "101626      1\n",
      "165115      1\n",
      "242941      1\n",
      "89392       1\n",
      "343872      1\n",
      "34091       1\n",
      "324655      1\n",
      "144685      1\n",
      "77102       1\n",
      "435503      1\n",
      "214323      1\n",
      "45288       1\n",
      "130356      1\n",
      "254905      1\n",
      "261056      1\n",
      "89146       1\n",
      "183618      1\n",
      "163140      1\n",
      "157893      1\n",
      "195876      1\n",
      "87329       1\n",
      "109854      1\n",
      "177437      1\n",
      "277788      1\n",
      "99925       1\n",
      "156951      1\n",
      "276153      1\n",
      "195860      1\n",
      "345363      1\n",
      "152102      1\n",
      "308493      1\n",
      "40200       1\n",
      "29957       1\n",
      "380162      1\n",
      "122112      1\n",
      "122032      1\n",
      "371886      1\n",
      "242861      1\n",
      "85074       1\n",
      "330826      1\n",
      "230475      1\n",
      "198078      1\n",
      "76878       1\n",
      "205903      1\n",
      "235108      1\n",
      "110199      1\n",
      "50132       1\n",
      "195668      1\n",
      "584790      1\n",
      "123991      1\n",
      "113756      1\n",
      "52322       1\n",
      "83043       1\n",
      "156743      1\n",
      "160837      1\n",
      "96321       1\n",
      "152641      1\n",
      "253006      1\n",
      "175166      1\n",
      "275517      1\n",
      "375868      1\n",
      "201785      1\n",
      "322614      1\n",
      "134220      1\n",
      "122742      1\n",
      "115763      1\n",
      "231738      1\n",
      "121904      1\n",
      "304175      1\n",
      "273454      1\n",
      "228452      1\n",
      "224358      1\n",
      "375980      1\n",
      "99483       1\n",
      "122000      1\n",
      "110908      1\n",
      "117906      1\n",
      "228500      1\n",
      "223851      1\n",
      "306405      1\n",
      "213290      1\n",
      "222311      1\n",
      "56480       1\n",
      "89391       1\n",
      "228516      1\n",
      "171176      1\n",
      "169129      1\n",
      "263339      1\n",
      "74895       1\n",
      "175246      1\n",
      "46221       1\n",
      "48268       1\n",
      "263307      1\n",
      "398473      1\n",
      "425092      1\n",
      "87169       1\n",
      "74879       1\n",
      "255407      1\n",
      "330874      1\n",
      "27766       1\n",
      "279667      1\n",
      "216178      1\n",
      "140399      1\n",
      "207982      1\n",
      "255282      1\n",
      "47261       1\n",
      "266138      1\n",
      "231323      1\n",
      "53878       1\n",
      "53206       1\n",
      "166509      1\n",
      "531055      1\n",
      "354929      1\n",
      "220944      1\n",
      "213620      1\n",
      "86646       1\n",
      "237229      1\n",
      "219682      1\n",
      "119891      1\n",
      "245975      1\n",
      "169605      1\n",
      "25216       1\n",
      "508548      1\n",
      "342635      1\n",
      "371305      1\n",
      "184362      1\n",
      "201310      1\n",
      "145762      1\n",
      "523484      1\n",
      "107096      1\n",
      "275034      1\n",
      "211547      1\n",
      "201930      1\n",
      "385632      1\n",
      "155449      1\n",
      "191073      1\n",
      "225890      1\n",
      "96867       1\n",
      "246372      1\n",
      "376929      1\n",
      "252519      1\n",
      "252257      1\n",
      "145649      1\n",
      "109193      1\n",
      "123584      1\n",
      "362600      1\n",
      "21174       1\n",
      "224462      1\n",
      "43705       1\n",
      "295612      1\n",
      "133821      1\n",
      "92865       1\n",
      "381895      1\n",
      "388247      1\n",
      "82628       1\n",
      "469705      1\n",
      "340682      1\n",
      "88922       1\n",
      "236090      1\n",
      "180916      1\n",
      "45814       1\n",
      "301743      1\n",
      "266926      1\n",
      "197292      1\n",
      "264095      1\n",
      "363707      1\n",
      "53926       1\n",
      "129699      1\n",
      "191137      1\n",
      "72351       1\n",
      "113307      1\n",
      "217750      1\n",
      "349502      1\n",
      "180884      1\n",
      "189072      1\n",
      "364832      1\n",
      "115284      1\n",
      "96851       1\n",
      "193106      1\n",
      "195075      1\n",
      "412149      1\n",
      "387250      1\n",
      "305657      1\n",
      "113147      1\n",
      "90624       1\n",
      "125441      1\n",
      "158412      1\n",
      "274913      1\n",
      "173524      1\n",
      "113163      1\n",
      "297485      1\n",
      "186145      1\n",
      "203279      1\n",
      "135566      1\n",
      "34321       1\n",
      "387569      1\n",
      "184285      1\n",
      "211435      1\n",
      "338409      1\n",
      "336360      1\n",
      "930948      1\n",
      "54816       1\n",
      "260579      1\n",
      "162840      1\n",
      "212705      1\n",
      "225612      1\n",
      "100829      1\n",
      "109231      1\n",
      "209370      1\n",
      "207321      1\n",
      "225473      1\n",
      "96287       1\n",
      "41496       1\n",
      "236111      1\n",
      "346693      1\n",
      "37438       1\n",
      "90688       1\n",
      "59969       1\n",
      "29250       1\n",
      "188008      1\n",
      "180804      1\n",
      "135607      1\n",
      "111130      1\n",
      "281678      1\n",
      "78410       1\n",
      "145995      1\n",
      "557644      1\n",
      "59660       1\n",
      "299598      1\n",
      "293565      1\n",
      "441210      1\n",
      "336440      1\n",
      "55863       1\n",
      "217654      1\n",
      "125489      1\n",
      "123440      1\n",
      "231981      1\n",
      "224147      1\n",
      "109097      1\n",
      "283174      1\n",
      "73054       1\n",
      "246308      1\n",
      "291362      1\n",
      "123424      1\n",
      "268831      1\n",
      "287317      1\n",
      "176811      1\n",
      "248533      1\n",
      "605502      1\n",
      "285575      1\n",
      "283510      1\n",
      "122041      1\n",
      "177018      1\n",
      "375675      1\n",
      "230268      1\n",
      "150657      1\n",
      "205704      1\n",
      "82804       1\n",
      "240521      1\n",
      "275338      1\n",
      "496526      1\n",
      "158609      1\n",
      "228243      1\n",
      "160654      1\n",
      "150389      1\n",
      "31603       1\n",
      "348886      1\n",
      "224097      1\n",
      "672412      1\n",
      "29522       1\n",
      "324854      1\n",
      "117589      1\n",
      "54102       1\n",
      "273241      1\n",
      "157273      1\n",
      "127858      1\n",
      "289748      1\n",
      "318749      1\n",
      "408427      1\n",
      "33644       1\n",
      "1184622     1\n",
      "171234      1\n",
      "220055      1\n",
      "142233      1\n",
      "66460       1\n",
      "224209      1\n",
      "203138      1\n",
      "213716      1\n",
      "25031       1\n",
      "80485       1\n",
      "211915      1\n",
      "123856      1\n",
      "193490      1\n",
      "332702      1\n",
      "240330      1\n",
      "268797      1\n",
      "74712       1\n",
      "407043      1\n",
      "46677       1\n",
      "202286      1\n",
      "324546      1\n",
      "746432      1\n",
      "334783      1\n",
      "312498      1\n",
      "89015       1\n",
      "195507      1\n",
      "158641      1\n",
      "203697      1\n",
      "258730      1\n",
      "70088       1\n",
      "539563      1\n",
      "257735      1\n",
      "209230      1\n",
      "185254      1\n",
      "183205      1\n",
      "195491      1\n",
      "113948      1\n",
      "267086      1\n",
      "199501      1\n",
      "233461      1\n",
      "373698      1\n",
      "543477      1\n",
      "138253      1\n",
      "187127      1\n",
      "142073      1\n",
      "144122      1\n",
      "197372      1\n",
      "496382      1\n",
      "193298      1\n",
      "291586      1\n",
      "117509      1\n",
      "119558      1\n",
      "291783      1\n",
      "252466      1\n",
      "80651       1\n",
      "180980      1\n",
      "359155      1\n",
      "94962       1\n",
      "26994       1\n",
      "260490      1\n",
      "209642      1\n",
      "344804      1\n",
      "183170      1\n",
      "195612      1\n",
      "256737      1\n",
      "194287      1\n",
      "133853      1\n",
      "163331      1\n",
      "375515      1\n",
      "244773      1\n",
      "139992      1\n",
      "219863      1\n",
      "27409       1\n",
      "231013      1\n",
      "277323      1\n",
      "76773       1\n",
      "103214      1\n",
      "62258       1\n",
      "64307       1\n",
      "520759      1\n",
      "247651      1\n",
      "240441      1\n",
      "384308      1\n",
      "183061      1\n",
      "234302      1\n",
      "125761      1\n",
      "202903      1\n",
      "52037       1\n",
      "217926      1\n",
      "74568       1\n",
      "439779      1\n",
      "214063      1\n",
      "373895      1\n",
      "78634       1\n",
      "238376      1\n",
      "38797       1\n",
      "183077      1\n",
      "327786      1\n",
      "162595      1\n",
      "324386      1\n",
      "60193       1\n",
      "189216      1\n",
      "496414      1\n",
      "459548      1\n",
      "144154      1\n",
      "238360      1\n",
      "66385       1\n",
      "72143       1\n",
      "145175      1\n",
      "164300      1\n",
      "203797      1\n",
      "32316       1\n",
      "213092      1\n",
      "415847      1\n",
      "184121      1\n",
      "287878      1\n",
      "90881       1\n",
      "102510      1\n",
      "190561      1\n",
      "192924      1\n",
      "190577      1\n",
      "192626      1\n",
      "118902      1\n",
      "636017      1\n",
      "363192      1\n",
      "185216      1\n",
      "211035      1\n",
      "473547      1\n",
      "28738       1\n",
      "350247      1\n",
      "204840      1\n",
      "272425      1\n",
      "424094      1\n",
      "30771       1\n",
      "237624      1\n",
      "83413       1\n",
      "239705      1\n",
      "172104      1\n",
      "178251      1\n",
      "67661       1\n",
      "86111       1\n",
      "227411      1\n",
      "84053       1\n",
      "36990       1\n",
      "188544      1\n",
      "129155      1\n",
      "167536      1\n",
      "367390      1\n",
      "136075      1\n",
      "107575      1\n",
      "118966      1\n",
      "230789      1\n",
      "362685      1\n",
      "352448      1\n",
      "75913       1\n",
      "116933      1\n",
      "153799      1\n",
      "139464      1\n",
      "110794      1\n",
      "337696      1\n",
      "93211       1\n",
      "61603       1\n",
      "135342      1\n",
      "209891      1\n",
      "211115      1\n",
      "293512      1\n",
      "141481      1\n",
      "83922       1\n",
      "88231       1\n",
      "473625      1\n",
      "200862      1\n",
      "243867      1\n",
      "174233      1\n",
      "88215       1\n",
      "102542      1\n",
      "198797      1\n",
      "229516      1\n",
      "44738       1\n",
      "316059      1\n",
      "129059      1\n",
      "216845      1\n",
      "171156      1\n",
      "178109      1\n",
      "403391      1\n",
      "188352      1\n",
      "55233       1\n",
      "419740      1\n",
      "325573      1\n",
      "280714      1\n",
      "258006      1\n",
      "319422      1\n",
      "77774       1\n",
      "42959       1\n",
      "146311      1\n",
      "151506      1\n",
      "196564      1\n",
      "34747       1\n",
      "237920      1\n",
      "303032      1\n",
      "304530      1\n",
      "229300      1\n",
      "83891       1\n",
      "83434       1\n",
      "75695       1\n",
      "110510      1\n",
      "89951       1\n",
      "193530      1\n",
      "139176      1\n",
      "288679      1\n",
      "147069      1\n",
      "280483      1\n",
      "217530      1\n",
      "253856      1\n",
      "456661      1\n",
      "190423      1\n",
      "108569      1\n",
      "139272      1\n",
      "362491      1\n",
      "126320      1\n",
      "200496      1\n",
      "159389      1\n",
      "126978      1\n",
      "120839      1\n",
      "75785       1\n",
      "198997      1\n",
      "176138      1\n",
      "56118       1\n",
      "235535      1\n",
      "333910      1\n",
      "147476      1\n",
      "118806      1\n",
      "204792      1\n",
      "131060      1\n",
      "60772       1\n",
      "450544      1\n",
      "174063      1\n",
      "143342      1\n",
      "147850      1\n",
      "134613      1\n",
      "59367       1\n",
      "358373      1\n",
      "262116      1\n",
      "169717      1\n",
      "206815      1\n",
      "274398      1\n",
      "245724      1\n",
      "198619      1\n",
      "126386      1\n",
      "370509      1\n",
      "96467       1\n",
      "450920      1\n",
      "101383      1\n",
      "188568      1\n",
      "164204      1\n",
      "166253      1\n",
      "495982      1\n",
      "278900      1\n",
      "198188      1\n",
      "110970      1\n",
      "168334      1\n",
      "328060      1\n",
      "243361      1\n",
      "418176      1\n",
      "117125      1\n",
      "270728      1\n",
      "225432      1\n",
      "110954      1\n",
      "237928      1\n",
      "416103      1\n",
      "53606       1\n",
      "53506       1\n",
      "129379      1\n",
      "192866      1\n",
      "190817      1\n",
      "156000      1\n",
      "268639      1\n",
      "299358      1\n",
      "199005      1\n",
      "78170       1\n",
      "167886      1\n",
      "335376      1\n",
      "137205      1\n",
      "383322      1\n",
      "295308      1\n",
      "332465      1\n",
      "68642       1\n",
      "19410       1\n",
      "215477      1\n",
      "151990      1\n",
      "128224      1\n",
      "238008      1\n",
      "443742      1\n",
      "176570      1\n",
      "92609       1\n",
      "94610       1\n",
      "326083      1\n",
      "246212      1\n",
      "388384      1\n",
      "156513      1\n",
      "205256      1\n",
      "242122      1\n",
      "160178      1\n",
      "92593       1\n",
      "199085      1\n",
      "197036      1\n",
      "23740       1\n",
      "338345      1\n",
      "401832      1\n",
      "49572       1\n",
      "192930      1\n",
      "146660      1\n",
      "191130      1\n",
      "299422      1\n",
      "185042      1\n",
      "211355      1\n",
      "212027      1\n",
      "403865      1\n",
      "147860      1\n",
      "155697      1\n",
      "176458      1\n",
      "22743       1\n",
      "147982      1\n",
      "442612      1\n",
      "90935       1\n",
      "115839      1\n",
      "221436      1\n",
      "235775      1\n",
      "258306      1\n",
      "147239      1\n",
      "259284      1\n",
      "182533      1\n",
      "383239      1\n",
      "172296      1\n",
      "207113      1\n",
      "340234      1\n",
      "233419      1\n",
      "227571      1\n",
      "327533      1\n",
      "26865       1\n",
      "286960      1\n",
      "364782      1\n",
      "257064      1\n",
      "426836      1\n",
      "121622      1\n",
      "106728      1\n",
      "55527       1\n",
      "23621       1\n",
      "311524      1\n",
      "127202      1\n",
      "354529      1\n",
      "91433       1\n",
      "75993       1\n",
      "336088      1\n",
      "266510      1\n",
      "298717      1\n",
      "74056       1\n",
      "375078      1\n",
      "26929       1\n",
      "301514      1\n",
      "206827      1\n",
      "41890       1\n",
      "74040       1\n",
      "71076       1\n",
      "164156      1\n",
      "164123      1\n",
      "231741      1\n",
      "26672       1\n",
      "125249      1\n",
      "357059      1\n",
      "217414      1\n",
      "153927      1\n",
      "135470      1\n",
      "297261      1\n",
      "57951       1\n",
      "305449      1\n",
      "74024       1\n",
      "121127      1\n",
      "86310       1\n",
      "252208      1\n",
      "397877      1\n",
      "325923      1\n",
      "343190      1\n",
      "143436      1\n",
      "287268      1\n",
      "327964      1\n",
      "237848      1\n",
      "184598      1\n",
      "186370      1\n",
      "386337      1\n",
      "148773      1\n",
      "187686      1\n",
      "237995      1\n",
      "217509      1\n",
      "84390       1\n",
      "180647      1\n",
      "218835      1\n",
      "209174      1\n",
      "43434       1\n",
      "367020      1\n",
      "176514      1\n",
      "326064      1\n",
      "192945      1\n",
      "274797      1\n",
      "168381      1\n",
      "186820      1\n",
      "131178      1\n",
      "416164      1\n",
      "197023      1\n",
      "240138      1\n",
      "123283      1\n",
      "94395       1\n",
      "205195      1\n",
      "104844      1\n",
      "144161      1\n",
      "194960      1\n",
      "385847      1\n",
      "219540      1\n",
      "199070      1\n",
      "444822      1\n",
      "147863      1\n",
      "405913      1\n",
      "144380      1\n",
      "268700      1\n",
      "270276      1\n",
      "282674      1\n",
      "41419       1\n",
      "70761       1\n",
      "166398      1\n",
      "106838      1\n",
      "109833      1\n",
      "451059      1\n",
      "199625      1\n",
      "141626      1\n",
      "203260      1\n",
      "227840      1\n",
      "233933      1\n",
      "553473      1\n",
      "186884      1\n",
      "184837      1\n",
      "108713      1\n",
      "164530      1\n",
      "95445       1\n",
      "285419      1\n",
      "140237      1\n",
      "123411      1\n",
      "201197      1\n",
      "236012      1\n",
      "369131      1\n",
      "141802      1\n",
      "143849      1\n",
      "116901      1\n",
      "257978      1\n",
      "39388       1\n",
      "261677      1\n",
      "379350      1\n",
      "119253      1\n",
      "55764       1\n",
      "256466      1\n",
      "166350      1\n",
      "47496       1\n",
      "213383      1\n",
      "160246      1\n",
      "297246      1\n",
      "373553      1\n",
      "293136      1\n",
      "26898       1\n",
      "139466      1\n",
      "55860       1\n",
      "266525      1\n",
      "164127      1\n",
      "337488      1\n",
      "31008       1\n",
      "160033      1\n",
      "273558      1\n",
      "76893       1\n",
      "182566      1\n",
      "276776      1\n",
      "213255      1\n",
      "176467      1\n",
      "217349      1\n",
      "28929       1\n",
      "459007      1\n",
      "340217      1\n",
      "145656      1\n",
      "301802      1\n",
      "284916      1\n",
      "356133      1\n",
      "179717      1\n",
      "268524      1\n",
      "272618      1\n",
      "229756      1\n",
      "234481      1\n",
      "180455      1\n",
      "232742      1\n",
      "194864      1\n",
      "57651       1\n",
      "518530      1\n",
      "89705       1\n",
      "113000      1\n",
      "27539       1\n",
      "262511      1\n",
      "91811       1\n",
      "116910      1\n",
      "125298      1\n",
      "22900       1\n",
      "153908      1\n",
      "184693      1\n",
      "51574       1\n",
      "145784      1\n",
      "274809      1\n",
      "237811      1\n",
      "225883      1\n",
      "47247       1\n",
      "360799      1\n",
      "45643       1\n",
      "106843      1\n",
      "215382      1\n",
      "131916      1\n",
      "317780      1\n",
      "289106      1\n",
      "248011      1\n",
      "141642      1\n",
      "167098      1\n",
      "194668      1\n",
      "61761       1\n",
      "401723      1\n",
      "108859      1\n",
      "112952      1\n",
      "250165      1\n",
      "108997      1\n",
      "270859      1\n",
      "254818      1\n",
      "209641      1\n",
      "111321      1\n",
      "280292      1\n",
      "266973      1\n",
      "133425      1\n",
      "193249      1\n",
      "80616       1\n",
      "287190      1\n",
      "611029      1\n",
      "189985      1\n",
      "105866      1\n",
      "156403      1\n",
      "246519      1\n",
      "45817       1\n",
      "43770       1\n",
      "182998      1\n",
      "29393       1\n",
      "27411       1\n",
      "292185      1\n",
      "189107      1\n",
      "40338       1\n",
      "153143      1\n",
      "315868      1\n",
      "242361      1\n",
      "207546      1\n",
      "258406      1\n",
      "278188      1\n",
      "197311      1\n",
      "160449      1\n",
      "109633      1\n",
      "154308      1\n",
      "48193       1\n",
      "277192      1\n",
      "281221      1\n",
      "328447      1\n",
      "29441       1\n",
      "203580      1\n",
      "342824      1\n",
      "41624       1\n",
      "295282      1\n",
      "187188      1\n",
      "82743       1\n",
      "29523       1\n",
      "129856      1\n",
      "195584      1\n",
      "52978       1\n",
      "189251      1\n",
      "152389      1\n",
      "179016      1\n",
      "205643      1\n",
      "39756       1\n",
      "213799      1\n",
      "217893      1\n",
      "182757      1\n",
      "258849      1\n",
      "396116      1\n",
      "101150      1\n",
      "105244      1\n",
      "365613      1\n",
      "193216      1\n",
      "50649       1\n",
      "117526      1\n",
      "35598       1\n",
      "547886      1\n",
      "269068      1\n",
      "95303       1\n",
      "144137      1\n",
      "408328      1\n",
      "195248      1\n",
      "180019      1\n",
      "137900      1\n",
      "184901      1\n",
      "248374      1\n",
      "314963      1\n",
      "207418      1\n",
      "39484       1\n",
      "133694      1\n",
      "193089      1\n",
      "182854      1\n",
      "318036      1\n",
      "111177      1\n",
      "174666      1\n",
      "215476      1\n",
      "657397      1\n",
      "201293      1\n",
      "218957      1\n",
      "217006      1\n",
      "118876      1\n",
      "194829      1\n",
      "64048       1\n",
      "131631      1\n",
      "178416      1\n",
      "240170      1\n",
      "176681      1\n",
      "59938       1\n",
      "61985       1\n",
      "131615      1\n",
      "372838      1\n",
      "694812      1\n",
      "209433      1\n",
      "479765      1\n",
      "239576      1\n",
      "226246      1\n",
      "71075       1\n",
      "86613       1\n",
      "41643       1\n",
      "354962      1\n",
      "467579      1\n",
      "188928      1\n",
      "72791       1\n",
      "397962      1\n",
      "234125      1\n",
      "195216      1\n",
      "277144      1\n",
      "81116       1\n",
      "533147      1\n",
      "367260      1\n",
      "98975       1\n",
      "70919       1\n",
      "320386      1\n",
      "305834      1\n",
      "197484      1\n",
      "277112      1\n",
      "82551       1\n",
      "305619      1\n",
      "161631      1\n",
      "199278      1\n",
      "103021      1\n",
      "139883      1\n",
      "109162      1\n",
      "388741      1\n",
      "110138      1\n",
      "283237      1\n",
      "416356      1\n",
      "86337       1\n",
      "131679      1\n",
      "343553      1\n",
      "272986      1\n",
      "201155      1\n",
      "37085       1\n",
      "218407      1\n",
      "470875      1\n",
      "169804      1\n",
      "204621      1\n",
      "198478      1\n",
      "84197       1\n",
      "128848      1\n",
      "239450      1\n",
      "104025      1\n",
      "417605      1\n",
      "40388       1\n",
      "296798      1\n",
      "331615      1\n",
      "98145       1\n",
      "192355      1\n",
      "186212      1\n",
      "53063       1\n",
      "164135      1\n",
      "71475       1\n",
      "452402      1\n",
      "481060      1\n",
      "118567      1\n",
      "343849      1\n",
      "339755      1\n",
      "263982      1\n",
      "102191      1\n",
      "126771      1\n",
      "59202       1\n",
      "304353      1\n",
      "182070      1\n",
      "168826      1\n",
      "165694      1\n",
      "36671       1\n",
      "63296       1\n",
      "146110      1\n",
      "280422      1\n",
      "119628      1\n",
      "112320      1\n",
      "198542      1\n",
      "163729      1\n",
      "124818      1\n",
      "193012      1\n",
      "53524       1\n",
      "36162       1\n",
      "171933      1\n",
      "333676      1\n",
      "227232      1\n",
      "124865      1\n",
      "306601      1\n",
      "186865      1\n",
      "180137      1\n",
      "100270      1\n",
      "213015      1\n",
      "176011      1\n",
      "108426      1\n",
      "311177      1\n",
      "209949      1\n",
      "188293      1\n",
      "192387      1\n",
      "96128       1\n",
      "135039      1\n",
      "40829       1\n",
      "503675      1\n",
      "49017       1\n",
      "374883      1\n",
      "184183      1\n",
      "25825       1\n",
      "320192      1\n",
      "233327      1\n",
      "28451       1\n",
      "167859      1\n",
      "227104      1\n",
      "249543      1\n",
      "251572      1\n",
      "310969      1\n",
      "335549      1\n",
      "691903      1\n",
      "392487      1\n",
      "286405      1\n",
      "59335       1\n",
      "38620       1\n",
      "399052      1\n",
      "322980      1\n",
      "63184       1\n",
      "382242      1\n",
      "245465      1\n",
      "239322      1\n",
      "99246       1\n",
      "26290       1\n",
      "68393       1\n",
      "167599      1\n",
      "43887       1\n",
      "399020      1\n",
      "206506      1\n",
      "301637      1\n",
      "203139      1\n",
      "360097      1\n",
      "110890      1\n",
      "329874      1\n",
      "43937       1\n",
      "147097      1\n",
      "214678      1\n",
      "220821      1\n",
      "257683      1\n",
      "227836      1\n",
      "178628      1\n",
      "266015      1\n",
      "190226      1\n",
      "247558      1\n",
      "315143      1\n",
      "175883      1\n",
      "34574       1\n",
      "96016       1\n",
      "50248       1\n",
      "67125       1\n",
      "220901      1\n",
      "205653      1\n",
      "245529      1\n",
      "233022      1\n",
      "203334      1\n",
      "237341      1\n",
      "34590       1\n",
      "286469      1\n",
      "107138      1\n",
      "165630      1\n",
      "302845      1\n",
      "112459      1\n",
      "117798      1\n",
      "112376      1\n",
      "182944      1\n",
      "190194      1\n",
      "211840      1\n",
      "165614      1\n",
      "237293      1\n",
      "241297      1\n",
      "143083      1\n",
      "243432      1\n",
      "52967       1\n",
      "444134      1\n",
      "100252      1\n",
      "487347      1\n",
      "205019      1\n",
      "198766      1\n",
      "181301      1\n",
      "227397      1\n",
      "213095      1\n",
      "141418      1\n",
      "335979      1\n",
      "102509      1\n",
      "303565      1\n",
      "190562      1\n",
      "325744      1\n",
      "118901      1\n",
      "401531      1\n",
      "173631      1\n",
      "323713      1\n",
      "382859      1\n",
      "179772      1\n",
      "159841      1\n",
      "191299      1\n",
      "41035       1\n",
      "178033      1\n",
      "63552       1\n",
      "327606      1\n",
      "47176       1\n",
      "405577      1\n",
      "187067      1\n",
      "67662       1\n",
      "165982      1\n",
      "30800       1\n",
      "241753      1\n",
      "126889      1\n",
      "111696      1\n",
      "71772       1\n",
      "102493      1\n",
      "121468      1\n",
      "102541      1\n",
      "47011       1\n",
      "370890      1\n",
      "39100       1\n",
      "299197      1\n",
      "132243      1\n",
      "159937      1\n",
      "55492       1\n",
      "201178      1\n",
      "217803      1\n",
      "298577      1\n",
      "115438      1\n",
      "34748       1\n",
      "56559       1\n",
      "411862      1\n",
      "409815      1\n",
      "174298      1\n",
      "145592      1\n",
      "124293      1\n",
      "379062      1\n",
      "90291       1\n",
      "125106      1\n",
      "250724      1\n",
      "129200      1\n",
      "198830      1\n",
      "226968      1\n",
      "145576      1\n",
      "149670      1\n",
      "219300      1\n",
      "520231      1\n",
      "240491      1\n",
      "123345      1\n",
      "73338       1\n",
      "637080      1\n",
      "34878       1\n",
      "172091      1\n",
      "174138      1\n",
      "252355      1\n",
      "178136      1\n",
      "143540      1\n",
      "268252      1\n",
      "40925       1\n",
      "200671      1\n",
      "163809      1\n",
      "149478      1\n",
      "97082       1\n",
      "193453      1\n",
      "276456      1\n",
      "321403      1\n",
      "337898      1\n",
      "208875      1\n",
      "160275      1\n",
      "51158       1\n",
      "64940       1\n",
      "317396      1\n",
      "159699      1\n",
      "212005      1\n",
      "161744      1\n",
      "198606      1\n",
      "208843      1\n",
      "131519      1\n",
      "81865       1\n",
      "186308      1\n",
      "63424       1\n",
      "200639      1\n",
      "165822      1\n",
      "46870       1\n",
      "61518       1\n",
      "247734      1\n",
      "167919      1\n",
      "632613      1\n",
      "243768      1\n",
      "342834      1\n",
      "206874      1\n",
      "170012      1\n",
      "162104      1\n",
      "222254      1\n",
      "53285       1\n",
      "187294      1\n",
      "167087      1\n",
      "487411      1\n",
      "270379      1\n",
      "162643      1\n",
      "200749      1\n",
      "194608      1\n",
      "188467      1\n",
      "249909      1\n",
      "309272      1\n",
      "180247      1\n",
      "334026      1\n",
      "119655      1\n",
      "231438      1\n",
      "36877       1\n",
      "165365      1\n",
      "174090      1\n",
      "176137      1\n",
      "41901       1\n",
      "190466      1\n",
      "126977      1\n",
      "428030      1\n",
      "270333      1\n",
      "169980      1\n",
      "237608      1\n",
      "133219      1\n",
      "99151       1\n",
      "548303      1\n",
      "224784      1\n",
      "52870       1\n",
      "433788      1\n",
      "134782      1\n",
      "165503      1\n",
      "63105       1\n",
      "192130      1\n",
      "139049      1\n",
      "571017      1\n",
      "175738      1\n",
      "175754      1\n",
      "304779      1\n",
      "170785      1\n",
      "165519      1\n",
      "180957      1\n",
      "159378      1\n",
      "435835      1\n",
      "79481       1\n",
      "30433       1\n",
      "205934      1\n",
      "99935       1\n",
      "228960      1\n",
      "226913      1\n",
      "185957      1\n",
      "181863      1\n",
      "177769      1\n",
      "106092      1\n",
      "81528       1\n",
      "134766      1\n",
      "115214      1\n",
      "172297      1\n",
      "288371      1\n",
      "153205      1\n",
      "151158      1\n",
      "321171      1\n",
      "54933       1\n",
      "183958      1\n",
      "82560       1\n",
      "267965      1\n",
      "196288      1\n",
      "198790      1\n",
      "108594      1\n",
      "162621      1\n",
      "199450      1\n",
      "293550      1\n",
      "116375      1\n",
      "36186       1\n",
      "118486      1\n",
      "340591      1\n",
      "38621       1\n",
      "102110      1\n",
      "100063      1\n",
      "143034      1\n",
      "145081      1\n",
      "182855      1\n",
      "222899      1\n",
      "361842      1\n",
      "38573       1\n",
      "128061      1\n",
      "75435       1\n",
      "399904      1\n",
      "347814      1\n",
      "220836      1\n",
      "360096      1\n",
      "336226      1\n",
      "202397      1\n",
      "171676      1\n",
      "308889      1\n",
      "95047       1\n",
      "52753       1\n",
      "344128      1\n",
      "274010      1\n",
      "232799      1\n",
      "155124      1\n",
      "179704      1\n",
      "208378      1\n",
      "112269      1\n",
      "292353      1\n",
      "353795      1\n",
      "280071      1\n",
      "192360      1\n",
      "179720      1\n",
      "200355      1\n",
      "302604      1\n",
      "298510      1\n",
      "128529      1\n",
      "147729      1\n",
      "169152      1\n",
      "99823       1\n",
      "290409      1\n",
      "306666      1\n",
      "212456      1\n",
      "214503      1\n",
      "220644      1\n",
      "105821      1\n",
      "325089      1\n",
      "118535      1\n",
      "175032      1\n",
      "171484      1\n",
      "75227       1\n",
      "177625      1\n",
      "243357      1\n",
      "290306      1\n",
      "240554      1\n",
      "220692      1\n",
      "288771      1\n",
      "147032      1\n",
      "73292       1\n",
      "278115      1\n",
      "77975       1\n",
      "180187      1\n",
      "260868      1\n",
      "186995      1\n",
      "316582      1\n",
      "396878      1\n",
      "283724      1\n",
      "34383       1\n",
      "95825       1\n",
      "128472      1\n",
      "38397       1\n",
      "52822       1\n",
      "247383      1\n",
      "116279      1\n",
      "151094      1\n",
      "153141      1\n",
      "212661      1\n",
      "355890      1\n",
      "194097      1\n",
      "133355      1\n",
      "106028      1\n",
      "208426      1\n",
      "140045      1\n",
      "118310      1\n",
      "312338      1\n",
      "89636       1\n",
      "91683       1\n",
      "93730       1\n",
      "152369      1\n",
      "34335       1\n",
      "205036      1\n",
      "59107       1\n",
      "189607      1\n",
      "253860      1\n",
      "42907       1\n",
      "169885      1\n",
      "198559      1\n",
      "325537      1\n",
      "159650      1\n",
      "111676      1\n",
      "53158       1\n",
      "84616       1\n",
      "231181      1\n",
      "143069      1\n",
      "139180      1\n",
      "48947       1\n",
      "80004       1\n",
      "342906      1\n",
      "176026      1\n",
      "214935      1\n",
      "548580      1\n",
      "140845      1\n",
      "235389      1\n",
      "216595      1\n",
      "65408       1\n",
      "201513      1\n",
      "122756      1\n",
      "348038      1\n",
      "343944      1\n",
      "280410      1\n",
      "210825      1\n",
      "208778      1\n",
      "436107      1\n",
      "237452      1\n",
      "266126      1\n",
      "99386       1\n",
      "169917      1\n",
      "133055      1\n",
      "849857      1\n",
      "208874      1\n",
      "308550      1\n",
      "126946      1\n",
      "350181      1\n",
      "21154       1\n",
      "81896       1\n",
      "236359      1\n",
      "202733      1\n",
      "290754      1\n",
      "69614       1\n",
      "124915      1\n",
      "75577       1\n",
      "170125      1\n",
      "145401      1\n",
      "110586      1\n",
      "135134      1\n",
      "235485      1\n",
      "237532      1\n",
      "241626      1\n",
      "295334      1\n",
      "20438       1\n",
      "186325      1\n",
      "92115       1\n",
      "229328      1\n",
      "213464      1\n",
      "139212      1\n",
      "337867      1\n",
      "372682      1\n",
      "212936      1\n",
      "186446      1\n",
      "217030      1\n",
      "155403      1\n",
      "204668      1\n",
      "185624      1\n",
      "276345      1\n",
      "300829      1\n",
      "126738      1\n",
      "57108       1\n",
      "98678       1\n",
      "118550      1\n",
      "214807      1\n",
      "296991      1\n",
      "198431      1\n",
      "132341      1\n",
      "98080       1\n",
      "91939       1\n",
      "122660      1\n",
      "184102      1\n",
      "145258      1\n",
      "311080      1\n",
      "180382      1\n",
      "270092      1\n",
      "424591      1\n",
      "46857       1\n",
      "347910      1\n",
      "192052      1\n",
      "167678      1\n",
      "254148      1\n",
      "162566      1\n",
      "72880       1\n",
      "118056      1\n",
      "95985       1\n",
      "215839      1\n",
      "132847      1\n",
      "437994      1\n",
      "55076       1\n",
      "315110      1\n",
      "309033      1\n",
      "71469       1\n",
      "348022      1\n",
      "178025      1\n",
      "102238      1\n",
      "92003       1\n",
      "188260      1\n",
      "118630      1\n",
      "51047       1\n",
      "376680      1\n",
      "110442      1\n",
      "32426       1\n",
      "206699      1\n",
      "139116      1\n",
      "167790      1\n",
      "165743      1\n",
      "145717      1\n",
      "61298       1\n",
      "368476      1\n",
      "124733      1\n",
      "269499      1\n",
      "114520      1\n",
      "43354       1\n",
      "26451       1\n",
      "119164      1\n",
      "334991      1\n",
      "207173      1\n",
      "223352      1\n",
      "317253      1\n",
      "134974      1\n",
      "143162      1\n",
      "336984      1\n",
      "147256      1\n",
      "345911      1\n",
      "72321       1\n",
      "208330      1\n",
      "287920      1\n",
      "314822      1\n",
      "255027      1\n",
      "187295      1\n",
      "74795       1\n",
      "105516      1\n",
      "494638      1\n",
      "427055      1\n",
      "335716      1\n",
      "117814      1\n",
      "349221      1\n",
      "181033      1\n",
      "173115      1\n",
      "267325      1\n",
      "369166      1\n",
      "128065      1\n",
      "123971      1\n",
      "242729      1\n",
      "180928      1\n",
      "31965       1\n",
      "216086      1\n",
      "172415      1\n",
      "35783       1\n",
      "635913      1\n",
      "239093      1\n",
      "361487      1\n",
      "119829      1\n",
      "114396      1\n",
      "177792      1\n",
      "474136      1\n",
      "175130      1\n",
      "206052      1\n",
      "208003      1\n",
      "64544       1\n",
      "128033      1\n",
      "185413      1\n",
      "216134      1\n",
      "39060       1\n",
      "199806      1\n",
      "363630      1\n",
      "121972      1\n",
      "87157       1\n",
      "115831      1\n",
      "244856      1\n",
      "177273      1\n",
      "164991      1\n",
      "49707       1\n",
      "162944      1\n",
      "29825       1\n",
      "85126       1\n",
      "104973      1\n",
      "144521      1\n",
      "631947      1\n",
      "169069      1\n",
      "171116      1\n",
      "402539      1\n",
      "273514      1\n",
      "169604      1\n",
      "206354      1\n",
      "121956      1\n",
      "156771      1\n",
      "234633      1\n",
      "31840       1\n",
      "392160      1\n",
      "281792      1\n",
      "146520      1\n",
      "224338      1\n",
      "226385      1\n",
      "293968      1\n",
      "197711      1\n",
      "194809      1\n",
      "125954      1\n",
      "203180      1\n",
      "193425      1\n",
      "324609      1\n",
      "205707      1\n",
      "168845      1\n",
      "199566      1\n",
      "426895      1\n",
      "97168       1\n",
      "206682      1\n",
      "295855      1\n",
      "164023      1\n",
      "58371       1\n",
      "191394      1\n",
      "222115      1\n",
      "179112      1\n",
      "76714       1\n",
      "455553      1\n",
      "301948      1\n",
      "336763      1\n",
      "109434      1\n",
      "177017      1\n",
      "248694      1\n",
      "121510      1\n",
      "99183       1\n",
      "172907      1\n",
      "109418      1\n",
      "226733      1\n",
      "316261      1\n",
      "226145      1\n",
      "101214      1\n",
      "267101      1\n",
      "205659      1\n",
      "82775       1\n",
      "358753      1\n",
      "93106       1\n",
      "162816      1\n",
      "220148      1\n",
      "170988      1\n",
      "166894      1\n",
      "170182      1\n",
      "31728       1\n",
      "77723       1\n",
      "125938      1\n",
      "283637      1\n",
      "154548      1\n",
      "281590      1\n",
      "410615      1\n",
      "48120       1\n",
      "273402      1\n",
      "41979       1\n",
      "81846       1\n",
      "205803      1\n",
      "220132      1\n",
      "185330      1\n",
      "103389      1\n",
      "163287      1\n",
      "316627      1\n",
      "54229       1\n",
      "154580      1\n",
      "324561      1\n",
      "221603      1\n",
      "198000      1\n",
      "178370      1\n",
      "142282      1\n",
      "199596      1\n",
      "164799      1\n",
      "172987      1\n",
      "175034      1\n",
      "169101      1\n",
      "29841       1\n",
      "126098      1\n",
      "52566       1\n",
      "216390      1\n",
      "247111      1\n",
      "208353      1\n",
      "105804      1\n",
      "103757      1\n",
      "197967      1\n",
      "116055      1\n",
      "152933      1\n",
      "114008      1\n",
      "111961      1\n",
      "593246      1\n",
      "165215      1\n",
      "97632       1\n",
      "259425      1\n",
      "286020      1\n",
      "320835      1\n",
      "94991       1\n",
      "232766      1\n",
      "267581      1\n",
      "105788      1\n",
      "64448       1\n",
      "179512      1\n",
      "183606      1\n",
      "268098      1\n",
      "259377      1\n",
      "174171      1\n",
      "128047      1\n",
      "337195      1\n",
      "264055      1\n",
      "210217      1\n",
      "410919      1\n",
      "391040      1\n",
      "150886      1\n",
      "126242      1\n",
      "375657      1\n",
      "181655      1\n",
      "273818      1\n",
      "552354      1\n",
      "312956      1\n",
      "153035      1\n",
      "38317       1\n",
      "54709       1\n",
      "310632      1\n",
      "476599      1\n",
      "70466       1\n",
      "167358      1\n",
      "64960       1\n",
      "503454      1\n",
      "126402      1\n",
      "185749      1\n",
      "228752      1\n",
      "329130      1\n",
      "267661      1\n",
      "269708      1\n",
      "342175      1\n",
      "114056      1\n",
      "183686      1\n",
      "23940       1\n",
      "161153      1\n",
      "213105      1\n",
      "142714      1\n",
      "374137      1\n",
      "256953      1\n",
      "284021      1\n",
      "103789      1\n",
      "341353      1\n",
      "329355      1\n",
      "251240      1\n",
      "187540      1\n",
      "175290      1\n",
      "42298       1\n",
      "257380      1\n",
      "173929      1\n",
      "318644      1\n",
      "282872      1\n",
      "115895      1\n",
      "103459      1\n",
      "287192      1\n",
      "335248      1\n",
      "218309      1\n",
      "179400      1\n",
      "46281       1\n",
      "240842      1\n",
      "110311      1\n",
      "228528      1\n",
      "165039      1\n",
      "99361       1\n",
      "171467      1\n",
      "140459      1\n",
      "240810      1\n",
      "275625      1\n",
      "194417      1\n",
      "91299       1\n",
      "336891      1\n",
      "95393       1\n",
      "361631      1\n",
      "101534      1\n",
      "169117      1\n",
      "304283      1\n",
      "179352      1\n",
      "119957      1\n",
      "266022      1\n",
      "277720      1\n",
      "219886      1\n",
      "343231      1\n",
      "254478      1\n",
      "52486       1\n",
      "82938       1\n",
      "121352      1\n",
      "175370      1\n",
      "107787      1\n",
      "62737       1\n",
      "271579      1\n",
      "386019      1\n",
      "384276      1\n",
      "314646      1\n",
      "127779      1\n",
      "156352      1\n",
      "240922      1\n",
      "32000       1\n",
      "66815       1\n",
      "201981      1\n",
      "173307      1\n",
      "113912      1\n",
      "249078      1\n",
      "87285       1\n",
      "187636      1\n",
      "158962      1\n",
      "224277      1\n",
      "30973       1\n",
      "476391      1\n",
      "175071      1\n",
      "390369      1\n",
      "99551       1\n",
      "68830       1\n",
      "171228      1\n",
      "336188      1\n",
      "293076      1\n",
      "127738      1\n",
      "96337       1\n",
      "51271       1\n",
      "178249      1\n",
      "139338      1\n",
      "104525      1\n",
      "406463      1\n",
      "536725      1\n",
      "446559      1\n",
      "315460      1\n",
      "315476      1\n",
      "153685      1\n",
      "247895      1\n",
      "123325      1\n",
      "75867       1\n",
      "36956       1\n",
      "284741      1\n",
      "28518       1\n",
      "67759       1\n",
      "147510      1\n",
      "282660      1\n",
      "30030       1\n",
      "228255      1\n",
      "239659      1\n",
      "44419       1\n",
      "219189      1\n",
      "116791      1\n",
      "161857      1\n",
      "110648      1\n",
      "122276      1\n",
      "106554      1\n",
      "628797      1\n",
      "187440      1\n",
      "95704       1\n",
      "184924      1\n",
      "193304      1\n",
      "198751      1\n",
      "391329      1\n",
      "89564       1\n",
      "195179      1\n",
      "180374      1\n",
      "176280      1\n",
      "34975       1\n",
      "200497      1\n",
      "254114      1\n",
      "249956      1\n",
      "247975      1\n",
      "241832      1\n",
      "176689      1\n",
      "336042      1\n",
      "200876      1\n",
      "235693      1\n",
      "56658       1\n",
      "135308      1\n",
      "336010      1\n",
      "215175      1\n",
      "76129       1\n",
      "315524      1\n",
      "114838      1\n",
      "186611      1\n",
      "162205      1\n",
      "406955      1\n",
      "32878       1\n",
      "186495      1\n",
      "370795      1\n",
      "189185      1\n",
      "566049      1\n",
      "147558      1\n",
      "120933      1\n",
      "418020      1\n",
      "377095      1\n",
      "329759      1\n",
      "206777      1\n",
      "60940       1\n",
      "300975      1\n",
      "356272      1\n",
      "260019      1\n",
      "97847       1\n",
      "563883      1\n",
      "178107      1\n",
      "283079      1\n",
      "102332      1\n",
      "204734      1\n",
      "232569      1\n",
      "190401      1\n",
      "292803      1\n",
      "217028      1\n",
      "79787       1\n",
      "239529      1\n",
      "256909      1\n",
      "196514      1\n",
      "72743       1\n",
      "181337      1\n",
      "387074      1\n",
      "560804      1\n",
      "83861       1\n",
      "161683      1\n",
      "169871      1\n",
      "34701       1\n",
      "176008      1\n",
      "167963      1\n",
      "63363       1\n",
      "196482      1\n",
      "157569      1\n",
      "305850      1\n",
      "200652      1\n",
      "299036      1\n",
      "102412      1\n",
      "303440      1\n",
      "169983      1\n",
      "175406      1\n",
      "249860      1\n",
      "170504      1\n",
      "403467      1\n",
      "104461      1\n",
      "301007      1\n",
      "262158      1\n",
      "231439      1\n",
      "114719      1\n",
      "180246      1\n",
      "255237      1\n",
      "215591      1\n",
      "174073      1\n",
      "274424      1\n",
      "282612      1\n",
      "176157      1\n",
      "106395      1\n",
      "142404      1\n",
      "330301      1\n",
      "403433      1\n",
      "267966      1\n",
      "53220       1\n",
      "255969      1\n",
      "240517      1\n",
      "114650      1\n",
      "195678      1\n",
      "255466      1\n",
      "201579      1\n",
      "321333      1\n",
      "196782      1\n",
      "28848       1\n",
      "195025      1\n",
      "195555      1\n",
      "366957      1\n",
      "360814      1\n",
      "351402      1\n",
      "188786      1\n",
      "256371      1\n",
      "219509      1\n",
      "80249       1\n",
      "165998      1\n",
      "43387       1\n",
      "240562      1\n",
      "383365      1\n",
      "106890      1\n",
      "43403       1\n",
      "147612      1\n",
      "178537      1\n",
      "117095      1\n",
      "103794      1\n",
      "135500      1\n",
      "282948      1\n",
      "82246       1\n",
      "444743      1\n",
      "176059      1\n",
      "178505      1\n",
      "76107       1\n",
      "221059      1\n",
      "249463      1\n",
      "278870      1\n",
      "182615      1\n",
      "312372      1\n",
      "133471      1\n",
      "96609       1\n",
      "319842      1\n",
      "96657       1\n",
      "130045      1\n",
      "709798      1\n",
      "176696      1\n",
      "232132      1\n",
      "143800      1\n",
      "211385      1\n",
      "106938      1\n",
      "70076       1\n",
      "367037      1\n",
      "264834      1\n",
      "84375       1\n",
      "152004      1\n",
      "350661      1\n",
      "318416      1\n",
      "70092       1\n",
      "131534      1\n",
      "55861       1\n",
      "186805      1\n",
      "53684       1\n",
      "354739      1\n",
      "291248      1\n",
      "68015       1\n",
      "266668      1\n",
      "240043      1\n",
      "377850      1\n",
      "438696      1\n",
      "215463      1\n",
      "256609      1\n",
      "416165      1\n",
      "65950       1\n",
      "137629      1\n",
      "245777      1\n",
      "131808      1\n",
      "105327      1\n",
      "67903       1\n",
      "234648      1\n",
      "170301      1\n",
      "428271      1\n",
      "75995       1\n",
      "481175      1\n",
      "178431      1\n",
      "176360      1\n",
      "112873      1\n",
      "108779      1\n",
      "155890      1\n",
      "192768      1\n",
      "130589      1\n",
      "49398       1\n",
      "118457      1\n",
      "209067      1\n",
      "47353       1\n",
      "139514      1\n",
      "256992      1\n",
      "243929      1\n",
      "151764      1\n",
      "188626      1\n",
      "293073      1\n",
      "144218      1\n",
      "67791       1\n",
      "186565      1\n",
      "20676       1\n",
      "192704      1\n",
      "32958       1\n",
      "106682      1\n",
      "80057       1\n",
      "223392      1\n",
      "98986       1\n",
      "256179      1\n",
      "90290       1\n",
      "31365       1\n",
      "63745       1\n",
      "299324      1\n",
      "262446      1\n",
      "26915       1\n",
      "317733      1\n",
      "114982      1\n",
      "182567      1\n",
      "41258       1\n",
      "190020      1\n",
      "58484       1\n",
      "348420      1\n",
      "211763      1\n",
      "186677      1\n",
      "349405      1\n",
      "244025      1\n",
      "145139      1\n",
      "43323       1\n",
      "123170      1\n",
      "325921      1\n",
      "127264      1\n",
      "198943      1\n",
      "196894      1\n",
      "102684      1\n",
      "272667      1\n",
      "246038      1\n",
      "184596      1\n",
      "190739      1\n",
      "26254       1\n",
      "229646      1\n",
      "39181       1\n",
      "76043       1\n",
      "205066      1\n",
      "241928      1\n",
      "341358      1\n",
      "364685      1\n",
      "169100      1\n",
      "102268      1\n",
      "183780      1\n",
      "318934      1\n",
      "146906      1\n",
      "34269       1\n",
      "204254      1\n",
      "93664       1\n",
      "161251      1\n",
      "30687       1\n",
      "292307      1\n",
      "275369      1\n",
      "54759       1\n",
      "89491       1\n",
      "67053       1\n",
      "71151       1\n",
      "327154      1\n",
      "181717      1\n",
      "216583      1\n",
      "232841      1\n",
      "305259      1\n",
      "206339      1\n",
      "218551      1\n",
      "31161       1\n",
      "140729      1\n",
      "177595      1\n",
      "236990      1\n",
      "103575      1\n",
      "155397      1\n",
      "129529      1\n",
      "214469      1\n",
      "56774       1\n",
      "115420      1\n",
      "176146      1\n",
      "298444      1\n",
      "445940      1\n",
      "116626      1\n",
      "185847      1\n",
      "415287      1\n",
      "56870       1\n",
      "120359      1\n",
      "212522      1\n",
      "360593      1\n",
      "325171      1\n",
      "155190      1\n",
      "173497      1\n",
      "331861      1\n",
      "147002      1\n",
      "296509      1\n",
      "388672      1\n",
      "180277      1\n",
      "301583      1\n",
      "33727       1\n",
      "118308      1\n",
      "327202      1\n",
      "200220      1\n",
      "79387       1\n",
      "212506      1\n",
      "220694      1\n",
      "396790      1\n",
      "163346      1\n",
      "335665      1\n",
      "36364       1\n",
      "142856      1\n",
      "349703      1\n",
      "280069      1\n",
      "280758      1\n",
      "32546       1\n",
      "140414      1\n",
      "36348       1\n",
      "228786      1\n",
      "222641      1\n",
      "73134       1\n",
      "30035       1\n",
      "264968      1\n",
      "1455435     1\n",
      "34125       1\n",
      "236878      1\n",
      "189777      1\n",
      "195922      1\n",
      "181589      1\n",
      "28683       1\n",
      "36020       1\n",
      "111963      1\n",
      "298332      1\n",
      "92649       1\n",
      "157025      1\n",
      "97634       1\n",
      "120135      1\n",
      "111476      1\n",
      "222529      1\n",
      "103743      1\n",
      "167711      1\n",
      "107833      1\n",
      "94242       1\n",
      "181557      1\n",
      "52532       1\n",
      "288049      1\n",
      "257328      1\n",
      "365871      1\n",
      "138542      1\n",
      "329005      1\n",
      "134444      1\n",
      "80479       1\n",
      "179498      1\n",
      "218357      1\n",
      "298539      1\n",
      "366563      1\n",
      "97698       1\n",
      "352806      1\n",
      "265628      1\n",
      "105886      1\n",
      "395022      1\n",
      "126368      1\n",
      "504871      1\n",
      "161187      1\n",
      "218471      1\n",
      "247205      1\n",
      "142760      1\n",
      "140713      1\n",
      "58213       1\n",
      "767403      1\n",
      "47085       1\n",
      "172652      1\n",
      "241469      1\n",
      "176760      1\n",
      "345493      1\n",
      "267663      1\n",
      "271753      1\n",
      "89478       1\n",
      "114225      1\n",
      "30069       1\n",
      "238969      1\n",
      "188064      1\n",
      "216436      1\n",
      "102693      1\n",
      "41837       1\n",
      "189809      1\n",
      "236910      1\n",
      "42881       1\n",
      "300623      1\n",
      "301747      1\n",
      "196178      1\n",
      "116517      1\n",
      "151866      1\n",
      "161638      1\n",
      "26401       1\n",
      "196386      1\n",
      "30499       1\n",
      "114230      1\n",
      "186151      1\n",
      "85812       1\n",
      "180010      1\n",
      "210731      1\n",
      "200492      1\n",
      "296749      1\n",
      "37683       1\n",
      "327474      1\n",
      "231197      1\n",
      "214594      1\n",
      "274200      1\n",
      "218903      1\n",
      "292627      1\n",
      "130834      1\n",
      "136975      1\n",
      "133495      1\n",
      "167692      1\n",
      "388998      1\n",
      "218887      1\n",
      "188166      1\n",
      "119287      1\n",
      "216871      1\n",
      "269221      1\n",
      "91905       1\n",
      "225024      1\n",
      "953588      1\n",
      "141113      1\n",
      "54373       1\n",
      "132973      1\n",
      "57635       1\n",
      "190305      1\n",
      "216932      1\n",
      "166320      1\n",
      "278378      1\n",
      "135020      1\n",
      "94064       1\n",
      "46907       1\n",
      "84324       1\n",
      "147236      1\n",
      "282484      1\n",
      "263886      1\n",
      "241528      1\n",
      "147322      1\n",
      "106334      1\n",
      "198493      1\n",
      "407618      1\n",
      "212826      1\n",
      "212798      1\n",
      "20308       1\n",
      "98130       1\n",
      "336540      1\n",
      "139086      1\n",
      "272625      1\n",
      "538443      1\n",
      "205004      1\n",
      "63299       1\n",
      "202559      1\n",
      "270142      1\n",
      "132925      1\n",
      "200508      1\n",
      "169727      1\n",
      "114859      1\n",
      "231230      1\n",
      "200332      1\n",
      "201928      1\n",
      "106110      1\n",
      "366207      1\n",
      "716416      1\n",
      "73266       1\n",
      "394669      1\n",
      "156933      1\n",
      "188070      1\n",
      "180262      1\n",
      "386705      1\n",
      "216724      1\n",
      "223529      1\n",
      "120471      1\n",
      "144811      1\n",
      "42617       1\n",
      "110200      1\n",
      "231002      1\n",
      "61040       1\n",
      "634226      1\n",
      "101996      1\n",
      "46699       1\n",
      "278122      1\n",
      "173673      1\n",
      "175720      1\n",
      "54887       1\n",
      "286310      1\n",
      "85604       1\n",
      "199847      1\n",
      "198237      1\n",
      "343642      1\n",
      "155222      1\n",
      "108185      1\n",
      "231085      1\n",
      "155382      1\n",
      "34541       1\n",
      "290528      1\n",
      "46094       1\n",
      "186087      1\n",
      "304873      1\n",
      "81642       1\n",
      "215797      1\n",
      "237294      1\n",
      "202415      1\n",
      "399087      1\n",
      "159472      1\n",
      "157425      1\n",
      "196338      1\n",
      "201099      1\n",
      "280309      1\n",
      "401118      1\n",
      "260167      1\n",
      "206553      1\n",
      "120535      1\n",
      "68954       1\n",
      "221936      1\n",
      "102092      1\n",
      "108233      1\n",
      "286406      1\n",
      "194243      1\n",
      "97986       1\n",
      "262684      1\n",
      "376506      1\n",
      "44728       1\n",
      "511668      1\n",
      "147430      1\n",
      "169564      1\n",
      "192976      1\n",
      "221650      1\n",
      "32385       1\n",
      "31985       1\n",
      "440706      1\n",
      "289442      1\n",
      "452283      1\n",
      "317320      1\n",
      "159770      1\n",
      "325786      1\n",
      "119386      1\n",
      "25826       1\n",
      "148998      1\n",
      "206074      1\n",
      "284952      1\n",
      "224498      1\n",
      "220421      1\n",
      "123484      1\n",
      "337666      1\n",
      "390368      1\n",
      "40269       1\n",
      "103628      1\n",
      "470203      1\n",
      "165054      1\n",
      "189850      1\n",
      "117959      1\n",
      "342769      1\n",
      "42186       1\n",
      "197838      1\n",
      "105693      1\n",
      "29904       1\n",
      "148694      1\n",
      "183511      1\n",
      "177368      1\n",
      "376025      1\n",
      "240859      1\n",
      "210184      1\n",
      "48393       1\n",
      "460046      1\n",
      "265535      1\n",
      "89397       1\n",
      "281911      1\n",
      "439608      1\n",
      "173370      1\n",
      "202044      1\n",
      "34110       1\n",
      "226624      1\n",
      "64785       1\n",
      "152900      1\n",
      "279878      1\n",
      "85319       1\n",
      "148475      1\n",
      "107850      1\n",
      "44363       1\n",
      "224563      1\n",
      "226608      1\n",
      "333100      1\n",
      "171914      1\n",
      "75050       1\n",
      "105043      1\n",
      "411652      1\n",
      "270973      1\n",
      "191779      1\n",
      "746786      1\n",
      "29984       1\n",
      "68895       1\n",
      "168048      1\n",
      "234780      1\n",
      "175387      1\n",
      "368115      1\n",
      "176981      1\n",
      "206010      1\n",
      "342599      1\n",
      "1125613     1\n",
      "103205      1\n",
      "191571      1\n",
      "272451      1\n",
      "463194      1\n",
      "304504      1\n",
      "117847      1\n",
      "177240      1\n",
      "33886       1\n",
      "228465      1\n",
      "99893       1\n",
      "195681      1\n",
      "166327      1\n",
      "187493      1\n",
      "52327       1\n",
      "144583      1\n",
      "326033      1\n",
      "199484      1\n",
      "308296      1\n",
      "148550      1\n",
      "318533      1\n",
      "216934      1\n",
      "118358      1\n",
      "269284      1\n",
      "291904      1\n",
      "261688      1\n",
      "66622       1\n",
      "169020      1\n",
      "177916      1\n",
      "107578      1\n",
      "82998       1\n",
      "220213      1\n",
      "324021      1\n",
      "240747      1\n",
      "53513       1\n",
      "221558      1\n",
      "31905       1\n",
      "62669       1\n",
      "31449       1\n",
      "283796      1\n",
      "281751      1\n",
      "277657      1\n",
      "234652      1\n",
      "216096      1\n",
      "27763       1\n",
      "84735       1\n",
      "117927      1\n",
      "233014      1\n",
      "230574      1\n",
      "151540      1\n",
      "211073      1\n",
      "259216      1\n",
      "134287      1\n",
      "40077       1\n",
      "267404      1\n",
      "76939       1\n",
      "179337      1\n",
      "224889      1\n",
      "293291      1\n",
      "201481      1\n",
      "156802      1\n",
      "171133      1\n",
      "105384      1\n",
      "240763      1\n",
      "343161      1\n",
      "298155      1\n",
      "214134      1\n",
      "269652      1\n",
      "209297      1\n",
      "263502      1\n",
      "68982       1\n",
      "284196      1\n",
      "205262      1\n",
      "184242      1\n",
      "94885       1\n",
      "138962      1\n",
      "232991      1\n",
      "337992      1\n",
      "31481       1\n",
      "257555      1\n",
      "243240      1\n",
      "221884      1\n",
      "202284      1\n",
      "411007      1\n",
      "200040      1\n",
      "359985      1\n",
      "509462      1\n",
      "228881      1\n",
      "198091      1\n",
      "335357      1\n",
      "441700      1\n",
      "159219      1\n",
      "54772       1\n",
      "268575      1\n",
      "208379      1\n",
      "103932      1\n",
      "132606      1\n",
      "296462      1\n",
      "101887      1\n",
      "130561      1\n",
      "108183      1\n",
      "249351      1\n",
      "77572       1\n",
      "208395      1\n",
      "58930       1\n",
      "226422      1\n",
      "286261      1\n",
      "251508      1\n",
      "128608      1\n",
      "290403      1\n",
      "300290      1\n",
      "104632      1\n",
      "241259      1\n",
      "215743      1\n",
      "151159      1\n",
      "181814      1\n",
      "195755      1\n",
      "245369      1\n",
      "100653      1\n",
      "217605      1\n",
      "211287      1\n",
      "128640      1\n",
      "396895      1\n",
      "271962      1\n",
      "81497       1\n",
      "79448       1\n",
      "323155      1\n",
      "362623      1\n",
      "285052      1\n",
      "376393      1\n",
      "144968      1\n",
      "216647      1\n",
      "323139      1\n",
      "419394      1\n",
      "163393      1\n",
      "134475      1\n",
      "306747      1\n",
      "245305      1\n",
      "243256      1\n",
      "59590       1\n",
      "178202      1\n",
      "136684      1\n",
      "239119      1\n",
      "171540      1\n",
      "155970      1\n",
      "454063      1\n",
      "138621      1\n",
      "68991       1\n",
      "193920      1\n",
      "89477       1\n",
      "85399       1\n",
      "406920      1\n",
      "316359      1\n",
      "175499      1\n",
      "361870      1\n",
      "159123      1\n",
      "286101      1\n",
      "205712      1\n",
      "21876       1\n",
      "91506       1\n",
      "91670       1\n",
      "244312      1\n",
      "171373      1\n",
      "314727      1\n",
      "192695      1\n",
      "135293      1\n",
      "117476      1\n",
      "265567      1\n",
      "329054      1\n",
      "365916      1\n",
      "402778      1\n",
      "83286       1\n",
      "261259      1\n",
      "493862      1\n",
      "211116      1\n",
      "175515      1\n",
      "144872      1\n",
      "50646       1\n",
      "202188      1\n",
      "131591      1\n",
      "390608      1\n",
      "115815      1\n",
      "153044      1\n",
      "187861      1\n",
      "179673      1\n",
      "185764      1\n",
      "99987       1\n",
      "176047      1\n",
      "218596      1\n",
      "267843      1\n",
      "214502      1\n",
      "347623      1\n",
      "318537      1\n",
      "245193      1\n",
      "314823      1\n",
      "229983      1\n",
      "316868      1\n",
      "222249      1\n",
      "200127      1\n",
      "165310      1\n",
      "272918      1\n",
      "164379      1\n",
      "349620      1\n",
      "128432      1\n",
      "365996      1\n",
      "239018      1\n",
      "179625      1\n",
      "79272       1\n",
      "509350      1\n",
      "38905       1\n",
      "330799      1\n",
      "203821      1\n",
      "498349      1\n",
      "170653      1\n",
      "94880       1\n",
      "100480      1\n",
      "86625       1\n",
      "172714      1\n",
      "109227      1\n",
      "199343      1\n",
      "111256      1\n",
      "167147      1\n",
      "265881      1\n",
      "325792      1\n",
      "79830       1\n",
      "113337      1\n",
      "294253      1\n",
      "195813      1\n",
      "180886      1\n",
      "44075       1\n",
      "41610       1\n",
      "172666      1\n",
      "255276      1\n",
      "48988       1\n",
      "351195      1\n",
      "522881      1\n",
      "209544      1\n",
      "92028       1\n",
      "383637      1\n",
      "47407       1\n",
      "295566      1\n",
      "494223      1\n",
      "121521      1\n",
      "114760      1\n",
      "297117      1\n",
      "137917      1\n",
      "114288      1\n",
      "258752      1\n",
      "189763      1\n",
      "152292      1\n",
      "342907      1\n",
      "107242      1\n",
      "430828      1\n",
      "318641      1\n",
      "256755      1\n",
      "120326      1\n",
      "260801      1\n",
      "311409      1\n",
      "205562      1\n",
      "104879      1\n",
      "160512      1\n",
      "189186      1\n",
      "192884      1\n",
      "129761      1\n",
      "228729      1\n",
      "109275      1\n",
      "45784       1\n",
      "115414      1\n",
      "142682      1\n",
      "354784      1\n",
      "256723      1\n",
      "99355       1\n",
      "97429       1\n",
      "327397      1\n",
      "342384      1\n",
      "178649      1\n",
      "76491       1\n",
      "139978      1\n",
      "123302      1\n",
      "320194      1\n",
      "111224      1\n",
      "353244      1\n",
      "23157       1\n",
      "242184      1\n",
      "61499       1\n",
      "104256      1\n",
      "233980      1\n",
      "100863      1\n",
      "105116      1\n",
      "103684      1\n",
      "401930      1\n",
      "205338      1\n",
      "266764      1\n",
      "203277      1\n",
      "205175      1\n",
      "166415      1\n",
      "92691       1\n",
      "45537       1\n",
      "168682      1\n",
      "49654       1\n",
      "190963      1\n",
      "188914      1\n",
      "51016       1\n",
      "231919      1\n",
      "82242       1\n",
      "201196      1\n",
      "174571      1\n",
      "209384      1\n",
      "149991      1\n",
      "370183      1\n",
      "221666      1\n",
      "29152       1\n",
      "311231      1\n",
      "168412      1\n",
      "113515      1\n",
      "357028      1\n",
      "34744       1\n",
      "86644       1\n",
      "123490      1\n",
      "51799       1\n",
      "78424       1\n",
      "203357      1\n",
      "88856       1\n",
      "512771      1\n",
      "175987      1\n",
      "177566      1\n",
      "182823      1\n",
      "124930      1\n",
      "205418      1\n",
      "103020      1\n",
      "98926       1\n",
      "225904      1\n",
      "57970       1\n",
      "363087      1\n",
      "459342      1\n",
      "380462      1\n",
      "305739      1\n",
      "185287      1\n",
      "117319      1\n",
      "213574      1\n",
      "221762      1\n",
      "197182      1\n",
      "303674      1\n",
      "178745      1\n",
      "209464      1\n",
      "84535       1\n",
      "53812       1\n",
      "97757       1\n",
      "791084      1\n",
      "143912      1\n",
      "431515      1\n",
      "178953      1\n",
      "184321      1\n",
      "256979      1\n",
      "275446      1\n",
      "150471      1\n",
      "231082      1\n",
      "173002      1\n",
      "166863      1\n",
      "389147      1\n",
      "128346      1\n",
      "265201      1\n",
      "197252      1\n",
      "408537      1\n",
      "36397       1\n",
      "305767      1\n",
      "39901       1\n",
      "291808      1\n",
      "291011      1\n",
      "256963      1\n",
      "228200      1\n",
      "95168       1\n",
      "234428      1\n",
      "167319      1\n",
      "121781      1\n",
      "222130      1\n",
      "195505      1\n",
      "29616       1\n",
      "199599      1\n",
      "33710       1\n",
      "758700      1\n",
      "806552      1\n",
      "271274      1\n",
      "342953      1\n",
      "351141      1\n",
      "52199       1\n",
      "146409      1\n",
      "129629      1\n",
      "226379      1\n",
      "195184      1\n",
      "353298      1\n",
      "257043      1\n",
      "152596      1\n",
      "171705      1\n",
      "375833      1\n",
      "138269      1\n",
      "383058      1\n",
      "395078      1\n",
      "195617      1\n",
      "87076       1\n",
      "192397      1\n",
      "109702      1\n",
      "277545      1\n",
      "98586       1\n",
      "136204      1\n",
      "88095       1\n",
      "336906      1\n",
      "175224      1\n",
      "255711      1\n",
      "97281       1\n",
      "180869      1\n",
      "168956      1\n",
      "273403      1\n",
      "140282      1\n",
      "117751      1\n",
      "185357      1\n",
      "322547      1\n",
      "224141      1\n",
      "226288      1\n",
      "132078      1\n",
      "225811      1\n",
      "271013      1\n",
      "207627      1\n",
      "211785      1\n",
      "242488      1\n",
      "47929       1\n",
      "62272       1\n",
      "123714      1\n",
      "60227       1\n",
      "183111      1\n",
      "347446      1\n",
      "133983      1\n",
      "35663       1\n",
      "198346      1\n",
      "154668      1\n",
      "121685      1\n",
      "209752      1\n",
      "142171      1\n",
      "247685      1\n",
      "191283      1\n",
      "133935      1\n",
      "197422      1\n",
      "170797      1\n",
      "332588      1\n",
      "43819       1\n",
      "219941      1\n",
      "54052       1\n",
      "107314      1\n",
      "297759      1\n",
      "301853      1\n",
      "109339      1\n",
      "267540      1\n",
      "95490       1\n",
      "224019      1\n",
      "199439      1\n",
      "131934      1\n",
      "189282      1\n",
      "400285      1\n",
      "398220      1\n",
      "119684      1\n",
      "246262      1\n",
      "213894      1\n",
      "183175      1\n",
      "113545      1\n",
      "142219      1\n",
      "276664      1\n",
      "349028      1\n",
      "193650      1\n",
      "312692      1\n",
      "158611      1\n",
      "63466       1\n",
      "408473      1\n",
      "143910      1\n",
      "123778      1\n",
      "97153       1\n",
      "199551      1\n",
      "33662       1\n",
      "170877      1\n",
      "292120      1\n",
      "127277      1\n",
      "260614      1\n",
      "152436      1\n",
      "86786       1\n",
      "254834      1\n",
      "52728       1\n",
      "407425      1\n",
      "41834       1\n",
      "113513      1\n",
      "168312      1\n",
      "180868      1\n",
      "144125      1\n",
      "90969       1\n",
      "197371      1\n",
      "156084      1\n",
      "74156       1\n",
      "242094      1\n",
      "393712      1\n",
      "508336      1\n",
      "117169      1\n",
      "154035      1\n",
      "420277      1\n",
      "189811      1\n",
      "152568      1\n",
      "164280      1\n",
      "100793      1\n",
      "37306       1\n",
      "334267      1\n",
      "198526      1\n",
      "432555      1\n",
      "391591      1\n",
      "262664      1\n",
      "192107      1\n",
      "240013      1\n",
      "274830      1\n",
      "180624      1\n",
      "215441      1\n",
      "55699       1\n",
      "156052      1\n",
      "114157      1\n",
      "258470      1\n",
      "262552      1\n",
      "292264      1\n",
      "186666      1\n",
      "213408      1\n",
      "182689      1\n",
      "186787      1\n",
      "174525      1\n",
      "231473      1\n",
      "119234      1\n",
      "365050      1\n",
      "353524      1\n",
      "328561      1\n",
      "541343      1\n",
      "29174       1\n",
      "100228      1\n",
      "211751      1\n",
      "64289       1\n",
      "273629      1\n",
      "113151      1\n",
      "477697      1\n",
      "217602      1\n",
      "88579       1\n",
      "271122      1\n",
      "61958       1\n",
      "117480      1\n",
      "363395      1\n",
      "137707      1\n",
      "78649       1\n",
      "119266      1\n",
      "117217      1\n",
      "303388      1\n",
      "97212       1\n",
      "106972      1\n",
      "137691      1\n",
      "102874      1\n",
      "129495      1\n",
      "172718      1\n",
      "109005      1\n",
      "208165      1\n",
      "181284      1\n",
      "94662       1\n",
      "127943      1\n",
      "107165      1\n",
      "144808      1\n",
      "153891      1\n",
      "137499      1\n",
      "106780      1\n",
      "164320      1\n",
      "209182      1\n",
      "211231      1\n",
      "84257       1\n",
      "125976      1\n",
      "178470      1\n",
      "192806      1\n",
      "179534      1\n",
      "234387      1\n",
      "203051      1\n",
      "248113      1\n",
      "282882      1\n",
      "194591      1\n",
      "200047      1\n",
      "229656      1\n",
      "454934      1\n",
      "183638      1\n",
      "182386      1\n",
      "110862      1\n",
      "436493      1\n",
      "112318      1\n",
      "231689      1\n",
      "393480      1\n",
      "215297      1\n",
      "409201      1\n",
      "149118      1\n",
      "233722      1\n",
      "33016       1\n",
      "225526      1\n",
      "233786      1\n",
      "106812      1\n",
      "385412      1\n",
      "259531      1\n",
      "188076      1\n",
      "88419       1\n",
      "188772      1\n",
      "140012      1\n",
      "175778      1\n",
      "143804      1\n",
      "94080       1\n",
      "183257      1\n",
      "264457      1\n",
      "160118      1\n",
      "242859      1\n",
      "117542      1\n",
      "145791      1\n",
      "158642      1\n",
      "192349      1\n",
      "148532      1\n",
      "67929       1\n",
      "228346      1\n",
      "142061      1\n",
      "190805      1\n",
      "360457      1\n",
      "174413      1\n",
      "233802      1\n",
      "100681      1\n",
      "66638       1\n",
      "192838      1\n",
      "175681      1\n",
      "153416      1\n",
      "228660      1\n",
      "477505      1\n",
      "237646      1\n",
      "32334       1\n",
      "199177      1\n",
      "35102       1\n",
      "304416      1\n",
      "107196      1\n",
      "243875      1\n",
      "342719      1\n",
      "279232      1\n",
      "182977      1\n",
      "320196      1\n",
      "127686      1\n",
      "111319      1\n",
      "164552      1\n",
      "193125      1\n",
      "68577       1\n",
      "172748      1\n",
      "173724      1\n",
      "112200      1\n",
      "203451      1\n",
      "147876      1\n",
      "362912      1\n",
      "291494      1\n",
      "181081      1\n",
      "443040      1\n",
      "117409      1\n",
      "282923      1\n",
      "282698      1\n",
      "26880       1\n",
      "64167       1\n",
      "169527      1\n",
      "172716      1\n",
      "371373      1\n",
      "84130       1\n",
      "381618      1\n",
      "121523      1\n",
      "123572      1\n",
      "119506      1\n",
      "199136      1\n",
      "243142      1\n",
      "197384      1\n",
      "47871       1\n",
      "101967      1\n",
      "188809      1\n",
      "350979      1\n",
      "303851      1\n",
      "362062      1\n",
      "318002      1\n",
      "39643       1\n",
      "301835      1\n",
      "26999       1\n",
      "411560      1\n",
      "350995      1\n",
      "420629      1\n",
      "99096       1\n",
      "340734      1\n",
      "72443       1\n",
      "201466      1\n",
      "29430       1\n",
      "180976      1\n",
      "211695      1\n",
      "340718      1\n",
      "174829      1\n",
      "110920      1\n",
      "236267      1\n",
      "35561       1\n",
      "129767      1\n",
      "158437      1\n",
      "176239      1\n",
      "379778      1\n",
      "176862      1\n",
      "354558      1\n",
      "427952      1\n",
      "170651      1\n",
      "33432       1\n",
      "254516      1\n",
      "109101      1\n",
      "209454      1\n",
      "342575      1\n",
      "115248      1\n",
      "182833      1\n",
      "184882      1\n",
      "125493      1\n",
      "142791      1\n",
      "197176      1\n",
      "109117      1\n",
      "406078      1\n",
      "193038      1\n",
      "177651      1\n",
      "121411      1\n",
      "301611      1\n",
      "119944      1\n",
      "393768      1\n",
      "52240       1\n",
      "606752      1\n",
      "297742      1\n",
      "209438      1\n",
      "76317       1\n",
      "37402       1\n",
      "231961      1\n",
      "418324      1\n",
      "339388      1\n",
      "348690      1\n",
      "180752      1\n",
      "145935      1\n",
      "238092      1\n",
      "279960      1\n",
      "195143      1\n",
      "250068      1\n",
      "339767      1\n",
      "193158      1\n",
      "89806       1\n",
      "135785      1\n",
      "58115       1\n",
      "73309       1\n",
      "348802      1\n",
      "378239      1\n",
      "162439      1\n",
      "303692      1\n",
      "70943       1\n",
      "139916      1\n",
      "172145      1\n",
      "82576       1\n",
      "117393      1\n",
      "549413      1\n",
      "170600      1\n",
      "246025      1\n",
      "217718      1\n",
      "339547      1\n",
      "557236      1\n",
      "135786      1\n",
      "232954      1\n",
      "88675       1\n",
      "146015      1\n",
      "174685      1\n",
      "334427      1\n",
      "168538      1\n",
      "262744      1\n",
      "125525      1\n",
      "221780      1\n",
      "184308      1\n",
      "167527      1\n",
      "225385      1\n",
      "256647      1\n",
      "303051      1\n",
      "114544      1\n",
      "104293      1\n",
      "214378      1\n",
      "217467      1\n",
      "517995      1\n",
      "186221      1\n",
      "193215      1\n",
      "405362      1\n",
      "255835      1\n",
      "282202      1\n",
      "42209       1\n",
      "231287      1\n",
      "281852      1\n",
      "326370      1\n",
      "247679      1\n",
      "241506      1\n",
      "259929      1\n",
      "23686       1\n",
      "141824      1\n",
      "191227      1\n",
      "128567      1\n",
      "364342      1\n",
      "226668      1\n",
      "188220      1\n",
      "153405      1\n",
      "206659      1\n",
      "65368       1\n",
      "194538      1\n",
      "131180      1\n",
      "138162      1\n",
      "149646      1\n",
      "86972       1\n",
      "104068      1\n",
      "147328      1\n",
      "286869      1\n",
      "108419      1\n",
      "117244      1\n",
      "182191      1\n",
      "145329      1\n",
      "176050      1\n",
      "171956      1\n",
      "268213      1\n",
      "96185       1\n",
      "352188      1\n",
      "333701      1\n",
      "163342      1\n",
      "250807      1\n",
      "436163      1\n",
      "303044      1\n",
      "169925      1\n",
      "167878      1\n",
      "544686      1\n",
      "55213       1\n",
      "349066      1\n",
      "266150      1\n",
      "325706      1\n",
      "247711      1\n",
      "352156      1\n",
      "356250      1\n",
      "200598      1\n",
      "335764      1\n",
      "35136       1\n",
      "130466      1\n",
      "247695      1\n",
      "85902       1\n",
      "147471      1\n",
      "165767      1\n",
      "332187      1\n",
      "126336      1\n",
      "24364       1\n",
      "102182      1\n",
      "34503       1\n",
      "190139      1\n",
      "53109       1\n",
      "118462      1\n",
      "50879       1\n",
      "241346      1\n",
      "235205      1\n",
      "259785      1\n",
      "243425      1\n",
      "188108      1\n",
      "186061      1\n",
      "249550      1\n",
      "138190      1\n",
      "57052       1\n",
      "167094      1\n",
      "192504      1\n",
      "337587      1\n",
      "112305      1\n",
      "218382      1\n",
      "177995      1\n",
      "253612      1\n",
      "91819       1\n",
      "226985      1\n",
      "204515      1\n",
      "403107      1\n",
      "306850      1\n",
      "177825      1\n",
      "212640      1\n",
      "247455      1\n",
      "109390      1\n",
      "163480      1\n",
      "263831      1\n",
      "118494      1\n",
      "339682      1\n",
      "136997      1\n",
      "132887      1\n",
      "261584      1\n",
      "188172      1\n",
      "642830      1\n",
      "83727       1\n",
      "302868      1\n",
      "364310      1\n",
      "259865      1\n",
      "171748      1\n",
      "354075      1\n",
      "89884       1\n",
      "287372      1\n",
      "278304      1\n",
      "106491      1\n",
      "488541      1\n",
      "126730      1\n",
      "128777      1\n",
      "171780      1\n",
      "105381      1\n",
      "277746      1\n",
      "147200      1\n",
      "89852       1\n",
      "222971      1\n",
      "196344      1\n",
      "302836      1\n",
      "403187      1\n",
      "81648       1\n",
      "216814      1\n",
      "124651      1\n",
      "325353      1\n",
      "271792      1\n",
      "333541      1\n",
      "100295      1\n",
      "149455      1\n",
      "47343       1\n",
      "170169      1\n",
      "276709      1\n",
      "262280      1\n",
      "69770       1\n",
      "176270      1\n",
      "49296       1\n",
      "389270      1\n",
      "397466      1\n",
      "158776      1\n",
      "243871      1\n",
      "192213      1\n",
      "123044      1\n",
      "200068      1\n",
      "52144       1\n",
      "557853      1\n",
      "219267      1\n",
      "209022      1\n",
      "278480      1\n",
      "110702      1\n",
      "234859      1\n",
      "282722      1\n",
      "319588      1\n",
      "354405      1\n",
      "161111      1\n",
      "204908      1\n",
      "344176      1\n",
      "261899      1\n",
      "149617      1\n",
      "286836      1\n",
      "157813      1\n",
      "493689      1\n",
      "167918      1\n",
      "270460      1\n",
      "198825      1\n",
      "301227      1\n",
      "159574      1\n",
      "53181       1\n",
      "157909      1\n",
      "127190      1\n",
      "131288      1\n",
      "198873      1\n",
      "200922      1\n",
      "119964      1\n",
      "168407      1\n",
      "70539       1\n",
      "114912      1\n",
      "116961      1\n",
      "36077       1\n",
      "242375      1\n",
      "270572      1\n",
      "141549      1\n",
      "221396      1\n",
      "55507       1\n",
      "250066      1\n",
      "63062       1\n",
      "110798      1\n",
      "297457      1\n",
      "106700      1\n",
      "104651      1\n",
      "164040      1\n",
      "293063      1\n",
      "185001      1\n",
      "190661      1\n",
      "204648      1\n",
      "278720      1\n",
      "860348      1\n",
      "96445       1\n",
      "380219      1\n",
      "47199       1\n",
      "338013      1\n",
      "434268      1\n",
      "30713       1\n",
      "147440      1\n",
      "40956       1\n",
      "208882      1\n",
      "75763       1\n",
      "270324      1\n",
      "462838      1\n",
      "192506      1\n",
      "32776       1\n",
      "167613      1\n",
      "88061       1\n",
      "282622      1\n",
      "247807      1\n",
      "51201       1\n",
      "274883      1\n",
      "500720      1\n",
      "92472       1\n",
      "57324       1\n",
      "258026      1\n",
      "194537      1\n",
      "196584      1\n",
      "263081      1\n",
      "104421      1\n",
      "110562      1\n",
      "145377      1\n",
      "212960      1\n",
      "327769      1\n",
      "153535      1\n",
      "288731      1\n",
      "31269       1\n",
      "225142      1\n",
      "122076      1\n",
      "28678       1\n",
      "40512       1\n",
      "199240      1\n",
      "227399      1\n",
      "157749      1\n",
      "133582      1\n",
      "403112      1\n",
      "309311      1\n",
      "171546      1\n",
      "385092      1\n",
      "60135       1\n",
      "87950       1\n",
      "65080       1\n",
      "352882      1\n",
      "184402      1\n",
      "90196       1\n",
      "232808      1\n",
      "92969       1\n",
      "250314      1\n",
      "184370      1\n",
      "181576      1\n",
      "101481      1\n",
      "370733      1\n",
      "172076      1\n",
      "462890      1\n",
      "51939       1\n",
      "127014      1\n",
      "72486       1\n",
      "195919      1\n",
      "145439      1\n",
      "436253      1\n",
      "399387      1\n",
      "198681      1\n",
      "96279       1\n",
      "282642      1\n",
      "267034      1\n",
      "182268      1\n",
      "240226      1\n",
      "28197       1\n",
      "38611       1\n",
      "196119      1\n",
      "217455      1\n",
      "179743      1\n",
      "314913      1\n",
      "58916       1\n",
      "30246       1\n",
      "124436      1\n",
      "97831       1\n",
      "77357       1\n",
      "178390      1\n",
      "179759      1\n",
      "144172      1\n",
      "56883       1\n",
      "93717       1\n",
      "314897      1\n",
      "398986      1\n",
      "147352      1\n",
      "160984      1\n",
      "370156      1\n",
      "351731      1\n",
      "108273      1\n",
      "298489      1\n",
      "73211       1\n",
      "186993      1\n",
      "378384      1\n",
      "230919      1\n",
      "265737      1\n",
      "302603      1\n",
      "173580      1\n",
      "248595      1\n",
      "212495      1\n",
      "194102      1\n",
      "32311       1\n",
      "198200      1\n",
      "345712      1\n",
      "188003      1\n",
      "226918      1\n",
      "231016      1\n",
      "298601      1\n",
      "32981       1\n",
      "38488       1\n",
      "254167      1\n",
      "173628      1\n",
      "412952      1\n",
      "435836      1\n",
      "238187      1\n",
      "118401      1\n",
      "120450      1\n",
      "192133      1\n",
      "59068       1\n",
      "505438      1\n",
      "372317      1\n",
      "267866      1\n",
      "69209       1\n",
      "99928       1\n",
      "335015      1\n",
      "56915       1\n",
      "251474      1\n",
      "93618       1\n",
      "194189      1\n",
      "91716       1\n",
      "664366      1\n",
      "972354      1\n",
      "249409      1\n",
      "181824      1\n",
      "48703       1\n",
      "163303      1\n",
      "257509      1\n",
      "318947      1\n",
      "93589       1\n",
      "261511      1\n",
      "92864       1\n",
      "215616      1\n",
      "107916      1\n",
      "177550      1\n",
      "21906       1\n",
      "194501      1\n",
      "93605       1\n",
      "294295      1\n",
      "190621      1\n",
      "62176       1\n",
      "232368      1\n",
      "183105      1\n",
      "286115      1\n",
      "90803       1\n",
      "511361      1\n",
      "402812      1\n",
      "103802      1\n",
      "30070       1\n",
      "224629      1\n",
      "58740       1\n",
      "144750      1\n",
      "497788      1\n",
      "259757      1\n",
      "36201       1\n",
      "159077      1\n",
      "451940      1\n",
      "65325       1\n",
      "109917      1\n",
      "396633      1\n",
      "130391      1\n",
      "47425       1\n",
      "230824      1\n",
      "245215      1\n",
      "181712      1\n",
      "130807      1\n",
      "99784       1\n",
      "101833      1\n",
      "167497      1\n",
      "308686      1\n",
      "141645      1\n",
      "150993      1\n",
      "138667      1\n",
      "41609       1\n",
      "319248      1\n",
      "327127      1\n",
      "285013      1\n",
      "202202      1\n",
      "195820      1\n",
      "124356      1\n",
      "318915      1\n",
      "87490       1\n",
      "198330      1\n",
      "247232      1\n",
      "146879      1\n",
      "110013      1\n",
      "89347       1\n",
      "204219      1\n",
      "234938      1\n",
      "265657      1\n",
      "263608      1\n",
      "255412      1\n",
      "220595      1\n",
      "216497      1\n",
      "308654      1\n",
      "109997      1\n",
      "102025      1\n",
      "182140      1\n",
      "112959      1\n",
      "192923      1\n",
      "659273      1\n",
      "403276      1\n",
      "155475      1\n",
      "227158      1\n",
      "329925      1\n",
      "169818      1\n",
      "77661       1\n",
      "267893      1\n",
      "145246      1\n",
      "604537      1\n",
      "354148      1\n",
      "69481       1\n",
      "127016      1\n",
      "112494      1\n",
      "192325      1\n",
      "128401      1\n",
      "210574      1\n",
      "92531       1\n",
      "284450      1\n",
      "188195      1\n",
      "288548      1\n",
      "52242       1\n",
      "194342      1\n",
      "156950      1\n",
      "239404      1\n",
      "39610       1\n",
      "212783      1\n",
      "116528      1\n",
      "184216      1\n",
      "305647      1\n",
      "268090      1\n",
      "51008       1\n",
      "182128      1\n",
      "221043      1\n",
      "190324      1\n",
      "124852      1\n",
      "98215       1\n",
      "190179      1\n",
      "247892      1\n",
      "347960      1\n",
      "380281      1\n",
      "153522      1\n",
      "68678       1\n",
      "290677      1\n",
      "124449      1\n",
      "99175       1\n",
      "51136       1\n",
      "118721      1\n",
      "317378      1\n",
      "24515       1\n",
      "211553      1\n",
      "124836      1\n",
      "659558      1\n",
      "219042      1\n",
      "116640      1\n",
      "606111      1\n",
      "532379      1\n",
      "169882      1\n",
      "65868       1\n",
      "419732      1\n",
      "369084      1\n",
      "280464      1\n",
      "210830      1\n",
      "185575      1\n",
      "302195      1\n",
      "136472      1\n",
      "250976      1\n",
      "79646       1\n",
      "296728      1\n",
      "161558      1\n",
      "140988      1\n",
      "24243       1\n",
      "222900      1\n",
      "212370      1\n",
      "266461      1\n",
      "189679      1\n",
      "169658      1\n",
      "109112      1\n",
      "280519      1\n",
      "144114      1\n",
      "499935      1\n",
      "50990       1\n",
      "182581      1\n",
      "323269      1\n",
      "66624       1\n",
      "114351      1\n",
      "291568      1\n",
      "175789      1\n",
      "331433      1\n",
      "67240       1\n",
      "32423       1\n",
      "188067      1\n",
      "181920      1\n",
      "195282      1\n",
      "206492      1\n",
      "401051      1\n",
      "102041      1\n",
      "83812       1\n",
      "229015      1\n",
      "193235      1\n",
      "192149      1\n",
      "129640      1\n",
      "273269      1\n",
      "170627      1\n",
      "388885      1\n",
      "32519       1\n",
      "139003      1\n",
      "80303       1\n",
      "44797       1\n",
      "131459      1\n",
      "48895       1\n",
      "147560      1\n",
      "129586      1\n",
      "175821      1\n",
      "302859      1\n",
      "77581       1\n",
      "114447      1\n",
      "214800      1\n",
      "250206      1\n",
      "382738      1\n",
      "322144      1\n",
      "257781      1\n",
      "449101      1\n",
      "83696       1\n",
      "177902      1\n",
      "233193      1\n",
      "157951      1\n",
      "257765      1\n",
      "286435      1\n",
      "187629      1\n",
      "273734      1\n",
      "46814       1\n",
      "75134       1\n",
      "111163      1\n",
      "331481      1\n",
      "193773      1\n",
      "118481      1\n",
      "124244      1\n",
      "253267      1\n",
      "237691      1\n",
      "66504       1\n",
      "27184       1\n",
      "82880       1\n",
      "250818      1\n",
      "222646      1\n",
      "93125       1\n",
      "259014      1\n",
      "166857      1\n",
      "199609      1\n",
      "134524      1\n",
      "304076      1\n",
      "109517      1\n",
      "192984      1\n",
      "277455      1\n",
      "181200      1\n",
      "269243      1\n",
      "161259      1\n",
      "19793       1\n",
      "278617      1\n",
      "68505       1\n",
      "496538      1\n",
      "205724      1\n",
      "169646      1\n",
      "373662      1\n",
      "160981      1\n",
      "254933      1\n",
      "89011       1\n",
      "133449      1\n",
      "271276      1\n",
      "135776      1\n",
      "102114      1\n",
      "279472      1\n",
      "250802      1\n",
      "347089      1\n",
      "130007      1\n",
      "263128      1\n",
      "27669       1\n",
      "149466      1\n",
      "230408      1\n",
      "134153      1\n",
      "192829      1\n",
      "347153      1\n",
      "205407      1\n",
      "195607      1\n",
      "155913      1\n",
      "197656      1\n",
      "88967       1\n",
      "175133      1\n",
      "242718      1\n",
      "197672      1\n",
      "169002      1\n",
      "248833      1\n",
      "243010      1\n",
      "160758      1\n",
      "386036      1\n",
      "169837      1\n",
      "181232      1\n",
      "99646       1\n",
      "236523      1\n",
      "166889      1\n",
      "53306       1\n",
      "392167      1\n",
      "62438       1\n",
      "256997      1\n",
      "123876      1\n",
      "349154      1\n",
      "146399      1\n",
      "173020      1\n",
      "28357       1\n",
      "424855      1\n",
      "224149      1\n",
      "205644      1\n",
      "175837      1\n",
      "60229       1\n",
      "29510       1\n",
      "293703      1\n",
      "33608       1\n",
      "693066      1\n",
      "255486      1\n",
      "139000      1\n",
      "158680      1\n",
      "109240      1\n",
      "377680      1\n",
      "281425      1\n",
      "54098       1\n",
      "154451      1\n",
      "408383      1\n",
      "369468      1\n",
      "234298      1\n",
      "66360       1\n",
      "389942      1\n",
      "256821      1\n",
      "318259      1\n",
      "250674      1\n",
      "177629      1\n",
      "211759      1\n",
      "373550      1\n",
      "107308      1\n",
      "133929      1\n",
      "172498      1\n",
      "191269      1\n",
      "134793      1\n",
      "211743      1\n",
      "123586      1\n",
      "523095      1\n",
      "347025      1\n",
      "252803      1\n",
      "197496      1\n",
      "199545      1\n",
      "37754       1\n",
      "330836      1\n",
      "50048       1\n",
      "183169      1\n",
      "123780      1\n",
      "263000      1\n",
      "33121       1\n",
      "161325      1\n",
      "131976      1\n",
      "104223      1\n",
      "205708      1\n",
      "111502      1\n",
      "195447      1\n",
      "291702      1\n",
      "419895      1\n",
      "187251      1\n",
      "257485      1\n",
      "151967      1\n",
      "199529      1\n",
      "164712      1\n",
      "204450      1\n",
      "160614      1\n",
      "447555      1\n",
      "90980       1\n",
      "126850      1\n",
      "249339      1\n",
      "314209      1\n",
      "148320      1\n",
      "236379      1\n",
      "138283      1\n",
      "44706       1\n",
      "408623      1\n",
      "111675      1\n",
      "183854      1\n",
      "25828       1\n",
      "170603      1\n",
      "212207      1\n",
      "187635      1\n",
      "423158      1\n",
      "400635      1\n",
      "298249      1\n",
      "77053       1\n",
      "274276      1\n",
      "185602      1\n",
      "220419      1\n",
      "101455      1\n",
      "45316       1\n",
      "152802      1\n",
      "50400       1\n",
      "177374      1\n",
      "175325      1\n",
      "335067      1\n",
      "296152      1\n",
      "95446       1\n",
      "188650      1\n",
      "312528      1\n",
      "77005       1\n",
      "38090       1\n",
      "261319      1\n",
      "229424      1\n",
      "382146      1\n",
      "229016      1\n",
      "123219      1\n",
      "228535      1\n",
      "66824       1\n",
      "187465      1\n",
      "126133      1\n",
      "279872      1\n",
      "270218      1\n",
      "341294      1\n",
      "195372      1\n",
      "45961       1\n",
      "163127      1\n",
      "331065      1\n",
      "118081      1\n",
      "138507      1\n",
      "156996      1\n",
      "218689      1\n",
      "218653      1\n",
      "36169       1\n",
      "336571      1\n",
      "50512       1\n",
      "34088       1\n",
      "294183      1\n",
      "193830      1\n",
      "183542      1\n",
      "181322      1\n",
      "217083      1\n",
      "150817      1\n",
      "46366       1\n",
      "77085       1\n",
      "236827      1\n",
      "267546      1\n",
      "118520      1\n",
      "29974       1\n",
      "125089      1\n",
      "288020      1\n",
      "275726      1\n",
      "173324      1\n",
      "219130      1\n",
      "152754      1\n",
      "202745      1\n",
      "287828      1\n",
      "170331      1\n",
      "277583      1\n",
      "115792      1\n",
      "223830      1\n",
      "185426      1\n",
      "229364      1\n",
      "193622      1\n",
      "162919      1\n",
      "261207      1\n",
      "54985       1\n",
      "144478      1\n",
      "296537      1\n",
      "181344      1\n",
      "300915      1\n",
      "151001      1\n",
      "313929      1\n",
      "66632       1\n",
      "107845      1\n",
      "62534       1\n",
      "60485       1\n",
      "255044      1\n",
      "351299      1\n",
      "185410      1\n",
      "375871      1\n",
      "198741      1\n",
      "400443      1\n",
      "180539      1\n",
      "197688      1\n",
      "128054      1\n",
      "420917      1\n",
      "154675      1\n",
      "29798       1\n",
      "90547       1\n",
      "183473      1\n",
      "114413      1\n",
      "204868      1\n",
      "201882      1\n",
      "173212      1\n",
      "359972      1\n",
      "181408      1\n",
      "248993      1\n",
      "124068      1\n",
      "115824      1\n",
      "359591      1\n",
      "230568      1\n",
      "167081      1\n",
      "566537      1\n",
      "210094      1\n",
      "212143      1\n",
      "355477      1\n",
      "187539      1\n",
      "140851      1\n",
      "183284      1\n",
      "184477      1\n",
      "167049      1\n",
      "86590       1\n",
      "521665      1\n",
      "183425      1\n",
      "279680      1\n",
      "33234       1\n",
      "236470      1\n",
      "215306      1\n",
      "136314      1\n",
      "35961       1\n",
      "353396      1\n",
      "224234      1\n",
      "584259      1\n",
      "272019      1\n",
      "144860      1\n",
      "77873       1\n",
      "53277       1\n",
      "340001      1\n",
      "368675      1\n",
      "166187      1\n",
      "256005      1\n",
      "180271      1\n",
      "394484      1\n",
      "124954      1\n",
      "301108      1\n",
      "462966      1\n",
      "229431      1\n",
      "423711      1\n",
      "259089      1\n",
      "47168       1\n",
      "186396      1\n",
      "296982      1\n",
      "198822      1\n",
      "632834      1\n",
      "268276      1\n",
      "268571      1\n",
      "192507      1\n",
      "139190      1\n",
      "121407      1\n",
      "151551      1\n",
      "270339      1\n",
      "462869      1\n",
      "233194      1\n",
      "133126      1\n",
      "163847      1\n",
      "223242      1\n",
      "273243      1\n",
      "247286      1\n",
      "263773      1\n",
      "237651      1\n",
      "266325      1\n",
      "41107       1\n",
      "297094      1\n",
      "94345       1\n",
      "219276      1\n",
      "573583      1\n",
      "276624      1\n",
      "229997      1\n",
      "269991      1\n",
      "190554      1\n",
      "200853      1\n",
      "115834      1\n",
      "161944      1\n",
      "355287      1\n",
      "113667      1\n",
      "1484705     1\n",
      "102533      1\n",
      "106627      1\n",
      "39603       1\n",
      "109004      1\n",
      "158242      1\n",
      "178946      1\n",
      "77937       1\n",
      "215150      1\n",
      "155755      1\n",
      "159849      1\n",
      "53498       1\n",
      "106595      1\n",
      "141410      1\n",
      "147551      1\n",
      "280670      1\n",
      "374313      1\n",
      "188507      1\n",
      "184303      1\n",
      "122861      1\n",
      "284652      1\n",
      "251804      1\n",
      "443855      1\n",
      "384795      1\n",
      "73621       1\n",
      "133014      1\n",
      "194456      1\n",
      "26522       1\n",
      "312634      1\n",
      "213208      1\n",
      "409505      1\n",
      "141218      1\n",
      "143267      1\n",
      "264102      1\n",
      "59306       1\n",
      "149422      1\n",
      "182158      1\n",
      "419722      1\n",
      "266119      1\n",
      "368517      1\n",
      "71556       1\n",
      "141186      1\n",
      "114561      1\n",
      "80924       1\n",
      "61307       1\n",
      "157562      1\n",
      "231286      1\n",
      "71540       1\n",
      "241523      1\n",
      "240857      1\n",
      "79728       1\n",
      "341757      1\n",
      "56179       1\n",
      "288598      1\n",
      "432052      1\n",
      "98281       1\n",
      "131033      1\n",
      "473040      1\n",
      "311249      1\n",
      "151484      1\n",
      "225014      1\n",
      "237525      1\n",
      "198614      1\n",
      "223194      1\n",
      "266400      1\n",
      "45564       1\n",
      "120796      1\n",
      "278329      1\n",
      "204773      1\n",
      "264166      1\n",
      "200679      1\n",
      "217039      1\n",
      "51150       1\n",
      "146272      1\n",
      "360393      1\n",
      "194504      1\n",
      "102343      1\n",
      "245659      1\n",
      "202692      1\n",
      "143299      1\n",
      "174018      1\n",
      "147393      1\n",
      "184255      1\n",
      "247378      1\n",
      "483261      1\n",
      "251836      1\n",
      "225211      1\n",
      "165814      1\n",
      "241825      1\n",
      "131239      1\n",
      "51672       1\n",
      "67958       1\n",
      "135525      1\n",
      "422249      1\n",
      "342084      1\n",
      "183522      1\n",
      "108914      1\n",
      "172403      1\n",
      "225657      1\n",
      "162136      1\n",
      "444219      1\n",
      "57723       1\n",
      "252284      1\n",
      "283005      1\n",
      "190418      1\n",
      "180607      1\n",
      "244064      1\n",
      "125197      1\n",
      "121004      1\n",
      "104772      1\n",
      "178120      1\n",
      "379198      1\n",
      "114204      1\n",
      "107627      1\n",
      "153751      1\n",
      "106819      1\n",
      "190903      1\n",
      "170324      1\n",
      "396538      1\n",
      "123211      1\n",
      "182606      1\n",
      "149653      1\n",
      "242001      1\n",
      "889965      1\n",
      "276864      1\n",
      "369027      1\n",
      "137604      1\n",
      "201141      1\n",
      "211360      1\n",
      "569761      1\n",
      "100903      1\n",
      "146857      1\n",
      "95691       1\n",
      "251825      1\n",
      "100790      1\n",
      "162184      1\n",
      "420282      1\n",
      "248254      1\n",
      "373185      1\n",
      "376150      1\n",
      "203204      1\n",
      "160972      1\n",
      "191800      1\n",
      "240143      1\n",
      "216522      1\n",
      "90523       1\n",
      "408531      1\n",
      "129432      1\n",
      "197015      1\n",
      "266645      1\n",
      "169711      1\n",
      "108946      1\n",
      "602513      1\n",
      "163747      1\n",
      "82319       1\n",
      "84366       1\n",
      "210626      1\n",
      "91137       1\n",
      "321733      1\n",
      "192825      1\n",
      "129336      1\n",
      "100662      1\n",
      "182494      1\n",
      "433705      1\n",
      "237671      1\n",
      "207058      1\n",
      "106707      1\n",
      "221403      1\n",
      "317660      1\n",
      "221672      1\n",
      "110458      1\n",
      "252518      1\n",
      "202980      1\n",
      "168165      1\n",
      "98535       1\n",
      "114770      1\n",
      "114927      1\n",
      "102226      1\n",
      "55500       1\n",
      "123083      1\n",
      "256202      1\n",
      "282092      1\n",
      "193237      1\n",
      "105650      1\n",
      "264390      1\n",
      "175534      1\n",
      "47296       1\n",
      "173652      1\n",
      "376383      1\n",
      "186556      1\n",
      "34998       1\n",
      "43701       1\n",
      "59583       1\n",
      "315565      1\n",
      "209137      1\n",
      "386643      1\n",
      "218188      1\n",
      "200997      1\n",
      "117022      1\n",
      "344351      1\n",
      "47392       1\n",
      "405793      1\n",
      "174370      1\n",
      "170276      1\n",
      "262439      1\n",
      "125178      1\n",
      "96552       1\n",
      "61737       1\n",
      "250157      1\n",
      "349347      1\n",
      "368947      1\n",
      "334132      1\n",
      "119069      1\n",
      "223514      1\n",
      "181153      1\n",
      "426263      1\n",
      "115331      1\n",
      "104724      1\n",
      "184589      1\n",
      "125194      1\n",
      "328947      1\n",
      "170244      1\n",
      "172291      1\n",
      "76034       1\n",
      "274689      1\n",
      "145664      1\n",
      "311551      1\n",
      "182526      1\n",
      "235197      1\n",
      "163689      1\n",
      "204645      1\n",
      "387777      1\n",
      "48641       1\n",
      "169460      1\n",
      "263670      1\n",
      "224763      1\n",
      "442045      1\n",
      "196898      1\n",
      "341504      1\n",
      "130513      1\n",
      "206322      1\n",
      "200199      1\n",
      "228230      1\n",
      "91658       1\n",
      "206232      1\n",
      "122381      1\n",
      "123816      1\n",
      "142835      1\n",
      "177648      1\n",
      "79712       1\n",
      "199256      1\n",
      "153052      1\n",
      "137184      1\n",
      "280030      1\n",
      "332785      1\n",
      "179681      1\n",
      "337378      1\n",
      "113703      1\n",
      "282095      1\n",
      "160811      1\n",
      "248749      1\n",
      "62952       1\n",
      "51543       1\n",
      "185836      1\n",
      "293176      1\n",
      "306707      1\n",
      "732569      1\n",
      "67320       1\n",
      "210496      1\n",
      "226872      1\n",
      "163385      1\n",
      "239612      1\n",
      "153148      1\n",
      "116286      1\n",
      "216639      1\n",
      "117525      1\n",
      "63000       1\n",
      "370242      1\n",
      "38468       1\n",
      "171589      1\n",
      "225879      1\n",
      "155213      1\n",
      "144133      1\n",
      "525878      1\n",
      "326199      1\n",
      "117585      1\n",
      "539864      1\n",
      "108082      1\n",
      "245297      1\n",
      "112176      1\n",
      "151087      1\n",
      "515629      1\n",
      "129879      1\n",
      "232242      1\n",
      "204325      1\n",
      "210311      1\n",
      "118303      1\n",
      "80333       1\n",
      "302097      1\n",
      "425497      1\n",
      "290267      1\n",
      "357848      1\n",
      "36311       1\n",
      "146429      1\n",
      "308608      1\n",
      "81281       1\n",
      "142723      1\n",
      "267652      1\n",
      "368005      1\n",
      "296326      1\n",
      "248384      1\n",
      "169364      1\n",
      "189834      1\n",
      "153356      1\n",
      "476558      1\n",
      "144784      1\n",
      "202959      1\n",
      "278139      1\n",
      "347519      1\n",
      "56701       1\n",
      "179985      1\n",
      "62857       1\n",
      "32121       1\n",
      "427382      1\n",
      "684015      1\n",
      "142707      1\n",
      "179569      1\n",
      "120172      1\n",
      "189802      1\n",
      "142621      1\n",
      "281784      1\n",
      "40293       1\n",
      "271714      1\n",
      "136309      1\n",
      "231231      1\n",
      "175507      1\n",
      "466325      1\n",
      "329174      1\n",
      "519627      1\n",
      "312766      1\n",
      "150975      1\n",
      "147500      1\n",
      "171461      1\n",
      "34246       1\n",
      "340018      1\n",
      "24013       1\n",
      "45427       1\n",
      "282063      1\n",
      "177616      1\n",
      "212433      1\n",
      "239058      1\n",
      "83859       1\n",
      "133536      1\n",
      "165302      1\n",
      "110003      1\n",
      "179633      1\n",
      "216469      1\n",
      "85423       1\n",
      "83374       1\n",
      "303973      1\n",
      "294313      1\n",
      "193960      1\n",
      "133729      1\n",
      "77219       1\n",
      "42402       1\n",
      "46496       1\n",
      "251292      1\n",
      "77392       1\n",
      "222618      1\n",
      "50880       1\n",
      "183887      1\n",
      "79440       1\n",
      "146329      1\n",
      "247566      1\n",
      "212737      1\n",
      "372483      1\n",
      "167687      1\n",
      "194312      1\n",
      "126500      1\n",
      "415500      1\n",
      "380687      1\n",
      "153372      1\n",
      "301591      1\n",
      "202516      1\n",
      "73493       1\n",
      "309932      1\n",
      "134935      1\n",
      "32537       1\n",
      "210688      1\n",
      "47314       1\n",
      "321274      1\n",
      "98475       1\n",
      "331511      1\n",
      "335605      1\n",
      "366324      1\n",
      "239346      1\n",
      "179953      1\n",
      "32186       1\n",
      "149230      1\n",
      "216160      1\n",
      "130793      1\n",
      "340614      1\n",
      "104164      1\n",
      "468706      1\n",
      "114401      1\n",
      "585203      1\n",
      "188189      1\n",
      "89821       1\n",
      "413648      1\n",
      "108890      1\n",
      "149457      1\n",
      "133352      1\n",
      "271901      1\n",
      "65353       1\n",
      "419658      1\n",
      "155469      1\n",
      "83742       1\n",
      "77651       1\n",
      "427862      1\n",
      "271354      1\n",
      "130905      1\n",
      "93886       1\n",
      "149342      1\n",
      "309056      1\n",
      "216461      1\n",
      "232036      1\n",
      "126779      1\n",
      "425785      1\n",
      "165686      1\n",
      "23324       1\n",
      "185616      1\n",
      "253741      1\n",
      "382764      1\n",
      "520033      1\n",
      "26410       1\n",
      "227203      1\n",
      "179781      1\n",
      "136996      1\n",
      "148443      1\n",
      "347935      1\n",
      "338283      1\n",
      "251612      1\n",
      "237141      1\n",
      "120460      1\n",
      "257659      1\n",
      "513660      1\n",
      "380543      1\n",
      "276096      1\n",
      "435842      1\n",
      "44675       1\n",
      "71788       1\n",
      "161444      1\n",
      "181902      1\n",
      "609935      1\n",
      "99369       1\n",
      "188488      1\n",
      "497300      1\n",
      "67222       1\n",
      "231725      1\n",
      "65145       1\n",
      "161400      1\n",
      "198262      1\n",
      "171637      1\n",
      "245361      1\n",
      "249983      1\n",
      "337469      1\n",
      "259688      1\n",
      "200295      1\n",
      "106085      1\n",
      "366180      1\n",
      "175715      1\n",
      "191648      1\n",
      "79691       1\n",
      "185948      1\n",
      "421467      1\n",
      "36503       1\n",
      "257691      1\n",
      "288840      1\n",
      "313038      1\n",
      "114045      1\n",
      "132806      1\n",
      "298695      1\n",
      "390856      1\n",
      "353994      1\n",
      "375499      1\n",
      "308944      1\n",
      "174020      1\n",
      "339667      1\n",
      "202452      1\n",
      "100054      1\n",
      "102103      1\n",
      "30424       1\n",
      "129188      1\n",
      "351576      1\n",
      "120478      1\n",
      "319165      1\n",
      "349884      1\n",
      "292536      1\n",
      "67001       1\n",
      "95799       1\n",
      "137974      1\n",
      "118447      1\n",
      "181934      1\n",
      "319149      1\n",
      "190122      1\n",
      "66095       1\n",
      "358056      1\n",
      "177824      1\n",
      "80625       1\n",
      "174327      1\n",
      "65991       1\n",
      "436861      1\n",
      "116367      1\n",
      "32008       1\n",
      "224506      1\n",
      "84399       1\n",
      "277760      1\n",
      "163002      1\n",
      "158199      1\n",
      "263431      1\n",
      "191754      1\n",
      "226717      1\n",
      "132626      1\n",
      "283917      1\n",
      "148751      1\n",
      "240914      1\n",
      "238867      1\n",
      "226585      1\n",
      "300908      1\n",
      "207352      1\n",
      "120173      1\n",
      "346871      1\n",
      "193152      1\n",
      "271571      1\n",
      "42279       1\n",
      "101590      1\n",
      "258430      1\n",
      "398662      1\n",
      "75073       1\n",
      "43408       1\n",
      "171236      1\n",
      "27882       1\n",
      "272778      1\n",
      "120045      1\n",
      "81136       1\n",
      "271603      1\n",
      "89587       1\n",
      "154908      1\n",
      "187332      1\n",
      "194065      1\n",
      "187724      1\n",
      "247119      1\n",
      "204116      1\n",
      "230743      1\n",
      "228696      1\n",
      "95577       1\n",
      "251229      1\n",
      "214303      1\n",
      "173411      1\n",
      "229110      1\n",
      "130408      1\n",
      "226665      1\n",
      "126314      1\n",
      "200445      1\n",
      "202053      1\n",
      "158077      1\n",
      "107843      1\n",
      "245056      1\n",
      "236612      1\n",
      "445758      1\n",
      "415037      1\n",
      "200479      1\n",
      "218085      1\n",
      "236985      1\n",
      "169269      1\n",
      "236852      1\n",
      "107827      1\n",
      "183598      1\n",
      "320811      1\n",
      "331046      1\n",
      "269604      1\n",
      "526734      1\n",
      "386864      1\n",
      "438996      1\n",
      "309196      1\n",
      "136277      1\n",
      "298070      1\n",
      "197719      1\n",
      "158810      1\n",
      "156763      1\n",
      "316509      1\n",
      "242768      1\n",
      "148607      1\n",
      "33895       1\n",
      "228456      1\n",
      "128105      1\n",
      "27255       1\n",
      "40052       1\n",
      "102559      1\n",
      "111697      1\n",
      "212048      1\n",
      "253866      1\n",
      "183374      1\n",
      "261192      1\n",
      "99399       1\n",
      "105540      1\n",
      "191806      1\n",
      "78913       1\n",
      "181311      1\n",
      "183358      1\n",
      "185405      1\n",
      "220220      1\n",
      "126010      1\n",
      "162872      1\n",
      "273285      1\n",
      "101430      1\n",
      "484475      1\n",
      "269444      1\n",
      "195784      1\n",
      "76978       1\n",
      "29865       1\n",
      "224426      1\n",
      "156843      1\n",
      "272359      1\n",
      "316589      1\n",
      "50351       1\n",
      "369843      1\n",
      "201861      1\n",
      "246595      1\n",
      "73019       1\n",
      "392886      1\n",
      "27834       1\n",
      "222395      1\n",
      "119929      1\n",
      "36006       1\n",
      "108505      1\n",
      "205987      1\n",
      "175266      1\n",
      "343200      1\n",
      "349341      1\n",
      "69285       1\n",
      "130200      1\n",
      "202989      1\n",
      "146576      1\n",
      "148623      1\n",
      "578701      1\n",
      "56460       1\n",
      "91275       1\n",
      "289930      1\n",
      "66695       1\n",
      "101510      1\n",
      "122220      1\n",
      "44402       1\n",
      "115161      1\n",
      "71221       1\n",
      "183315      1\n",
      "280111      1\n",
      "114224      1\n",
      "132327      1\n",
      "339506      1\n",
      "239155      1\n",
      "425528      1\n",
      "89644       1\n",
      "161337      1\n",
      "303121      1\n",
      "116287      1\n",
      "112761      1\n",
      "142914      1\n",
      "42563       1\n",
      "78307       1\n",
      "128553      1\n",
      "173427      1\n",
      "302612      1\n",
      "192010      1\n",
      "201689      1\n",
      "218637      1\n",
      "314894      1\n",
      "83471       1\n",
      "46609       1\n",
      "431637      1\n",
      "101926      1\n",
      "257562      1\n",
      "146551      1\n",
      "185885      1\n",
      "282142      1\n",
      "116255      1\n",
      "212512      1\n",
      "176986      1\n",
      "99911       1\n",
      "294907      1\n",
      "173224      1\n",
      "151150      1\n",
      "243313      1\n",
      "244572      1\n",
      "108147      1\n",
      "302708      1\n",
      "691830      1\n",
      "25684       1\n",
      "93770       1\n",
      "297551      1\n",
      "437890      1\n",
      "167558      1\n",
      "196232      1\n",
      "423561      1\n",
      "188044      1\n",
      "120429      1\n",
      "26721       1\n",
      "99844       1\n",
      "363053      1\n",
      "200042      1\n",
      "75363       1\n",
      "175714      1\n",
      "177761      1\n",
      "181855      1\n",
      "183902      1\n",
      "480861      1\n",
      "124507      1\n",
      "149419      1\n",
      "99897       1\n",
      "215596      1\n",
      "310864      1\n",
      "220748      1\n",
      "200198      1\n",
      "595461      1\n",
      "304643      1\n",
      "87469       1\n",
      "205884      1\n",
      "204196      1\n",
      "230823      1\n",
      "100154      1\n",
      "191914      1\n",
      "222635      1\n",
      "314798      1\n",
      "312767      1\n",
      "83375       1\n",
      "376240      1\n",
      "275889      1\n",
      "169397      1\n",
      "191930      1\n",
      "38537       1\n",
      "372130      1\n",
      "253296      1\n",
      "91547       1\n",
      "193945      1\n",
      "232854      1\n",
      "343440      1\n",
      "214415      1\n",
      "118158      1\n",
      "126346      1\n",
      "129786      1\n",
      "433989      1\n",
      "234885      1\n",
      "81280       1\n",
      "316797      1\n",
      "224634      1\n",
      "30073       1\n",
      "206250      1\n",
      "153021      1\n",
      "144833      1\n",
      "145119      1\n",
      "167414      1\n",
      "120301      1\n",
      "114160      1\n",
      "268358      1\n",
      "339442      1\n",
      "108019      1\n",
      "237044      1\n",
      "346321      1\n",
      "239043      1\n",
      "163320      1\n",
      "126614      1\n",
      "93690       1\n",
      "318972      1\n",
      "151038      1\n",
      "177665      1\n",
      "253420      1\n",
      "321313      1\n",
      "394727      1\n",
      "303187      1\n",
      "172906      1\n",
      "206307      1\n",
      "148959      1\n",
      "34066       1\n",
      "185821      1\n",
      "355802      1\n",
      "396758      1\n",
      "299908      1\n",
      "206291      1\n",
      "109482      1\n",
      "480717      1\n",
      "327112      1\n",
      "132551      1\n",
      "407913      1\n",
      "50223       1\n",
      "183342      1\n",
      "209569      1\n",
      "293528      1\n",
      "117791      1\n",
      "514716      1\n",
      "283293      1\n",
      "246431      1\n",
      "201991      1\n",
      "309350      1\n",
      "45713       1\n",
      "35494       1\n",
      "126125      1\n",
      "367049      1\n",
      "156400      1\n",
      "180911      1\n",
      "182863      1\n",
      "236180      1\n",
      "344719      1\n",
      "208117      1\n",
      "123515      1\n",
      "213615      1\n",
      "273010      1\n",
      "79864       1\n",
      "31352       1\n",
      "225913      1\n",
      "191098      1\n",
      "154236      1\n",
      "135520      1\n",
      "211584      1\n",
      "109186      1\n",
      "133766      1\n",
      "64148       1\n",
      "31368       1\n",
      "222637      1\n",
      "218889      1\n",
      "63704       1\n",
      "197303      1\n",
      "316141      1\n",
      "220430      1\n",
      "115305      1\n",
      "269028      1\n",
      "164583      1\n",
      "224520      1\n",
      "31924       1\n",
      "215790      1\n",
      "193775      1\n",
      "80158       1\n",
      "205555      1\n",
      "72436       1\n",
      "299765      1\n",
      "101110      1\n",
      "129784      1\n",
      "64216       1\n",
      "133846      1\n",
      "137940      1\n",
      "336595      1\n",
      "269045      1\n",
      "312015      1\n",
      "121548      1\n",
      "352971      1\n",
      "31432       1\n",
      "197319      1\n",
      "201413      1\n",
      "198986      1\n",
      "76482       1\n",
      "82623       1\n",
      "316093      1\n",
      "323054      1\n",
      "387770      1\n",
      "21101       1\n",
      "160303      1\n",
      "185567      1\n",
      "119309      1\n",
      "178688      1\n",
      "155094      1\n",
      "74243       1\n",
      "268804      1\n",
      "264710      1\n",
      "130926      1\n",
      "73037       1\n",
      "253370      1\n",
      "176657      1\n",
      "33729       1\n",
      "133654      1\n",
      "379885      1\n",
      "96792       1\n",
      "191002      1\n",
      "217597      1\n",
      "495061      1\n",
      "301556      1\n",
      "143857      1\n",
      "147951      1\n",
      "95552       1\n",
      "334308      1\n",
      "176609      1\n",
      "63577       1\n",
      "182750      1\n",
      "105943      1\n",
      "25051       1\n",
      "256474      1\n",
      "401886      1\n",
      "205267      1\n",
      "211408      1\n",
      "241802      1\n",
      "277024      1\n",
      "43554       1\n",
      "226196      1\n",
      "141350      1\n",
      "178556      1\n",
      "73679       1\n",
      "251073      1\n",
      "38360       1\n",
      "105044      1\n",
      "100950      1\n",
      "152157      1\n",
      "236068      1\n",
      "215646      1\n",
      "242804      1\n",
      "278514      1\n",
      "469602      1\n",
      "105060      1\n",
      "297574      1\n",
      "96840       1\n",
      "247151      1\n",
      "139843      1\n",
      "111169      1\n",
      "180799      1\n",
      "391122      1\n",
      "71676       1\n",
      "391736      1\n",
      "234037      1\n",
      "322385      1\n",
      "257940      1\n",
      "305714      1\n",
      "316246      1\n",
      "112561      1\n",
      "447066      1\n",
      "251323      1\n",
      "48976       1\n",
      "110844      1\n",
      "275438      1\n",
      "252668      1\n",
      "273362      1\n",
      "224202      1\n",
      "47298       1\n",
      "56613       1\n",
      "81243       1\n",
      "211920      1\n",
      "233717      1\n",
      "598995      1\n",
      "320102      1\n",
      "105428      1\n",
      "293398      1\n",
      "328663      1\n",
      "212206      1\n",
      "105188      1\n",
      "78817       1\n",
      "129102      1\n",
      "272185      1\n",
      "168901      1\n",
      "179136      1\n",
      "119741      1\n",
      "121788      1\n",
      "254907      1\n",
      "324947      1\n",
      "131461      1\n",
      "136310      1\n",
      "71800       1\n",
      "107443      1\n",
      "152156      1\n",
      "492263      1\n",
      "115631      1\n",
      "152493      1\n",
      "156587      1\n",
      "75804       1\n",
      "45114       1\n",
      "155261      1\n",
      "23580       1\n",
      "357283      1\n",
      "46097       1\n",
      "238611      1\n",
      "166934      1\n",
      "253408      1\n",
      "97304       1\n",
      "374454      1\n",
      "167716      1\n",
      "142370      1\n",
      "168997      1\n",
      "33831       1\n",
      "293928      1\n",
      "103148      1\n",
      "158762      1\n",
      "282069      1\n",
      "60426       1\n",
      "99335       1\n",
      "306178      1\n",
      "220230      1\n",
      "188307      1\n",
      "212918      1\n",
      "351228      1\n",
      "156667      1\n",
      "42696       1\n",
      "324601      1\n",
      "369386      1\n",
      "237272      1\n",
      "734193      1\n",
      "39110       1\n",
      "306889      1\n",
      "163772      1\n",
      "95455       1\n",
      "275361      1\n",
      "117502      1\n",
      "164210      1\n",
      "97064       1\n",
      "158506      1\n",
      "88876       1\n",
      "316205      1\n",
      "215854      1\n",
      "38822       1\n",
      "438839      1\n",
      "87653       1\n",
      "164663      1\n",
      "33350       1\n",
      "108909      1\n",
      "414525      1\n",
      "35021       1\n",
      "182423      1\n",
      "164647      1\n",
      "178843      1\n",
      "41763       1\n",
      "63564       1\n",
      "90907       1\n",
      "60186       1\n",
      "357145      1\n",
      "113211      1\n",
      "197399      1\n",
      "170772      1\n",
      "238355      1\n",
      "178960      1\n",
      "19214       1\n",
      "146440      1\n",
      "127753      1\n",
      "289458      1\n",
      "277248      1\n",
      "336707      1\n",
      "281422      1\n",
      "277408      1\n",
      "294029      1\n",
      "166774      1\n",
      "317539      1\n",
      "127865      1\n",
      "242968      1\n",
      "308077      1\n",
      "142210      1\n",
      "95113       1\n",
      "354408      1\n",
      "254859      1\n",
      "179088      1\n",
      "58426       1\n",
      "131991      1\n",
      "187292      1\n",
      "344991      1\n",
      "58985       1\n",
      "278151      1\n",
      "250733      1\n",
      "351084      1\n",
      "235700      1\n",
      "93034       1\n",
      "289572      1\n",
      "97128       1\n",
      "263015      1\n",
      "166758      1\n",
      "103358      1\n",
      "113504      1\n",
      "115551      1\n",
      "249249      1\n",
      "414791      1\n",
      "39764       1\n",
      "277328      1\n",
      "192453      1\n",
      "307149      1\n",
      "103161      1\n",
      "93319       1\n",
      "118798      1\n",
      "318593      1\n",
      "272896      1\n",
      "22313       1\n",
      "128132      1\n",
      "392325      1\n",
      "300168      1\n",
      "126071      1\n",
      "58913       1\n",
      "164231      1\n",
      "115858      1\n",
      "160916      1\n",
      "195733      1\n",
      "257175      1\n",
      "203897      1\n",
      "372728      1\n",
      "146653      1\n",
      "205235      1\n",
      "410450      1\n",
      "226388      1\n",
      "222294      1\n",
      "431192      1\n",
      "72793       1\n",
      "664670      1\n",
      "97614       1\n",
      "47415       1\n",
      "230356      1\n",
      "514033      1\n",
      "105577      1\n",
      "107630      1\n",
      "283760      1\n",
      "88904       1\n",
      "169112      1\n",
      "296090      1\n",
      "111772      1\n",
      "187601      1\n",
      "287797      1\n",
      "91334       1\n",
      "166855      1\n",
      "257874      1\n",
      "177499      1\n",
      "306383      1\n",
      "148690      1\n",
      "146589      1\n",
      "105460      1\n",
      "128212      1\n",
      "191703      1\n",
      "496856      1\n",
      "171225      1\n",
      "197850      1\n",
      "253121      1\n",
      "134331      1\n",
      "165050      1\n",
      "103608      1\n",
      "130040      1\n",
      "179262      1\n",
      "165737      1\n",
      "115890      1\n",
      "122033      1\n",
      "185520      1\n",
      "48301       1\n",
      "144556      1\n",
      "36011       1\n",
      "234664      1\n",
      "27815       1\n",
      "218435      1\n",
      "160932      1\n",
      "144460      1\n",
      "365640      1\n",
      "210488      1\n",
      "357348      1\n",
      "37848       1\n",
      "302041      1\n",
      "263130      1\n",
      "46044       1\n",
      "512992      1\n",
      "150499      1\n",
      "222182      1\n",
      "279538      1\n",
      "125927      1\n",
      "168936      1\n",
      "105449      1\n",
      "343021      1\n",
      "238574      1\n",
      "181772      1\n",
      "224215      1\n",
      "515025      1\n",
      "250832      1\n",
      "342989      1\n",
      "111296      1\n",
      "185660      1\n",
      "256967      1\n",
      "169719      1\n",
      "65291       1\n",
      "279490      1\n",
      "187329      1\n",
      "164964      1\n",
      "164682      1\n",
      "68539       1\n",
      "132026      1\n",
      "332008      1\n",
      "158647      1\n",
      "89073       1\n",
      "195573      1\n",
      "52291       1\n",
      "268840      1\n",
      "19491       1\n",
      "359461      1\n",
      "255014      1\n",
      "93223       1\n",
      "180181      1\n",
      "92374       1\n",
      "142383      1\n",
      "353270      1\n",
      "85043       1\n",
      "162869      1\n",
      "236601      1\n",
      "185408      1\n",
      "252993      1\n",
      "105728      1\n",
      "121889      1\n",
      "24723       1\n",
      "277533      1\n",
      "161235      1\n",
      "228373      1\n",
      "160279      1\n",
      "185360      1\n",
      "207887      1\n",
      "293399      1\n",
      "144396      1\n",
      "101387      1\n",
      "103432      1\n",
      "228357      1\n",
      "109567      1\n",
      "205822      1\n",
      "315728      1\n",
      "191479      1\n",
      "243674      1\n",
      "283872      1\n",
      "422836      1\n",
      "314819      1\n",
      "159159      1\n",
      "202168      1\n",
      "73145       1\n",
      "165306      1\n",
      "363963      1\n",
      "239038      1\n",
      "226756      1\n",
      "345522      1\n",
      "93639       1\n",
      "202184      1\n",
      "230858      1\n",
      "32550       1\n",
      "306639      1\n",
      "31360       1\n",
      "120066      1\n",
      "284080      1\n",
      "252939      1\n",
      "157078      1\n",
      "302473      1\n",
      "34186       1\n",
      "36235       1\n",
      "318865      1\n",
      "95636       1\n",
      "64643       1\n",
      "558490      1\n",
      "275884      1\n",
      "69019       1\n",
      "68219       1\n",
      "336163      1\n",
      "142751      1\n",
      "161386      1\n",
      "148884      1\n",
      "267736      1\n",
      "230874      1\n",
      "107998      1\n",
      "208415      1\n",
      "122385      1\n",
      "118291      1\n",
      "194068      1\n",
      "189974      1\n",
      "159255      1\n",
      "140830      1\n",
      "87584       1\n",
      "220641      1\n",
      "187937      1\n",
      "423460      1\n",
      "124454      1\n",
      "192039      1\n",
      "300584      1\n",
      "173888      1\n",
      "54800       1\n",
      "281363      1\n",
      "79372       1\n",
      "298507      1\n",
      "171564      1\n",
      "263150      1\n",
      "163333      1\n",
      "247298      1\n",
      "203313      1\n",
      "140798      1\n",
      "333119      1\n",
      "200187      1\n",
      "28151       1\n",
      "153072      1\n",
      "304622      1\n",
      "119570      1\n",
      "40425       1\n",
      "239171      1\n",
      "189830      1\n",
      "176037      1\n",
      "344743      1\n",
      "177420      1\n",
      "212237      1\n",
      "140558      1\n",
      "77071       1\n",
      "316688      1\n",
      "154897      1\n",
      "267205      1\n",
      "111916      1\n",
      "302579      1\n",
      "199963      1\n",
      "48413       1\n",
      "197389      1\n",
      "454614      1\n",
      "314659      1\n",
      "173266      1\n",
      "160674      1\n",
      "189702      1\n",
      "228613      1\n",
      "85251       1\n",
      "187649      1\n",
      "120064      1\n",
      "206667      1\n",
      "299616      1\n",
      "153414      1\n",
      "126199      1\n",
      "185143      1\n",
      "175343      1\n",
      "408813      1\n",
      "394474      1\n",
      "189670      1\n",
      "130277      1\n",
      "138537      1\n",
      "163582      1\n",
      "110445      1\n",
      "101739      1\n",
      "269657      1\n",
      "374108      1\n",
      "21856       1\n",
      "302711      1\n",
      "255334      1\n",
      "421223      1\n",
      "206190      1\n",
      "54576       1\n",
      "367292      1\n",
      "225263      1\n",
      "126327      1\n",
      "261519      1\n",
      "146813      1\n",
      "206206      1\n",
      "38232       1\n",
      "45546       1\n",
      "130389      1\n",
      "152657      1\n",
      "174695      1\n",
      "177484      1\n",
      "236873      1\n",
      "234824      1\n",
      "249948      1\n",
      "330901      1\n",
      "382272      1\n",
      "308540      1\n",
      "499001      1\n",
      "27959       1\n",
      "95540       1\n",
      "281907      1\n",
      "276559      1\n",
      "162741      1\n",
      "115634      1\n",
      "350162      1\n",
      "139822      1\n",
      "389850      1\n",
      "113120      1\n",
      "104235      1\n",
      "81030       1\n",
      "277256      1\n",
      "45612       1\n",
      "163293      1\n",
      "137753      1\n",
      "106498      1\n",
      "549430      1\n",
      "174202      1\n",
      "229946      1\n",
      "80445       1\n",
      "259120      1\n",
      "199725      1\n",
      "102936      1\n",
      "37440       1\n",
      "100875      1\n",
      "109055      1\n",
      "117251      1\n",
      "61956       1\n",
      "270968      1\n",
      "256529      1\n",
      "197130      1\n",
      "332931      1\n",
      "152889      1\n",
      "145933      1\n",
      "177599      1\n",
      "86067       1\n",
      "317969      1\n",
      "248339      1\n",
      "457237      1\n",
      "84547       1\n",
      "254534      1\n",
      "293623      1\n",
      "195189      1\n",
      "39529       1\n",
      "422933      1\n",
      "340588      1\n",
      "172654      1\n",
      "152176      1\n",
      "246386      1\n",
      "346668      1\n",
      "334409      1\n",
      "198277      1\n",
      "169249      1\n",
      "240255      1\n",
      "142764      1\n",
      "178792      1\n",
      "281860      1\n",
      "110747      1\n",
      "64101       1\n",
      "223594      1\n",
      "279156      1\n",
      "541282      1\n",
      "305759      1\n",
      "146013      1\n",
      "176732      1\n",
      "125527      1\n",
      "286989      1\n",
      "232082      1\n",
      "160340      1\n",
      "51795       1\n",
      "245521      1\n",
      "43599       1\n",
      "205390      1\n",
      "141264      1\n",
      "171818      1\n",
      "211453      1\n",
      "340476      1\n",
      "574005      1\n",
      "141727      1\n",
      "186785      1\n",
      "192932      1\n",
      "181242      1\n",
      "262570      1\n",
      "111020      1\n",
      "186573      1\n",
      "106942      1\n",
      "341846      1\n",
      "161637      1\n",
      "358837      1\n",
      "289207      1\n",
      "151153      1\n",
      "98746       1\n",
      "85482       1\n",
      "192916      1\n",
      "301408      1\n",
      "209292      1\n",
      "123270      1\n",
      "213378      1\n",
      "416129      1\n",
      "315776      1\n",
      "174463      1\n",
      "178976      1\n",
      "209276      1\n",
      "59767       1\n",
      "63861       1\n",
      "225652      1\n",
      "265105      1\n",
      "101602      1\n",
      "132683      1\n",
      "242108      1\n",
      "88513       1\n",
      "231931      1\n",
      "276973      1\n",
      "217568      1\n",
      "84451       1\n",
      "94692       1\n",
      "96741       1\n",
      "366898      1\n",
      "284531      1\n",
      "167615      1\n",
      "205051      1\n",
      "285169      1\n",
      "147954      1\n",
      "31221       1\n",
      "102904      1\n",
      "497253      1\n",
      "33274       1\n",
      "283918      1\n",
      "172510      1\n",
      "229772      1\n",
      "404951      1\n",
      "280433      1\n",
      "90582       1\n",
      "125437      1\n",
      "246226      1\n",
      "197883      1\n",
      "174543      1\n",
      "126797      1\n",
      "571853      1\n",
      "264651      1\n",
      "39369       1\n",
      "162245      1\n",
      "61892       1\n",
      "68089       1\n",
      "158343      1\n",
      "73684       1\n",
      "25319       1\n",
      "113501      1\n",
      "346963      1\n",
      "31573       1\n",
      "115497      1\n",
      "322391      1\n",
      "201560      1\n",
      "223789      1\n",
      "219737      1\n",
      "435022      1\n",
      "220001      1\n",
      "50018       1\n",
      "150371      1\n",
      "153005      1\n",
      "182013      1\n",
      "144236      1\n",
      "148306      1\n",
      "105289      1\n",
      "199307      1\n",
      "105273      1\n",
      "172846      1\n",
      "230563      1\n",
      "84787       1\n",
      "127796      1\n",
      "97077       1\n",
      "422960      1\n",
      "130812      1\n",
      "136610      1\n",
      "308028      1\n",
      "234657      1\n",
      "313255      1\n",
      "324420      1\n",
      "275074      1\n",
      "123718      1\n",
      "244589      1\n",
      "41838       1\n",
      "306031      1\n",
      "183203      1\n",
      "201624      1\n",
      "197530      1\n",
      "304030      1\n",
      "182570      1\n",
      "121761      1\n",
      "115618      1\n",
      "97189       1\n",
      "346189      1\n",
      "131650      1\n",
      "125863      1\n",
      "70568       1\n",
      "179117      1\n",
      "107438      1\n",
      "175023      1\n",
      "158615      1\n",
      "243960      1\n",
      "115602      1\n",
      "220049      1\n",
      "172942      1\n",
      "135458      1\n",
      "197514      1\n",
      "213726      1\n",
      "156550      1\n",
      "183171      1\n",
      "86912       1\n",
      "174975      1\n",
      "115603      1\n",
      "373628      1\n",
      "353142      1\n",
      "161198      1\n",
      "268553      1\n",
      "275244      1\n",
      "334633      1\n",
      "191271      1\n",
      "169624      1\n",
      "287244      1\n",
      "365020      1\n",
      "47022       1\n",
      "39609       1\n",
      "237478      1\n",
      "133819      1\n",
      "23233       1\n",
      "129311      1\n",
      "182979      1\n",
      "191175      1\n",
      "72393       1\n",
      "197322      1\n",
      "379046      1\n",
      "303822      1\n",
      "152240      1\n",
      "174767      1\n",
      "275116      1\n",
      "207392      1\n",
      "266489      1\n",
      "254630      1\n",
      "193188      1\n",
      "118365      1\n",
      "113309      1\n",
      "257269      1\n",
      "156310      1\n",
      "148626      1\n",
      "193172      1\n",
      "109199      1\n",
      "159960      1\n",
      "178829      1\n",
      "429346      1\n",
      "139660      1\n",
      "123606      1\n",
      "64293       1\n",
      "224644      1\n",
      "117507      1\n",
      "31493       1\n",
      "29276       1\n",
      "271118      1\n",
      "84755       1\n",
      "324372      1\n",
      "387270      1\n",
      "244933      1\n",
      "176924      1\n",
      "310045      1\n",
      "95530       1\n",
      "246562      1\n",
      "276540      1\n",
      "226084      1\n",
      "115458      1\n",
      "334585      1\n",
      "98882       1\n",
      "185072      1\n",
      "90646       1\n",
      "264939      1\n",
      "336215      1\n",
      "168680      1\n",
      "223975      1\n",
      "213389      1\n",
      "226020      1\n",
      "281315      1\n",
      "148194      1\n",
      "288519      1\n",
      "345898      1\n",
      "172766      1\n",
      "144092      1\n",
      "144940      1\n",
      "239150      1\n",
      "208431      1\n",
      "338270      1\n",
      "121168      1\n",
      "358740      1\n",
      "26966       1\n",
      "319831      1\n",
      "299353      1\n",
      "263855      1\n",
      "253752      1\n",
      "26950       1\n",
      "186720      1\n",
      "146651      1\n",
      "369909      1\n",
      "287079      1\n",
      "199018      1\n",
      "131435      1\n",
      "362826      1\n",
      "117058      1\n",
      "39352       1\n",
      "135465      1\n",
      "434463      1\n",
      "219424      1\n",
      "282913      1\n",
      "160037      1\n",
      "150171      1\n",
      "178489      1\n",
      "340269      1\n",
      "53569       1\n",
      "170299      1\n",
      "184625      1\n",
      "201017      1\n",
      "233149      1\n",
      "112956      1\n",
      "78141       1\n",
      "176493      1\n",
      "88432       1\n",
      "119153      1\n",
      "229803      1\n",
      "138069      1\n",
      "350624      1\n",
      "184737      1\n",
      "51618       1\n",
      "158118      1\n",
      "170408      1\n",
      "37109       1\n",
      "248178      1\n",
      "176557      1\n",
      "141742      1\n",
      "121264      1\n",
      "151985      1\n",
      "30656       1\n",
      "213427      1\n",
      "242077      1\n",
      "137444      1\n",
      "496025      1\n",
      "197240      1\n",
      "96660       1\n",
      "66297       1\n",
      "177457      1\n",
      "231818      1\n",
      "233865      1\n",
      "24967       1\n",
      "278915      1\n",
      "102442      1\n",
      "108926      1\n",
      "143741      1\n",
      "462255      1\n",
      "164219      1\n",
      "136363      1\n",
      "145692      1\n",
      "98587       1\n",
      "321880      1\n",
      "204991      1\n",
      "180142      1\n",
      "356772      1\n",
      "44489       1\n",
      "170529      1\n",
      "243900      1\n",
      "239806      1\n",
      "39943       1\n",
      "159979      1\n",
      "184513      1\n",
      "180419      1\n",
      "21792       1\n",
      "249271      1\n",
      "89760       1\n",
      "180837      1\n",
      "37894       1\n",
      "172700      1\n",
      "302372      1\n",
      "247986      1\n",
      "37720       1\n",
      "148599      1\n",
      "143533      1\n",
      "47276       1\n",
      "292504      1\n",
      "202920      1\n",
      "77132       1\n",
      "159909      1\n",
      "248886      1\n",
      "51362       1\n",
      "515797      1\n",
      "311124      1\n",
      "298445      1\n",
      "164043      1\n",
      "121040      1\n",
      "125206      1\n",
      "346754      1\n",
      "91044       1\n",
      "295163      1\n",
      "237078      1\n",
      "209149      1\n",
      "186624      1\n",
      "250249      1\n",
      "192773      1\n",
      "118993      1\n",
      "125190      1\n",
      "286983      1\n",
      "67136       1\n",
      "33035       1\n",
      "330263      1\n",
      "238628      1\n",
      "210424      1\n",
      "292511      1\n",
      "151793      1\n",
      "186534      1\n",
      "141550      1\n",
      "106723      1\n",
      "103632      1\n",
      "202984      1\n",
      "474617      1\n",
      "194788      1\n",
      "239753      1\n",
      "197397      1\n",
      "78045       1\n",
      "447079      1\n",
      "35034       1\n",
      "181342      1\n",
      "123095      1\n",
      "424012      1\n",
      "201145      1\n",
      "338290      1\n",
      "122489      1\n",
      "389765      1\n",
      "99141       1\n",
      "133770      1\n",
      "121488      1\n",
      "283281      1\n",
      "129684      1\n",
      "498328      1\n",
      "379522      1\n",
      "168601      1\n",
      "25468       1\n",
      "164507      1\n",
      "375452      1\n",
      "336543      1\n",
      "317479      1\n",
      "49795       1\n",
      "43646       1\n",
      "141758      1\n",
      "77370       1\n",
      "141918      1\n",
      "74335       1\n",
      "117346      1\n",
      "82531       1\n",
      "291429      1\n",
      "28186       1\n",
      "188325      1\n",
      "307837      1\n",
      "174702      1\n",
      "346635      1\n",
      "219760      1\n",
      "184945      1\n",
      "502316      1\n",
      "140035      1\n",
      "180899      1\n",
      "357029      1\n",
      "176813      1\n",
      "158438      1\n",
      "195284      1\n",
      "92886       1\n",
      "143110      1\n",
      "39640       1\n",
      "25610       1\n",
      "121568      1\n",
      "34297       1\n",
      "110476      1\n",
      "473836      1\n",
      "275181      1\n",
      "187981      1\n",
      "148211      1\n",
      "27382       1\n",
      "221943      1\n",
      "150226      1\n",
      "187088      1\n",
      "238287      1\n",
      "142030      1\n",
      "190067      1\n",
      "45474       1\n",
      "588484      1\n",
      "180931      1\n",
      "128493      1\n",
      "80572       1\n",
      "126446      1\n",
      "299705      1\n",
      "229987      1\n",
      "58039       1\n",
      "291509      1\n",
      "293971      1\n",
      "450246      1\n",
      "166517      1\n",
      "187584      1\n",
      "127573      1\n",
      "365049      1\n",
      "38245       1\n",
      "207342      1\n",
      "336367      1\n",
      "281074      1\n",
      "311795      1\n",
      "293364      1\n",
      "199512      1\n",
      "94741       1\n",
      "27142       1\n",
      "113760      1\n",
      "39432       1\n",
      "233993      1\n",
      "218415      1\n",
      "272910      1\n",
      "37353       1\n",
      "188903      1\n",
      "129508      1\n",
      "346594      1\n",
      "292217      1\n",
      "124563      1\n",
      "373213      1\n",
      "98779       1\n",
      "100563      1\n",
      "258517      1\n",
      "227796      1\n",
      "88528       1\n",
      "251730      1\n",
      "123335      1\n",
      "192965      1\n",
      "129476      1\n",
      "117186      1\n",
      "246291      1\n",
      "231962      1\n",
      "129620      1\n",
      "400132      1\n",
      "273828      1\n",
      "33339       1\n",
      "361875      1\n",
      "154176      1\n",
      "152129      1\n",
      "223861      1\n",
      "320071      1\n",
      "131611      1\n",
      "178764      1\n",
      "340557      1\n",
      "207438      1\n",
      "121424      1\n",
      "283217      1\n",
      "248402      1\n",
      "153663      1\n",
      "385591      1\n",
      "404023      1\n",
      "49715       1\n",
      "281138      1\n",
      "239947      1\n",
      "244268      1\n",
      "164395      1\n",
      "39464       1\n",
      "193553      1\n",
      "193061      1\n",
      "162340      1\n",
      "148003      1\n",
      "167552      1\n",
      "271262      1\n",
      "205343      1\n",
      "156612      1\n",
      "176285      1\n",
      "295067      1\n",
      "100506      1\n",
      "42750       1\n",
      "98037       1\n",
      "26358       1\n",
      "159479      1\n",
      "181661      1\n",
      "237305      1\n",
      "33442       1\n",
      "337046      1\n",
      "97142       1\n",
      "188161      1\n",
      "229125      1\n",
      "309230      1\n",
      "237321      1\n",
      "132874      1\n",
      "167691      1\n",
      "241025      1\n",
      "122609      1\n",
      "123031      1\n",
      "177064      1\n",
      "20179       1\n",
      "98005       1\n",
      "255702      1\n",
      "28375       1\n",
      "300760      1\n",
      "79580       1\n",
      "120544      1\n",
      "186096      1\n",
      "59287       1\n",
      "163557      1\n",
      "288486      1\n",
      "276009      1\n",
      "243436      1\n",
      "278253      1\n",
      "231562      1\n",
      "348148      1\n",
      "210541      1\n",
      "370494      1\n",
      "220977      1\n",
      "28471       1\n",
      "235320      1\n",
      "266043      1\n",
      "374588      1\n",
      "245565      1\n",
      "73394       1\n",
      "126743      1\n",
      "257863      1\n",
      "128092      1\n",
      "187352      1\n",
      "372559      1\n",
      "45599       1\n",
      "188241      1\n",
      "212781      1\n",
      "285671      1\n",
      "36651       1\n",
      "104232      1\n",
      "225063      1\n",
      "194087      1\n",
      "182388      1\n",
      "222835      1\n",
      "415520      1\n",
      "104613      1\n",
      "239390      1\n",
      "48925       1\n",
      "243484      1\n",
      "36635       1\n",
      "202056      1\n",
      "212588      1\n",
      "104216      1\n",
      "214738      1\n",
      "337494      1\n",
      "212685      1\n",
      "309504      1\n",
      "104024      1\n",
      "204377      1\n",
      "296538      1\n",
      "167515      1\n",
      "185952      1\n",
      "56929       1\n",
      "226916      1\n",
      "255693      1\n",
      "167531      1\n",
      "348172      1\n",
      "57889       1\n",
      "317040      1\n",
      "183923      1\n",
      "373366      1\n",
      "159319      1\n",
      "294485      1\n",
      "183891      1\n",
      "280146      1\n",
      "89681       1\n",
      "185936      1\n",
      "208463      1\n",
      "308812      1\n",
      "73289       1\n",
      "124486      1\n",
      "151107      1\n",
      "104756      1\n",
      "208447      1\n",
      "36411       1\n",
      "202296      1\n",
      "124470      1\n",
      "378418      1\n",
      "335481      1\n",
      "122497      1\n",
      "40856       1\n",
      "222442      1\n",
      "186032      1\n",
      "214706      1\n",
      "413363      1\n",
      "161460      1\n",
      "130741      1\n",
      "89667       1\n",
      "157614      1\n",
      "345730      1\n",
      "106169      1\n",
      "178931      1\n",
      "36539       1\n",
      "308924      1\n",
      "48829       1\n",
      "28359       1\n",
      "434097      1\n",
      "200363      1\n",
      "296618      1\n",
      "222381      1\n",
      "386726      1\n",
      "229029      1\n",
      "226980      1\n",
      "110239      1\n",
      "112284      1\n",
      "331419      1\n",
      "204441      1\n",
      "366232      1\n",
      "28311       1\n",
      "118419      1\n",
      "319121      1\n",
      "71367       1\n",
      "267912      1\n",
      "116562      1\n",
      "184147      1\n",
      "292692      1\n",
      "342121      1\n",
      "94245       1\n",
      "129912      1\n",
      "266281      1\n",
      "327723      1\n",
      "186416      1\n",
      "194612      1\n",
      "231482      1\n",
      "172111      1\n",
      "375114      1\n",
      "162391      1\n",
      "24647       1\n",
      "413760      1\n",
      "33688       1\n",
      "30126       1\n",
      "129060      1\n",
      "737315      1\n",
      "172063      1\n",
      "234665      1\n",
      "112668      1\n",
      "124950      1\n",
      "323605      1\n",
      "248588      1\n",
      "99829       1\n",
      "65547       1\n",
      "233182      1\n",
      "182274      1\n",
      "249857      1\n",
      "112780      1\n",
      "210940      1\n",
      "397307      1\n",
      "172025      1\n",
      "143437      1\n",
      "217169      1\n",
      "61431       1\n",
      "119890      1\n",
      "98427       1\n",
      "176253      1\n",
      "108670      1\n",
      "55424       1\n",
      "182402      1\n",
      "82051       1\n",
      "143517      1\n",
      "177783      1\n",
      "186324      1\n",
      "374924      1\n",
      "241805      1\n",
      "41103       1\n",
      "158834      1\n",
      "114835      1\n",
      "264314      1\n",
      "235431      1\n",
      "308242      1\n",
      "135601      1\n",
      "73839       1\n",
      "328239      1\n",
      "241844      1\n",
      "235624      1\n",
      "188519      1\n",
      "174147      1\n",
      "325732      1\n",
      "116834      1\n",
      "111332      1\n",
      "403550      1\n",
      "137304      1\n",
      "154978      1\n",
      "225365      1\n",
      "104440      1\n",
      "308237      1\n",
      "223062      1\n",
      "182162      1\n",
      "159623      1\n",
      "139145      1\n",
      "298891      1\n",
      "210828      1\n",
      "186256      1\n",
      "155537      1\n",
      "151443      1\n",
      "227236      1\n",
      "327573      1\n",
      "198554      1\n",
      "243612      1\n",
      "245661      1\n",
      "108446      1\n",
      "182178      1\n",
      "294789      1\n",
      "128900      1\n",
      "53123       1\n",
      "483201      1\n",
      "175999      1\n",
      "210812      1\n",
      "331643      1\n",
      "67450       1\n",
      "128884      1\n",
      "151411      1\n",
      "568490      1\n",
      "105478      1\n",
      "94055       1\n",
      "163685      1\n",
      "206686      1\n",
      "257343      1\n",
      "167771      1\n",
      "151459      1\n",
      "167851      1\n",
      "183043      1\n",
      "185537      1\n",
      "73689       1\n",
      "78356       1\n",
      "90245       1\n",
      "309212      1\n",
      "143327      1\n",
      "51170       1\n",
      "186819      1\n",
      "128162      1\n",
      "172009      1\n",
      "198634      1\n",
      "229895      1\n",
      "140569      1\n",
      "188401      1\n",
      "194548      1\n",
      "156292      1\n",
      "575442      1\n",
      "24529       1\n",
      "75726       1\n",
      "69579       1\n",
      "139209      1\n",
      "288132      1\n",
      "190406      1\n",
      "331611      1\n",
      "77759       1\n",
      "374716      1\n",
      "132130      1\n",
      "213844      1\n",
      "176893      1\n",
      "477106      1\n",
      "253873      1\n",
      "241583      1\n",
      "94652       1\n",
      "74539       1\n",
      "190823      1\n",
      "142076      1\n",
      "20296       1\n",
      "27380       1\n",
      "101689      1\n",
      "391926      1\n",
      "29431       1\n",
      "72442       1\n",
      "279297      1\n",
      "113390      1\n",
      "219906      1\n",
      "143732      1\n",
      "180079      1\n",
      "123653      1\n",
      "101128      1\n",
      "137994      1\n",
      "445168      1\n",
      "164585      1\n",
      "285522      1\n",
      "203833      1\n",
      "207564      1\n",
      "344855      1\n",
      "217379      1\n",
      "60116       1\n",
      "151991      1\n",
      "160029      1\n",
      "393945      1\n",
      "204692      1\n",
      "176863      1\n",
      "312157      1\n",
      "328051      1\n",
      "94401       1\n",
      "191204      1\n",
      "186451      1\n",
      "107277      1\n",
      "121618      1\n",
      "121425      1\n",
      "238397      1\n",
      "487330      1\n",
      "193335      1\n",
      "199480      1\n",
      "262024      1\n",
      "72506       1\n",
      "207676      1\n",
      "111423      1\n",
      "31510       1\n",
      "28008       1\n",
      "189253      1\n",
      "101192      1\n",
      "364563      1\n",
      "334666      1\n",
      "220912      1\n",
      "254773      1\n",
      "121650      1\n",
      "250170      1\n",
      "172845      1\n",
      "30118       1\n",
      "138026      1\n",
      "195343      1\n",
      "85154       1\n",
      "195366      1\n",
      "22055       1\n",
      "323009      1\n",
      "482082      1\n",
      "73928       1\n",
      "500509      1\n",
      "334618      1\n",
      "199448      1\n",
      "106758      1\n",
      "459465      1\n",
      "199368      1\n",
      "326342      1\n",
      "233275      1\n",
      "314422      1\n",
      "422813      1\n",
      "182896      1\n",
      "219762      1\n",
      "256628      1\n",
      "204494      1\n",
      "240252      1\n",
      "33417       1\n",
      "336509      1\n",
      "375422      1\n",
      "248448      1\n",
      "55938       1\n",
      "250499      1\n",
      "75065       1\n",
      "240236      1\n",
      "217892      1\n",
      "64102       1\n",
      "57957       1\n",
      "152163      1\n",
      "324019      1\n",
      "148065      1\n",
      "172637      1\n",
      "174684      1\n",
      "229977      1\n",
      "189013      1\n",
      "289364      1\n",
      "154194      1\n",
      "84560       1\n",
      "371089      1\n",
      "297544      1\n",
      "520775      1\n",
      "598606      1\n",
      "397963      1\n",
      "27332       1\n",
      "262841      1\n",
      "50700       1\n",
      "113326      1\n",
      "140206      1\n",
      "121195      1\n",
      "127671      1\n",
      "199352      1\n",
      "334522      1\n",
      "244366      1\n",
      "268451      1\n",
      "80574       1\n",
      "248512      1\n",
      "126223      1\n",
      "95725       1\n",
      "86723       1\n",
      "76460       1\n",
      "289390      1\n",
      "98985       1\n",
      "326310      1\n",
      "123557      1\n",
      "267408      1\n",
      "215712      1\n",
      "668319      1\n",
      "205469      1\n",
      "81929       1\n",
      "268954      1\n",
      "238216      1\n",
      "259643      1\n",
      "254613      1\n",
      "280440      1\n",
      "180881      1\n",
      "117392      1\n",
      "213841      1\n",
      "330470      1\n",
      "189589      1\n",
      "403519      1\n",
      "169003      1\n",
      "177199      1\n",
      "119859      1\n",
      "191540      1\n",
      "174032      1\n",
      "203834      1\n",
      "111679      1\n",
      "86010       1\n",
      "19520       1\n",
      "181313      1\n",
      "283715      1\n",
      "234970      1\n",
      "53434       1\n",
      "33865       1\n",
      "302122      1\n",
      "199720      1\n",
      "238381      1\n",
      "308239      1\n",
      "259299      1\n",
      "252930      1\n",
      "302438      1\n",
      "361481      1\n",
      "369677      1\n",
      "50058       1\n",
      "219599      1\n",
      "193575      1\n",
      "226327      1\n",
      "221215      1\n",
      "153841      1\n",
      "150560      1\n",
      "115745      1\n",
      "285730      1\n",
      "337039      1\n",
      "207948      1\n",
      "140365      1\n",
      "27780       1\n",
      "117872      1\n",
      "214129      1\n",
      "185459      1\n",
      "205949      1\n",
      "107548      1\n",
      "398652      1\n",
      "255109      1\n",
      "143851      1\n",
      "199816      1\n",
      "203914      1\n",
      "44172       1\n",
      "177295      1\n",
      "216208      1\n",
      "83089       1\n",
      "210031      1\n",
      "441454      1\n",
      "180497      1\n",
      "195686      1\n",
      "156773      1\n",
      "257124      1\n",
      "157272      1\n",
      "105059      1\n",
      "148577      1\n",
      "187248      1\n",
      "139753      1\n",
      "367706      1\n",
      "361561      1\n",
      "199768      1\n",
      "285408      1\n",
      "283731      1\n",
      "56402       1\n",
      "109564      1\n",
      "328697      1\n",
      "318450      1\n",
      "369549      1\n",
      "411587      1\n",
      "195462      1\n",
      "33673       1\n",
      "236426      1\n",
      "267147      1\n",
      "201617      1\n",
      "310158      1\n",
      "281504      1\n",
      "50065       1\n",
      "93076       1\n",
      "101272      1\n",
      "105370      1\n",
      "273308      1\n",
      "211870      1\n",
      "191364      1\n",
      "70209       1\n",
      "242559      1\n",
      "107389      1\n",
      "203642      1\n",
      "160631      1\n",
      "151463      1\n",
      "54131       1\n",
      "401998      1\n",
      "197481      1\n",
      "127894      1\n",
      "236330      1\n",
      "277342      1\n",
      "172893      1\n",
      "99161       1\n",
      "226135      1\n",
      "147227      1\n",
      "331609      1\n",
      "213921      1\n",
      "345073      1\n",
      "117728      1\n",
      "175052      1\n",
      "506830      1\n",
      "150480      1\n",
      "132057      1\n",
      "95946       1\n",
      "402397      1\n",
      "265230      1\n",
      "185251      1\n",
      "183784      1\n",
      "54243       1\n",
      "191460      1\n",
      "192257      1\n",
      "103403      1\n",
      "306156      1\n",
      "103371      1\n",
      "232392      1\n",
      "162758      1\n",
      "421967      1\n",
      "113598      1\n",
      "29623       1\n",
      "289716      1\n",
      "50164       1\n",
      "396595      1\n",
      "150011      1\n",
      "176810      1\n",
      "196627      1\n",
      "273324      1\n",
      "136107      1\n",
      "226215      1\n",
      "326566      1\n",
      "289700      1\n",
      "227910      1\n",
      "90693       1\n",
      "266624      1\n",
      "37019       1\n",
      "182416      1\n",
      "217235      1\n",
      "319637      1\n",
      "192663      1\n",
      "276309      1\n",
      "301210      1\n",
      "61559       1\n",
      "161926      1\n",
      "111445      1\n",
      "187508      1\n",
      "190628      1\n",
      "90277       1\n",
      "288959      1\n",
      "180401      1\n",
      "88725       1\n",
      "26756       1\n",
      "88642       1\n",
      "188877      1\n",
      "219815      1\n",
      "298995      1\n",
      "152696      1\n",
      "32604       1\n",
      "395368      1\n",
      "69739       1\n",
      "245873      1\n",
      "247936      1\n",
      "448626      1\n",
      "150958      1\n",
      "227446      1\n",
      "256274      1\n",
      "202874      1\n",
      "335997      1\n",
      "106740      1\n",
      "1366120     1\n",
      "336061      1\n",
      "116489      1\n",
      "121074      1\n",
      "304169      1\n",
      "118306      1\n",
      "395512      1\n",
      "108796      1\n",
      "47358       1\n",
      "84224       1\n",
      "215232      1\n",
      "233639      1\n",
      "184579      1\n",
      "402462      1\n",
      "146645      1\n",
      "262409      1\n",
      "168203      1\n",
      "276718      1\n",
      "106733      1\n",
      "50862       1\n",
      "284898      1\n",
      "180449      1\n",
      "51424       1\n",
      "307423      1\n",
      "34146       1\n",
      "287229      1\n",
      "151763      1\n",
      "205005      1\n",
      "168139      1\n",
      "262345      1\n",
      "192711      1\n",
      "177794      1\n",
      "190660      1\n",
      "194981      1\n",
      "198744      1\n",
      "63574       1\n",
      "211022      1\n",
      "153602      1\n",
      "188403      1\n",
      "323573      1\n",
      "70708       1\n",
      "12285       1\n",
      "79870       1\n",
      "184806      1\n",
      "45912       1\n",
      "22546       1\n",
      "137476      1\n",
      "96262       1\n",
      "94215       1\n",
      "198664      1\n",
      "276494      1\n",
      "110607      1\n",
      "88050       1\n",
      "577521      1\n",
      "50644       1\n",
      "119848      1\n",
      "198632      1\n",
      "163815      1\n",
      "194534      1\n",
      "192485      1\n",
      "71733       1\n",
      "186338      1\n",
      "178142      1\n",
      "166697      1\n",
      "42972       1\n",
      "187458      1\n",
      "67544       1\n",
      "229335      1\n",
      "124884      1\n",
      "147473      1\n",
      "192813      1\n",
      "1085515     1\n",
      "344129      1\n",
      "137953      1\n",
      "323639      1\n",
      "130731      1\n",
      "71738       1\n",
      "285885      1\n",
      "98265       1\n",
      "186434      1\n",
      "82815       1\n",
      "358465      1\n",
      "190532      1\n",
      "57413       1\n",
      "192583      1\n",
      "198728      1\n",
      "137290      1\n",
      "155701      1\n",
      "141570      1\n",
      "266792      1\n",
      "213041      1\n",
      "176175      1\n",
      "178222      1\n",
      "272428      1\n",
      "167979      1\n",
      "205396      1\n",
      "913447      1\n",
      "387108      1\n",
      "284706      1\n",
      "376979      1\n",
      "211361      1\n",
      "432154      1\n",
      "329752      1\n",
      "389143      1\n",
      "106765      1\n",
      "241935      1\n",
      "311569      1\n",
      "223716      1\n",
      "25045       1\n",
      "297796      1\n",
      "192983      1\n",
      "395736      1\n",
      "97837       1\n",
      "109020      1\n",
      "549349      1\n",
      "98809       1\n",
      "231912      1\n",
      "181014      1\n",
      "334314      1\n",
      "567788      1\n",
      "243493      1\n",
      "223732      1\n",
      "206063      1\n",
      "315859      1\n",
      "51664       1\n",
      "174540      1\n",
      "137674      1\n",
      "262601      1\n",
      "96710       1\n",
      "387116      1\n",
      "143807      1\n",
      "174524      1\n",
      "174844      1\n",
      "122195      1\n",
      "115630      1\n",
      "46691       1\n",
      "129100      1\n",
      "607799      1\n",
      "31873       1\n",
      "188917      1\n",
      "137722      1\n",
      "78255       1\n",
      "125492      1\n",
      "141868      1\n",
      "41517       1\n",
      "78383       1\n",
      "180714      1\n",
      "353195      1\n",
      "184883      1\n",
      "25141       1\n",
      "321031      1\n",
      "162358      1\n",
      "127543      1\n",
      "199224      1\n",
      "203322      1\n",
      "400061      1\n",
      "47678       1\n",
      "201259      1\n",
      "240543      1\n",
      "428584      1\n",
      "23074       1\n",
      "82465       1\n",
      "242207      1\n",
      "223447      1\n",
      "305692      1\n",
      "363032      1\n",
      "243858      1\n",
      "59924       1\n",
      "267952      1\n",
      "373263      1\n",
      "99736       1\n",
      "334346      1\n",
      "403625      1\n",
      "41793       1\n",
      "147889      1\n",
      "186991      1\n",
      "217363      1\n",
      "106761      1\n",
      "252210      1\n",
      "446771      1\n",
      "61751       1\n",
      "309566      1\n",
      "27162       1\n",
      "249385      1\n",
      "63814       1\n",
      "203098      1\n",
      "127303      1\n",
      "112974      1\n",
      "115025      1\n",
      "101885      1\n",
      "219426      1\n",
      "251841      1\n",
      "45766       1\n",
      "80174       1\n",
      "172333      1\n",
      "126832      1\n",
      "123901      1\n",
      "28967       1\n",
      "31014       1\n",
      "188709      1\n",
      "119075      1\n",
      "377121      1\n",
      "202117      1\n",
      "368925      1\n",
      "109928      1\n",
      "299291      1\n",
      "203034      1\n",
      "262425      1\n",
      "192791      1\n",
      "131417      1\n",
      "108892      1\n",
      "321327      1\n",
      "264600      1\n",
      "84954       1\n",
      "104842      1\n",
      "266635      1\n",
      "272780      1\n",
      "23698       1\n",
      "160151      1\n",
      "75821       1\n",
      "21472       1\n",
      "178749      1\n",
      "373935      1\n",
      "74141       1\n",
      "113054      1\n",
      "250354      1\n",
      "206927      1\n",
      "27012       1\n",
      "122540      1\n",
      "309630      1\n",
      "235951      1\n",
      "206721      1\n",
      "151023      1\n",
      "234277      1\n",
      "346480      1\n",
      "340335      1\n",
      "532845      1\n",
      "235882      1\n",
      "589809      1\n",
      "291175      1\n",
      "256356      1\n",
      "282979      1\n",
      "157568      1\n",
      "405855      1\n",
      "187538      1\n",
      "195734      1\n",
      "243921      1\n",
      "57298       1\n",
      "225106      1\n",
      "28612       1\n",
      "255941      1\n",
      "202699      1\n",
      "201177      1\n",
      "214993      1\n",
      "255957      1\n",
      "167033      1\n",
      "294870      1\n",
      "89326       1\n",
      "110556      1\n",
      "180190      1\n",
      "177102      1\n",
      "163814      1\n",
      "35683       1\n",
      "141245      1\n",
      "75839       1\n",
      "141229      1\n",
      "372636      1\n",
      "173981      1\n",
      "157605      1\n",
      "167848      1\n",
      "311696      1\n",
      "88676       1\n",
      "227160      1\n",
      "227298      1\n",
      "430554      1\n",
      "346033      1\n",
      "290740      1\n",
      "51255       1\n",
      "423863      1\n",
      "237498      1\n",
      "232918      1\n",
      "148576      1\n",
      "114670      1\n",
      "229418      1\n",
      "68624       1\n",
      "270366      1\n",
      "217120      1\n",
      "153633      1\n",
      "81954       1\n",
      "184493      1\n",
      "446512      1\n",
      "348144      1\n",
      "312108      1\n",
      "182323      1\n",
      "159796      1\n",
      "325971      1\n",
      "100079      1\n",
      "211005      1\n",
      "557082      1\n",
      "143175      1\n",
      "190487      1\n",
      "249332      1\n",
      "245302      1\n",
      "141327      1\n",
      "145220      1\n",
      "104457      1\n",
      "155654      1\n",
      "265662      1\n",
      "278530      1\n",
      "391679      1\n",
      "292855      1\n",
      "215095      1\n",
      "359808      1\n",
      "24562       1\n",
      "83953       1\n",
      "237466      1\n",
      "102686      1\n",
      "94100       1\n",
      "220978      1\n",
      "110380      1\n",
      "239405      1\n",
      "112731      1\n",
      "242097      1\n",
      "184112      1\n",
      "149297      1\n",
      "193122      1\n",
      "237386      1\n",
      "165350      1\n",
      "452405      1\n",
      "96055       1\n",
      "184128      1\n",
      "99076       1\n",
      "161607      1\n",
      "333611      1\n",
      "165673      1\n",
      "146929      1\n",
      "327462      1\n",
      "266037      1\n",
      "149281      1\n",
      "216864      1\n",
      "230754      1\n",
      "108317      1\n",
      "208668      1\n",
      "141308      1\n",
      "73498       1\n",
      "231193      1\n",
      "176389      1\n",
      "182504      1\n",
      "218899      1\n",
      "108301      1\n",
      "179171      1\n",
      "115605      1\n",
      "251795      1\n",
      "252413      1\n",
      "141165      1\n",
      "218995      1\n",
      "159604      1\n",
      "190325      1\n",
      "74977       1\n",
      "102264      1\n",
      "225156      1\n",
      "304973      1\n",
      "386949      1\n",
      "30599       1\n",
      "167816      1\n",
      "204682      1\n",
      "176012      1\n",
      "194828      1\n",
      "208748      1\n",
      "247469      1\n",
      "233320      1\n",
      "128871      1\n",
      "221026      1\n",
      "29980       1\n",
      "180062      1\n",
      "132055      1\n",
      "175964      1\n",
      "139098      1\n",
      "266072      1\n",
      "317313      1\n",
      "190293      1\n",
      "257876      1\n",
      "51025       1\n",
      "145231      1\n",
      "167581      1\n",
      "204862      1\n",
      "151616      1\n",
      "33945       1\n",
      "207103      1\n",
      "279679      1\n",
      "293691      1\n",
      "362747      1\n",
      "428405      1\n",
      "178429      1\n",
      "434430      1\n",
      "348416      1\n",
      "137875      1\n",
      "180007      1\n",
      "200968      1\n",
      "112291      1\n",
      "428299      1\n",
      "172891      1\n",
      "483530      1\n",
      "369463      1\n",
      "409842      1\n",
      "284737      1\n",
      "132393      1\n",
      "84179       1\n",
      "155862      1\n",
      "288983      1\n",
      "89787       1\n",
      "166107      1\n",
      "156822      1\n",
      "290213      1\n",
      "317681      1\n",
      "192740      1\n",
      "201595      1\n",
      "33002       1\n",
      "100587      1\n",
      "145098      1\n",
      "174319      1\n",
      "258550      1\n",
      "358677      1\n",
      "254230      1\n",
      "228287      1\n",
      "282944      1\n",
      "317761      1\n",
      "345339      1\n",
      "235849      1\n",
      "304857      1\n",
      "152968      1\n",
      "185397      1\n",
      "296212      1\n",
      "33114       1\n",
      "166235      1\n",
      "78172       1\n",
      "211293      1\n",
      "76127       1\n",
      "217971      1\n",
      "218962      1\n",
      "209212      1\n",
      "452406      1\n",
      "301369      1\n",
      "135480      1\n",
      "149811      1\n",
      "219441      1\n",
      "198286      1\n",
      "209448      1\n",
      "362795      1\n",
      "90406       1\n",
      "121238      1\n",
      "82210       1\n",
      "272671      1\n",
      "558183      1\n",
      "214061      1\n",
      "104729      1\n",
      "225231      1\n",
      "80077       1\n",
      "307404      1\n",
      "163946      1\n",
      "178013      1\n",
      "219233      1\n",
      "89346       1\n",
      "391171      1\n",
      "200808      1\n",
      "189574      1\n",
      "154117      1\n",
      "128617      1\n",
      "182387      1\n",
      "225603      1\n",
      "24694       1\n",
      "162856      1\n",
      "36984       1\n",
      "128392      1\n",
      "298885      1\n",
      "110684      1\n",
      "231515      1\n",
      "229466      1\n",
      "399449      1\n",
      "223319      1\n",
      "192596      1\n",
      "182355      1\n",
      "245842      1\n",
      "370767      1\n",
      "112929      1\n",
      "110668      1\n",
      "299080      1\n",
      "296085      1\n",
      "292933      1\n",
      "198425      1\n",
      "114754      1\n",
      "229498      1\n",
      "335998      1\n",
      "405526      1\n",
      "107814      1\n",
      "106670      1\n",
      "322013      1\n",
      "182451      1\n",
      "285902      1\n",
      "266681      1\n",
      "32954       1\n",
      "78012       1\n",
      "131258      1\n",
      "204990      1\n",
      "517036      1\n",
      "182467      1\n",
      "280525      1\n",
      "63685       1\n",
      "747719      1\n",
      "104617      1\n",
      "250819      1\n",
      "96421       1\n",
      "346275      1\n",
      "213154      1\n",
      "32922       1\n",
      "210526      1\n",
      "129173      1\n",
      "290964      1\n",
      "226357      1\n",
      "127709      1\n",
      "108687      1\n",
      "156117      1\n",
      "166027      1\n",
      "393354      1\n",
      "358533      1\n",
      "51331       1\n",
      "307315      1\n",
      "257796      1\n",
      "157942      1\n",
      "105479      1\n",
      "334593      1\n",
      "425447      1\n",
      "276249      1\n",
      "355700      1\n",
      "341548      1\n",
      "101752      1\n",
      "370045      1\n",
      "155238      1\n",
      "277886      1\n",
      "445824      1\n",
      "179955      1\n",
      "187778      1\n",
      "617860      1\n",
      "91525       1\n",
      "265576      1\n",
      "187746      1\n",
      "122626      1\n",
      "212302      1\n",
      "20323       1\n",
      "35557       1\n",
      "193863      1\n",
      "171338      1\n",
      "341117      1\n",
      "44364       1\n",
      "187730      1\n",
      "81259       1\n",
      "257364      1\n",
      "359766      1\n",
      "30039       1\n",
      "165209      1\n",
      "300379      1\n",
      "212318      1\n",
      "259463      1\n",
      "232840      1\n",
      "202508      1\n",
      "228806      1\n",
      "175548      1\n",
      "179646      1\n",
      "341439      1\n",
      "85440       1\n",
      "149775      1\n",
      "286146      1\n",
      "200136      1\n",
      "114062      1\n",
      "148769      1\n",
      "312785      1\n",
      "122322      1\n",
      "87507       1\n",
      "615893      1\n",
      "32214       1\n",
      "34233       1\n",
      "226978      1\n",
      "290641      1\n",
      "291965      1\n",
      "315974      1\n",
      "109996      1\n",
      "103851      1\n",
      "165289      1\n",
      "323020      1\n",
      "93604       1\n",
      "112031      1\n",
      "48542       1\n",
      "71067       1\n",
      "259479      1\n",
      "220562      1\n",
      "130078      1\n",
      "177906      1\n",
      "183616      1\n",
      "236858      1\n",
      "392502      1\n",
      "111306      1\n",
      "165065      1\n",
      "236746      1\n",
      "431307      1\n",
      "273612      1\n",
      "236940      1\n",
      "50385       1\n",
      "31983       1\n",
      "234731      1\n",
      "386261      1\n",
      "261334      1\n",
      "232664      1\n",
      "66777       1\n",
      "314592      1\n",
      "58597       1\n",
      "249208      1\n",
      "377322      1\n",
      "148673      1\n",
      "91999       1\n",
      "140477      1\n",
      "103164      1\n",
      "199864      1\n",
      "126132      1\n",
      "200892      1\n",
      "187570      1\n",
      "148657      1\n",
      "99138       1\n",
      "200419      1\n",
      "267352      1\n",
      "101549      1\n",
      "179358      1\n",
      "339100      1\n",
      "197865      1\n",
      "127875      1\n",
      "152883      1\n",
      "410913      1\n",
      "202011      1\n",
      "208899      1\n",
      "69311       1\n",
      "339163      1\n",
      "505119      1\n",
      "445728      1\n",
      "64980       1\n",
      "266189      1\n",
      "161063      1\n",
      "274746      1\n",
      "314092      1\n",
      "171306      1\n",
      "442429      1\n",
      "286002      1\n",
      "101656      1\n",
      "236994      1\n",
      "210364      1\n",
      "187666      1\n",
      "91488       1\n",
      "68872       1\n",
      "353541      1\n",
      "120067      1\n",
      "154882      1\n",
      "177407      1\n",
      "117167      1\n",
      "361721      1\n",
      "212665      1\n",
      "279593      1\n",
      "216093      1\n",
      "114043      1\n",
      "249072      1\n",
      "130931      1\n",
      "263641      1\n",
      "271837      1\n",
      "163494      1\n",
      "77689       1\n",
      "116385      1\n",
      "286370      1\n",
      "54947       1\n",
      "207385      1\n",
      "104193      1\n",
      "200360      1\n",
      "282304      1\n",
      "177839      1\n",
      "155314      1\n",
      "271243      1\n",
      "321205      1\n",
      "196278      1\n",
      "67257       1\n",
      "140957      1\n",
      "203735      1\n",
      "126154      1\n",
      "24872       1\n",
      "22831       1\n",
      "372692      1\n",
      "165513      1\n",
      "259719      1\n",
      "523910      1\n",
      "120451      1\n",
      "405083      1\n",
      "263729      1\n",
      "177791      1\n",
      "204410      1\n",
      "111545      1\n",
      "194167      1\n",
      "311913      1\n",
      "197148      1\n",
      "181953      1\n",
      "177775      1\n",
      "188146      1\n",
      "149217      1\n",
      "257764      1\n",
      "292583      1\n",
      "312427      1\n",
      "136939      1\n",
      "50929       1\n",
      "126708      1\n",
      "224964      1\n",
      "354037      1\n",
      "130806      1\n",
      "302626      1\n",
      "153238      1\n",
      "235259      1\n",
      "48894       1\n",
      "43313       1\n",
      "112351      1\n",
      "337629      1\n",
      "138970      1\n",
      "175594      1\n",
      "39223       1\n",
      "186067      1\n",
      "278637      1\n",
      "151248      1\n",
      "538319      1\n",
      "77516       1\n",
      "750972      1\n",
      "171722      1\n",
      "409622      1\n",
      "298696      1\n",
      "229062      1\n",
      "255685      1\n",
      "220786      1\n",
      "110188      1\n",
      "341471      1\n",
      "180407      1\n",
      "240150      1\n",
      "144911      1\n",
      "91901       1\n",
      "220690      1\n",
      "198616      1\n",
      "210869      1\n",
      "334676      1\n",
      "382499      1\n",
      "36376       1\n",
      "466458      1\n",
      "71195       1\n",
      "160467      1\n",
      "206365      1\n",
      "168768      1\n",
      "236487      1\n",
      "194055      1\n",
      "206775      1\n",
      "185859      1\n",
      "65704       1\n",
      "103931      1\n",
      "392694      1\n",
      "168943      1\n",
      "24050       1\n",
      "196501      1\n",
      "142828      1\n",
      "398827      1\n",
      "158813      1\n",
      "130534      1\n",
      "323044      1\n",
      "87523       1\n",
      "83425       1\n",
      "216608      1\n",
      "421412      1\n",
      "462440      1\n",
      "177929      1\n",
      "599629      1\n",
      "48718       1\n",
      "118352      1\n",
      "239415      1\n",
      "288341      1\n",
      "34393       1\n",
      "110172      1\n",
      "188982      1\n",
      "67794       1\n",
      "343646      1\n",
      "210527      1\n",
      "269246      1\n",
      "349795      1\n",
      "63079       1\n",
      "142924      1\n",
      "1268339     1\n",
      "542265      1\n",
      "222789      1\n",
      "54851       1\n",
      "312897      1\n",
      "58447       1\n",
      "48702       1\n",
      "378045      1\n",
      "34361       1\n",
      "357943      1\n",
      "65078       1\n",
      "68318       1\n",
      "284211      1\n",
      "312881      1\n",
      "177711      1\n",
      "179758      1\n",
      "229376      1\n",
      "Name: fnlwgt, dtype: int64\n",
      "education\n",
      "HS-grad         10501\n",
      "Some-college     7291\n",
      "Bachelors        5355\n",
      "Masters          1723\n",
      "Assoc-voc        1382\n",
      "11th             1175\n",
      "Assoc-acdm       1067\n",
      "10th              933\n",
      "7th-8th           646\n",
      "Prof-school       576\n",
      "9th               514\n",
      "12th              433\n",
      "Doctorate         413\n",
      "5th-6th           333\n",
      "1st-4th           168\n",
      "Preschool          51\n",
      "Name: education, dtype: int64\n",
      "education_num\n",
      "9     10501\n",
      "10     7291\n",
      "13     5355\n",
      "14     1723\n",
      "11     1382\n",
      "7      1175\n",
      "12     1067\n",
      "6       933\n",
      "4       646\n",
      "15      576\n",
      "5       514\n",
      "8       433\n",
      "16      413\n",
      "3       333\n",
      "2       168\n",
      "1        51\n",
      "Name: education_num, dtype: int64\n",
      "marital_status\n",
      "Married-civ-spouse       14976\n",
      "Never-married            10683\n",
      "Divorced                  4443\n",
      "Separated                 1025\n",
      "Widowed                    993\n",
      "Married-spouse-absent      418\n",
      "Married-AF-spouse           23\n",
      "Name: marital_status, dtype: int64\n",
      "occupation\n",
      "Prof-specialty       4140\n",
      "Craft-repair         4099\n",
      "Exec-managerial      4066\n",
      "Adm-clerical         3770\n",
      "Sales                3650\n",
      "Other-service        3295\n",
      "Machine-op-inspct    2002\n",
      "?                    1843\n",
      "Transport-moving     1597\n",
      "Handlers-cleaners    1370\n",
      "Farming-fishing       994\n",
      "Tech-support          928\n",
      "Protective-serv       649\n",
      "Priv-house-serv       149\n",
      "Armed-Forces            9\n",
      "Name: occupation, dtype: int64\n",
      "relationship\n",
      "Husband           13193\n",
      "Not-in-family      8305\n",
      "Own-child          5068\n",
      "Unmarried          3446\n",
      "Wife               1568\n",
      "Other-relative      981\n",
      "Name: relationship, dtype: int64\n",
      "race\n",
      "White                 27816\n",
      "Black                  3124\n",
      "Asian-Pac-Islander     1039\n",
      "Amer-Indian-Eskimo      311\n",
      "Other                   271\n",
      "Name: race, dtype: int64\n",
      "sex\n",
      "Male      21790\n",
      "Female    10771\n",
      "Name: sex, dtype: int64\n",
      "capital_gain\n",
      "0        29849\n",
      "15024      347\n",
      "7688       284\n",
      "7298       246\n",
      "99999      159\n",
      "5178        97\n",
      "3103        97\n",
      "4386        70\n",
      "5013        69\n",
      "8614        55\n",
      "3325        53\n",
      "2174        48\n",
      "10520       43\n",
      "4064        42\n",
      "4650        41\n",
      "14084       41\n",
      "20051       37\n",
      "3137        37\n",
      "27828       34\n",
      "594         34\n",
      "3908        32\n",
      "2829        31\n",
      "13550       27\n",
      "6849        27\n",
      "14344       26\n",
      "1055        25\n",
      "2885        24\n",
      "3411        24\n",
      "4787        23\n",
      "2176        23\n",
      "3464        23\n",
      "9386        22\n",
      "2597        20\n",
      "4101        20\n",
      "2407        19\n",
      "4865        17\n",
      "2202        16\n",
      "1506        15\n",
      "3942        14\n",
      "3674        14\n",
      "4508        12\n",
      "4416        12\n",
      "3781        12\n",
      "2580        12\n",
      "10605       12\n",
      "2907        11\n",
      "25236       11\n",
      "5455        11\n",
      "6497        11\n",
      "2354        11\n",
      "2635        11\n",
      "2463        11\n",
      "2964         9\n",
      "2105         9\n",
      "6418         9\n",
      "7430         9\n",
      "2414         8\n",
      "914          8\n",
      "2977         8\n",
      "1151         8\n",
      "3471         8\n",
      "4934         7\n",
      "1471         7\n",
      "1831         7\n",
      "1797         7\n",
      "3818         7\n",
      "1409         7\n",
      "114          6\n",
      "10566        6\n",
      "1848         6\n",
      "2346         6\n",
      "15831        6\n",
      "3887         6\n",
      "2329         6\n",
      "3273         6\n",
      "2050         5\n",
      "2290         5\n",
      "7443         5\n",
      "2653         5\n",
      "6767         5\n",
      "15020        5\n",
      "2228         5\n",
      "3418         5\n",
      "34095        5\n",
      "6514         5\n",
      "991          5\n",
      "5556         5\n",
      "2036         4\n",
      "3432         4\n",
      "9562         4\n",
      "1086         4\n",
      "25124        4\n",
      "1424         3\n",
      "2961         3\n",
      "7896         3\n",
      "4687         3\n",
      "2936         3\n",
      "1173         3\n",
      "5721         3\n",
      "2009         3\n",
      "6360         3\n",
      "41310        2\n",
      "6723         2\n",
      "3456         2\n",
      "2993         2\n",
      "401          2\n",
      "11678        2\n",
      "2062         2\n",
      "18481        2\n",
      "7978         1\n",
      "1639         1\n",
      "2538         1\n",
      "2387         1\n",
      "5060         1\n",
      "4931         1\n",
      "1455         1\n",
      "6097         1\n",
      "22040        1\n",
      "1111         1\n",
      "Name: capital_gain, dtype: int64\n",
      "capital_loss\n",
      "0       31042\n",
      "1902      202\n",
      "1977      168\n",
      "1887      159\n",
      "1848       51\n",
      "1485       51\n",
      "2415       49\n",
      "1602       47\n",
      "1740       42\n",
      "1590       40\n",
      "1876       39\n",
      "1672       34\n",
      "1564       25\n",
      "2258       25\n",
      "1669       24\n",
      "1741       24\n",
      "2001       24\n",
      "1980       23\n",
      "1719       22\n",
      "2002       21\n",
      "2051       21\n",
      "1408       21\n",
      "1579       20\n",
      "2377       20\n",
      "1721       18\n",
      "1504       18\n",
      "1974       18\n",
      "2339       17\n",
      "2179       15\n",
      "1628       15\n",
      "1762       14\n",
      "2444       12\n",
      "2559       12\n",
      "625        12\n",
      "2824       10\n",
      "2042        9\n",
      "1617        9\n",
      "2205        9\n",
      "1651        9\n",
      "2392        9\n",
      "1594        8\n",
      "1340        7\n",
      "1380        7\n",
      "1092        7\n",
      "2174        7\n",
      "1573        6\n",
      "880         6\n",
      "2246        6\n",
      "2057        6\n",
      "2206        6\n",
      "2603        5\n",
      "1668        4\n",
      "1825        4\n",
      "1258        4\n",
      "2547        4\n",
      "1726        4\n",
      "213         4\n",
      "2457        3\n",
      "2129        3\n",
      "653         3\n",
      "2231        3\n",
      "419         3\n",
      "323         3\n",
      "4356        3\n",
      "2267        3\n",
      "3683        2\n",
      "1755        2\n",
      "2352        2\n",
      "1648        2\n",
      "1138        2\n",
      "810         2\n",
      "1735        2\n",
      "2238        2\n",
      "2754        2\n",
      "3004        2\n",
      "3900        2\n",
      "974         2\n",
      "2149        2\n",
      "1816        2\n",
      "3770        2\n",
      "2080        1\n",
      "2489        1\n",
      "2282        1\n",
      "2163        1\n",
      "155         1\n",
      "2467        1\n",
      "1844        1\n",
      "1411        1\n",
      "1539        1\n",
      "2472        1\n",
      "1944        1\n",
      "2201        1\n",
      "Name: capital_loss, dtype: int64\n",
      "hours_per_week\n",
      "40    15217\n",
      "50     2819\n",
      "45     1824\n",
      "60     1475\n",
      "35     1297\n",
      "20     1224\n",
      "30     1149\n",
      "55      694\n",
      "25      674\n",
      "48      517\n",
      "38      476\n",
      "15      404\n",
      "70      291\n",
      "10      278\n",
      "32      266\n",
      "24      252\n",
      "65      244\n",
      "36      220\n",
      "42      219\n",
      "44      212\n",
      "16      205\n",
      "12      173\n",
      "43      151\n",
      "37      149\n",
      "8       145\n",
      "52      138\n",
      "80      133\n",
      "56       97\n",
      "28       86\n",
      "99       85\n",
      "46       82\n",
      "18       75\n",
      "72       71\n",
      "75       66\n",
      "6        64\n",
      "5        60\n",
      "4        54\n",
      "47       49\n",
      "84       45\n",
      "22       44\n",
      "54       41\n",
      "3        39\n",
      "33       39\n",
      "39       38\n",
      "41       36\n",
      "14       34\n",
      "2        32\n",
      "27       30\n",
      "26       30\n",
      "17       29\n",
      "49       29\n",
      "90       29\n",
      "58       28\n",
      "34       28\n",
      "7        26\n",
      "53       25\n",
      "21       24\n",
      "13       23\n",
      "23       21\n",
      "1        20\n",
      "62       18\n",
      "9        18\n",
      "66       17\n",
      "57       17\n",
      "19       14\n",
      "64       14\n",
      "51       13\n",
      "85       13\n",
      "68       12\n",
      "98       11\n",
      "11       11\n",
      "63       10\n",
      "78        8\n",
      "29        7\n",
      "77        6\n",
      "59        5\n",
      "31        5\n",
      "96        5\n",
      "67        4\n",
      "91        3\n",
      "76        3\n",
      "81        3\n",
      "73        2\n",
      "89        2\n",
      "97        2\n",
      "88        2\n",
      "86        2\n",
      "61        2\n",
      "95        2\n",
      "92        1\n",
      "94        1\n",
      "87        1\n",
      "74        1\n",
      "82        1\n",
      "Name: hours_per_week, dtype: int64\n",
      "native_country\n",
      "United-States                 29170\n",
      "Mexico                          643\n",
      "?                               583\n",
      "Philippines                     198\n",
      "Germany                         137\n",
      "Canada                          121\n",
      "Puerto-Rico                     114\n",
      "El-Salvador                     106\n",
      "India                           100\n",
      "Cuba                             95\n",
      "England                          90\n",
      "Jamaica                          81\n",
      "South                            80\n",
      "China                            75\n",
      "Italy                            73\n",
      "Dominican-Republic               70\n",
      "Vietnam                          67\n",
      "Guatemala                        64\n",
      "Japan                            62\n",
      "Poland                           60\n",
      "Columbia                         59\n",
      "Taiwan                           51\n",
      "Haiti                            44\n",
      "Iran                             43\n",
      "Portugal                         37\n",
      "Nicaragua                        34\n",
      "Peru                             31\n",
      "France                           29\n",
      "Greece                           29\n",
      "Ecuador                          28\n",
      "Ireland                          24\n",
      "Hong                             20\n",
      "Trinadad&Tobago                  19\n",
      "Cambodia                         19\n",
      "Laos                             18\n",
      "Thailand                         18\n",
      "Yugoslavia                       16\n",
      "Outlying-US(Guam-USVI-etc)       14\n",
      "Hungary                          13\n",
      "Honduras                         13\n",
      "Scotland                         12\n",
      "Holand-Netherlands                1\n",
      "Name: native_country, dtype: int64\n",
      "target\n",
      "<=50K    24720\n",
      ">50K      7841\n",
      "Name: target, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df:\n",
    "    print(col)\n",
    "    Printthis(df[col].value_counts() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_class\n",
      "Private             22696\n",
      "Self-emp-not-inc     2541\n",
      "Local-gov            2093\n",
      "?                    1836\n",
      "State-gov            1298\n",
      "Self-emp-inc         1116\n",
      "Federal-gov           960\n",
      "Without-pay            14\n",
      "Never-worked            7\n",
      "Name: work_class, dtype: int64\n",
      "occupation\n",
      "Prof-specialty       4140\n",
      "Craft-repair         4099\n",
      "Exec-managerial      4066\n",
      "Adm-clerical         3770\n",
      "Sales                3650\n",
      "Other-service        3295\n",
      "Machine-op-inspct    2002\n",
      "?                    1843\n",
      "Transport-moving     1597\n",
      "Handlers-cleaners    1370\n",
      "Farming-fishing       994\n",
      "Tech-support          928\n",
      "Protective-serv       649\n",
      "Priv-house-serv       149\n",
      "Armed-Forces            9\n",
      "Name: occupation, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in df[['work_class','occupation']]:\n",
    "    print(col)\n",
    "    Printthis(df[col].value_counts() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.073462117256841"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[(df['work_class']=='?') | (df['native_country']=='?')])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age        work_class  fnlwgt     education  education_num  \\\n",
      "30707   27                 ?  146651       HS-grad              9   \n",
      "24714   18                 ?  172214       HS-grad              9   \n",
      "20658   36           Private  218948           9th              5   \n",
      "15036   55           Private  158702  Some-college             10   \n",
      "21487   48                 ?  355890     Bachelors             13   \n",
      "24813   73                 ?  135601     Bachelors             13   \n",
      "22230   44           Private  228729       HS-grad              9   \n",
      "5526    20                 ?  201680  Some-college             10   \n",
      "3990    77                 ?  147284       HS-grad              9   \n",
      "20963   24                 ?  154373       HS-grad              9   \n",
      "13302   27                 ?  175552       5th-6th              3   \n",
      "27513   46                 ?  228620          11th              7   \n",
      "5823    38  Self-emp-not-inc  414991       HS-grad              9   \n",
      "28937   46           Private  268022       Masters             14   \n",
      "23565   30       Federal-gov   54684   Prof-school             15   \n",
      "30334   20                 ?  162667          11th              7   \n",
      "8042    22                 ?  219233       HS-grad              9   \n",
      "25044   18                 ?  126154  Some-college             10   \n",
      "27475   67                 ?  125926  Some-college             10   \n",
      "29029   45  Self-emp-not-inc  138962  Some-college             10   \n",
      "18459   44      Self-emp-inc  116358     Bachelors             13   \n",
      "3256    44           Private  180985     Bachelors             13   \n",
      "10161   18                 ?  331511  Some-college             10   \n",
      "13347   38                 ?  177273       HS-grad              9   \n",
      "7253    48           Private  166929     Bachelors             13   \n",
      "2181    34           Private  244147     Bachelors             13   \n",
      "28293   42                 ?  116632  Some-college             10   \n",
      "30206   20                 ?  289116  Some-college             10   \n",
      "30922   49      Self-emp-inc  119539  Some-college             10   \n",
      "10674   37           Private  188576     Doctorate             16   \n",
      "1441    61                 ?  347089       HS-grad              9   \n",
      "7971    30                 ?  104965           9th              5   \n",
      "15023   45      Self-emp-inc  120131       7th-8th              4   \n",
      "28943   23                 ?   86337  Some-college             10   \n",
      "19812   49                 ?  407495       HS-grad              9   \n",
      "17470   19                 ?   37085  Some-college             10   \n",
      "25342   41           Private   90021       HS-grad              9   \n",
      "25441   60                 ?  160155     Bachelors             13   \n",
      "12198   18                 ?  343161          11th              7   \n",
      "393     34         State-gov   98101     Bachelors             13   \n",
      "19548   54                 ?  172991       HS-grad              9   \n",
      "17021   29           Private  113870       1st-4th              2   \n",
      "2036    19                 ?   33487  Some-college             10   \n",
      "31235   27                 ?  174163  Some-college             10   \n",
      "19253   17                 ?  198797          11th              7   \n",
      "17757   48                 ?  175653    Assoc-acdm             12   \n",
      "19414   34           Private  317809     Bachelors             13   \n",
      "11234   17                 ?  297117          11th              7   \n",
      "9138    27                 ?   61387     Bachelors             13   \n",
      "27086   19                 ?  140590          12th              8   \n",
      "\n",
      "              marital_status         occupation    relationship  \\\n",
      "30707     Married-civ-spouse                  ?       Own-child   \n",
      "24714          Never-married                  ?       Own-child   \n",
      "20658              Separated      Other-service       Unmarried   \n",
      "15036          Never-married       Adm-clerical   Not-in-family   \n",
      "21487     Married-civ-spouse                  ?         Husband   \n",
      "24813     Married-civ-spouse                  ?         Husband   \n",
      "22230     Married-civ-spouse       Craft-repair         Husband   \n",
      "5526           Never-married                  ?       Own-child   \n",
      "3990                 Widowed                  ?   Not-in-family   \n",
      "20963     Married-civ-spouse                  ?            Wife   \n",
      "13302     Married-civ-spouse                  ?            Wife   \n",
      "27513                Widowed                  ?       Unmarried   \n",
      "5823      Married-civ-spouse  Machine-op-inspct         Husband   \n",
      "28937     Married-civ-spouse    Exec-managerial         Husband   \n",
      "23565          Never-married    Exec-managerial   Not-in-family   \n",
      "30334          Never-married                  ?       Unmarried   \n",
      "8042           Never-married                  ?       Own-child   \n",
      "25044          Never-married                  ?       Own-child   \n",
      "27475     Married-civ-spouse                  ?         Husband   \n",
      "29029     Married-civ-spouse    Exec-managerial         Husband   \n",
      "18459     Married-civ-spouse              Sales         Husband   \n",
      "3256      Married-civ-spouse     Prof-specialty         Husband   \n",
      "10161          Never-married                  ?       Own-child   \n",
      "13347     Married-civ-spouse                  ?            Wife   \n",
      "7253      Married-civ-spouse       Adm-clerical         Husband   \n",
      "2181      Married-civ-spouse     Prof-specialty         Husband   \n",
      "28293     Married-civ-spouse                  ?         Husband   \n",
      "30206          Never-married                  ?       Own-child   \n",
      "30922     Married-civ-spouse    Exec-managerial         Husband   \n",
      "10674     Married-civ-spouse     Prof-specialty         Husband   \n",
      "1441      Married-civ-spouse                  ?         Husband   \n",
      "7971           Never-married                  ?   Not-in-family   \n",
      "15023     Married-civ-spouse    Exec-managerial         Husband   \n",
      "28943          Never-married                  ?   Not-in-family   \n",
      "19812  Married-spouse-absent                  ?   Not-in-family   \n",
      "17470          Never-married                  ?       Own-child   \n",
      "25342     Married-civ-spouse  Handlers-cleaners         Husband   \n",
      "25441     Married-civ-spouse                  ?         Husband   \n",
      "12198          Never-married                  ?       Own-child   \n",
      "393       Married-civ-spouse    Exec-managerial         Husband   \n",
      "19548     Married-civ-spouse                  ?         Husband   \n",
      "17021     Married-civ-spouse      Other-service         Husband   \n",
      "2036           Never-married                  ?  Other-relative   \n",
      "31235     Married-civ-spouse                  ?            Wife   \n",
      "19253          Never-married                  ?       Own-child   \n",
      "17757               Divorced                  ?   Not-in-family   \n",
      "19414     Married-civ-spouse    Exec-managerial         Husband   \n",
      "11234          Never-married                  ?       Own-child   \n",
      "9138      Married-civ-spouse                  ?         Husband   \n",
      "27086          Never-married                  ?       Own-child   \n",
      "\n",
      "                     race     sex  capital_gain  capital_loss  hours_per_week  \\\n",
      "30707               White  Female             0             0              15   \n",
      "24714               Black  Female             0             0              20   \n",
      "20658               Black  Female             0             0              40   \n",
      "15036               Black  Female             0          2339              45   \n",
      "21487               White    Male             0             0              55   \n",
      "24813               White    Male             0             0              10   \n",
      "22230               Black    Male             0             0              40   \n",
      "5526                White    Male             0             0              35   \n",
      "3990                White  Female             0             0              14   \n",
      "20963               White  Female             0             0              25   \n",
      "13302               White  Female             0             0              40   \n",
      "27513               Black  Female             0             0              40   \n",
      "5823                White    Male             0             0              70   \n",
      "28937               White    Male             0             0              55   \n",
      "23565               White    Male             0             0              55   \n",
      "30334               White    Male             0             0              40   \n",
      "8042                Black    Male             0          1602              30   \n",
      "25044               White    Male             0             0              40   \n",
      "27475               White    Male             0             0               8   \n",
      "29029  Asian-Pac-Islander    Male             0             0              72   \n",
      "18459  Asian-Pac-Islander    Male             0             0              50   \n",
      "3256                White    Male             0             0              50   \n",
      "10161               White    Male             0             0              30   \n",
      "13347               White  Female             0             0              35   \n",
      "7253                White    Male             0             0              45   \n",
      "2181                White    Male             0             0              40   \n",
      "28293               White    Male             0             0              60   \n",
      "30206               White  Female             0             0               5   \n",
      "30922               White    Male             0             0              60   \n",
      "10674  Asian-Pac-Islander    Male             0             0              40   \n",
      "1441                White    Male             0             0              16   \n",
      "7971                White  Female             0             0              30   \n",
      "15023               White    Male             0             0              52   \n",
      "28943               White  Female             0             0              15   \n",
      "19812               White    Male             0             0              70   \n",
      "17470               White  Female             0             0              30   \n",
      "25342               White    Male             0             0              40   \n",
      "25441               White    Male             0             0              12   \n",
      "12198               White    Male             0             0              16   \n",
      "393                 White    Male          7688             0              45   \n",
      "19548               White    Male             0             0              40   \n",
      "17021               White    Male             0             0              40   \n",
      "2036   Amer-Indian-Eskimo  Female             0             0              40   \n",
      "31235               White  Female             0             0              40   \n",
      "19253               White    Male             0             0              20   \n",
      "17757               White  Female         14084             0              40   \n",
      "19414               White    Male             0             0              50   \n",
      "11234               White  Female             0             0              40   \n",
      "9138                White    Male             0             0              15   \n",
      "27086               Black    Male             0             0              30   \n",
      "\n",
      "      native_country target  \n",
      "30707  United-States  <=50K  \n",
      "24714  United-States  <=50K  \n",
      "20658              ?  <=50K  \n",
      "15036              ?  <=50K  \n",
      "21487  United-States   >50K  \n",
      "24813  United-States  <=50K  \n",
      "22230              ?  <=50K  \n",
      "5526   United-States  <=50K  \n",
      "3990   United-States  <=50K  \n",
      "20963  United-States  <=50K  \n",
      "13302         Mexico  <=50K  \n",
      "27513  United-States  <=50K  \n",
      "5823               ?  <=50K  \n",
      "28937              ?   >50K  \n",
      "23565              ?  <=50K  \n",
      "30334    El-Salvador  <=50K  \n",
      "8042   United-States  <=50K  \n",
      "25044  United-States  <=50K  \n",
      "27475  United-States  <=50K  \n",
      "29029              ?  <=50K  \n",
      "18459              ?   >50K  \n",
      "3256               ?   >50K  \n",
      "10161  United-States  <=50K  \n",
      "13347  United-States  <=50K  \n",
      "7253               ?   >50K  \n",
      "2181               ?   >50K  \n",
      "28293  United-States  <=50K  \n",
      "30206  United-States  <=50K  \n",
      "30922              ?   >50K  \n",
      "10674              ?  <=50K  \n",
      "1441   United-States  <=50K  \n",
      "7971   United-States  <=50K  \n",
      "15023              ?  <=50K  \n",
      "28943  United-States  <=50K  \n",
      "19812  United-States  <=50K  \n",
      "17470  United-States  <=50K  \n",
      "25342              ?  <=50K  \n",
      "25441  United-States  <=50K  \n",
      "12198  United-States  <=50K  \n",
      "393                ?   >50K  \n",
      "19548  United-States  <=50K  \n",
      "17021              ?  <=50K  \n",
      "2036   United-States  <=50K  \n",
      "31235  United-States   >50K  \n",
      "19253           Peru  <=50K  \n",
      "17757  United-States   >50K  \n",
      "19414              ?   >50K  \n",
      "11234  United-States  <=50K  \n",
      "9138   United-States  <=50K  \n",
      "27086  United-States  <=50K  \n"
     ]
    }
   ],
   "source": [
    "rows=50\n",
    "Printthis(df[(df['work_class']=='?') | (df['native_country']=='?')] ,rand=True ,elems=rows ,rows=rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work_class        education   \n",
      "?                 10th             100\n",
      "                  11th             118\n",
      "                  12th              40\n",
      "                  1st-4th           12\n",
      "                  5th-6th           30\n",
      "                  7th-8th           72\n",
      "                  9th               51\n",
      "                  Assoc-acdm        47\n",
      "                  Assoc-voc         61\n",
      "                  Bachelors        173\n",
      "                  Doctorate         15\n",
      "                  HS-grad          532\n",
      "                  Masters           48\n",
      "                  Preschool          5\n",
      "                  Prof-school       18\n",
      "                  Some-college     514\n",
      "Federal-gov       10th               6\n",
      "                  11th               9\n",
      "                  12th               5\n",
      "                  5th-6th            1\n",
      "                  7th-8th            2\n",
      "                  9th                3\n",
      "                  Assoc-acdm        55\n",
      "                  Assoc-voc         38\n",
      "                  Bachelors        212\n",
      "                  Doctorate         16\n",
      "                  HS-grad          263\n",
      "                  Masters           67\n",
      "                  Prof-school       29\n",
      "                  Some-college     254\n",
      "Local-gov         10th              31\n",
      "                  11th              36\n",
      "                  12th              19\n",
      "                  1st-4th            4\n",
      "                  5th-6th            9\n",
      "                  7th-8th           28\n",
      "                  9th               23\n",
      "                  Assoc-acdm        88\n",
      "                  Assoc-voc         86\n",
      "                  Bachelors        477\n",
      "                  Doctorate         27\n",
      "                  HS-grad          503\n",
      "                  Masters          342\n",
      "                  Preschool          4\n",
      "                  Prof-school       29\n",
      "                  Some-college     387\n",
      "Never-worked      10th               2\n",
      "                  11th               1\n",
      "                  7th-8th            1\n",
      "                  HS-grad            1\n",
      "                  Some-college       2\n",
      "Private           10th             695\n",
      "                  11th             923\n",
      "                  12th             333\n",
      "                  1st-4th          136\n",
      "                  5th-6th          266\n",
      "                  7th-8th          424\n",
      "                  9th              387\n",
      "                  Assoc-acdm       729\n",
      "                  Assoc-voc       1005\n",
      "                  Bachelors       3551\n",
      "                  Doctorate        181\n",
      "                  HS-grad         7780\n",
      "                  Masters          894\n",
      "                  Preschool         41\n",
      "                  Prof-school      257\n",
      "                  Some-college    5094\n",
      "Self-emp-inc      10th              19\n",
      "                  11th              14\n",
      "                  12th               7\n",
      "                  1st-4th            2\n",
      "                  5th-6th            4\n",
      "                  7th-8th           14\n",
      "                  9th               10\n",
      "                  Assoc-acdm        35\n",
      "                  Assoc-voc         38\n",
      "                  Bachelors        273\n",
      "                  Doctorate         35\n",
      "                  HS-grad          279\n",
      "                  Masters           79\n",
      "                  Prof-school       81\n",
      "                  Some-college     226\n",
      "Self-emp-not-inc  10th              67\n",
      "                  11th              60\n",
      "                  12th              19\n",
      "                  1st-4th           13\n",
      "                  5th-6th           19\n",
      "                  7th-8th           94\n",
      "                  9th               34\n",
      "                  Assoc-acdm        71\n",
      "                  Assoc-voc        108\n",
      "                  Bachelors        399\n",
      "                  Doctorate         50\n",
      "                  HS-grad          866\n",
      "                  Masters          124\n",
      "                  Prof-school      131\n",
      "                  Some-college     486\n",
      "State-gov         10th              13\n",
      "                  11th              14\n",
      "                  12th              10\n",
      "                  1st-4th            1\n",
      "                  5th-6th            4\n",
      "                  7th-8th           10\n",
      "                  9th                6\n",
      "                  Assoc-acdm        41\n",
      "                  Assoc-voc         46\n",
      "                  Bachelors        270\n",
      "                  Doctorate         89\n",
      "                  HS-grad          268\n",
      "                  Masters          169\n",
      "                  Preschool          1\n",
      "                  Prof-school       31\n",
      "                  Some-college     325\n",
      "Without-pay       7th-8th            1\n",
      "                  Assoc-acdm         1\n",
      "                  HS-grad            9\n",
      "                  Some-college       3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Printthis(df.groupby(['work_class', 'education']).size() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education     work_class\n",
      "10th          ?             100\n",
      "11th          ?             118\n",
      "12th          ?              40\n",
      "1st-4th       ?              12\n",
      "5th-6th       ?              30\n",
      "7th-8th       ?              72\n",
      "9th           ?              51\n",
      "Assoc-acdm    ?              47\n",
      "Assoc-voc     ?              61\n",
      "Bachelors     ?             173\n",
      "Doctorate     ?              15\n",
      "HS-grad       ?             532\n",
      "Masters       ?              48\n",
      "Preschool     ?               5\n",
      "Prof-school   ?              18\n",
      "Some-college  ?             514\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Printthis(df[df['work_class']=='?'].groupby(['education', 'work_class']).size() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "17     64\n",
      "18     92\n",
      "19    113\n",
      "20    115\n",
      "21     89\n",
      "22     79\n",
      "23     46\n",
      "24     34\n",
      "25     32\n",
      "26     22\n",
      "27     33\n",
      "28     41\n",
      "29     28\n",
      "30     28\n",
      "31     19\n",
      "32     25\n",
      "33     26\n",
      "34     26\n",
      "35     32\n",
      "36     23\n",
      "37      9\n",
      "38     17\n",
      "39     12\n",
      "40     17\n",
      "41     18\n",
      "42     15\n",
      "43     13\n",
      "44     10\n",
      "45     11\n",
      "46     11\n",
      "47     14\n",
      "48     16\n",
      "49     18\n",
      "50     14\n",
      "51     17\n",
      "52     14\n",
      "53     12\n",
      "54     16\n",
      "55     22\n",
      "56     13\n",
      "57     16\n",
      "58     20\n",
      "59     20\n",
      "60     31\n",
      "61     36\n",
      "62     42\n",
      "63     39\n",
      "64     31\n",
      "65     39\n",
      "66     37\n",
      "67     39\n",
      "68     28\n",
      "69     28\n",
      "70     24\n",
      "71     18\n",
      "72     25\n",
      "73     15\n",
      "74     12\n",
      "75     11\n",
      "76     16\n",
      "77      9\n",
      "78      9\n",
      "79      7\n",
      "80      6\n",
      "81      6\n",
      "82      5\n",
      "83      1\n",
      "84      2\n",
      "87      1\n",
      "90      7\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Printthis(df[df['work_class']=='?'].groupby(['age']).size() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education\n",
      "10th             833\n",
      "11th            1057\n",
      "12th             393\n",
      "1st-4th          156\n",
      "5th-6th          303\n",
      "7th-8th          574\n",
      "9th              463\n",
      "Assoc-acdm      1020\n",
      "Assoc-voc       1321\n",
      "Bachelors       5182\n",
      "Doctorate        398\n",
      "HS-grad         9969\n",
      "Masters         1675\n",
      "Preschool         46\n",
      "Prof-school      558\n",
      "Some-college    6777\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Printthis(df[df['work_class']!='?'].groupby(['education']).size() ,prtall=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "17    331\n",
      "18    458\n",
      "19    599\n",
      "20    638\n",
      "21    631\n",
      "22    686\n",
      "23    831\n",
      "24    764\n",
      "25    809\n",
      "26    763\n",
      "27    802\n",
      "28    826\n",
      "29    785\n",
      "30    833\n",
      "31    869\n",
      "32    803\n",
      "33    849\n",
      "34    860\n",
      "35    844\n",
      "36    875\n",
      "37    849\n",
      "38    810\n",
      "39    804\n",
      "40    777\n",
      "41    790\n",
      "42    765\n",
      "43    757\n",
      "44    714\n",
      "45    723\n",
      "46    726\n",
      "47    694\n",
      "48    527\n",
      "49    559\n",
      "50    588\n",
      "51    578\n",
      "52    464\n",
      "53    452\n",
      "54    399\n",
      "55    397\n",
      "56    353\n",
      "57    342\n",
      "58    346\n",
      "59    335\n",
      "60    281\n",
      "61    264\n",
      "62    216\n",
      "63    191\n",
      "64    177\n",
      "65    139\n",
      "66    113\n",
      "67    112\n",
      "68     92\n",
      "69     80\n",
      "70     65\n",
      "71     54\n",
      "72     42\n",
      "73     49\n",
      "74     39\n",
      "75     34\n",
      "76     30\n",
      "77     20\n",
      "78     14\n",
      "79     15\n",
      "80     16\n",
      "81     14\n",
      "82      7\n",
      "83      5\n",
      "84      8\n",
      "85      3\n",
      "86      1\n",
      "88      3\n",
      "90     36\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "Printthis(df[df['work_class']!='?'].groupby(['age']).size() ,prtall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since the combined missing data (?) is less than 10% of the size of the dataset, it can be dropped. \n",
    "Otherwise, the IterativeImputer seems like a viable solution since the '?' values do not have an easily\n",
    "inspected relation to the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df[(df['work_class']!='?') & (df['native_country']!='?')].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Train Test Validate Split\n",
    "Ideally you will split the data and use the train data filling in proceedure for the test data. Because this is expensive you can do experiments initially to see if this matters. Just keep carefully in mind what you will know and what you can't know during the test evaluation. Both sklearn and tensorflow provide facilities for train test split. Take your pick.\n",
    "\n",
    "At the end of this you should have a train, validate and test split. In the next part you are going to do preliminary testing of your model with your train+validation sets to get some idea of good canditates for hyperparameters. Later you will merge your training and validation set and resplit them up using cross validation to get better estimates for setting hyper-parameters\n",
    "\n",
    "NOTE: It is very important that you record very carefully any parameters you have for filling in data in step 1. For example if you you build a \"fit\" using some training data, later you will need to use the this \"fit\" to transform the data, you can not re-fit on new data. In other words if your \"pipline\" in training takes the mean of the input to fill in the first column, you need to fill with exactly that number, when you get new data for testing. Don't take the mean of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>work_class</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        work_class  fnlwgt  education  education_num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital_status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital_gain  capital_loss  hours_per_week native_country target  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data setup/inspection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['target'] = (df_imputed['target']=='<=50K').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dtyped.loc[:,'target'] = df_imputed['target']!='<=50K'\n",
    "#df_dtyped.loc[:,'sex'] = df_imputed['target']!='<=50K'\n",
    "df_dtyped =  df_imputed[df_imputed.columns[df.columns!='education']].astype(\n",
    "    {'work_class':'category','marital_status':'category', 'occupation':'category'\n",
    "     ,'relationship':'category', 'race':'category', 'sex':'category'\n",
    "    ,'native_country':'category','age':'int64', 'fnlwgt':'int64', 'education_num':'category',       \n",
    "       'capital_gain':'int64', 'capital_loss':'int64', 'hours_per_week':'int64','target':'int64'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_large_counts = df_dtyped.groupby(column).filter(lambda x: len(x) > 1)\n",
    "\n",
    "#i=0\n",
    "#while i < 2*len(df_dtyped.columns):\n",
    "for column in df_large_counts:\n",
    "    df_large_counts = df_large_counts.groupby(column).filter(lambda x: len(x) > 1)\n",
    "#i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15673, 13)\n",
      "(15673,)\n",
      "\n",
      " (9403, 13)\n",
      "(9403,)\n",
      "(6270, 13)\n",
      "(6270,)\n"
     ]
    }
   ],
   "source": [
    "X = df_large_counts[df_large_counts.columns[df_large_counts.columns!='target']]\n",
    "y = df_large_counts['target']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "for train_index, test_val_index in split.split(X, X[\"native_country\"]):                               \n",
    "    train_set = X.iloc[train_index]    \n",
    "    y_train = y.iloc[train_index]\n",
    "    \n",
    "    test_val_set = X.iloc[test_val_index]    \n",
    "    test_val_y = y.iloc[test_val_index]\n",
    "\n",
    "print('\\n' ,train_set.shape)\n",
    "print(y_train.shape)\n",
    "print(test_val_set.shape)\n",
    "print(test_val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "#only in a jupyter notebook\n",
    "import matplotlib.pyplot as plt\n",
    "bins = len(test_val_set.columns)\n",
    "df_dtyped.hist(bins=bins, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7f9868d51df0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 42 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(df_dtyped ,height=2 ,aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up your models here\n",
    "#### Get baseline results here with logisic regression and random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del nums\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del onehot\n",
    "except NameError:\n",
    "    pass\n",
    "try:\n",
    "    del ordinal\n",
    "except NameError:\n",
    "    pass\n",
    "    \n",
    "nums = ['age', 'fnlwgt' ,'capital_gain', 'capital_loss', 'hours_per_week']\n",
    "onehot = [#'education_num',\n",
    "          'work_class','marital_status', 'occupation', 'relationship', 'race', 'sex','native_country']\n",
    "ordinal = ['education_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9403, 13)\n",
      "(6270, 13)\n",
      "\n",
      " (9403, 89)\n",
      "(3135, 86)\n",
      "(3135,)\n",
      "(3135, 86)\n",
      "(3135,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print(train_set.shape)\n",
    "print(test_val_set.shape)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "   #     ('imputer' ,MostFrequentImputer()),\n",
    "        ('cat_encoder' ,OneHotEncoder(sparse=False)),\n",
    "    ])\n",
    "\n",
    "ord_pipeline = Pipeline([\n",
    "        ('ordinal' ,OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num' ,num_pipeline ,nums),\n",
    "    ('cat' ,cat_pipeline ,onehot),\n",
    "    ('ord' ,ord_pipeline ,ordinal),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "test_size = math.floor(len(test_val_set)/2)\n",
    "x_train = full_pipeline.fit_transform(train_set)\n",
    "x_test = full_pipeline.fit_transform(test_val_set[:test_size])\n",
    "x_val = full_pipeline.fit_transform(test_val_set[test_size:])\n",
    "\n",
    "y_test = test_val_y[:test_size]\n",
    "y_val = test_val_y[test_size:]\n",
    "\n",
    "print('\\n' ,x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### for some reason the number of columns do not match up after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " (9403, 86)\n",
      "(3135, 86)\n",
      "(3135, 86)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train[:,:min(x_train.shape[1],x_test.shape[1],x_val.shape[1])]\n",
    "x_test = x_test[:,:min(x_train.shape[1],x_test.shape[1],x_val.shape[1])]\n",
    "x_val = x_val[:,:min(x_train.shape[1],x_test.shape[1],x_val.shape[1])]\n",
    "\n",
    "print('\\n' ,x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Build different 2 sklearn models and five different variations of Keras/tensorflow models\n",
    "Two simple models should be baseline from sklearn. Try a logistic regression and a random forest to know what your dense neural network should be able to beat. Use the training and validation data from above (don't look at the testing data). Try varations on the number of notes in a layer, the number of layers. Also play with feature selection. You can try to eliminate featuers and see if your validation score goes up or down. See how the batch size effects things.\n",
    "\n",
    "At the end of this section provide a report with figures on your conclusion on how these things effected preformance:\n",
    "number of hidden layers\n",
    "number of nodes per hidden layer aka matrix dimension\n",
    "activation function\n",
    "weight initialization\n",
    "metrics for evaluation\n",
    "batch size\n",
    "number of epochs\n",
    "optimizer\n",
    "also carry out feature selection / dimensionality reduction\n",
    "does the model do better or worse with dimensionality reduction?\n",
    "* Note: do not try regularization yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(max_iter=1000 ,random_state=42)\n",
    "log_reg.fit(x_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49856459330143543"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.389792663476874"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = log_reg.predict(x_val)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_forest = RandomForestClassifier(random_state=42)\n",
    "rand_forest.fit(x_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7352472089314195"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_forest.predict(x_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6880382775119617"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rand_forest.predict(x_val)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_bool = y_train\n",
    "y_test_bool = y_test\n",
    "y_val_bool = y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid'))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "    \n",
    "#decreasing output node amount\n",
    "def model_two():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(20 ,input_shape=(86,) ,activation='sigmoid'))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "    \n",
    "    return model1    \n",
    "\n",
    "#changing activation function\n",
    "def model_three(): \n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='relu'))\n",
    "    model1.add(Dense(1 ,activation='relu'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "\n",
    "    return model1\n",
    "\n",
    "#added hidden layer\n",
    "def model_four():   \n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid'))\n",
    "    model1.add(Dense(10 ,input_shape=(20,) ,activation='sigmoid'))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "\n",
    "    return model1\n",
    "\n",
    "#added dropout\n",
    "def model_five():\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='adam' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "\n",
    "    return model1\n",
    "\n",
    "# Perform preliminary evaluations here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 0.6435 - accuracy: 0.6652 - val_loss: 0.6071 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5998 - accuracy: 0.7033 - val_loss: 0.5947 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5682 - accuracy: 0.7100 - val_loss: 0.5861 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5448 - accuracy: 0.7157 - val_loss: 0.5783 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5299 - accuracy: 0.7141 - val_loss: 0.5766 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.5137 - accuracy: 0.7229 - val_loss: 0.5648 - val_accuracy: 0.7120\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4965 - accuracy: 0.7394 - val_loss: 0.5589 - val_accuracy: 0.7145\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4836 - accuracy: 0.7492 - val_loss: 0.5571 - val_accuracy: 0.7145\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4746 - accuracy: 0.7495 - val_loss: 0.5540 - val_accuracy: 0.7152\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4665 - accuracy: 0.7558 - val_loss: 0.5500 - val_accuracy: 0.7158\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4593 - accuracy: 0.7634 - val_loss: 0.5444 - val_accuracy: 0.7161\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4526 - accuracy: 0.7738 - val_loss: 0.5442 - val_accuracy: 0.7158\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4469 - accuracy: 0.7735 - val_loss: 0.5458 - val_accuracy: 0.7158\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4486 - accuracy: 0.7696 - val_loss: 0.5531 - val_accuracy: 0.7158\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4412 - accuracy: 0.7692 - val_loss: 0.5377 - val_accuracy: 0.7241\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4396 - accuracy: 0.7763 - val_loss: 0.5496 - val_accuracy: 0.7167\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4398 - accuracy: 0.7788 - val_loss: 0.5549 - val_accuracy: 0.7171\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4330 - accuracy: 0.7846 - val_loss: 0.5446 - val_accuracy: 0.7203\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4333 - accuracy: 0.7794 - val_loss: 0.5540 - val_accuracy: 0.7183\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4196 - accuracy: 0.7933 - val_loss: 0.5471 - val_accuracy: 0.7199\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4235 - accuracy: 0.7876 - val_loss: 0.5428 - val_accuracy: 0.7215\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4180 - accuracy: 0.7902 - val_loss: 0.5456 - val_accuracy: 0.7225\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4166 - accuracy: 0.7923 - val_loss: 0.5374 - val_accuracy: 0.7225\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.7968 - val_loss: 0.5436 - val_accuracy: 0.7234\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.7962 - val_loss: 0.5480 - val_accuracy: 0.7241\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4137 - accuracy: 0.7988 - val_loss: 0.5382 - val_accuracy: 0.7270\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4120 - accuracy: 0.7957 - val_loss: 0.5376 - val_accuracy: 0.7263\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4000 - accuracy: 0.8030 - val_loss: 0.5339 - val_accuracy: 0.7301\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4058 - accuracy: 0.8000 - val_loss: 0.5308 - val_accuracy: 0.7359\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4101 - accuracy: 0.7985 - val_loss: 0.5383 - val_accuracy: 0.7279\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4076 - accuracy: 0.7999 - val_loss: 0.5407 - val_accuracy: 0.7295\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.8045 - val_loss: 0.5356 - val_accuracy: 0.7324\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4040 - accuracy: 0.8051 - val_loss: 0.5315 - val_accuracy: 0.7327\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4031 - accuracy: 0.8055 - val_loss: 0.5308 - val_accuracy: 0.7340\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3999 - accuracy: 0.8047 - val_loss: 0.5328 - val_accuracy: 0.7314\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4014 - accuracy: 0.8024 - val_loss: 0.5360 - val_accuracy: 0.7321\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4005 - accuracy: 0.8060 - val_loss: 0.5322 - val_accuracy: 0.7317\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3935 - accuracy: 0.8088 - val_loss: 0.5317 - val_accuracy: 0.7346\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8036 - val_loss: 0.5346 - val_accuracy: 0.7317\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3902 - accuracy: 0.8117 - val_loss: 0.5304 - val_accuracy: 0.7362\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3939 - accuracy: 0.8081 - val_loss: 0.5313 - val_accuracy: 0.7356\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3909 - accuracy: 0.8105 - val_loss: 0.5310 - val_accuracy: 0.7368\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3867 - accuracy: 0.8149 - val_loss: 0.5284 - val_accuracy: 0.7391\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3993 - accuracy: 0.8032 - val_loss: 0.5263 - val_accuracy: 0.7413\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3897 - accuracy: 0.8112 - val_loss: 0.5263 - val_accuracy: 0.7445\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3888 - accuracy: 0.8122 - val_loss: 0.5264 - val_accuracy: 0.7419\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.8147 - val_loss: 0.5260 - val_accuracy: 0.7419\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3902 - accuracy: 0.8149 - val_loss: 0.5258 - val_accuracy: 0.7432\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3920 - accuracy: 0.8104 - val_loss: 0.5251 - val_accuracy: 0.7429\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3844 - accuracy: 0.8148 - val_loss: 0.5256 - val_accuracy: 0.7400\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3903 - accuracy: 0.8120 - val_loss: 0.5265 - val_accuracy: 0.7397\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3826 - accuracy: 0.8168 - val_loss: 0.5263 - val_accuracy: 0.7413\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3853 - accuracy: 0.8184 - val_loss: 0.5249 - val_accuracy: 0.7432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3832 - accuracy: 0.8174 - val_loss: 0.5238 - val_accuracy: 0.7445\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3762 - accuracy: 0.8203 - val_loss: 0.5234 - val_accuracy: 0.7429\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8171 - val_loss: 0.5246 - val_accuracy: 0.7429\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3871 - accuracy: 0.8154 - val_loss: 0.5228 - val_accuracy: 0.7455\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3817 - accuracy: 0.8201 - val_loss: 0.5229 - val_accuracy: 0.7435\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3808 - accuracy: 0.8203 - val_loss: 0.5227 - val_accuracy: 0.7432\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3842 - accuracy: 0.8155 - val_loss: 0.5222 - val_accuracy: 0.7423\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3829 - accuracy: 0.8162 - val_loss: 0.5230 - val_accuracy: 0.7435\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3868 - accuracy: 0.8129 - val_loss: 0.5214 - val_accuracy: 0.7432\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3855 - accuracy: 0.8154 - val_loss: 0.5217 - val_accuracy: 0.7432\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3878 - accuracy: 0.8119 - val_loss: 0.5222 - val_accuracy: 0.7407\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3864 - accuracy: 0.8161 - val_loss: 0.5207 - val_accuracy: 0.7432\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3833 - accuracy: 0.8146 - val_loss: 0.5207 - val_accuracy: 0.7439\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3801 - accuracy: 0.8176 - val_loss: 0.5196 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8187 - val_loss: 0.5192 - val_accuracy: 0.7445\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3730 - accuracy: 0.8221 - val_loss: 0.5190 - val_accuracy: 0.7445\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3765 - accuracy: 0.8209 - val_loss: 0.5193 - val_accuracy: 0.7423\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3798 - accuracy: 0.8178 - val_loss: 0.5185 - val_accuracy: 0.7435\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.8183 - val_loss: 0.5184 - val_accuracy: 0.7451\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3774 - accuracy: 0.8198 - val_loss: 0.5178 - val_accuracy: 0.7461\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3795 - accuracy: 0.8205 - val_loss: 0.5181 - val_accuracy: 0.7464\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3778 - accuracy: 0.8179 - val_loss: 0.5182 - val_accuracy: 0.7435\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3720 - accuracy: 0.8221 - val_loss: 0.5169 - val_accuracy: 0.7442\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3748 - accuracy: 0.8184 - val_loss: 0.5174 - val_accuracy: 0.7477\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3822 - accuracy: 0.8188 - val_loss: 0.5163 - val_accuracy: 0.7458\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3800 - accuracy: 0.8145 - val_loss: 0.5187 - val_accuracy: 0.7432\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3735 - accuracy: 0.8195 - val_loss: 0.5161 - val_accuracy: 0.7455\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3771 - accuracy: 0.8190 - val_loss: 0.5158 - val_accuracy: 0.7455\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3695 - accuracy: 0.8251 - val_loss: 0.5167 - val_accuracy: 0.7467\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3758 - accuracy: 0.8234 - val_loss: 0.5188 - val_accuracy: 0.7426\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3759 - accuracy: 0.8202 - val_loss: 0.5207 - val_accuracy: 0.7388\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3735 - accuracy: 0.8225 - val_loss: 0.5150 - val_accuracy: 0.7470\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8196 - val_loss: 0.5141 - val_accuracy: 0.7467\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3804 - accuracy: 0.8158 - val_loss: 0.5213 - val_accuracy: 0.7362\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3811 - accuracy: 0.8172 - val_loss: 0.5133 - val_accuracy: 0.7470\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3738 - accuracy: 0.8209 - val_loss: 0.5210 - val_accuracy: 0.7365\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3803 - accuracy: 0.8182 - val_loss: 0.5129 - val_accuracy: 0.7483\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3792 - accuracy: 0.8200 - val_loss: 0.5175 - val_accuracy: 0.7413\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3749 - accuracy: 0.8182 - val_loss: 0.5148 - val_accuracy: 0.7413\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3693 - accuracy: 0.8263 - val_loss: 0.5184 - val_accuracy: 0.7397\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.8216 - val_loss: 0.5133 - val_accuracy: 0.7451\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3749 - accuracy: 0.8216 - val_loss: 0.5115 - val_accuracy: 0.7493\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3753 - accuracy: 0.8180 - val_loss: 0.5235 - val_accuracy: 0.7340\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3705 - accuracy: 0.8231 - val_loss: 0.5155 - val_accuracy: 0.7426\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.8240 - val_loss: 0.5137 - val_accuracy: 0.7410\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3752 - accuracy: 0.8210 - val_loss: 0.5161 - val_accuracy: 0.7410\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8236 - val_loss: 0.5106 - val_accuracy: 0.7506\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3764 - accuracy: 0.8213 - val_loss: 0.5119 - val_accuracy: 0.7439\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3756 - accuracy: 0.8199 - val_loss: 0.5101 - val_accuracy: 0.7509\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3753 - accuracy: 0.8208 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3828 - accuracy: 0.8191 - val_loss: 0.5091 - val_accuracy: 0.7525\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8240 - val_loss: 0.5124 - val_accuracy: 0.7423\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3767 - accuracy: 0.8200 - val_loss: 0.5124 - val_accuracy: 0.7432\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3789 - accuracy: 0.8159 - val_loss: 0.5083 - val_accuracy: 0.7525\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3698 - accuracy: 0.8238 - val_loss: 0.5103 - val_accuracy: 0.7432\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3788 - accuracy: 0.8166 - val_loss: 0.5081 - val_accuracy: 0.7493\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3733 - accuracy: 0.8233 - val_loss: 0.5076 - val_accuracy: 0.7528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3762 - accuracy: 0.8180 - val_loss: 0.5074 - val_accuracy: 0.7534\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3738 - accuracy: 0.8182 - val_loss: 0.5102 - val_accuracy: 0.7435\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3748 - accuracy: 0.8233 - val_loss: 0.5071 - val_accuracy: 0.7496\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3687 - accuracy: 0.8242 - val_loss: 0.5103 - val_accuracy: 0.7435\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.8248 - val_loss: 0.5063 - val_accuracy: 0.7531\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3722 - accuracy: 0.8238 - val_loss: 0.5089 - val_accuracy: 0.7439\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3731 - accuracy: 0.8226 - val_loss: 0.5140 - val_accuracy: 0.7413\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3740 - accuracy: 0.8208 - val_loss: 0.5109 - val_accuracy: 0.7439\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3721 - accuracy: 0.8227 - val_loss: 0.5162 - val_accuracy: 0.7365\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3795 - accuracy: 0.8201 - val_loss: 0.5058 - val_accuracy: 0.7458\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.8230 - val_loss: 0.5090 - val_accuracy: 0.7455\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3748 - accuracy: 0.8215 - val_loss: 0.5058 - val_accuracy: 0.7461\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.8252 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.8176 - val_loss: 0.5203 - val_accuracy: 0.7266\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3715 - accuracy: 0.8196 - val_loss: 0.5077 - val_accuracy: 0.7470\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.8234 - val_loss: 0.5100 - val_accuracy: 0.7435\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3721 - accuracy: 0.8203 - val_loss: 0.5077 - val_accuracy: 0.7461\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8265 - val_loss: 0.5035 - val_accuracy: 0.7502\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.8225 - val_loss: 0.5061 - val_accuracy: 0.7467\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3755 - accuracy: 0.8226 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3685 - accuracy: 0.8255 - val_loss: 0.5038 - val_accuracy: 0.7467\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3738 - accuracy: 0.8242 - val_loss: 0.5026 - val_accuracy: 0.7490\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3707 - accuracy: 0.8201 - val_loss: 0.5073 - val_accuracy: 0.7451\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3728 - accuracy: 0.8217 - val_loss: 0.5043 - val_accuracy: 0.7477\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3759 - accuracy: 0.8212 - val_loss: 0.5077 - val_accuracy: 0.7451\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3733 - accuracy: 0.8214 - val_loss: 0.5013 - val_accuracy: 0.7534\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3699 - accuracy: 0.8241 - val_loss: 0.5102 - val_accuracy: 0.7416\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3741 - accuracy: 0.8195 - val_loss: 0.5004 - val_accuracy: 0.7579\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3824 - accuracy: 0.8179 - val_loss: 0.5011 - val_accuracy: 0.7506\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3747 - accuracy: 0.8235 - val_loss: 0.5077 - val_accuracy: 0.7442\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3729 - accuracy: 0.8191 - val_loss: 0.5054 - val_accuracy: 0.7480\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3710 - accuracy: 0.8246 - val_loss: 0.5039 - val_accuracy: 0.7455\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8182 - val_loss: 0.5135 - val_accuracy: 0.7337\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3793 - accuracy: 0.8161 - val_loss: 0.5022 - val_accuracy: 0.7467\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3696 - accuracy: 0.8228 - val_loss: 0.5028 - val_accuracy: 0.7464\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8228 - val_loss: 0.4988 - val_accuracy: 0.7522\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.8233 - val_loss: 0.5020 - val_accuracy: 0.7461\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3707 - accuracy: 0.8259 - val_loss: 0.5045 - val_accuracy: 0.7458\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8254 - val_loss: 0.5164 - val_accuracy: 0.7317\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3790 - accuracy: 0.8182 - val_loss: 0.4985 - val_accuracy: 0.7528\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3702 - accuracy: 0.8225 - val_loss: 0.5005 - val_accuracy: 0.7474\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3707 - accuracy: 0.8219 - val_loss: 0.5065 - val_accuracy: 0.7439\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3736 - accuracy: 0.8228 - val_loss: 0.4990 - val_accuracy: 0.7515\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3688 - accuracy: 0.8229 - val_loss: 0.5071 - val_accuracy: 0.7426\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3717 - accuracy: 0.8227 - val_loss: 0.5025 - val_accuracy: 0.7477\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3761 - accuracy: 0.8197 - val_loss: 0.4990 - val_accuracy: 0.7496\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3722 - accuracy: 0.8217 - val_loss: 0.4987 - val_accuracy: 0.7496\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.8254 - val_loss: 0.5095 - val_accuracy: 0.7356\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3694 - accuracy: 0.8222 - val_loss: 0.5098 - val_accuracy: 0.7362\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8210 - val_loss: 0.5055 - val_accuracy: 0.7451\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8223 - val_loss: 0.4983 - val_accuracy: 0.7486\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3743 - accuracy: 0.8209 - val_loss: 0.5001 - val_accuracy: 0.7486\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3663 - accuracy: 0.8259 - val_loss: 0.5000 - val_accuracy: 0.7480\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8225 - val_loss: 0.5098 - val_accuracy: 0.7359\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8234 - val_loss: 0.5022 - val_accuracy: 0.7477\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8255 - val_loss: 0.5069 - val_accuracy: 0.7384\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3722 - accuracy: 0.8227 - val_loss: 0.5031 - val_accuracy: 0.7477\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3706 - accuracy: 0.8222 - val_loss: 0.4964 - val_accuracy: 0.7512\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8214 - val_loss: 0.5058 - val_accuracy: 0.7400\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3705 - accuracy: 0.8228 - val_loss: 0.4944 - val_accuracy: 0.7553\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3710 - accuracy: 0.8228 - val_loss: 0.5009 - val_accuracy: 0.7483\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3715 - accuracy: 0.8239 - val_loss: 0.5002 - val_accuracy: 0.7496\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8232 - val_loss: 0.4975 - val_accuracy: 0.7480\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3742 - accuracy: 0.8215 - val_loss: 0.4937 - val_accuracy: 0.7569\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3709 - accuracy: 0.8240 - val_loss: 0.4993 - val_accuracy: 0.7496\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3712 - accuracy: 0.8234 - val_loss: 0.4988 - val_accuracy: 0.7490\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3746 - accuracy: 0.8216 - val_loss: 0.4944 - val_accuracy: 0.7528\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3651 - accuracy: 0.8251 - val_loss: 0.5090 - val_accuracy: 0.7346\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8242 - val_loss: 0.4955 - val_accuracy: 0.7490\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3641 - accuracy: 0.8268 - val_loss: 0.4954 - val_accuracy: 0.7486\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8226 - val_loss: 0.4970 - val_accuracy: 0.7499\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3659 - accuracy: 0.8264 - val_loss: 0.4926 - val_accuracy: 0.7541\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.8298 - val_loss: 0.4976 - val_accuracy: 0.7515\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8203 - val_loss: 0.4914 - val_accuracy: 0.7585\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3703 - accuracy: 0.8209 - val_loss: 0.4924 - val_accuracy: 0.7531\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3708 - accuracy: 0.8247 - val_loss: 0.5003 - val_accuracy: 0.7461\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3654 - accuracy: 0.8290 - val_loss: 0.4912 - val_accuracy: 0.7601\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.8216 - val_loss: 0.4926 - val_accuracy: 0.7502\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.8264 - val_loss: 0.4963 - val_accuracy: 0.7512\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3630 - accuracy: 0.8309 - val_loss: 0.4951 - val_accuracy: 0.7502\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3633 - accuracy: 0.8271 - val_loss: 0.5027 - val_accuracy: 0.7416\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3599 - accuracy: 0.8297 - val_loss: 0.4997 - val_accuracy: 0.7477\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3675 - accuracy: 0.8256 - val_loss: 0.4970 - val_accuracy: 0.7522\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3705 - accuracy: 0.8239 - val_loss: 0.4974 - val_accuracy: 0.7534\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8265 - val_loss: 0.4967 - val_accuracy: 0.7531\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3691 - accuracy: 0.8238 - val_loss: 0.4926 - val_accuracy: 0.7515\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.8236 - val_loss: 0.5027 - val_accuracy: 0.7404\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.8256 - val_loss: 0.4965 - val_accuracy: 0.7512\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8245 - val_loss: 0.4936 - val_accuracy: 0.7493\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3660 - accuracy: 0.8250 - val_loss: 0.4907 - val_accuracy: 0.7515\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3695 - accuracy: 0.8258 - val_loss: 0.4939 - val_accuracy: 0.7512\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3717 - accuracy: 0.8215 - val_loss: 0.4905 - val_accuracy: 0.7553\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3643 - accuracy: 0.8244 - val_loss: 0.4990 - val_accuracy: 0.7451\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.8234 - val_loss: 0.4908 - val_accuracy: 0.7534\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3680 - accuracy: 0.8249 - val_loss: 0.4940 - val_accuracy: 0.7502\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3677 - accuracy: 0.8228 - val_loss: 0.4907 - val_accuracy: 0.7528\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8265 - val_loss: 0.4896 - val_accuracy: 0.7557\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3636 - accuracy: 0.8294 - val_loss: 0.4927 - val_accuracy: 0.7518\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3722 - accuracy: 0.8251 - val_loss: 0.4900 - val_accuracy: 0.7525\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3678 - accuracy: 0.8240 - val_loss: 0.4910 - val_accuracy: 0.7496\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.8181 - val_loss: 0.4914 - val_accuracy: 0.7512\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3686 - accuracy: 0.8260 - val_loss: 0.4895 - val_accuracy: 0.7537\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3688 - accuracy: 0.8239 - val_loss: 0.5008 - val_accuracy: 0.7410\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.8273 - val_loss: 0.4921 - val_accuracy: 0.7528\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3636 - accuracy: 0.8292 - val_loss: 0.4929 - val_accuracy: 0.7528\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3619 - accuracy: 0.8253 - val_loss: 0.5002 - val_accuracy: 0.7419\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3691 - accuracy: 0.8238 - val_loss: 0.4915 - val_accuracy: 0.7512\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3648 - accuracy: 0.8252 - val_loss: 0.4924 - val_accuracy: 0.7534\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.8238 - val_loss: 0.4919 - val_accuracy: 0.7509\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3638 - accuracy: 0.8224 - val_loss: 0.5071 - val_accuracy: 0.7327\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.8242 - val_loss: 0.4900 - val_accuracy: 0.7537\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.8259 - val_loss: 0.4960 - val_accuracy: 0.7467\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8206 - val_loss: 0.4925 - val_accuracy: 0.7534\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3674 - accuracy: 0.8277 - val_loss: 0.4943 - val_accuracy: 0.7490\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3659 - accuracy: 0.8278 - val_loss: 0.4915 - val_accuracy: 0.7515\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3626 - accuracy: 0.8270 - val_loss: 0.4963 - val_accuracy: 0.7448\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3705 - accuracy: 0.8212 - val_loss: 0.4870 - val_accuracy: 0.7643\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3628 - accuracy: 0.8288 - val_loss: 0.4967 - val_accuracy: 0.7435\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3705 - accuracy: 0.8236 - val_loss: 0.4902 - val_accuracy: 0.7515\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3633 - accuracy: 0.8303 - val_loss: 0.4920 - val_accuracy: 0.7528\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3624 - accuracy: 0.8266 - val_loss: 0.4918 - val_accuracy: 0.7518\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3689 - accuracy: 0.8241 - val_loss: 0.4893 - val_accuracy: 0.7518\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8255 - val_loss: 0.4900 - val_accuracy: 0.7506\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3652 - accuracy: 0.8258 - val_loss: 0.4968 - val_accuracy: 0.7445\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3649 - accuracy: 0.8264 - val_loss: 0.4947 - val_accuracy: 0.7467\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8266 - val_loss: 0.4934 - val_accuracy: 0.7470\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.8261 - val_loss: 0.4954 - val_accuracy: 0.7455\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3672 - accuracy: 0.8258 - val_loss: 0.4893 - val_accuracy: 0.7512\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3670 - accuracy: 0.8265 - val_loss: 0.4903 - val_accuracy: 0.7522\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3648 - accuracy: 0.8279 - val_loss: 0.4874 - val_accuracy: 0.7557\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 0.8279 - val_loss: 0.4873 - val_accuracy: 0.7550\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.8269 - val_loss: 0.5009 - val_accuracy: 0.7375\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.8290 - val_loss: 0.5041 - val_accuracy: 0.7321\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3661 - accuracy: 0.8255 - val_loss: 0.4900 - val_accuracy: 0.7531\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3600 - accuracy: 0.8289 - val_loss: 0.4917 - val_accuracy: 0.7496\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3510 - accuracy: 0.8373 - val_loss: 0.4962 - val_accuracy: 0.7448\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3701 - accuracy: 0.8254 - val_loss: 0.4949 - val_accuracy: 0.7445\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.8203 - val_loss: 0.4850 - val_accuracy: 0.7608\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.8250 - val_loss: 0.4875 - val_accuracy: 0.7537\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8238 - val_loss: 0.4887 - val_accuracy: 0.7528\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3715 - accuracy: 0.8211 - val_loss: 0.4972 - val_accuracy: 0.7432\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3628 - accuracy: 0.8287 - val_loss: 0.4888 - val_accuracy: 0.7537\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3669 - accuracy: 0.8233 - val_loss: 0.4934 - val_accuracy: 0.7435\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8269 - val_loss: 0.4858 - val_accuracy: 0.7547\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.8278 - val_loss: 0.4974 - val_accuracy: 0.7429\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3678 - accuracy: 0.8249 - val_loss: 0.4996 - val_accuracy: 0.7397\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.8224 - val_loss: 0.5030 - val_accuracy: 0.7308\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3646 - accuracy: 0.8243 - val_loss: 0.4882 - val_accuracy: 0.7537\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3611 - accuracy: 0.8315 - val_loss: 0.4850 - val_accuracy: 0.7563\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3723 - accuracy: 0.8206 - val_loss: 0.4928 - val_accuracy: 0.7439\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.8288 - val_loss: 0.4949 - val_accuracy: 0.7445\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3653 - accuracy: 0.8273 - val_loss: 0.4871 - val_accuracy: 0.7544\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3645 - accuracy: 0.8263 - val_loss: 0.4910 - val_accuracy: 0.7458\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3710 - accuracy: 0.8241 - val_loss: 0.4889 - val_accuracy: 0.7506\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3622 - accuracy: 0.8341 - val_loss: 0.4880 - val_accuracy: 0.7537\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3595 - accuracy: 0.8300 - val_loss: 0.4985 - val_accuracy: 0.7394\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.8259 - val_loss: 0.4892 - val_accuracy: 0.7461\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.8288 - val_loss: 0.4919 - val_accuracy: 0.7445\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8254 - val_loss: 0.4999 - val_accuracy: 0.7346\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3601 - accuracy: 0.8305 - val_loss: 0.4892 - val_accuracy: 0.7480\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8285 - val_loss: 0.5037 - val_accuracy: 0.7279\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.8318 - val_loss: 0.4885 - val_accuracy: 0.7506\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3663 - accuracy: 0.8262 - val_loss: 0.4850 - val_accuracy: 0.7547\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3632 - accuracy: 0.8290 - val_loss: 0.4869 - val_accuracy: 0.7553\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3662 - accuracy: 0.8274 - val_loss: 0.4881 - val_accuracy: 0.7518\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3647 - accuracy: 0.8285 - val_loss: 0.4922 - val_accuracy: 0.7426\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3660 - accuracy: 0.8279 - val_loss: 0.4977 - val_accuracy: 0.7372\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3631 - accuracy: 0.8281 - val_loss: 0.4913 - val_accuracy: 0.7435\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3641 - accuracy: 0.8274 - val_loss: 0.4901 - val_accuracy: 0.7455\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.8275 - val_loss: 0.4835 - val_accuracy: 0.7617\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3628 - accuracy: 0.8285 - val_loss: 0.5059 - val_accuracy: 0.7219\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3645 - accuracy: 0.8333 - val_loss: 0.5019 - val_accuracy: 0.7305\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3659 - accuracy: 0.8276 - val_loss: 0.4881 - val_accuracy: 0.7502\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3639 - accuracy: 0.8267 - val_loss: 0.4911 - val_accuracy: 0.7442\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.8250 - val_loss: 0.5039 - val_accuracy: 0.7263\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3671 - accuracy: 0.8263 - val_loss: 0.4913 - val_accuracy: 0.7435\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3669 - accuracy: 0.8272 - val_loss: 0.4849 - val_accuracy: 0.7560\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3568 - accuracy: 0.8320 - val_loss: 0.5119 - val_accuracy: 0.7148\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.8290 - val_loss: 0.4866 - val_accuracy: 0.7515\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3619 - accuracy: 0.8286 - val_loss: 0.4843 - val_accuracy: 0.7569\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3617 - accuracy: 0.8305 - val_loss: 0.4888 - val_accuracy: 0.7474\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3643 - accuracy: 0.8287 - val_loss: 0.4887 - val_accuracy: 0.7480\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.8269 - val_loss: 0.4879 - val_accuracy: 0.7490\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3682 - accuracy: 0.8271 - val_loss: 0.4970 - val_accuracy: 0.7340\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.8255 - val_loss: 0.4868 - val_accuracy: 0.7493\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.8273 - val_loss: 0.4986 - val_accuracy: 0.7308\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3573 - accuracy: 0.8332 - val_loss: 0.4950 - val_accuracy: 0.7375\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3722 - accuracy: 0.8221 - val_loss: 0.4947 - val_accuracy: 0.7391\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3585 - accuracy: 0.8318 - val_loss: 0.4832 - val_accuracy: 0.7566\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3555 - accuracy: 0.8312 - val_loss: 0.4878 - val_accuracy: 0.7496\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3630 - accuracy: 0.8278 - val_loss: 0.4854 - val_accuracy: 0.7547\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8272 - val_loss: 0.4914 - val_accuracy: 0.7429\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3655 - accuracy: 0.8269 - val_loss: 0.4942 - val_accuracy: 0.7410\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.8309 - val_loss: 0.4892 - val_accuracy: 0.7477\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.8297 - val_loss: 0.4911 - val_accuracy: 0.7429\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3561 - accuracy: 0.8333 - val_loss: 0.4862 - val_accuracy: 0.7531\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3623 - accuracy: 0.8299 - val_loss: 0.5055 - val_accuracy: 0.7199\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.8251 - val_loss: 0.5068 - val_accuracy: 0.7196\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.8271 - val_loss: 0.5062 - val_accuracy: 0.7196\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3583 - accuracy: 0.8317 - val_loss: 0.4939 - val_accuracy: 0.7410\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3666 - accuracy: 0.8291 - val_loss: 0.5033 - val_accuracy: 0.7257\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3606 - accuracy: 0.8292 - val_loss: 0.4899 - val_accuracy: 0.7445\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3584 - accuracy: 0.8308 - val_loss: 0.4941 - val_accuracy: 0.7394\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3588 - accuracy: 0.8331 - val_loss: 0.4878 - val_accuracy: 0.7477\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3632 - accuracy: 0.8300 - val_loss: 0.4954 - val_accuracy: 0.7340\n",
      "Epoch 00315: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model1 = model_one()\n",
    "history = model1.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4953840970993042, 0.7339712977409363]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 30ms/step - loss: 0.6050 - accuracy: 0.7056 - val_loss: 0.5817 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5667 - accuracy: 0.7129 - val_loss: 0.5713 - val_accuracy: 0.7104\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5464 - accuracy: 0.7105 - val_loss: 0.5604 - val_accuracy: 0.7136\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5194 - accuracy: 0.7233 - val_loss: 0.5515 - val_accuracy: 0.7145\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.5067 - accuracy: 0.7288 - val_loss: 0.5445 - val_accuracy: 0.7174\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4878 - accuracy: 0.7457 - val_loss: 0.5376 - val_accuracy: 0.7190\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4801 - accuracy: 0.7514 - val_loss: 0.5339 - val_accuracy: 0.7180\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4750 - accuracy: 0.7488 - val_loss: 0.5294 - val_accuracy: 0.7219\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4633 - accuracy: 0.7533 - val_loss: 0.5279 - val_accuracy: 0.7225\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4535 - accuracy: 0.7666 - val_loss: 0.5232 - val_accuracy: 0.7257\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4486 - accuracy: 0.7680 - val_loss: 0.5220 - val_accuracy: 0.7260\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4501 - accuracy: 0.7635 - val_loss: 0.5192 - val_accuracy: 0.7311\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4395 - accuracy: 0.7735 - val_loss: 0.5182 - val_accuracy: 0.7311\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4434 - accuracy: 0.7730 - val_loss: 0.5186 - val_accuracy: 0.7301\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4370 - accuracy: 0.7761 - val_loss: 0.5154 - val_accuracy: 0.7349\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4317 - accuracy: 0.7833 - val_loss: 0.5164 - val_accuracy: 0.7356\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4336 - accuracy: 0.7796 - val_loss: 0.5189 - val_accuracy: 0.7333\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4323 - accuracy: 0.7774 - val_loss: 0.5151 - val_accuracy: 0.7378\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4281 - accuracy: 0.7835 - val_loss: 0.5163 - val_accuracy: 0.7362\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4236 - accuracy: 0.7836 - val_loss: 0.5125 - val_accuracy: 0.7397\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4228 - accuracy: 0.7881 - val_loss: 0.5135 - val_accuracy: 0.7400\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4218 - accuracy: 0.7862 - val_loss: 0.5141 - val_accuracy: 0.7410\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4165 - accuracy: 0.7925 - val_loss: 0.5129 - val_accuracy: 0.7419\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4187 - accuracy: 0.7899 - val_loss: 0.5103 - val_accuracy: 0.7439\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4107 - accuracy: 0.7949 - val_loss: 0.5110 - val_accuracy: 0.7435\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4139 - accuracy: 0.7936 - val_loss: 0.5098 - val_accuracy: 0.7439\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4121 - accuracy: 0.7945 - val_loss: 0.5072 - val_accuracy: 0.7467\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4095 - accuracy: 0.7984 - val_loss: 0.5077 - val_accuracy: 0.7480\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4103 - accuracy: 0.7972 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4072 - accuracy: 0.7982 - val_loss: 0.5062 - val_accuracy: 0.7490\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4048 - accuracy: 0.8012 - val_loss: 0.5051 - val_accuracy: 0.7493\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.8050 - val_loss: 0.5046 - val_accuracy: 0.7506\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4002 - accuracy: 0.8064 - val_loss: 0.5086 - val_accuracy: 0.7477\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3986 - accuracy: 0.8081 - val_loss: 0.5040 - val_accuracy: 0.7493\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4055 - accuracy: 0.8013 - val_loss: 0.5057 - val_accuracy: 0.7499\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4021 - accuracy: 0.8054 - val_loss: 0.5037 - val_accuracy: 0.7490\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8068 - val_loss: 0.5040 - val_accuracy: 0.7490\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3953 - accuracy: 0.8070 - val_loss: 0.5046 - val_accuracy: 0.7490\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3921 - accuracy: 0.8121 - val_loss: 0.5025 - val_accuracy: 0.7509\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3910 - accuracy: 0.8131 - val_loss: 0.5023 - val_accuracy: 0.7506\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3912 - accuracy: 0.8138 - val_loss: 0.5025 - val_accuracy: 0.7499\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3846 - accuracy: 0.8156 - val_loss: 0.5010 - val_accuracy: 0.7560\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3928 - accuracy: 0.8083 - val_loss: 0.5012 - val_accuracy: 0.7522\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.8143 - val_loss: 0.5003 - val_accuracy: 0.7553\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3889 - accuracy: 0.8131 - val_loss: 0.5003 - val_accuracy: 0.7541\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3900 - accuracy: 0.8098 - val_loss: 0.4997 - val_accuracy: 0.7553\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3974 - accuracy: 0.8082 - val_loss: 0.5013 - val_accuracy: 0.7525\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3821 - accuracy: 0.8167 - val_loss: 0.4994 - val_accuracy: 0.7534\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3857 - accuracy: 0.8129 - val_loss: 0.4998 - val_accuracy: 0.7550\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3818 - accuracy: 0.8154 - val_loss: 0.4993 - val_accuracy: 0.7534\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3871 - accuracy: 0.8138 - val_loss: 0.5018 - val_accuracy: 0.7537\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3850 - accuracy: 0.8162 - val_loss: 0.4989 - val_accuracy: 0.7534\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3873 - accuracy: 0.8150 - val_loss: 0.4990 - val_accuracy: 0.7550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8174 - val_loss: 0.4980 - val_accuracy: 0.7547\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3868 - accuracy: 0.8174 - val_loss: 0.4981 - val_accuracy: 0.7550\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3871 - accuracy: 0.8150 - val_loss: 0.4976 - val_accuracy: 0.7518\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3843 - accuracy: 0.8141 - val_loss: 0.4971 - val_accuracy: 0.7547\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3810 - accuracy: 0.8175 - val_loss: 0.4968 - val_accuracy: 0.7547\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3816 - accuracy: 0.8173 - val_loss: 0.4965 - val_accuracy: 0.7547\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3820 - accuracy: 0.8199 - val_loss: 0.4965 - val_accuracy: 0.7537\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3858 - accuracy: 0.8178 - val_loss: 0.4972 - val_accuracy: 0.7531\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3778 - accuracy: 0.8222 - val_loss: 0.4961 - val_accuracy: 0.7537\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3828 - accuracy: 0.8185 - val_loss: 0.4966 - val_accuracy: 0.7553\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3759 - accuracy: 0.8223 - val_loss: 0.4956 - val_accuracy: 0.7534\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3820 - accuracy: 0.8161 - val_loss: 0.4953 - val_accuracy: 0.7541\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3791 - accuracy: 0.8207 - val_loss: 0.4949 - val_accuracy: 0.7550\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3820 - accuracy: 0.8215 - val_loss: 0.4945 - val_accuracy: 0.7537\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3788 - accuracy: 0.8182 - val_loss: 0.4942 - val_accuracy: 0.7563\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3827 - accuracy: 0.8166 - val_loss: 0.4939 - val_accuracy: 0.7566\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3808 - accuracy: 0.8187 - val_loss: 0.4949 - val_accuracy: 0.7537\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3834 - accuracy: 0.8173 - val_loss: 0.4935 - val_accuracy: 0.7547\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3832 - accuracy: 0.8166 - val_loss: 0.4928 - val_accuracy: 0.7566\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.8177 - val_loss: 0.4929 - val_accuracy: 0.7550\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3799 - accuracy: 0.8175 - val_loss: 0.4930 - val_accuracy: 0.7589\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3783 - accuracy: 0.8188 - val_loss: 0.4944 - val_accuracy: 0.7566\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3753 - accuracy: 0.8227 - val_loss: 0.4921 - val_accuracy: 0.7573\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3757 - accuracy: 0.8206 - val_loss: 0.4922 - val_accuracy: 0.7585\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3826 - accuracy: 0.8201 - val_loss: 0.4928 - val_accuracy: 0.7553\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3793 - accuracy: 0.8183 - val_loss: 0.4916 - val_accuracy: 0.7582\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.8236 - val_loss: 0.4911 - val_accuracy: 0.7598\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3810 - accuracy: 0.8193 - val_loss: 0.4917 - val_accuracy: 0.7560\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3791 - accuracy: 0.8187 - val_loss: 0.4906 - val_accuracy: 0.7579\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8201 - val_loss: 0.4896 - val_accuracy: 0.7595\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3749 - accuracy: 0.8205 - val_loss: 0.4895 - val_accuracy: 0.7589\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8207 - val_loss: 0.4921 - val_accuracy: 0.7557\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3782 - accuracy: 0.8184 - val_loss: 0.4893 - val_accuracy: 0.7576\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3701 - accuracy: 0.8247 - val_loss: 0.4889 - val_accuracy: 0.7589\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3736 - accuracy: 0.8196 - val_loss: 0.4887 - val_accuracy: 0.7576\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3781 - accuracy: 0.8186 - val_loss: 0.4890 - val_accuracy: 0.7566\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3707 - accuracy: 0.8223 - val_loss: 0.4883 - val_accuracy: 0.7595\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3769 - accuracy: 0.8184 - val_loss: 0.4879 - val_accuracy: 0.7604\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3758 - accuracy: 0.8193 - val_loss: 0.4873 - val_accuracy: 0.7608\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3835 - accuracy: 0.8154 - val_loss: 0.4871 - val_accuracy: 0.7601\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3775 - accuracy: 0.8186 - val_loss: 0.4871 - val_accuracy: 0.7604\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3704 - accuracy: 0.8242 - val_loss: 0.4872 - val_accuracy: 0.7582\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3764 - accuracy: 0.8195 - val_loss: 0.4863 - val_accuracy: 0.7589\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3757 - accuracy: 0.8185 - val_loss: 0.4857 - val_accuracy: 0.7592\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3721 - accuracy: 0.8222 - val_loss: 0.4858 - val_accuracy: 0.7595\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3768 - accuracy: 0.8188 - val_loss: 0.4857 - val_accuracy: 0.7598\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3815 - accuracy: 0.8192 - val_loss: 0.4861 - val_accuracy: 0.7598\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3683 - accuracy: 0.8251 - val_loss: 0.4892 - val_accuracy: 0.7550\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3745 - accuracy: 0.8181 - val_loss: 0.4849 - val_accuracy: 0.7611\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3797 - accuracy: 0.8158 - val_loss: 0.4843 - val_accuracy: 0.7601\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3662 - accuracy: 0.8247 - val_loss: 0.4844 - val_accuracy: 0.7598\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.8229 - val_loss: 0.4852 - val_accuracy: 0.7595\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3718 - accuracy: 0.8204 - val_loss: 0.4855 - val_accuracy: 0.7582\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.8243 - val_loss: 0.4903 - val_accuracy: 0.7528\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3736 - accuracy: 0.8232 - val_loss: 0.4838 - val_accuracy: 0.7617\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3696 - accuracy: 0.8263 - val_loss: 0.4857 - val_accuracy: 0.7579\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3658 - accuracy: 0.8267 - val_loss: 0.4833 - val_accuracy: 0.7604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3735 - accuracy: 0.8240 - val_loss: 0.4824 - val_accuracy: 0.7604\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3694 - accuracy: 0.8231 - val_loss: 0.4823 - val_accuracy: 0.7604\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8248 - val_loss: 0.4821 - val_accuracy: 0.7595\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3740 - accuracy: 0.8196 - val_loss: 0.4819 - val_accuracy: 0.7624\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3766 - accuracy: 0.8169 - val_loss: 0.4848 - val_accuracy: 0.7569\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3780 - accuracy: 0.8180 - val_loss: 0.4812 - val_accuracy: 0.7598\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.8154 - val_loss: 0.4824 - val_accuracy: 0.7585\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3696 - accuracy: 0.8238 - val_loss: 0.4810 - val_accuracy: 0.7617\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3737 - accuracy: 0.8194 - val_loss: 0.4815 - val_accuracy: 0.7592\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3728 - accuracy: 0.8227 - val_loss: 0.4812 - val_accuracy: 0.7598\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3795 - accuracy: 0.8181 - val_loss: 0.4819 - val_accuracy: 0.7585\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3640 - accuracy: 0.8291 - val_loss: 0.4824 - val_accuracy: 0.7576\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8260 - val_loss: 0.4834 - val_accuracy: 0.7553\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8245 - val_loss: 0.4797 - val_accuracy: 0.7627\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.8257 - val_loss: 0.4796 - val_accuracy: 0.7624\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3754 - accuracy: 0.8198 - val_loss: 0.4802 - val_accuracy: 0.7659\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3738 - accuracy: 0.8192 - val_loss: 0.4796 - val_accuracy: 0.7620\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8228 - val_loss: 0.4804 - val_accuracy: 0.7582\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3764 - accuracy: 0.8203 - val_loss: 0.4786 - val_accuracy: 0.7611\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.8211 - val_loss: 0.4827 - val_accuracy: 0.7537\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8210 - val_loss: 0.4798 - val_accuracy: 0.7582\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3722 - accuracy: 0.8240 - val_loss: 0.4824 - val_accuracy: 0.7534\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3672 - accuracy: 0.8273 - val_loss: 0.4780 - val_accuracy: 0.7627\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3734 - accuracy: 0.8229 - val_loss: 0.4799 - val_accuracy: 0.7579\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3693 - accuracy: 0.8243 - val_loss: 0.4778 - val_accuracy: 0.7614\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8263 - val_loss: 0.4808 - val_accuracy: 0.7563\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.8242 - val_loss: 0.4799 - val_accuracy: 0.7566\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3718 - accuracy: 0.8235 - val_loss: 0.4778 - val_accuracy: 0.7611\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3737 - accuracy: 0.8196 - val_loss: 0.4784 - val_accuracy: 0.7579\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3691 - accuracy: 0.8256 - val_loss: 0.4777 - val_accuracy: 0.7592\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3743 - accuracy: 0.8205 - val_loss: 0.4761 - val_accuracy: 0.7643\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8237 - val_loss: 0.4772 - val_accuracy: 0.7595\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8226 - val_loss: 0.4765 - val_accuracy: 0.7646\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3658 - accuracy: 0.8232 - val_loss: 0.4774 - val_accuracy: 0.7579\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3680 - accuracy: 0.8256 - val_loss: 0.4759 - val_accuracy: 0.7646\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3693 - accuracy: 0.8250 - val_loss: 0.4764 - val_accuracy: 0.7589\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3677 - accuracy: 0.8233 - val_loss: 0.4754 - val_accuracy: 0.7620\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8233 - val_loss: 0.4769 - val_accuracy: 0.7582\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3684 - accuracy: 0.8243 - val_loss: 0.4753 - val_accuracy: 0.7604\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3690 - accuracy: 0.8257 - val_loss: 0.4767 - val_accuracy: 0.7566\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3727 - accuracy: 0.8240 - val_loss: 0.4758 - val_accuracy: 0.7595\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8257 - val_loss: 0.4784 - val_accuracy: 0.7528\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3723 - accuracy: 0.8227 - val_loss: 0.4760 - val_accuracy: 0.7582\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8272 - val_loss: 0.4774 - val_accuracy: 0.7547\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.8274 - val_loss: 0.4755 - val_accuracy: 0.7585\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3744 - accuracy: 0.8194 - val_loss: 0.4741 - val_accuracy: 0.7620\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3645 - accuracy: 0.8289 - val_loss: 0.4771 - val_accuracy: 0.7550\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3697 - accuracy: 0.8235 - val_loss: 0.4746 - val_accuracy: 0.7604\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8272 - val_loss: 0.4757 - val_accuracy: 0.7579\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3699 - accuracy: 0.8237 - val_loss: 0.4756 - val_accuracy: 0.7573\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3708 - accuracy: 0.8232 - val_loss: 0.4785 - val_accuracy: 0.7499\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3637 - accuracy: 0.8317 - val_loss: 0.4745 - val_accuracy: 0.7598\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3676 - accuracy: 0.8237 - val_loss: 0.4736 - val_accuracy: 0.7604\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3650 - accuracy: 0.8292 - val_loss: 0.4739 - val_accuracy: 0.7611\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3691 - accuracy: 0.8223 - val_loss: 0.4740 - val_accuracy: 0.7601\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3664 - accuracy: 0.8254 - val_loss: 0.4753 - val_accuracy: 0.7544\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3645 - accuracy: 0.8258 - val_loss: 0.4746 - val_accuracy: 0.7566\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.8257 - val_loss: 0.4735 - val_accuracy: 0.7595\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3671 - accuracy: 0.8250 - val_loss: 0.4750 - val_accuracy: 0.7525\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3671 - accuracy: 0.8261 - val_loss: 0.4727 - val_accuracy: 0.7598\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3731 - accuracy: 0.8203 - val_loss: 0.4720 - val_accuracy: 0.7627\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3676 - accuracy: 0.8247 - val_loss: 0.4741 - val_accuracy: 0.7528\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3661 - accuracy: 0.8275 - val_loss: 0.4748 - val_accuracy: 0.7509\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3670 - accuracy: 0.8232 - val_loss: 0.4730 - val_accuracy: 0.7553\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3739 - accuracy: 0.8212 - val_loss: 0.4717 - val_accuracy: 0.7640\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3643 - accuracy: 0.8285 - val_loss: 0.4720 - val_accuracy: 0.7617\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3708 - accuracy: 0.8240 - val_loss: 0.4727 - val_accuracy: 0.7557\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3686 - accuracy: 0.8213 - val_loss: 0.4729 - val_accuracy: 0.7557\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3641 - accuracy: 0.8257 - val_loss: 0.4760 - val_accuracy: 0.7502\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3634 - accuracy: 0.8236 - val_loss: 0.4716 - val_accuracy: 0.7643\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3648 - accuracy: 0.8286 - val_loss: 0.4713 - val_accuracy: 0.7636\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3675 - accuracy: 0.8260 - val_loss: 0.4741 - val_accuracy: 0.7512\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8274 - val_loss: 0.4716 - val_accuracy: 0.7636\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3718 - accuracy: 0.8204 - val_loss: 0.4713 - val_accuracy: 0.7624\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8288 - val_loss: 0.4719 - val_accuracy: 0.7604\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8264 - val_loss: 0.4716 - val_accuracy: 0.7649\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3689 - accuracy: 0.8213 - val_loss: 0.4711 - val_accuracy: 0.7656\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3719 - accuracy: 0.8186 - val_loss: 0.4716 - val_accuracy: 0.7611\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3655 - accuracy: 0.8254 - val_loss: 0.4710 - val_accuracy: 0.7640\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3688 - accuracy: 0.8236 - val_loss: 0.4713 - val_accuracy: 0.7576\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.8229 - val_loss: 0.4706 - val_accuracy: 0.7646\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3683 - accuracy: 0.8231 - val_loss: 0.4705 - val_accuracy: 0.7633\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3717 - accuracy: 0.8183 - val_loss: 0.4725 - val_accuracy: 0.7665\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3726 - accuracy: 0.8229 - val_loss: 0.4708 - val_accuracy: 0.7630\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3628 - accuracy: 0.8244 - val_loss: 0.4710 - val_accuracy: 0.7601\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.8270 - val_loss: 0.4709 - val_accuracy: 0.7624\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.8261 - val_loss: 0.4709 - val_accuracy: 0.7611\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3688 - accuracy: 0.8207 - val_loss: 0.4708 - val_accuracy: 0.7643\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3678 - accuracy: 0.8251 - val_loss: 0.4708 - val_accuracy: 0.7573\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3756 - accuracy: 0.8218 - val_loss: 0.4714 - val_accuracy: 0.7547\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3677 - accuracy: 0.8238 - val_loss: 0.4701 - val_accuracy: 0.7627\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3709 - accuracy: 0.8259 - val_loss: 0.4706 - val_accuracy: 0.7611\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8300 - val_loss: 0.4703 - val_accuracy: 0.7640\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.8272 - val_loss: 0.4704 - val_accuracy: 0.7633\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3652 - accuracy: 0.8264 - val_loss: 0.4707 - val_accuracy: 0.7649\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3642 - accuracy: 0.8266 - val_loss: 0.4717 - val_accuracy: 0.7550\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.8225 - val_loss: 0.4706 - val_accuracy: 0.7620\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8289 - val_loss: 0.4705 - val_accuracy: 0.7633\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3541 - accuracy: 0.8329 - val_loss: 0.4710 - val_accuracy: 0.7601\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3651 - accuracy: 0.8239 - val_loss: 0.4702 - val_accuracy: 0.7620\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3679 - accuracy: 0.8228 - val_loss: 0.4716 - val_accuracy: 0.7646\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3595 - accuracy: 0.8298 - val_loss: 0.4708 - val_accuracy: 0.7640\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3671 - accuracy: 0.8258 - val_loss: 0.4707 - val_accuracy: 0.7592\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3650 - accuracy: 0.8258 - val_loss: 0.4710 - val_accuracy: 0.7573\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8273 - val_loss: 0.4702 - val_accuracy: 0.7611\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.8269 - val_loss: 0.4702 - val_accuracy: 0.7630\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3702 - accuracy: 0.8260 - val_loss: 0.4701 - val_accuracy: 0.7640\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3647 - accuracy: 0.8242 - val_loss: 0.4709 - val_accuracy: 0.7563\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3662 - accuracy: 0.8259 - val_loss: 0.4701 - val_accuracy: 0.7604\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3687 - accuracy: 0.8245 - val_loss: 0.4705 - val_accuracy: 0.7640\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3633 - accuracy: 0.8290 - val_loss: 0.4705 - val_accuracy: 0.7617\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3663 - accuracy: 0.8280 - val_loss: 0.4701 - val_accuracy: 0.7646\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.8212 - val_loss: 0.4699 - val_accuracy: 0.7633\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3634 - accuracy: 0.8253 - val_loss: 0.4699 - val_accuracy: 0.7595\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.8278 - val_loss: 0.4701 - val_accuracy: 0.7640\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3668 - accuracy: 0.8294 - val_loss: 0.4699 - val_accuracy: 0.7617\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3630 - accuracy: 0.8273 - val_loss: 0.4699 - val_accuracy: 0.7614\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3695 - accuracy: 0.8256 - val_loss: 0.4701 - val_accuracy: 0.7652\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3654 - accuracy: 0.8259 - val_loss: 0.4699 - val_accuracy: 0.7624\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3624 - accuracy: 0.8293 - val_loss: 0.4696 - val_accuracy: 0.7595\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3706 - accuracy: 0.8207 - val_loss: 0.4692 - val_accuracy: 0.7614\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3666 - accuracy: 0.8285 - val_loss: 0.4699 - val_accuracy: 0.7579\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3648 - accuracy: 0.8258 - val_loss: 0.4694 - val_accuracy: 0.7611\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3664 - accuracy: 0.8247 - val_loss: 0.4698 - val_accuracy: 0.7624\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3632 - accuracy: 0.8284 - val_loss: 0.4706 - val_accuracy: 0.7656\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3641 - accuracy: 0.8293 - val_loss: 0.4712 - val_accuracy: 0.7528\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3612 - accuracy: 0.8301 - val_loss: 0.4703 - val_accuracy: 0.7573\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3682 - accuracy: 0.8221 - val_loss: 0.4707 - val_accuracy: 0.7534\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3628 - accuracy: 0.8253 - val_loss: 0.4699 - val_accuracy: 0.7592\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3620 - accuracy: 0.8275 - val_loss: 0.4713 - val_accuracy: 0.7662\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3592 - accuracy: 0.8335 - val_loss: 0.4702 - val_accuracy: 0.7640\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3637 - accuracy: 0.8261 - val_loss: 0.4705 - val_accuracy: 0.7636\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3705 - accuracy: 0.8266 - val_loss: 0.4703 - val_accuracy: 0.7582\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8320 - val_loss: 0.4700 - val_accuracy: 0.7611\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3598 - accuracy: 0.8270 - val_loss: 0.4709 - val_accuracy: 0.7531\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8256 - val_loss: 0.4706 - val_accuracy: 0.7614\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8291 - val_loss: 0.4709 - val_accuracy: 0.7620\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3605 - accuracy: 0.8288 - val_loss: 0.4705 - val_accuracy: 0.7598\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.8274 - val_loss: 0.4701 - val_accuracy: 0.7608\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3569 - accuracy: 0.8315 - val_loss: 0.4709 - val_accuracy: 0.7646\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.8268 - val_loss: 0.4714 - val_accuracy: 0.7652\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3661 - accuracy: 0.8248 - val_loss: 0.4700 - val_accuracy: 0.7617\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3630 - accuracy: 0.8291 - val_loss: 0.4711 - val_accuracy: 0.7509\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8309 - val_loss: 0.4733 - val_accuracy: 0.7614\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3617 - accuracy: 0.8290 - val_loss: 0.4707 - val_accuracy: 0.7640\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3560 - accuracy: 0.8319 - val_loss: 0.4713 - val_accuracy: 0.7509\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3617 - accuracy: 0.8304 - val_loss: 0.4705 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3657 - accuracy: 0.8264 - val_loss: 0.4712 - val_accuracy: 0.7636\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3627 - accuracy: 0.8267 - val_loss: 0.4709 - val_accuracy: 0.7636\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3655 - accuracy: 0.8243 - val_loss: 0.4703 - val_accuracy: 0.7608\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3591 - accuracy: 0.8292 - val_loss: 0.4702 - val_accuracy: 0.7611\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3677 - accuracy: 0.8278 - val_loss: 0.4708 - val_accuracy: 0.7640\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3638 - accuracy: 0.8271 - val_loss: 0.4717 - val_accuracy: 0.7630\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3716 - accuracy: 0.8228 - val_loss: 0.4710 - val_accuracy: 0.7525\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3584 - accuracy: 0.8280 - val_loss: 0.4713 - val_accuracy: 0.7630\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.8283 - val_loss: 0.4708 - val_accuracy: 0.7611\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8294 - val_loss: 0.4728 - val_accuracy: 0.7624\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3601 - accuracy: 0.8274 - val_loss: 0.4711 - val_accuracy: 0.7614\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3576 - accuracy: 0.8318 - val_loss: 0.4709 - val_accuracy: 0.7604\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3614 - accuracy: 0.8297 - val_loss: 0.4719 - val_accuracy: 0.7624\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3627 - accuracy: 0.8300 - val_loss: 0.4735 - val_accuracy: 0.7611\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3599 - accuracy: 0.8304 - val_loss: 0.4730 - val_accuracy: 0.7614\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8318 - val_loss: 0.4734 - val_accuracy: 0.7611\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3676 - accuracy: 0.8240 - val_loss: 0.4745 - val_accuracy: 0.7611\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3665 - accuracy: 0.8227 - val_loss: 0.4713 - val_accuracy: 0.7620\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3571 - accuracy: 0.8291 - val_loss: 0.4728 - val_accuracy: 0.7620\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3619 - accuracy: 0.8313 - val_loss: 0.4716 - val_accuracy: 0.7630\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3689 - accuracy: 0.8262 - val_loss: 0.4712 - val_accuracy: 0.7620\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8300 - val_loss: 0.4709 - val_accuracy: 0.7589\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3644 - accuracy: 0.8252 - val_loss: 0.4737 - val_accuracy: 0.7595\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3623 - accuracy: 0.8313 - val_loss: 0.4734 - val_accuracy: 0.7595\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3651 - accuracy: 0.8280 - val_loss: 0.4728 - val_accuracy: 0.7617\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3684 - accuracy: 0.8243 - val_loss: 0.4737 - val_accuracy: 0.7601\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3687 - accuracy: 0.8239 - val_loss: 0.4729 - val_accuracy: 0.7627\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3587 - accuracy: 0.8346 - val_loss: 0.4716 - val_accuracy: 0.7512\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3639 - accuracy: 0.8270 - val_loss: 0.4752 - val_accuracy: 0.7617\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3570 - accuracy: 0.8291 - val_loss: 0.4718 - val_accuracy: 0.7541\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3614 - accuracy: 0.8300 - val_loss: 0.4762 - val_accuracy: 0.7601\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3631 - accuracy: 0.8277 - val_loss: 0.4755 - val_accuracy: 0.7598\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3589 - accuracy: 0.8308 - val_loss: 0.4739 - val_accuracy: 0.7598\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3533 - accuracy: 0.8326 - val_loss: 0.4730 - val_accuracy: 0.7608\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3610 - accuracy: 0.8312 - val_loss: 0.4759 - val_accuracy: 0.7598\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3643 - accuracy: 0.8272 - val_loss: 0.4719 - val_accuracy: 0.7598\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.8297 - val_loss: 0.4732 - val_accuracy: 0.7620\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3618 - accuracy: 0.8277 - val_loss: 0.4727 - val_accuracy: 0.7608\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3626 - accuracy: 0.8291 - val_loss: 0.4752 - val_accuracy: 0.7589\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3622 - accuracy: 0.8249 - val_loss: 0.4753 - val_accuracy: 0.7585\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3611 - accuracy: 0.8331 - val_loss: 0.4722 - val_accuracy: 0.7531\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3603 - accuracy: 0.8293 - val_loss: 0.4736 - val_accuracy: 0.7611\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3596 - accuracy: 0.8259 - val_loss: 0.4734 - val_accuracy: 0.7617\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3590 - accuracy: 0.8275 - val_loss: 0.4764 - val_accuracy: 0.7611\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3565 - accuracy: 0.8332 - val_loss: 0.4728 - val_accuracy: 0.7614\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3574 - accuracy: 0.8294 - val_loss: 0.4719 - val_accuracy: 0.7592\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3653 - accuracy: 0.8259 - val_loss: 0.4796 - val_accuracy: 0.7604\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3572 - accuracy: 0.8328 - val_loss: 0.4726 - val_accuracy: 0.7592\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3571 - accuracy: 0.8322 - val_loss: 0.4734 - val_accuracy: 0.7598\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3636 - accuracy: 0.8271 - val_loss: 0.4770 - val_accuracy: 0.7608\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3581 - accuracy: 0.8289 - val_loss: 0.4763 - val_accuracy: 0.7595\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3600 - accuracy: 0.8280 - val_loss: 0.4752 - val_accuracy: 0.7604\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3655 - accuracy: 0.8239 - val_loss: 0.4775 - val_accuracy: 0.7601\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.8309 - val_loss: 0.4731 - val_accuracy: 0.7601\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3620 - accuracy: 0.8256 - val_loss: 0.4724 - val_accuracy: 0.7598\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3606 - accuracy: 0.8307 - val_loss: 0.4762 - val_accuracy: 0.7598\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3605 - accuracy: 0.8263 - val_loss: 0.4755 - val_accuracy: 0.7601\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3645 - accuracy: 0.8284 - val_loss: 0.4804 - val_accuracy: 0.7604\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3681 - accuracy: 0.8257 - val_loss: 0.4745 - val_accuracy: 0.7573\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3607 - accuracy: 0.8301 - val_loss: 0.4806 - val_accuracy: 0.7592\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3632 - accuracy: 0.8269 - val_loss: 0.4803 - val_accuracy: 0.7589\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3603 - accuracy: 0.8279 - val_loss: 0.4742 - val_accuracy: 0.7589\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3658 - accuracy: 0.8262 - val_loss: 0.4771 - val_accuracy: 0.7595\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3513 - accuracy: 0.8369 - val_loss: 0.4798 - val_accuracy: 0.7589\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3603 - accuracy: 0.8307 - val_loss: 0.4812 - val_accuracy: 0.7598\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3613 - accuracy: 0.8288 - val_loss: 0.4803 - val_accuracy: 0.7592\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3608 - accuracy: 0.8279 - val_loss: 0.4751 - val_accuracy: 0.7582\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3619 - accuracy: 0.8319 - val_loss: 0.4769 - val_accuracy: 0.7592\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3629 - accuracy: 0.8277 - val_loss: 0.4821 - val_accuracy: 0.7601\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 0.3584 - accuracy: 0.8300 - val_loss: 0.4846 - val_accuracy: 0.7617\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3567 - accuracy: 0.8329 - val_loss: 0.4773 - val_accuracy: 0.7592\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.3635 - accuracy: 0.8273 - val_loss: 0.4800 - val_accuracy: 0.7585\n",
      "Epoch 00329: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model2 = model_two()\n",
    "history = model2.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.47995850443840027, 0.758532702922821]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 35ms/step - loss: 9.5219 - accuracy: 0.3773 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.4163 - accuracy: 0.6912 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5177 - accuracy: 0.7037 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.4928 - accuracy: 0.7054 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5368 - accuracy: 0.7025 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4891 - accuracy: 0.7056 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4778 - accuracy: 0.7064 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4039 - accuracy: 0.7112 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3835 - accuracy: 0.7125 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5098 - accuracy: 0.7043 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4883 - accuracy: 0.7057 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4128 - accuracy: 0.7106 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4541 - accuracy: 0.7079 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5088 - accuracy: 0.7043 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4044 - accuracy: 0.7112 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3765 - accuracy: 0.7130 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4577 - accuracy: 0.7077 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3925 - accuracy: 0.7120 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5473 - accuracy: 0.7018 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4570 - accuracy: 0.7077 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4880 - accuracy: 0.7057 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3944 - accuracy: 0.7118 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4573 - accuracy: 0.7077 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5194 - accuracy: 0.7036 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4008 - accuracy: 0.7114 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4444 - accuracy: 0.7085 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4382 - accuracy: 0.7090 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5491 - accuracy: 0.7017 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4571 - accuracy: 0.7077 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4900 - accuracy: 0.7056 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4430 - accuracy: 0.7086 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4878 - accuracy: 0.7057 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4241 - accuracy: 0.7099 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4557 - accuracy: 0.7078 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5830 - accuracy: 0.6995 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5253 - accuracy: 0.7032 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5897 - accuracy: 0.6990 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4422 - accuracy: 0.7087 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4848 - accuracy: 0.7059 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4786 - accuracy: 0.7063 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5757 - accuracy: 0.6999 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4913 - accuracy: 0.7055 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4585 - accuracy: 0.7076 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3751 - accuracy: 0.7131 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4237 - accuracy: 0.7099 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4482 - accuracy: 0.7083 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3831 - accuracy: 0.7126 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4926 - accuracy: 0.7054 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4018 - accuracy: 0.7113 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4665 - accuracy: 0.7071 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4541 - accuracy: 0.7079 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4240 - accuracy: 0.7099 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4831 - accuracy: 0.7060 - val_loss: 4.4459 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4261 - accuracy: 0.7097 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4143 - accuracy: 0.7105 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5383 - accuracy: 0.7024 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4004 - accuracy: 0.7114 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3492 - accuracy: 0.7148 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.3751 - accuracy: 0.7131 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4704 - accuracy: 0.7068 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4290 - accuracy: 0.7096 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4383 - accuracy: 0.7089 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4606 - accuracy: 0.7075 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3901 - accuracy: 0.7121 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3433 - accuracy: 0.7152 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5379 - accuracy: 0.7024 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4291 - accuracy: 0.7096 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.5303 - accuracy: 0.7029 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4528 - accuracy: 0.7080 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4693 - accuracy: 0.7069 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4217 - accuracy: 0.7100 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4472 - accuracy: 0.7084 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4536 - accuracy: 0.7079 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4375 - accuracy: 0.7090 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4304 - accuracy: 0.7095 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4429 - accuracy: 0.7086 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5507 - accuracy: 0.7016 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4696 - accuracy: 0.7069 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4988 - accuracy: 0.7050 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5117 - accuracy: 0.7041 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4528 - accuracy: 0.7080 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5669 - accuracy: 0.7005 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4762 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4792 - accuracy: 0.7063 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4587 - accuracy: 0.7076 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3718 - accuracy: 0.7133 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3951 - accuracy: 0.7118 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4242 - accuracy: 0.7099 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4604 - accuracy: 0.7075 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4730 - accuracy: 0.7067 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4502 - accuracy: 0.7082 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4692 - accuracy: 0.7069 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3211 - accuracy: 0.7166 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4789 - accuracy: 0.7063 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5298 - accuracy: 0.7029 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4186 - accuracy: 0.7102 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4246 - accuracy: 0.7098 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4266 - accuracy: 0.7097 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4671 - accuracy: 0.7071 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4155 - accuracy: 0.7104 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4246 - accuracy: 0.7098 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3857 - accuracy: 0.7124 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4654 - accuracy: 0.7072 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4612 - accuracy: 0.7074 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5775 - accuracy: 0.6998 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4748 - accuracy: 0.7066 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4440 - accuracy: 0.7086 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4694 - accuracy: 0.7069 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4834 - accuracy: 0.7060 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3900 - accuracy: 0.7121 - val_loss: 4.4459 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4066 - accuracy: 0.7110 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4162 - accuracy: 0.7104 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4670 - accuracy: 0.7071 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4296 - accuracy: 0.7095 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.5166 - accuracy: 0.7038 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5688 - accuracy: 0.7004 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3606 - accuracy: 0.7140 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4655 - accuracy: 0.7072 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4104 - accuracy: 0.7108 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4627 - accuracy: 0.7073 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5544 - accuracy: 0.7013 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4623 - accuracy: 0.7074 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4499 - accuracy: 0.7082 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4042 - accuracy: 0.7112 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4968 - accuracy: 0.7051 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4429 - accuracy: 0.7086 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5385 - accuracy: 0.7024 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.3852 - accuracy: 0.7124 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4782 - accuracy: 0.7063 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3936 - accuracy: 0.7119 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5182 - accuracy: 0.7037 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4971 - accuracy: 0.7051 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3302 - accuracy: 0.7160 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.6114 - accuracy: 0.6976 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.5429 - accuracy: 0.7021 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3393 - accuracy: 0.7154 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - ETA: 0s - loss: 4.4299 - accuracy: 0.70 - 0s 14ms/step - loss: 4.4324 - accuracy: 0.7093 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4814 - accuracy: 0.7061 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.5406 - accuracy: 0.7022 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4603 - accuracy: 0.7075 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4750 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4358 - accuracy: 0.7091 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4676 - accuracy: 0.7070 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4977 - accuracy: 0.7051 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.6157 - accuracy: 0.6973 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4680 - accuracy: 0.7070 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4546 - accuracy: 0.7079 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4935 - accuracy: 0.7053 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5597 - accuracy: 0.7010 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5035 - accuracy: 0.7047 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5138 - accuracy: 0.7040 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4949 - accuracy: 0.7052 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4762 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4521 - accuracy: 0.7080 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3900 - accuracy: 0.7121 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.3267 - accuracy: 0.7163 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 4.4725 - accuracy: 0.7067 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5010 - accuracy: 0.7048 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5070 - accuracy: 0.7044 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4769 - accuracy: 0.7064 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4258 - accuracy: 0.7098 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4920 - accuracy: 0.7054 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4914 - accuracy: 0.7055 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4463 - accuracy: 0.7084 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4755 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.3858 - accuracy: 0.7124 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4974 - accuracy: 0.7051 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3474 - accuracy: 0.7149 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.5152 - accuracy: 0.7039 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4306 - accuracy: 0.7095 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4676 - accuracy: 0.7070 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4101 - accuracy: 0.7108 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4750 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4917 - accuracy: 0.7054 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4993 - accuracy: 0.7049 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4090 - accuracy: 0.7109 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4119 - accuracy: 0.7107 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4954 - accuracy: 0.7052 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.3753 - accuracy: 0.7131 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4016 - accuracy: 0.7114 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4659 - accuracy: 0.7071 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4522 - accuracy: 0.7080 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4855 - accuracy: 0.7059 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4078 - accuracy: 0.7109 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3433 - accuracy: 0.7152 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4099 - accuracy: 0.7108 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.3992 - accuracy: 0.7115 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5031 - accuracy: 0.7047 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4765 - accuracy: 0.7064 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.4026 - accuracy: 0.7113 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4393 - accuracy: 0.7089 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.5078 - accuracy: 0.7044 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4693 - accuracy: 0.7069 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5131 - accuracy: 0.7040 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.4763 - accuracy: 0.7065 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3623 - accuracy: 0.7139 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.4107 - accuracy: 0.7108 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 4.5170 - accuracy: 0.7038 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3969 - accuracy: 0.7117 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 4.3759 - accuracy: 0.7130 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 4.5191 - accuracy: 0.7036 - val_loss: 4.4459 - val_accuracy: 0.7085\n",
      "Epoch 00201: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model3 = model_three()\n",
    "history = model3.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 4.4459 - accuracy: 0.7085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.445871353149414, 0.7084529399871826]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 32ms/step - loss: 0.6090 - accuracy: 0.7139 - val_loss: 0.6068 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6061 - accuracy: 0.7081 - val_loss: 0.6059 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6076 - accuracy: 0.7042 - val_loss: 0.6054 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6000 - accuracy: 0.7106 - val_loss: 0.6048 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6002 - accuracy: 0.7087 - val_loss: 0.6042 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6026 - accuracy: 0.7036 - val_loss: 0.6037 - val_accuracy: 0.7085\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5973 - accuracy: 0.7081 - val_loss: 0.6032 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5941 - accuracy: 0.7095 - val_loss: 0.6025 - val_accuracy: 0.7085\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5956 - accuracy: 0.7051 - val_loss: 0.6018 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5931 - accuracy: 0.7056 - val_loss: 0.6016 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5891 - accuracy: 0.7071 - val_loss: 0.6003 - val_accuracy: 0.7085\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5838 - accuracy: 0.7103 - val_loss: 0.5999 - val_accuracy: 0.7085\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5840 - accuracy: 0.7066 - val_loss: 0.5984 - val_accuracy: 0.7085\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5818 - accuracy: 0.7044 - val_loss: 0.5975 - val_accuracy: 0.7085\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5758 - accuracy: 0.7072 - val_loss: 0.5965 - val_accuracy: 0.7085\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.7074 - val_loss: 0.5948 - val_accuracy: 0.7085\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5624 - accuracy: 0.7108 - val_loss: 0.5935 - val_accuracy: 0.7085\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5506 - accuracy: 0.7171 - val_loss: 0.5900 - val_accuracy: 0.7085\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5495 - accuracy: 0.7111 - val_loss: 0.5885 - val_accuracy: 0.7085\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5467 - accuracy: 0.7052 - val_loss: 0.5883 - val_accuracy: 0.7085\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5382 - accuracy: 0.7044 - val_loss: 0.5860 - val_accuracy: 0.7085\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5271 - accuracy: 0.7096 - val_loss: 0.5828 - val_accuracy: 0.7085\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5196 - accuracy: 0.7098 - val_loss: 0.5846 - val_accuracy: 0.7085\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5124 - accuracy: 0.7108 - val_loss: 0.5844 - val_accuracy: 0.7091\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7195 - val_loss: 0.5765 - val_accuracy: 0.7120\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4917 - accuracy: 0.7294 - val_loss: 0.5745 - val_accuracy: 0.7126\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4858 - accuracy: 0.7338 - val_loss: 0.5807 - val_accuracy: 0.7132\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4780 - accuracy: 0.7371 - val_loss: 0.5854 - val_accuracy: 0.7132\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4680 - accuracy: 0.7475 - val_loss: 0.5783 - val_accuracy: 0.7142\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4630 - accuracy: 0.7566 - val_loss: 0.5780 - val_accuracy: 0.7139\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4592 - accuracy: 0.7611 - val_loss: 0.5764 - val_accuracy: 0.7139\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4584 - accuracy: 0.7593 - val_loss: 0.5866 - val_accuracy: 0.7142\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4503 - accuracy: 0.7637 - val_loss: 0.5815 - val_accuracy: 0.7142\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4506 - accuracy: 0.7642 - val_loss: 0.5932 - val_accuracy: 0.7139\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4437 - accuracy: 0.7661 - val_loss: 0.5784 - val_accuracy: 0.7145\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4440 - accuracy: 0.7700 - val_loss: 0.5815 - val_accuracy: 0.7148\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4388 - accuracy: 0.7792 - val_loss: 0.5883 - val_accuracy: 0.7145\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4323 - accuracy: 0.7753 - val_loss: 0.5903 - val_accuracy: 0.7148\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4378 - accuracy: 0.7762 - val_loss: 0.6001 - val_accuracy: 0.7148\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4360 - accuracy: 0.7752 - val_loss: 0.5925 - val_accuracy: 0.7145\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4301 - accuracy: 0.7820 - val_loss: 0.5961 - val_accuracy: 0.7145\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4279 - accuracy: 0.7802 - val_loss: 0.6107 - val_accuracy: 0.7152\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4293 - accuracy: 0.7812 - val_loss: 0.6100 - val_accuracy: 0.7155\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4305 - accuracy: 0.7804 - val_loss: 0.6127 - val_accuracy: 0.7155\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4198 - accuracy: 0.7888 - val_loss: 0.5963 - val_accuracy: 0.7164\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4255 - accuracy: 0.7837 - val_loss: 0.6028 - val_accuracy: 0.7155\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4160 - accuracy: 0.7892 - val_loss: 0.5986 - val_accuracy: 0.7161\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4230 - accuracy: 0.7837 - val_loss: 0.5902 - val_accuracy: 0.7167\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.7827 - val_loss: 0.5949 - val_accuracy: 0.7167\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4138 - accuracy: 0.7865 - val_loss: 0.5849 - val_accuracy: 0.7167\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4100 - accuracy: 0.7968 - val_loss: 0.5972 - val_accuracy: 0.7171\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.7899 - val_loss: 0.6135 - val_accuracy: 0.7161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4162 - accuracy: 0.7889 - val_loss: 0.5821 - val_accuracy: 0.7187\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4126 - accuracy: 0.7975 - val_loss: 0.5772 - val_accuracy: 0.7187\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4121 - accuracy: 0.7945 - val_loss: 0.5988 - val_accuracy: 0.7183\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4094 - accuracy: 0.7943 - val_loss: 0.5893 - val_accuracy: 0.7196\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4061 - accuracy: 0.7975 - val_loss: 0.5897 - val_accuracy: 0.7203\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4037 - accuracy: 0.8001 - val_loss: 0.5921 - val_accuracy: 0.7203\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4066 - accuracy: 0.7982 - val_loss: 0.5799 - val_accuracy: 0.7228\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8064 - val_loss: 0.5727 - val_accuracy: 0.7222\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4019 - accuracy: 0.8036 - val_loss: 0.5917 - val_accuracy: 0.7219\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3971 - accuracy: 0.8105 - val_loss: 0.5847 - val_accuracy: 0.7231\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3999 - accuracy: 0.8028 - val_loss: 0.5720 - val_accuracy: 0.7238\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3983 - accuracy: 0.8081 - val_loss: 0.5827 - val_accuracy: 0.7238\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3947 - accuracy: 0.8092 - val_loss: 0.5691 - val_accuracy: 0.7273\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8044 - val_loss: 0.5802 - val_accuracy: 0.7254\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3952 - accuracy: 0.8108 - val_loss: 0.5752 - val_accuracy: 0.7279\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3910 - accuracy: 0.8124 - val_loss: 0.5776 - val_accuracy: 0.7282\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3880 - accuracy: 0.8128 - val_loss: 0.5746 - val_accuracy: 0.7301\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3940 - accuracy: 0.8117 - val_loss: 0.5762 - val_accuracy: 0.7317\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3926 - accuracy: 0.8092 - val_loss: 0.5806 - val_accuracy: 0.7321\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3913 - accuracy: 0.8111 - val_loss: 0.5917 - val_accuracy: 0.7317\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3882 - accuracy: 0.8120 - val_loss: 0.5744 - val_accuracy: 0.7343\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3857 - accuracy: 0.8143 - val_loss: 0.5538 - val_accuracy: 0.7375\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3822 - accuracy: 0.8188 - val_loss: 0.5733 - val_accuracy: 0.7359\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3876 - accuracy: 0.8135 - val_loss: 0.5818 - val_accuracy: 0.7352\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.8186 - val_loss: 0.5652 - val_accuracy: 0.7372\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3866 - accuracy: 0.8142 - val_loss: 0.5763 - val_accuracy: 0.7372\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8199 - val_loss: 0.5670 - val_accuracy: 0.7381\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8069 - val_loss: 0.5513 - val_accuracy: 0.7381\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3880 - accuracy: 0.8141 - val_loss: 0.5751 - val_accuracy: 0.7388\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3864 - accuracy: 0.8137 - val_loss: 0.5516 - val_accuracy: 0.7394\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3875 - accuracy: 0.8149 - val_loss: 0.5560 - val_accuracy: 0.7397\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3848 - accuracy: 0.8172 - val_loss: 0.5499 - val_accuracy: 0.7407\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3850 - accuracy: 0.8171 - val_loss: 0.5401 - val_accuracy: 0.7384\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3841 - accuracy: 0.8187 - val_loss: 0.5603 - val_accuracy: 0.7407\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3783 - accuracy: 0.8210 - val_loss: 0.5299 - val_accuracy: 0.7458\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3807 - accuracy: 0.8219 - val_loss: 0.5447 - val_accuracy: 0.7404\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3815 - accuracy: 0.8188 - val_loss: 0.5400 - val_accuracy: 0.7404\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3825 - accuracy: 0.8132 - val_loss: 0.5522 - val_accuracy: 0.7410\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3816 - accuracy: 0.8184 - val_loss: 0.5417 - val_accuracy: 0.7407\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3869 - accuracy: 0.8197 - val_loss: 0.5446 - val_accuracy: 0.7419\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8158 - val_loss: 0.5275 - val_accuracy: 0.7467\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3814 - accuracy: 0.8158 - val_loss: 0.5317 - val_accuracy: 0.7429\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3840 - accuracy: 0.8162 - val_loss: 0.5303 - val_accuracy: 0.7429\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3763 - accuracy: 0.8189 - val_loss: 0.5268 - val_accuracy: 0.7470\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3819 - accuracy: 0.8203 - val_loss: 0.5406 - val_accuracy: 0.7432\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3820 - accuracy: 0.8177 - val_loss: 0.5304 - val_accuracy: 0.7439\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3862 - accuracy: 0.8151 - val_loss: 0.5253 - val_accuracy: 0.7483\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.8202 - val_loss: 0.5360 - val_accuracy: 0.7426\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3774 - accuracy: 0.8195 - val_loss: 0.5321 - val_accuracy: 0.7445\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8229 - val_loss: 0.5175 - val_accuracy: 0.7525\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8195 - val_loss: 0.5151 - val_accuracy: 0.7522\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8209 - val_loss: 0.5258 - val_accuracy: 0.7464\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3766 - accuracy: 0.8221 - val_loss: 0.5329 - val_accuracy: 0.7451\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3735 - accuracy: 0.8196 - val_loss: 0.5188 - val_accuracy: 0.7512\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3830 - accuracy: 0.8193 - val_loss: 0.5144 - val_accuracy: 0.7541\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3772 - accuracy: 0.8186 - val_loss: 0.5281 - val_accuracy: 0.7467\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3829 - accuracy: 0.8150 - val_loss: 0.5173 - val_accuracy: 0.7512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3742 - accuracy: 0.8193 - val_loss: 0.5081 - val_accuracy: 0.7544\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.8184 - val_loss: 0.5169 - val_accuracy: 0.7512\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3750 - accuracy: 0.8240 - val_loss: 0.5204 - val_accuracy: 0.7512\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3822 - accuracy: 0.8162 - val_loss: 0.5190 - val_accuracy: 0.7506\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3730 - accuracy: 0.8223 - val_loss: 0.5128 - val_accuracy: 0.7534\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3767 - accuracy: 0.8200 - val_loss: 0.5069 - val_accuracy: 0.7566\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8213 - val_loss: 0.5140 - val_accuracy: 0.7518\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8187 - val_loss: 0.5061 - val_accuracy: 0.7563\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3842 - accuracy: 0.8158 - val_loss: 0.5048 - val_accuracy: 0.7557\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3782 - accuracy: 0.8183 - val_loss: 0.5037 - val_accuracy: 0.7541\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8217 - val_loss: 0.5071 - val_accuracy: 0.7569\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8239 - val_loss: 0.5081 - val_accuracy: 0.7566\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3839 - accuracy: 0.8189 - val_loss: 0.5046 - val_accuracy: 0.7598\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3803 - accuracy: 0.8213 - val_loss: 0.5065 - val_accuracy: 0.7579\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3795 - accuracy: 0.8192 - val_loss: 0.5130 - val_accuracy: 0.7531\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3740 - accuracy: 0.8228 - val_loss: 0.5024 - val_accuracy: 0.7592\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3700 - accuracy: 0.8218 - val_loss: 0.5003 - val_accuracy: 0.7560\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3768 - accuracy: 0.8185 - val_loss: 0.5004 - val_accuracy: 0.7601\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3776 - accuracy: 0.8216 - val_loss: 0.4997 - val_accuracy: 0.7589\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 0.8179 - val_loss: 0.5043 - val_accuracy: 0.7598\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8203 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3759 - accuracy: 0.8231 - val_loss: 0.5036 - val_accuracy: 0.7585\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3776 - accuracy: 0.8219 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 0.8221 - val_loss: 0.4972 - val_accuracy: 0.7576\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3844 - accuracy: 0.8158 - val_loss: 0.4967 - val_accuracy: 0.7569\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3747 - accuracy: 0.8215 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3746 - accuracy: 0.8221 - val_loss: 0.4968 - val_accuracy: 0.7557\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3725 - accuracy: 0.8211 - val_loss: 0.4991 - val_accuracy: 0.7493\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3750 - accuracy: 0.8215 - val_loss: 0.4952 - val_accuracy: 0.7614\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3720 - accuracy: 0.8239 - val_loss: 0.4944 - val_accuracy: 0.7598\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8205 - val_loss: 0.4946 - val_accuracy: 0.7630\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3739 - accuracy: 0.8220 - val_loss: 0.4943 - val_accuracy: 0.7592\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3796 - accuracy: 0.8180 - val_loss: 0.4943 - val_accuracy: 0.7550\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3651 - accuracy: 0.8275 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3792 - accuracy: 0.8172 - val_loss: 0.4964 - val_accuracy: 0.7617\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3797 - accuracy: 0.8173 - val_loss: 0.4975 - val_accuracy: 0.7474\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3711 - accuracy: 0.8241 - val_loss: 0.4919 - val_accuracy: 0.7601\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3689 - accuracy: 0.8263 - val_loss: 0.4945 - val_accuracy: 0.7518\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3727 - accuracy: 0.8226 - val_loss: 0.4914 - val_accuracy: 0.7598\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.8266 - val_loss: 0.4910 - val_accuracy: 0.7627\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3709 - accuracy: 0.8225 - val_loss: 0.4908 - val_accuracy: 0.7595\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3679 - accuracy: 0.8260 - val_loss: 0.4905 - val_accuracy: 0.7601\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3784 - accuracy: 0.8214 - val_loss: 0.4900 - val_accuracy: 0.7611\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3749 - accuracy: 0.8161 - val_loss: 0.4901 - val_accuracy: 0.7624\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8219 - val_loss: 0.4910 - val_accuracy: 0.7553\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3762 - accuracy: 0.8140 - val_loss: 0.4917 - val_accuracy: 0.7557\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3734 - accuracy: 0.8245 - val_loss: 0.4932 - val_accuracy: 0.7499\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3771 - accuracy: 0.8178 - val_loss: 0.4922 - val_accuracy: 0.7509\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3763 - accuracy: 0.8158 - val_loss: 0.4916 - val_accuracy: 0.7518\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3738 - accuracy: 0.8232 - val_loss: 0.4944 - val_accuracy: 0.7496\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8203 - val_loss: 0.4876 - val_accuracy: 0.7592\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3779 - accuracy: 0.8175 - val_loss: 0.4879 - val_accuracy: 0.7582\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3696 - accuracy: 0.8231 - val_loss: 0.4868 - val_accuracy: 0.7608\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8215 - val_loss: 0.4977 - val_accuracy: 0.7474\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3661 - accuracy: 0.8223 - val_loss: 0.4900 - val_accuracy: 0.7525\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3728 - accuracy: 0.8208 - val_loss: 0.5102 - val_accuracy: 0.7419\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3737 - accuracy: 0.8209 - val_loss: 0.4905 - val_accuracy: 0.7490\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3701 - accuracy: 0.8229 - val_loss: 0.4851 - val_accuracy: 0.7608\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3724 - accuracy: 0.8184 - val_loss: 0.4876 - val_accuracy: 0.7576\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3677 - accuracy: 0.8247 - val_loss: 0.4999 - val_accuracy: 0.7467\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3678 - accuracy: 0.8225 - val_loss: 0.4946 - val_accuracy: 0.7486\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3708 - accuracy: 0.8232 - val_loss: 0.4916 - val_accuracy: 0.7522\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3751 - accuracy: 0.8167 - val_loss: 0.4939 - val_accuracy: 0.7486\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3672 - accuracy: 0.8233 - val_loss: 0.4877 - val_accuracy: 0.7531\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3734 - accuracy: 0.8226 - val_loss: 0.4972 - val_accuracy: 0.7474\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3727 - accuracy: 0.8209 - val_loss: 0.4870 - val_accuracy: 0.7550\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3724 - accuracy: 0.8185 - val_loss: 0.5030 - val_accuracy: 0.7458\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3776 - accuracy: 0.8160 - val_loss: 0.5047 - val_accuracy: 0.7442\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3699 - accuracy: 0.8207 - val_loss: 0.4850 - val_accuracy: 0.7585\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3753 - accuracy: 0.8179 - val_loss: 0.4890 - val_accuracy: 0.7502\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3673 - accuracy: 0.8245 - val_loss: 0.5072 - val_accuracy: 0.7445\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3653 - accuracy: 0.8251 - val_loss: 0.4963 - val_accuracy: 0.7486\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3762 - accuracy: 0.8200 - val_loss: 0.4854 - val_accuracy: 0.7553\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3672 - accuracy: 0.8257 - val_loss: 0.4911 - val_accuracy: 0.7493\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3780 - accuracy: 0.8184 - val_loss: 0.4910 - val_accuracy: 0.7496\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3731 - accuracy: 0.8197 - val_loss: 0.5001 - val_accuracy: 0.7470\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 0.8277 - val_loss: 0.4834 - val_accuracy: 0.7576\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.8200 - val_loss: 0.4794 - val_accuracy: 0.7630\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3715 - accuracy: 0.8245 - val_loss: 0.5016 - val_accuracy: 0.7467\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3741 - accuracy: 0.8210 - val_loss: 0.4856 - val_accuracy: 0.7534\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3733 - accuracy: 0.8229 - val_loss: 0.4933 - val_accuracy: 0.7486\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3687 - accuracy: 0.8221 - val_loss: 0.4907 - val_accuracy: 0.7493\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3711 - accuracy: 0.8212 - val_loss: 0.4965 - val_accuracy: 0.7480\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8212 - val_loss: 0.4907 - val_accuracy: 0.7506\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3660 - accuracy: 0.8277 - val_loss: 0.4895 - val_accuracy: 0.7506\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3680 - accuracy: 0.8238 - val_loss: 0.4871 - val_accuracy: 0.7496\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3702 - accuracy: 0.8218 - val_loss: 0.4782 - val_accuracy: 0.7633\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3779 - accuracy: 0.8207 - val_loss: 0.4826 - val_accuracy: 0.7566\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8210 - val_loss: 0.4873 - val_accuracy: 0.7528\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3744 - accuracy: 0.8225 - val_loss: 0.5075 - val_accuracy: 0.7365\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3745 - accuracy: 0.8192 - val_loss: 0.4858 - val_accuracy: 0.7537\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3671 - accuracy: 0.8276 - val_loss: 0.4975 - val_accuracy: 0.7474\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3667 - accuracy: 0.8220 - val_loss: 0.4946 - val_accuracy: 0.7493\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3721 - accuracy: 0.8226 - val_loss: 0.4947 - val_accuracy: 0.7483\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.8228 - val_loss: 0.4850 - val_accuracy: 0.7531\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3678 - accuracy: 0.8247 - val_loss: 0.4856 - val_accuracy: 0.7525\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3680 - accuracy: 0.8260 - val_loss: 0.4843 - val_accuracy: 0.7534\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3685 - accuracy: 0.8276 - val_loss: 0.4940 - val_accuracy: 0.7496\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3622 - accuracy: 0.8270 - val_loss: 0.5161 - val_accuracy: 0.7295\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.8266 - val_loss: 0.4937 - val_accuracy: 0.7486\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3711 - accuracy: 0.8212 - val_loss: 0.4833 - val_accuracy: 0.7541\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3729 - accuracy: 0.8265 - val_loss: 0.4962 - val_accuracy: 0.7474\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3670 - accuracy: 0.8254 - val_loss: 0.5006 - val_accuracy: 0.7442\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.8217 - val_loss: 0.5093 - val_accuracy: 0.7330\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.8273 - val_loss: 0.4984 - val_accuracy: 0.7458\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3697 - accuracy: 0.8237 - val_loss: 0.4921 - val_accuracy: 0.7493\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3699 - accuracy: 0.8235 - val_loss: 0.5214 - val_accuracy: 0.7244\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3702 - accuracy: 0.8218 - val_loss: 0.4894 - val_accuracy: 0.7528\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3794 - accuracy: 0.8173 - val_loss: 0.4881 - val_accuracy: 0.7534\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3677 - accuracy: 0.8246 - val_loss: 0.4857 - val_accuracy: 0.7531\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3688 - accuracy: 0.8226 - val_loss: 0.4858 - val_accuracy: 0.7537\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3615 - accuracy: 0.8266 - val_loss: 0.4893 - val_accuracy: 0.7506\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3644 - accuracy: 0.8262 - val_loss: 0.4916 - val_accuracy: 0.7496\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8269 - val_loss: 0.4822 - val_accuracy: 0.7569\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.8281 - val_loss: 0.5149 - val_accuracy: 0.7324\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3693 - accuracy: 0.8235 - val_loss: 0.4870 - val_accuracy: 0.7541\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3685 - accuracy: 0.8253 - val_loss: 0.4861 - val_accuracy: 0.7544\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3692 - accuracy: 0.8242 - val_loss: 0.4808 - val_accuracy: 0.7579\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.8228 - val_loss: 0.4975 - val_accuracy: 0.7439\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3748 - accuracy: 0.8218 - val_loss: 0.5001 - val_accuracy: 0.7404\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3681 - accuracy: 0.8242 - val_loss: 0.4805 - val_accuracy: 0.7585\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3697 - accuracy: 0.8211 - val_loss: 0.4893 - val_accuracy: 0.7518\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3647 - accuracy: 0.8276 - val_loss: 0.5068 - val_accuracy: 0.7343\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3703 - accuracy: 0.8204 - val_loss: 0.5067 - val_accuracy: 0.7349\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3641 - accuracy: 0.8276 - val_loss: 0.4955 - val_accuracy: 0.7467\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3710 - accuracy: 0.8211 - val_loss: 0.4704 - val_accuracy: 0.7729\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3699 - accuracy: 0.8227 - val_loss: 0.5185 - val_accuracy: 0.7241\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3671 - accuracy: 0.8224 - val_loss: 0.4896 - val_accuracy: 0.7515\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3694 - accuracy: 0.8177 - val_loss: 0.5018 - val_accuracy: 0.7381\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3635 - accuracy: 0.8269 - val_loss: 0.4902 - val_accuracy: 0.7499\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3718 - accuracy: 0.8210 - val_loss: 0.4887 - val_accuracy: 0.7518\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.8234 - val_loss: 0.4892 - val_accuracy: 0.7525\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3744 - accuracy: 0.8202 - val_loss: 0.5043 - val_accuracy: 0.7378\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8284 - val_loss: 0.4776 - val_accuracy: 0.7598\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3663 - accuracy: 0.8204 - val_loss: 0.4964 - val_accuracy: 0.7477\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3625 - accuracy: 0.8291 - val_loss: 0.4869 - val_accuracy: 0.7525\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3729 - accuracy: 0.8188 - val_loss: 0.5037 - val_accuracy: 0.7368\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3585 - accuracy: 0.8300 - val_loss: 0.5123 - val_accuracy: 0.7295\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3649 - accuracy: 0.8289 - val_loss: 0.4845 - val_accuracy: 0.7547\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3698 - accuracy: 0.8247 - val_loss: 0.5017 - val_accuracy: 0.7381\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3679 - accuracy: 0.8257 - val_loss: 0.4919 - val_accuracy: 0.7493\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8282 - val_loss: 0.4848 - val_accuracy: 0.7537\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3708 - accuracy: 0.8220 - val_loss: 0.4843 - val_accuracy: 0.7544\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3652 - accuracy: 0.8267 - val_loss: 0.4892 - val_accuracy: 0.7493\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3655 - accuracy: 0.8281 - val_loss: 0.4969 - val_accuracy: 0.7442\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3656 - accuracy: 0.8250 - val_loss: 0.4895 - val_accuracy: 0.7512\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3609 - accuracy: 0.8287 - val_loss: 0.4861 - val_accuracy: 0.7525\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3646 - accuracy: 0.8251 - val_loss: 0.4846 - val_accuracy: 0.7534\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8263 - val_loss: 0.5013 - val_accuracy: 0.7381\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.8274 - val_loss: 0.4958 - val_accuracy: 0.7445\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3604 - accuracy: 0.8322 - val_loss: 0.4793 - val_accuracy: 0.7557\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3731 - accuracy: 0.8218 - val_loss: 0.4866 - val_accuracy: 0.7531\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3607 - accuracy: 0.8324 - val_loss: 0.4862 - val_accuracy: 0.7534\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8275 - val_loss: 0.4837 - val_accuracy: 0.7544\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3594 - accuracy: 0.8279 - val_loss: 0.5658 - val_accuracy: 0.6711\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.8216 - val_loss: 0.4889 - val_accuracy: 0.7544\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8222 - val_loss: 0.5088 - val_accuracy: 0.7324\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3632 - accuracy: 0.8271 - val_loss: 0.4919 - val_accuracy: 0.7502\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3640 - accuracy: 0.8252 - val_loss: 0.5097 - val_accuracy: 0.7324\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3676 - accuracy: 0.8227 - val_loss: 0.5067 - val_accuracy: 0.7333\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 0.8291 - val_loss: 0.5098 - val_accuracy: 0.7337\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3605 - accuracy: 0.8297 - val_loss: 0.4813 - val_accuracy: 0.7560\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3662 - accuracy: 0.8281 - val_loss: 0.5162 - val_accuracy: 0.7257\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3666 - accuracy: 0.8241 - val_loss: 0.5033 - val_accuracy: 0.7343\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3674 - accuracy: 0.8267 - val_loss: 0.4955 - val_accuracy: 0.7439\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3692 - accuracy: 0.8244 - val_loss: 0.5311 - val_accuracy: 0.7129\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3666 - accuracy: 0.8234 - val_loss: 0.5056 - val_accuracy: 0.7346\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3651 - accuracy: 0.8267 - val_loss: 0.5221 - val_accuracy: 0.7212\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3565 - accuracy: 0.8314 - val_loss: 0.5404 - val_accuracy: 0.6982\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3646 - accuracy: 0.8258 - val_loss: 0.4911 - val_accuracy: 0.7496\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3664 - accuracy: 0.8256 - val_loss: 0.5255 - val_accuracy: 0.7180\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3606 - accuracy: 0.8290 - val_loss: 0.5133 - val_accuracy: 0.7270\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3687 - accuracy: 0.8238 - val_loss: 0.5024 - val_accuracy: 0.7362\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3645 - accuracy: 0.8228 - val_loss: 0.4817 - val_accuracy: 0.7592\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3644 - accuracy: 0.8278 - val_loss: 0.5313 - val_accuracy: 0.7097\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8245 - val_loss: 0.5058 - val_accuracy: 0.7346\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3679 - accuracy: 0.8256 - val_loss: 0.4861 - val_accuracy: 0.7560\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3631 - accuracy: 0.8283 - val_loss: 0.4914 - val_accuracy: 0.7483\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8288 - val_loss: 0.5039 - val_accuracy: 0.7356\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3637 - accuracy: 0.8296 - val_loss: 0.4933 - val_accuracy: 0.7467\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3593 - accuracy: 0.8317 - val_loss: 0.5235 - val_accuracy: 0.7199\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3618 - accuracy: 0.8288 - val_loss: 0.4974 - val_accuracy: 0.7381\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3700 - accuracy: 0.8246 - val_loss: 0.5027 - val_accuracy: 0.7356\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3612 - accuracy: 0.8307 - val_loss: 0.4958 - val_accuracy: 0.7416\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3665 - accuracy: 0.8252 - val_loss: 0.5030 - val_accuracy: 0.7346\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3642 - accuracy: 0.8290 - val_loss: 0.5217 - val_accuracy: 0.7225\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3621 - accuracy: 0.8273 - val_loss: 0.4916 - val_accuracy: 0.7461\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3628 - accuracy: 0.8285 - val_loss: 0.4869 - val_accuracy: 0.7522\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3668 - accuracy: 0.8311 - val_loss: 0.4999 - val_accuracy: 0.7365\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3614 - accuracy: 0.8272 - val_loss: 0.4857 - val_accuracy: 0.7544\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3683 - accuracy: 0.8251 - val_loss: 0.4946 - val_accuracy: 0.7435\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3611 - accuracy: 0.8276 - val_loss: 0.5118 - val_accuracy: 0.7282\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3619 - accuracy: 0.8287 - val_loss: 0.4985 - val_accuracy: 0.7388\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3650 - accuracy: 0.8274 - val_loss: 0.4867 - val_accuracy: 0.7525\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3629 - accuracy: 0.8272 - val_loss: 0.5119 - val_accuracy: 0.7289\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3704 - accuracy: 0.8199 - val_loss: 0.4865 - val_accuracy: 0.7518\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3592 - accuracy: 0.8303 - val_loss: 0.5153 - val_accuracy: 0.7247\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3640 - accuracy: 0.8251 - val_loss: 0.5165 - val_accuracy: 0.7231\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3615 - accuracy: 0.8308 - val_loss: 0.5120 - val_accuracy: 0.7282\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3643 - accuracy: 0.8293 - val_loss: 0.5083 - val_accuracy: 0.7333\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3675 - accuracy: 0.8255 - val_loss: 0.5012 - val_accuracy: 0.7372\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3626 - accuracy: 0.8289 - val_loss: 0.5253 - val_accuracy: 0.7148\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3618 - accuracy: 0.8293 - val_loss: 0.5224 - val_accuracy: 0.7209\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3653 - accuracy: 0.8264 - val_loss: 0.4934 - val_accuracy: 0.7439\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3656 - accuracy: 0.8288 - val_loss: 0.4845 - val_accuracy: 0.7547\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3724 - accuracy: 0.8247 - val_loss: 0.5224 - val_accuracy: 0.7199\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3669 - accuracy: 0.8250 - val_loss: 0.5004 - val_accuracy: 0.7400\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3588 - accuracy: 0.8280 - val_loss: 0.4835 - val_accuracy: 0.7582\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3671 - accuracy: 0.8233 - val_loss: 0.5258 - val_accuracy: 0.7129\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3634 - accuracy: 0.8280 - val_loss: 0.4998 - val_accuracy: 0.7384\n",
      "Epoch 00319: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model4 = model_four()\n",
    "history = model4.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4998343288898468, 0.7384369969367981]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 0.8293 - accuracy: 0.7114 - val_loss: 0.5257 - val_accuracy: 0.7129\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4480 - accuracy: 0.7430 - val_loss: 0.4883 - val_accuracy: 0.7142\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.4047 - accuracy: 0.8120 - val_loss: 0.5065 - val_accuracy: 0.7164\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3883 - accuracy: 0.8059 - val_loss: 0.4979 - val_accuracy: 0.7282\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3773 - accuracy: 0.8222 - val_loss: 0.5058 - val_accuracy: 0.7254\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3713 - accuracy: 0.8151 - val_loss: 0.5092 - val_accuracy: 0.7285\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3706 - accuracy: 0.8238 - val_loss: 0.5198 - val_accuracy: 0.7295\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3690 - accuracy: 0.8210 - val_loss: 0.5099 - val_accuracy: 0.7333\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3679 - accuracy: 0.8216 - val_loss: 0.5136 - val_accuracy: 0.7321\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3539 - accuracy: 0.8238 - val_loss: 0.5215 - val_accuracy: 0.7321\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3573 - accuracy: 0.8257 - val_loss: 0.5277 - val_accuracy: 0.7384\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3508 - accuracy: 0.8335 - val_loss: 0.5443 - val_accuracy: 0.7295\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3537 - accuracy: 0.8255 - val_loss: 0.5489 - val_accuracy: 0.7314\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3484 - accuracy: 0.8301 - val_loss: 0.5329 - val_accuracy: 0.7314\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3492 - accuracy: 0.8320 - val_loss: 0.5558 - val_accuracy: 0.7404\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3411 - accuracy: 0.8335 - val_loss: 0.5525 - val_accuracy: 0.7349\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3436 - accuracy: 0.8342 - val_loss: 0.5420 - val_accuracy: 0.7413\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3486 - accuracy: 0.8331 - val_loss: 0.5530 - val_accuracy: 0.7352\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3514 - accuracy: 0.8297 - val_loss: 0.5698 - val_accuracy: 0.7388\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3485 - accuracy: 0.8266 - val_loss: 0.5346 - val_accuracy: 0.7378\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3363 - accuracy: 0.8379 - val_loss: 0.5521 - val_accuracy: 0.7359\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3322 - accuracy: 0.8427 - val_loss: 0.5442 - val_accuracy: 0.7372\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3379 - accuracy: 0.8355 - val_loss: 0.5669 - val_accuracy: 0.7327\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3366 - accuracy: 0.8349 - val_loss: 0.5342 - val_accuracy: 0.7337\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3410 - accuracy: 0.8336 - val_loss: 0.5742 - val_accuracy: 0.7285\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3374 - accuracy: 0.8320 - val_loss: 0.5463 - val_accuracy: 0.7330\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3370 - accuracy: 0.8339 - val_loss: 0.5729 - val_accuracy: 0.7317\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3346 - accuracy: 0.8365 - val_loss: 0.5770 - val_accuracy: 0.7244\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3339 - accuracy: 0.8399 - val_loss: 0.5606 - val_accuracy: 0.7349\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3262 - accuracy: 0.8388 - val_loss: 0.5406 - val_accuracy: 0.7270\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3331 - accuracy: 0.8342 - val_loss: 0.5375 - val_accuracy: 0.7346\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3244 - accuracy: 0.8429 - val_loss: 0.5530 - val_accuracy: 0.7308\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3343 - accuracy: 0.8422 - val_loss: 0.6171 - val_accuracy: 0.7241\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3302 - accuracy: 0.8345 - val_loss: 0.5547 - val_accuracy: 0.7324\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3317 - accuracy: 0.8362 - val_loss: 0.5962 - val_accuracy: 0.7260\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3283 - accuracy: 0.8385 - val_loss: 0.5674 - val_accuracy: 0.7276\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3281 - accuracy: 0.8380 - val_loss: 0.5810 - val_accuracy: 0.7266\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3313 - accuracy: 0.8364 - val_loss: 0.5706 - val_accuracy: 0.7285\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3297 - accuracy: 0.8358 - val_loss: 0.5930 - val_accuracy: 0.7257\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3278 - accuracy: 0.8366 - val_loss: 0.5804 - val_accuracy: 0.7244\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3232 - accuracy: 0.8393 - val_loss: 0.5670 - val_accuracy: 0.7276\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3220 - accuracy: 0.8424 - val_loss: 0.5434 - val_accuracy: 0.7257\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3319 - accuracy: 0.8343 - val_loss: 0.5611 - val_accuracy: 0.7250\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3227 - accuracy: 0.8482 - val_loss: 0.5568 - val_accuracy: 0.7266\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3246 - accuracy: 0.8425 - val_loss: 0.5829 - val_accuracy: 0.7273\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3106 - accuracy: 0.8496 - val_loss: 0.5801 - val_accuracy: 0.7289\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3163 - accuracy: 0.8483 - val_loss: 0.5722 - val_accuracy: 0.7263\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3248 - accuracy: 0.8442 - val_loss: 0.5807 - val_accuracy: 0.7270\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3203 - accuracy: 0.8464 - val_loss: 0.5453 - val_accuracy: 0.7266\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3186 - accuracy: 0.8459 - val_loss: 0.5878 - val_accuracy: 0.7295\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3166 - accuracy: 0.8461 - val_loss: 0.6115 - val_accuracy: 0.7228\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3190 - accuracy: 0.8441 - val_loss: 0.6177 - val_accuracy: 0.7289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3221 - accuracy: 0.8410 - val_loss: 0.5758 - val_accuracy: 0.7231\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3194 - accuracy: 0.8458 - val_loss: 0.6053 - val_accuracy: 0.7231\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3156 - accuracy: 0.8456 - val_loss: 0.6068 - val_accuracy: 0.7244\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3171 - accuracy: 0.8460 - val_loss: 0.5844 - val_accuracy: 0.7222\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3218 - accuracy: 0.8376 - val_loss: 0.6115 - val_accuracy: 0.7247\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3204 - accuracy: 0.8395 - val_loss: 0.5695 - val_accuracy: 0.7289\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3121 - accuracy: 0.8497 - val_loss: 0.5837 - val_accuracy: 0.7298\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3133 - accuracy: 0.8497 - val_loss: 0.5889 - val_accuracy: 0.7238\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3151 - accuracy: 0.8470 - val_loss: 0.5749 - val_accuracy: 0.7263\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8477 - val_loss: 0.5904 - val_accuracy: 0.7215\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3177 - accuracy: 0.8417 - val_loss: 0.6268 - val_accuracy: 0.7231\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3142 - accuracy: 0.8442 - val_loss: 0.5611 - val_accuracy: 0.7228\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3202 - accuracy: 0.8378 - val_loss: 0.5794 - val_accuracy: 0.7219\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3116 - accuracy: 0.8473 - val_loss: 0.5467 - val_accuracy: 0.7266\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3198 - accuracy: 0.8476 - val_loss: 0.5820 - val_accuracy: 0.7215\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3165 - accuracy: 0.8449 - val_loss: 0.5994 - val_accuracy: 0.7231\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3121 - accuracy: 0.8457 - val_loss: 0.5838 - val_accuracy: 0.7244\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3118 - accuracy: 0.8429 - val_loss: 0.6132 - val_accuracy: 0.7222\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3080 - accuracy: 0.8430 - val_loss: 0.5831 - val_accuracy: 0.7225\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3122 - accuracy: 0.8473 - val_loss: 0.6047 - val_accuracy: 0.7193\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3050 - accuracy: 0.8483 - val_loss: 0.5980 - val_accuracy: 0.7190\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3213 - accuracy: 0.8387 - val_loss: 0.6478 - val_accuracy: 0.7199\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3093 - accuracy: 0.8499 - val_loss: 0.5653 - val_accuracy: 0.7196\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3114 - accuracy: 0.8455 - val_loss: 0.6298 - val_accuracy: 0.7219\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3135 - accuracy: 0.8447 - val_loss: 0.5704 - val_accuracy: 0.7187\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3125 - accuracy: 0.8461 - val_loss: 0.5654 - val_accuracy: 0.7196\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3081 - accuracy: 0.8493 - val_loss: 0.5809 - val_accuracy: 0.7190\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3156 - accuracy: 0.8436 - val_loss: 0.5886 - val_accuracy: 0.7203\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3126 - accuracy: 0.8445 - val_loss: 0.5790 - val_accuracy: 0.7180\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3109 - accuracy: 0.8412 - val_loss: 0.6062 - val_accuracy: 0.7193\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3098 - accuracy: 0.8443 - val_loss: 0.6061 - val_accuracy: 0.7193\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3170 - accuracy: 0.8446 - val_loss: 0.6415 - val_accuracy: 0.7190\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3077 - accuracy: 0.8505 - val_loss: 0.6292 - val_accuracy: 0.7241\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3157 - accuracy: 0.8386 - val_loss: 0.6602 - val_accuracy: 0.7219\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3084 - accuracy: 0.8486 - val_loss: 0.6348 - val_accuracy: 0.7231\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3126 - accuracy: 0.8398 - val_loss: 0.6491 - val_accuracy: 0.7212\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3112 - accuracy: 0.8407 - val_loss: 0.6364 - val_accuracy: 0.7190\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3079 - accuracy: 0.8485 - val_loss: 0.6526 - val_accuracy: 0.7190\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3090 - accuracy: 0.8463 - val_loss: 0.6076 - val_accuracy: 0.7171\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3043 - accuracy: 0.8459 - val_loss: 0.5798 - val_accuracy: 0.7174\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3150 - accuracy: 0.8444 - val_loss: 0.6157 - val_accuracy: 0.7190\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3069 - accuracy: 0.8452 - val_loss: 0.6096 - val_accuracy: 0.7212\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3015 - accuracy: 0.8486 - val_loss: 0.6051 - val_accuracy: 0.7148\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3130 - accuracy: 0.8424 - val_loss: 0.6538 - val_accuracy: 0.7215\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3071 - accuracy: 0.8497 - val_loss: 0.6153 - val_accuracy: 0.7171\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3137 - accuracy: 0.8401 - val_loss: 0.6179 - val_accuracy: 0.7174\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3146 - accuracy: 0.8466 - val_loss: 0.5880 - val_accuracy: 0.7155\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3080 - accuracy: 0.8499 - val_loss: 0.6055 - val_accuracy: 0.7177\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3038 - accuracy: 0.8505 - val_loss: 0.6066 - val_accuracy: 0.7209\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3077 - accuracy: 0.8506 - val_loss: 0.6090 - val_accuracy: 0.7171\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3059 - accuracy: 0.8525 - val_loss: 0.6039 - val_accuracy: 0.7145\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3059 - accuracy: 0.8496 - val_loss: 0.6347 - val_accuracy: 0.7164\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3088 - accuracy: 0.8473 - val_loss: 0.6165 - val_accuracy: 0.7152\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3083 - accuracy: 0.8505 - val_loss: 0.6458 - val_accuracy: 0.7219\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3003 - accuracy: 0.8536 - val_loss: 0.6559 - val_accuracy: 0.7187\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3033 - accuracy: 0.8486 - val_loss: 0.6202 - val_accuracy: 0.7132\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2982 - accuracy: 0.8533 - val_loss: 0.6408 - val_accuracy: 0.7167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3077 - accuracy: 0.8472 - val_loss: 0.6311 - val_accuracy: 0.7155\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3091 - accuracy: 0.8477 - val_loss: 0.6379 - val_accuracy: 0.7158\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2986 - accuracy: 0.8531 - val_loss: 0.6571 - val_accuracy: 0.7174\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3041 - accuracy: 0.8500 - val_loss: 0.7210 - val_accuracy: 0.7209\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3027 - accuracy: 0.8523 - val_loss: 0.6856 - val_accuracy: 0.7190\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3092 - accuracy: 0.8467 - val_loss: 0.6636 - val_accuracy: 0.7190\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3074 - accuracy: 0.8443 - val_loss: 0.6685 - val_accuracy: 0.7177\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3078 - accuracy: 0.8444 - val_loss: 0.6835 - val_accuracy: 0.7164\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3112 - accuracy: 0.8454 - val_loss: 0.6703 - val_accuracy: 0.7187\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2996 - accuracy: 0.8547 - val_loss: 0.6592 - val_accuracy: 0.7148\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3035 - accuracy: 0.8496 - val_loss: 0.7001 - val_accuracy: 0.7231\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3094 - accuracy: 0.8460 - val_loss: 0.6809 - val_accuracy: 0.7209\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3042 - accuracy: 0.8486 - val_loss: 0.6404 - val_accuracy: 0.7187\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3041 - accuracy: 0.8510 - val_loss: 0.6356 - val_accuracy: 0.7241\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3096 - accuracy: 0.8498 - val_loss: 0.6542 - val_accuracy: 0.7187\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3021 - accuracy: 0.8518 - val_loss: 0.6631 - val_accuracy: 0.7203\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2997 - accuracy: 0.8495 - val_loss: 0.6532 - val_accuracy: 0.7203\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3043 - accuracy: 0.8454 - val_loss: 0.6612 - val_accuracy: 0.7282\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3013 - accuracy: 0.8483 - val_loss: 0.6914 - val_accuracy: 0.7193\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3031 - accuracy: 0.8463 - val_loss: 0.6924 - val_accuracy: 0.7238\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3057 - accuracy: 0.8518 - val_loss: 0.6600 - val_accuracy: 0.7190\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2939 - accuracy: 0.8526 - val_loss: 0.6921 - val_accuracy: 0.7174\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3068 - accuracy: 0.8492 - val_loss: 0.6872 - val_accuracy: 0.7164\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3001 - accuracy: 0.8514 - val_loss: 0.7072 - val_accuracy: 0.7279\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3100 - accuracy: 0.8473 - val_loss: 0.7288 - val_accuracy: 0.7193\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3048 - accuracy: 0.8470 - val_loss: 0.6905 - val_accuracy: 0.7266\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3082 - accuracy: 0.8490 - val_loss: 0.7335 - val_accuracy: 0.7276\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3022 - accuracy: 0.8543 - val_loss: 0.7146 - val_accuracy: 0.7219\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3068 - accuracy: 0.8480 - val_loss: 0.7701 - val_accuracy: 0.7263\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3001 - accuracy: 0.8553 - val_loss: 0.7425 - val_accuracy: 0.7260\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3012 - accuracy: 0.8535 - val_loss: 0.7316 - val_accuracy: 0.7234\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3025 - accuracy: 0.8490 - val_loss: 0.7488 - val_accuracy: 0.7295\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3019 - accuracy: 0.8543 - val_loss: 0.8947 - val_accuracy: 0.7231\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3016 - accuracy: 0.8503 - val_loss: 0.8636 - val_accuracy: 0.7228\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3014 - accuracy: 0.8506 - val_loss: 0.8645 - val_accuracy: 0.7295\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2994 - accuracy: 0.8519 - val_loss: 0.8797 - val_accuracy: 0.7244\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2976 - accuracy: 0.8458 - val_loss: 0.7823 - val_accuracy: 0.7327\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2961 - accuracy: 0.8541 - val_loss: 0.8121 - val_accuracy: 0.7273\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2976 - accuracy: 0.8496 - val_loss: 0.7366 - val_accuracy: 0.7298\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2950 - accuracy: 0.8507 - val_loss: 0.7848 - val_accuracy: 0.7273\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2998 - accuracy: 0.8497 - val_loss: 0.7831 - val_accuracy: 0.7289\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2964 - accuracy: 0.8549 - val_loss: 0.7793 - val_accuracy: 0.7244\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2956 - accuracy: 0.8473 - val_loss: 0.8394 - val_accuracy: 0.7314\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3049 - accuracy: 0.8450 - val_loss: 0.8799 - val_accuracy: 0.7292\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2944 - accuracy: 0.8535 - val_loss: 0.7817 - val_accuracy: 0.7365\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2962 - accuracy: 0.8436 - val_loss: 0.8143 - val_accuracy: 0.7292\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2901 - accuracy: 0.8554 - val_loss: 0.7102 - val_accuracy: 0.7346\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.2922 - accuracy: 0.8539 - val_loss: 0.7008 - val_accuracy: 0.7365\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3046 - accuracy: 0.8461 - val_loss: 0.7807 - val_accuracy: 0.7301\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3003 - accuracy: 0.8513 - val_loss: 0.6953 - val_accuracy: 0.7352\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2988 - accuracy: 0.8513 - val_loss: 0.7344 - val_accuracy: 0.7362\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3097 - accuracy: 0.8444 - val_loss: 0.7048 - val_accuracy: 0.7365\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3018 - accuracy: 0.8491 - val_loss: 0.7174 - val_accuracy: 0.7340\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2995 - accuracy: 0.8520 - val_loss: 0.7156 - val_accuracy: 0.7400\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2980 - accuracy: 0.8488 - val_loss: 0.6932 - val_accuracy: 0.7416\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3007 - accuracy: 0.8520 - val_loss: 0.6723 - val_accuracy: 0.7391\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2973 - accuracy: 0.8485 - val_loss: 0.7463 - val_accuracy: 0.7333\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3063 - accuracy: 0.8459 - val_loss: 0.6951 - val_accuracy: 0.7372\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3006 - accuracy: 0.8532 - val_loss: 0.6821 - val_accuracy: 0.7368\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3052 - accuracy: 0.8443 - val_loss: 0.7118 - val_accuracy: 0.7352\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3035 - accuracy: 0.8512 - val_loss: 0.7183 - val_accuracy: 0.7365\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3082 - accuracy: 0.8470 - val_loss: 0.7096 - val_accuracy: 0.7397\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3018 - accuracy: 0.8473 - val_loss: 0.7713 - val_accuracy: 0.7384\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2935 - accuracy: 0.8527 - val_loss: 0.6842 - val_accuracy: 0.7305\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2947 - accuracy: 0.8482 - val_loss: 0.7248 - val_accuracy: 0.7365\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3013 - accuracy: 0.8471 - val_loss: 0.7038 - val_accuracy: 0.7321\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3032 - accuracy: 0.8512 - val_loss: 0.7270 - val_accuracy: 0.7346\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2960 - accuracy: 0.8490 - val_loss: 0.7614 - val_accuracy: 0.7381\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2922 - accuracy: 0.8517 - val_loss: 0.7430 - val_accuracy: 0.7356\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3001 - accuracy: 0.8521 - val_loss: 0.7331 - val_accuracy: 0.7356\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2957 - accuracy: 0.8538 - val_loss: 0.7539 - val_accuracy: 0.7365\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2976 - accuracy: 0.8499 - val_loss: 0.7025 - val_accuracy: 0.7368\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.3030 - accuracy: 0.8494 - val_loss: 0.7757 - val_accuracy: 0.7317\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2947 - accuracy: 0.8501 - val_loss: 0.7357 - val_accuracy: 0.7416\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2926 - accuracy: 0.8551 - val_loss: 0.7498 - val_accuracy: 0.7311\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2964 - accuracy: 0.8499 - val_loss: 0.7061 - val_accuracy: 0.7381\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2958 - accuracy: 0.8502 - val_loss: 0.7140 - val_accuracy: 0.7333\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2947 - accuracy: 0.8508 - val_loss: 0.7131 - val_accuracy: 0.7349\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2938 - accuracy: 0.8503 - val_loss: 0.7478 - val_accuracy: 0.7381\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2929 - accuracy: 0.8476 - val_loss: 0.6713 - val_accuracy: 0.7381\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2940 - accuracy: 0.8530 - val_loss: 0.7564 - val_accuracy: 0.7410\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3008 - accuracy: 0.8514 - val_loss: 0.7012 - val_accuracy: 0.7429\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2940 - accuracy: 0.8527 - val_loss: 0.7610 - val_accuracy: 0.7400\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3000 - accuracy: 0.8503 - val_loss: 0.7566 - val_accuracy: 0.7343\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2887 - accuracy: 0.8555 - val_loss: 0.8232 - val_accuracy: 0.7362\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.2926 - accuracy: 0.8515 - val_loss: 0.7695 - val_accuracy: 0.7410\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2984 - accuracy: 0.8531 - val_loss: 0.6249 - val_accuracy: 0.7423\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2933 - accuracy: 0.8520 - val_loss: 0.6527 - val_accuracy: 0.7400\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2943 - accuracy: 0.8569 - val_loss: 0.6864 - val_accuracy: 0.7343\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3008 - accuracy: 0.8478 - val_loss: 0.6886 - val_accuracy: 0.7423\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2994 - accuracy: 0.8491 - val_loss: 0.6694 - val_accuracy: 0.7343\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.2972 - accuracy: 0.8480 - val_loss: 0.6903 - val_accuracy: 0.7388\n",
      "Epoch 00201: early stopping\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model5 = model_five()\n",
    "history = model5.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6903 - accuracy: 0.7388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6903107166290283, 0.738756000995636]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preliminary conclusions on your models\n",
    "Include some graphs and peformance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1:\n",
    "The model's test and validation accuracy was comparable. This indicates that the model was able to generalize well with an accuracy of ~70%.\n",
    "\n",
    "Model 2:\n",
    "Decreasing the number of output nodes in the first layer by half performed similarly. This may mean the previous model can be simplified and perform simlarly.\n",
    "\n",
    "Model 3:\n",
    "By changing the activation function, the model performs worse.\n",
    "\n",
    "Model 4:\n",
    "Introducing a hidden layer allows the model to perform slightly worse than Model 1. This may mean this model is too complex. However, from the progression throughout epochs, the model appears to have escaped a local minima/maxima and continues to improve before cutting off. Possibly allowing it to run longer would prove to perform better.\n",
    "\n",
    "Model 5:\n",
    "Adding the dropout layer enabled the model to regularize and perform slightly better. This may mean model 1 was too complex.\n",
    "\n",
    "Most of these models performed significantly better than the logistic regression model, but only marginally better than the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Cross-validation\n",
    "We really should have used k-fold (eg. k=5) crossvalidation here, to not only evaluate our five keras/tensorflow models. See how your preliminary results change. Now that we have validation results with uncertainy (+- standard deviation), do your prior conclusion change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "x_train_test_val = np.concatenate((x_train, x_test ,x_val))\n",
    "y_train_test_val = np.concatenate((y_train_bool, y_test_bool ,y_val_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6923 - accuracy: 0.6147\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.7019\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7071\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7167\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7285\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5067 - accuracy: 0.7360\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7422\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7476\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7508\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7619\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4593 - accuracy: 0.7683\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7662\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7668\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4412 - accuracy: 0.7772\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7736\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.7729\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7786\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7800\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7845\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4224 - accuracy: 0.7857\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.7858\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4105 - accuracy: 0.7966\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4134 - accuracy: 0.7961\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4177 - accuracy: 0.7901\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7978\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4121 - accuracy: 0.7974\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4032 - accuracy: 0.8060\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4035 - accuracy: 0.8013\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7991\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8056\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8028\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4026 - accuracy: 0.8037\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8104\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8075\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3926 - accuracy: 0.8149\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8063\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8046\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3925 - accuracy: 0.8105\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8093\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8165\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8126\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8113\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.8097\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8156\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8124\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8152\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8134\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8130\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8135\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8173\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8150\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8147\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8114\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8150\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8175\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8156\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8180\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8183\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8155\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8147\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8177\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8135\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8173\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8189\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8174\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8151\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8195\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8177\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8174\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8213\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8149\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8224\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8187\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8175\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8223\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8155\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8176\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8199\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8139\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8175\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8164\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8224\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8190\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8221\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8218\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8123\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8244\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8224\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8211\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8174\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8138\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8224\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3824 - accuracy: 0.8163\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8194\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8245\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8204\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8180\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8190\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8204\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8118\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8220\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8252\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8139\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3805 - accuracy: 0.8189\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8228\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8246\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8195\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8152\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8173\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8204\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8242\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8197\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8194\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8217\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8262\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8187\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8238\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8178\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8246\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8209\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8247\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8202\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8221\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8224\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8226\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8130\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8265\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8216\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8221\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8269\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8267\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8221\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8235\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8249\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8239\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8202\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8245\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8182\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8186\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8237\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8265\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8190\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8248\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8182\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8239\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8283\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8253\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8241\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8205\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8277\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8205\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8215\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8244\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8271\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8305\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8285\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8244\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8237\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8301\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8295\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8256\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8273\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8259\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8251\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8261\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8213\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8237\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8258\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8287\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8249\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8264\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8248\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8246\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8225\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8196\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8214\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8246\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8251\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8236\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8297\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8242\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8263\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8295\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8249\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8290\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8278\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3603 - accuracy: 0.8278\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8270\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8245\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8264\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8302\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8224\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8302\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8253\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8281\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8264\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8270\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8235\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8299\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8235\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8194\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8255\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8278\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8256\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3583 - accuracy: 0.8302\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8261\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8286\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8252\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8232\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8294\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8309\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8226\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8277\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8265\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8283\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8246\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8292\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8262\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8306\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8289\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8234\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8264\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8251\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8279\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8279\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3587 - accuracy: 0.8317\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8250\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8296\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8271\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8314\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8302\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8253\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8250\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8288\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8287\n",
      "Epoch 236/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3642 - accuracy: 0.8228\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8290\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8242\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8242\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8302\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8218\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8236\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8252\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8280\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8290\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8232\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8263\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8275\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8218\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8291\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8251\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8276\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8272\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3663 - accuracy: 0.8238\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8261\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8309\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8317\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8311\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8249\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3591 - accuracy: 0.8265\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8327\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8264\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8317\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8198\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8283\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8264\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8255\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8292\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8252\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8249\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8271\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8247\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3595 - accuracy: 0.8307\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8283\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8285\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8263\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3616 - accuracy: 0.8265\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8266\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8286\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3610 - accuracy: 0.8264\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8199\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3654 - accuracy: 0.8253\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8268\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8273\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8280\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8267\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3547 - accuracy: 0.8322\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8302\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8268\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8296\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8294\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8295\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8293\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8265\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8250\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8316\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8304\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8278\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8308\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8275\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8298\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3548 - accuracy: 0.8331\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8300\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3702 - accuracy: 0.8232\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8267\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8239\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8259\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8308\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8250\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8266\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8287\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8262\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8258\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8268\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8247\n",
      "Epoch 316/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8281\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8260\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8277\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8240\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8296\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3549 - accuracy: 0.8334\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3620 - accuracy: 0.8292\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8287\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8321\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8349\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8257\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8304\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8293\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8295\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3669 - accuracy: 0.8245\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8335\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8294\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8328\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8288\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8300\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8298\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8290\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8262\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8309\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8301\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8278\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8285\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8286\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8310\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8328\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8257\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3582 - accuracy: 0.8276\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3540 - accuracy: 0.8325\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8317\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3542 - accuracy: 0.8321\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8286\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8255\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8279\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3616 - accuracy: 0.8293\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3573 - accuracy: 0.8310\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3582 - accuracy: 0.8287\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8267\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.8316\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8291\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.8328\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8278\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8233\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8284\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8272\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3480 - accuracy: 0.8335\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8318\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3577 - accuracy: 0.8326\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8287\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8246\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3565 - accuracy: 0.8308\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8328\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8292\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8272\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8291\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3568 - accuracy: 0.8300\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3550 - accuracy: 0.8303\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8281\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3515 - accuracy: 0.8364\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3574 - accuracy: 0.8299\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3600 - accuracy: 0.8269\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8297\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8231\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8275\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8301\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3562 - accuracy: 0.8319\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3563 - accuracy: 0.8297\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3506 - accuracy: 0.8356\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8281\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3561 - accuracy: 0.8293\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3506 - accuracy: 0.8350\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8294\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3542 - accuracy: 0.8336\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3592 - accuracy: 0.8298\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3534 - accuracy: 0.8342\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8297\n",
      "Epoch 396/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8310\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8266\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8274\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3500 - accuracy: 0.8337\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8314\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8272\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8247\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8327\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3516 - accuracy: 0.8367\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8301\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8290\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8294\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3494 - accuracy: 0.8376\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8313\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3584 - accuracy: 0.8297\n",
      "Epoch 00410: early stopping\n",
      "Score for fold 1: loss of 0.36908984184265137; accuracy of 82.0414662361145%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6665 - accuracy: 0.6155\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7143\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5542 - accuracy: 0.7114\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5362 - accuracy: 0.7129\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5149 - accuracy: 0.7244\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7371\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.7522\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7558\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7616\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7616\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7720\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7788\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.7721\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4385 - accuracy: 0.7790\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4317 - accuracy: 0.7822\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4271 - accuracy: 0.7870\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4303 - accuracy: 0.7809\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.7890\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4223 - accuracy: 0.7879\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4197 - accuracy: 0.7873\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7928\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4138 - accuracy: 0.7923\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.7957\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7988\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8016\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4036 - accuracy: 0.8008\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8026\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4029 - accuracy: 0.8032\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3963 - accuracy: 0.8092\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8085\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8058\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8054\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8094\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8100\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8077\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8046\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8099\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8108\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8066\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8164\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8152\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8127\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8127\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8138\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8152\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8182\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8175\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8186\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8166\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8181\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8111\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8196\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8134\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8202\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8125\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8195\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8153\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8150\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8187\n",
      "Epoch 60/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8210\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8148\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8159\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8211\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8169\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8212\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8182\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8159\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3801 - accuracy: 0.8169\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3782 - accuracy: 0.8194\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8153\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8177\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8196\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8181\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8180\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8214\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8211\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8241\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8201\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8217\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8209\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8198\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8213\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8185\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8208\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8189\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8157\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8228\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8196\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8206\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8209\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8243\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8224\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8188\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8214\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8252\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8202\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8227\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8196\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8215\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8269\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8180\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8197\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8208\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8230\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8216\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8239\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8158\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8219\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8208\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8198\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8223\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8205\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8244\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8253\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8210\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8211\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8201\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8244\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8211\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8206\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8222\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8221\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8247\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8194\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8224\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8239\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8207\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8244\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8212\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8202\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8241\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8241\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8235\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8184\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8149\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8259\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8228\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8203\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8250\n",
      "Epoch 140/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8271\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8216\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8219\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8205\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8238\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8235\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8249\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8264\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8295\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8238\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8217\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8205\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8272\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8244\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8225\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8242\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8184\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8255\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8244\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8224\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8259\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8290\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8227\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8282\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8261\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8262\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8238\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8245\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8218\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8219\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8227\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8208\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8279\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8215\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3623 - accuracy: 0.8291\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8203\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8263\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8245\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8266\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8245\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8263\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8255\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8224\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8240\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8246\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8258\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8258\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8244\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8243\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8233\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8297\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8228\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8263\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8252\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8205\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8238\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8205\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8282\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8252\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8271\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8254\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8255\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8301\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8282\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8253\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8210\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8283\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3578 - accuracy: 0.8297\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8212\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8240\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8269\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8259\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8228\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8213\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8292\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8243\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8317\n",
      "Epoch 00216: early stopping\n",
      "Score for fold 2: loss of 0.38328784704208374; accuracy of 82.07336664199829%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5922 - accuracy: 0.7080\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5653 - accuracy: 0.7109\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7129\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7216\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5068 - accuracy: 0.7395\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7460\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4864 - accuracy: 0.7485\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.7521\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7559\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4648 - accuracy: 0.7606\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7717\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7711\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7733\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.7736\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4402 - accuracy: 0.7746\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4344 - accuracy: 0.7809\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.7813\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.7827\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4260 - accuracy: 0.7863\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4222 - accuracy: 0.7890\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7891\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4178 - accuracy: 0.7941\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4159 - accuracy: 0.7912\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.8004\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4143 - accuracy: 0.7953\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.7998\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4082 - accuracy: 0.8005\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4086 - accuracy: 0.7998\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.8001\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4012 - accuracy: 0.8036\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8026\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3990 - accuracy: 0.8068\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3948 - accuracy: 0.8100\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.8110\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3967 - accuracy: 0.8113\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8089\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3970 - accuracy: 0.8098\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8097\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3972 - accuracy: 0.8086\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8197\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8136\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3943 - accuracy: 0.8089\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8082\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8124\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3983 - accuracy: 0.8083\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8104\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3913 - accuracy: 0.8114\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8098\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8105\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8147\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8109\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8094\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8085\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8047\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8144\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8086\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8087\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8209\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8129\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8086\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8153\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8117\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8114\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3871 - accuracy: 0.8128\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3907 - accuracy: 0.8114\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8164\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8137\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8183\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8154\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8174\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8112\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8155\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3878 - accuracy: 0.8134\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8162\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8152\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3810 - accuracy: 0.8133\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8197\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8145\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8129\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8153\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8079\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8165\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8133\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8129\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8153\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8173\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8204\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8118\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8130\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8099\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8111\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8169\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8194\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8186\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8135\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8165\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8132\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8171\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8219\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8194\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8202\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8174\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8188\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8155\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8136\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8114\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8169\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8182\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8141\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8149\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8203\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8142\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8169\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8156\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8227\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8154\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8197\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8214\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8168\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8220\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8198\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8146\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8107\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8216\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8191\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8210\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8192\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.8135\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8175\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8152\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8189\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8184\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8160\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8174\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8133\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8182\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8145\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8125\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8190\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8177\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8206\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8163\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8106\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8236\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8211\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8149\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8214\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8227\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3815 - accuracy: 0.8144\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8177\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8260\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8174\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8138\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8222\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8188\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8206\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8191\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8154\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8174\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8212\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8187\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8232\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8214\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8152\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8156\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8187\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8154\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8263\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8205\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8243\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8217\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8182\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8185\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8178\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8235\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8215\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8237\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8185\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8230\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8179\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8151\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8165\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8240\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8196\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8190\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8238\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8212\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8254\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8220\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8211\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8201\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8209\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8188\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8240\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8198\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8248\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8245\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8233\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8246\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8231\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8199\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8214\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8262\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8171\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8196\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8261\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8271\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8224\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8212\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8240\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8217\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8228\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8190\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8253\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8192\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8264\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8263\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8218\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8214\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8235\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8270\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8287\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8233\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8239\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3681 - accuracy: 0.8237\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3740 - accuracy: 0.8200\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3685 - accuracy: 0.8239\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8217\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8244\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8240\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8234\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8215\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8229\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8238\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8253\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8219\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8220\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8217\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8279\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8237\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8229\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8240\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8260\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8240\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8267\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8203\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8217\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3706 - accuracy: 0.8245\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8154\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8214\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8240\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8184\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8239\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8209\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3740 - accuracy: 0.8214\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3682 - accuracy: 0.8271\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8237\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8241\n",
      "Epoch 00258: early stopping\n",
      "Score for fold 3: loss of 0.35390427708625793; accuracy of 83.31738710403442%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.6097\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5745 - accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5483 - accuracy: 0.7156\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7171\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7227\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7349\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7438\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7545\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7608\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7615\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7629\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7633\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.7687\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.7753\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4362 - accuracy: 0.7753\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.7789\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4310 - accuracy: 0.7823\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7811\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.7824\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4188 - accuracy: 0.7899\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.7864\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4211 - accuracy: 0.7903\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.7941\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4126 - accuracy: 0.7954\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4086 - accuracy: 0.7981\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.7913\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7950\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4089 - accuracy: 0.7930\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8027\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4030 - accuracy: 0.8011\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8025\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8064\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8061\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8066\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8051\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8117\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3935 - accuracy: 0.8065\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8115\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8041\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8057\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8093\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8143\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3960 - accuracy: 0.8074\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8121\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3867 - accuracy: 0.8125\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8163\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4004 - accuracy: 0.8087\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8090\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8113\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8147\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8172\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8097\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8089\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8182\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8164\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8114\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8136\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8154\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8162\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8136\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8161\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8168\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8154\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8078\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8184\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8186\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8197\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8191\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8193\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3841 - accuracy: 0.8154\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8147\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8162\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8162\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8141\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8178\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8196\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8169\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8244\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8200\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8160\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8142\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8242\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8174\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8178\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8153\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8182\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8204\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8230\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3906 - accuracy: 0.8110\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8157\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8224\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8207\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8185\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8213\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8235\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8177\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8169\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8197\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8163\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8197\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8247\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8200\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8171\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8172\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8213\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8185\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8221\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8286\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8215\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8201\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8197\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8156\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8182\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8180\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8248\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8182\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8188\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8201\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8195\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8198\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8279\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8193\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8194\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8220\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8166\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8157\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8193\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8170\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8247\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8251\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8243\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8194\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8190\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8227\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8265\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8183\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8217\n",
      "Epoch 138/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8224\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8193\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8234\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8226\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3726 - accuracy: 0.8234\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8242\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8258\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8207\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8231\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3733 - accuracy: 0.8201\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8247\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8272\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8273\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8213\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8277\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8241\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8258\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8222\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8260\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8256\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8246\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8247\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8216\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8208\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8231\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8180\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8254\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8234\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8273\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8244\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8250\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8191\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8280\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8234\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8236\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8255\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8256\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8289\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8270\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8258\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8255\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8214\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8246\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8243\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8268\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8267\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8269\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8295\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8288\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8219\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8255\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8235\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8262\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8267\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8279\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8273\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8296\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8333\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8270\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8270\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8290\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8258\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8273\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8273\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8268\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8279\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8243\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8285\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8224\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8290\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8252\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8281\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8261\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8217\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8303\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8300\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8262\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8281\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8297\n",
      "Epoch 00216: early stopping\n",
      "Score for fold 4: loss of 0.36861923336982727; accuracy of 82.54626393318176%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6212 - accuracy: 0.6517\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5643 - accuracy: 0.7116\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7185\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5222 - accuracy: 0.7233\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5025 - accuracy: 0.7386\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7464\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7573\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4670 - accuracy: 0.7599\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4595 - accuracy: 0.7619\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7697\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7701\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.7693\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7772\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.7796\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7824\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4266 - accuracy: 0.7843\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.7883\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4200 - accuracy: 0.7911\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7902\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4142 - accuracy: 0.7954\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8010\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4122 - accuracy: 0.7967\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4111 - accuracy: 0.7952\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.7984\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.8010\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8029\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.7975\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3986 - accuracy: 0.8033\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8088\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8050\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8024\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8086\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3994 - accuracy: 0.8031\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3934 - accuracy: 0.8066\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8087\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8057\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8105\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3853 - accuracy: 0.8125\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8091\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8120\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8144\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8144\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8175\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8122\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8119\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8146\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8176\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8119\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8168\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8180\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3889 - accuracy: 0.8057\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8129\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8144\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8179\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8156\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8168\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8165\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8158\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8185\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8166\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8113\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8131\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8179\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8137\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8208\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8185\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8171\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8174\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8208\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8141\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8175\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8159\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8197\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8153\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8135\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8208\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8190\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8208\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8149\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8204\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8210\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8194\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8218\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8211\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8228\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8234\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8210\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8232\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8221\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8239\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8234\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8201\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8186\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8222\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8204\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8208\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8195\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8208\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8167\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8221\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8185\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8236\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8247\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8248\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8274\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8194\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8227\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8180\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8195\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8245\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8234\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8211\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8209\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8241\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8231\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8235\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8233\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8205\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8262\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8201\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8242\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8254\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8201\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8209\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8233\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8239\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8267\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8256\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8224\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8189\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8260\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8256\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8257\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8282\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8212\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8198\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8242\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8237\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8245\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8246\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8279\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8236\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8238\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8157\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8250\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8216\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3645 - accuracy: 0.8297\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8228\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8269\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8312\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8285\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8258\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8232\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8231\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8283\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8259\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8264\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8209\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8270\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8239\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8209\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8277\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8294\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8287\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8291\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8237\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8230\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8245\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8280\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8243\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8298\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8205\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3588 - accuracy: 0.8303\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8260\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8218\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8228\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8255\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8259\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8262\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.8269\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8289\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8241\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8278\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8297\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8271\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8258\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8267\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8253\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8255\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8256\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3610 - accuracy: 0.8283\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8241\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8256\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8256\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8204\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8283\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8251\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8257\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8232\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8260\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8275\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8254\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8257\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8255\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8278\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8189\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8280\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8299\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8282\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8229\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3590 - accuracy: 0.8264\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8239\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8256\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8289\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8270\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8272\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8260\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8273\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8278\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8218\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8292\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8255\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8258\n",
      "Epoch 00223: early stopping\n",
      "Score for fold 5: loss of 0.3801879584789276; accuracy of 81.84428811073303%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.36908984184265137 - Accuracy: 82.0414662361145%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.38328784704208374 - Accuracy: 82.07336664199829%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.35390427708625793 - Accuracy: 83.31738710403442%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.36861923336982727 - Accuracy: 82.54626393318176%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.3801879584789276 - Accuracy: 81.84428811073303%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 82.3645544052124 (+- 0.5292942093254508)\n",
      "> Loss: 0.3710178315639496\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model1 = model_one()\n",
    "    history = model1.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model1.evaluate(x_train_test_val[test], y_train_test_val[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model1.metrics_names[0]} of {scores[0]}; {model1.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 cross-validation:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.6651\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.7105\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5548 - accuracy: 0.7146\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7169\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7164\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5085 - accuracy: 0.7282\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.7386\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7475\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7543\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4671 - accuracy: 0.7616\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.7623\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4532 - accuracy: 0.7694\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4516 - accuracy: 0.7677\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4474 - accuracy: 0.7704\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4381 - accuracy: 0.7776\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.7724\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.7803\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.7848\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.7871\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4250 - accuracy: 0.7868\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7787\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4184 - accuracy: 0.7877\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.7927\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4167 - accuracy: 0.7910\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4124 - accuracy: 0.7963\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4139 - accuracy: 0.7951\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.7951\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4079 - accuracy: 0.7990\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4057 - accuracy: 0.8050\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4018 - accuracy: 0.8033\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8004\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8052\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4023 - accuracy: 0.8032\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4021 - accuracy: 0.8026\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8056\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8055\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8060\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3977 - accuracy: 0.8078\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3935 - accuracy: 0.8149\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8135\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3942 - accuracy: 0.8103\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8117\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8085\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3961 - accuracy: 0.8098\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3924 - accuracy: 0.8124\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3885 - accuracy: 0.8122\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8151\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8113\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8133\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3920 - accuracy: 0.8110\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8167\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3908 - accuracy: 0.8137\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3822 - accuracy: 0.8222\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8192\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8174\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8157\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8148\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.8171\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8175\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8203\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8172\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8214\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8186\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3865 - accuracy: 0.8143\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8203\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8220\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8207\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8224\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8184\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8206\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8227\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8157\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8195\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8179\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8227\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8160\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8223\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8257\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3793 - accuracy: 0.8189\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8214\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8192\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8216\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8164\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8207\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8237\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8200\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8205\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8189\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8205\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.3773 - accuracy: 0.8217\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8178\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8195\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3816 - accuracy: 0.8180\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8200\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8229\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8216\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8206\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.8165\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8170\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8239\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8238\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8228\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3797 - accuracy: 0.8213\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8217\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3817 - accuracy: 0.8185\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8202\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8222\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8212\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8190\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8227\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8270\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8202\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8260\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8213\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8254\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8203\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8271\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8270\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8211\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8247\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8235\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8255\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8247\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8252\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8224\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8245\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8243\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8250\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8253\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8245\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8253\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8180\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8271\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8256\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8231\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8233\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3730 - accuracy: 0.8199\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8247\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8266\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8251\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8252\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8257\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8218\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8236\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8184\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8222\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8196\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8267\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8257\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8213\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8286\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8270\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8230\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8181\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8227\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8241\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8302\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8207\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8235\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8251\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8214\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8260\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8213\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8223\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8234\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8225\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8228\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8247\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8306\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8258\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8219\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8201\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8218\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8268\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8272\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8200\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8239\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8242\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8213\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8271\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8237\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8254\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8246\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8261\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8231\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8254\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8209\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8244\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8240\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8274\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8240\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8290\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8248\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8265\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8244\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8243\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8231\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8166\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8236\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8219\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8297\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8188\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8302\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8256\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8258\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8228\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8207\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8265\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8271\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8233\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8258\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8245\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8244\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8264\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8302\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8268\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8276\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8287\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8264\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8311\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8243\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8239\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8245\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3593 - accuracy: 0.8282\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8230\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8279\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8306\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8225\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8240\n",
      "Epoch 00229: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score for fold 1: loss of 1.0487453937530518; accuracy of 30.558213591575623%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6502 - accuracy: 0.6033\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.7011\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7093\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5416 - accuracy: 0.7112\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5266 - accuracy: 0.7203\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.7284\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4997 - accuracy: 0.7394\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.7454\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4758 - accuracy: 0.7546\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4708 - accuracy: 0.7576\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.7576\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.7627\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7666\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.7610\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7737\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.7738\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4373 - accuracy: 0.7780\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4370 - accuracy: 0.7787\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4369 - accuracy: 0.7772\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.7789\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.7843\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.7857\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7944\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4190 - accuracy: 0.7896\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7928\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4166 - accuracy: 0.7936\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.7982\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7993\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4078 - accuracy: 0.8024\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8045\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8036\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4025 - accuracy: 0.8037\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4046 - accuracy: 0.8020\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3994 - accuracy: 0.8091\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3983 - accuracy: 0.8084\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4041 - accuracy: 0.8040\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4031 - accuracy: 0.8044\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4071 - accuracy: 0.8066\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8085\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4003 - accuracy: 0.8084\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.8065\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3954 - accuracy: 0.8104\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8050\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8137\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8151\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3946 - accuracy: 0.8111\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3915 - accuracy: 0.8141\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8147\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3879 - accuracy: 0.8158\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8146\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8122\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8150\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3905 - accuracy: 0.8138\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8128\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3862 - accuracy: 0.8153\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3963 - accuracy: 0.8127\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8180\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8196\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8169\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3926 - accuracy: 0.8101\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8203\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8205\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8191\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8160\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8181\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8125\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8178\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8240\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3843 - accuracy: 0.8151\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8184\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8181\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8191\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8178\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8162\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3869 - accuracy: 0.8156\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8228\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8190\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8219\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3783 - accuracy: 0.8190\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8166\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8175\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8204\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3802 - accuracy: 0.8211\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8195\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8183\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8198\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8166\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8252\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8200\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8170\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8194\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.8186\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8201\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3848 - accuracy: 0.8185\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8187\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3792 - accuracy: 0.8178\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8249\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8214\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8224\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8177\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8197\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8275\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8190\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8164\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3853 - accuracy: 0.8171\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8220\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8172\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8227\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8204\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3875 - accuracy: 0.8150\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8229\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8234\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8239\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8240\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3772 - accuracy: 0.8199\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8175\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3790 - accuracy: 0.8192\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8256\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8233\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8203\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8238\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8209\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3741 - accuracy: 0.8271\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8165\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8212\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8220\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8172\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8237\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8212\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8260\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8239\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8241\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8194\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8258\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8212\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8240\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8236\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3787 - accuracy: 0.8208\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8231\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3714 - accuracy: 0.8247\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8218\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8220\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8236\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8225\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3752 - accuracy: 0.8250\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8190\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8191\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8249\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8224\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8220\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8221\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8262\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8202\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8258\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8264\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8263\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8216\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8247\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8263\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3719 - accuracy: 0.8203\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8201\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8238\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3699 - accuracy: 0.8239\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8248\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8211\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8286\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8209\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8206\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8276\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8210\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8232\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8286\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8302\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8238\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8243\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8244\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8214\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8260\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8244\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8243\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8235\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8232\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8236\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8242\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8227\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3674 - accuracy: 0.8224\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8231\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8192\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8230\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8247\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8255\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8255\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8268\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8290\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8255\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8220\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8283\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8293\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8275\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8243\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8261\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8260\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8246\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8265\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8231\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8251\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3691 - accuracy: 0.8219\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8249\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8297\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8228\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8264\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8235\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8250\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3672 - accuracy: 0.8286\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8218\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8268\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8211\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8273\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8262\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8271\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8251\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8271\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8317\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8192\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8238\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8263\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8221\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8260\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8307\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8286\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8312\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8276\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8250\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3674 - accuracy: 0.8282\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8257\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3618 - accuracy: 0.8338\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8284\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8275\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8230\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3698 - accuracy: 0.8248\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8258\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8189\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8285\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8262\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8294\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8316\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8275\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8251\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8257\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8288\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8265\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3669 - accuracy: 0.8266\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8206\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8263\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8221\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8249\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8192\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8274\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8272\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3587 - accuracy: 0.8340\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8249\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8266\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8317\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8266\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8280\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8266\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3702 - accuracy: 0.8242\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8266\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8264\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8282\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8213\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3596 - accuracy: 0.8281\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.8335\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8269\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8292\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3567 - accuracy: 0.8338\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8288\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8276\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8250\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8214\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8270\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8258\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3591 - accuracy: 0.8318\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8252\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8287\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3589 - accuracy: 0.8308\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8300\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3608 - accuracy: 0.8295\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3651 - accuracy: 0.8261\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3595 - accuracy: 0.8293\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8267\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3592 - accuracy: 0.8347\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8268\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3626 - accuracy: 0.8308\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.8295\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3637 - accuracy: 0.8275\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3569 - accuracy: 0.8300\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3563 - accuracy: 0.8320\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8311\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3609 - accuracy: 0.8312\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8291\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3624 - accuracy: 0.8330\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8247\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3614 - accuracy: 0.8283\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8285\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3599 - accuracy: 0.8316\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8293\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8278\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3559 - accuracy: 0.8335\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8223\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.8281\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8241\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8292\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.8297\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8283\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8285\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3555 - accuracy: 0.8317\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8250\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8245\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8265\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3557 - accuracy: 0.8325\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8277\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8226\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3596 - accuracy: 0.8316\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8253\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8274\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8262\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3539 - accuracy: 0.8332\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3598 - accuracy: 0.8325\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3659 - accuracy: 0.8259\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3569 - accuracy: 0.8334\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8316\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8317\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8277\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.8315\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8255\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3531 - accuracy: 0.8326\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8226\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3540 - accuracy: 0.8307\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8301\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3578 - accuracy: 0.8314\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3605 - accuracy: 0.8342\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8308\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3608 - accuracy: 0.8276\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8265\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8256\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.8278\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8284\n",
      "Epoch 00348: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score for fold 2: loss of 0.8239304423332214; accuracy of 27.527910470962524%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6346 - accuracy: 0.7038\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5938 - accuracy: 0.7072\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5640 - accuracy: 0.7106\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7148\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5202 - accuracy: 0.7301\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5033 - accuracy: 0.7409\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4884 - accuracy: 0.7486\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4804 - accuracy: 0.7523\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.7616\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.7585\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4518 - accuracy: 0.7691\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4493 - accuracy: 0.7724\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7774\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4345 - accuracy: 0.7804\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.7841\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4363 - accuracy: 0.7794\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4276 - accuracy: 0.7870\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.7876\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.7913\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.7885\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4158 - accuracy: 0.7956\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4106 - accuracy: 0.8013\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.8001\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4108 - accuracy: 0.8004\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4136 - accuracy: 0.7973\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8038\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4061 - accuracy: 0.8003\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4009 - accuracy: 0.8063\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4011 - accuracy: 0.8028\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8010\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3969 - accuracy: 0.8077\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8062\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3971 - accuracy: 0.8110\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3937 - accuracy: 0.8098\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3923 - accuracy: 0.8172\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3933 - accuracy: 0.8063\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3930 - accuracy: 0.8122\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8131\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3911 - accuracy: 0.8137\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8112\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3925 - accuracy: 0.8114\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3894 - accuracy: 0.8154\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3913 - accuracy: 0.8139\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3964 - accuracy: 0.8086\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3924 - accuracy: 0.8124\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8136\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8181\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8143\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3868 - accuracy: 0.8143\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8155\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8133\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8229\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.8131\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3938 - accuracy: 0.8100\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8179\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8115\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3784 - accuracy: 0.8222\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8125\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8153\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3874 - accuracy: 0.8138\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8205\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8161\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3769 - accuracy: 0.8208\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.8208\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8204\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8188\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3808 - accuracy: 0.8230\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3812 - accuracy: 0.8219\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8219\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8153\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8159\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3846 - accuracy: 0.8159\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8154\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8160\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8165\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8180\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8167\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8243\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8175\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8185\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8177\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8189\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8209\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8240\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8179\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8192\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8225\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8173\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8176\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8187\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3804 - accuracy: 0.8174\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8222\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3803 - accuracy: 0.8231\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8207\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8176\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8193\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8162\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8250\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3880 - accuracy: 0.8150\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.8187\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8225\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8187\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8198\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8220\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8209\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8182\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3782 - accuracy: 0.8184\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8245\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3835 - accuracy: 0.8176\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8242\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8237\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8225\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8148\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8154\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8227\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8180\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8226\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8198\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3753 - accuracy: 0.8215\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8258\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3776 - accuracy: 0.8213\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8220\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8189\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8243\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8267\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8271\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8261\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8226\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8288\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8274\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8187\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8260\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8200\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8259\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8195\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8211\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3733 - accuracy: 0.8204\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8255\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8214\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8199\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3746 - accuracy: 0.8220\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8239\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8234\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8231\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8199\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8225\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8171\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8210\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8175\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8216\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8244\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8273\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3781 - accuracy: 0.8180\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8235\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8215\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8253\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8170\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.8200\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8240\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8193\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8226\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8265\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8250\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8220\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8239\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8275\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3689 - accuracy: 0.8259\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8265\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3737 - accuracy: 0.8215\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8243\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3663 - accuracy: 0.8285\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8247\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8242\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8217\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8226\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8216\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8211\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8258\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.8272\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8217\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3712 - accuracy: 0.8242\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8229\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8244\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3610 - accuracy: 0.8313\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8251\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8261\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8261\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8284\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8270\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8296\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8265\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8244\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3627 - accuracy: 0.8301\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8311\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8271\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8239\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3757 - accuracy: 0.8214\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8300\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8253\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8246\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8221\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3657 - accuracy: 0.8286\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8250\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8304\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8297\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3654 - accuracy: 0.8264\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3767 - accuracy: 0.8208\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8278\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8294\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8287\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8310\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8294\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3734 - accuracy: 0.8220\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8296\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8315\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8255\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3638 - accuracy: 0.8304\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8307\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8286\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3643 - accuracy: 0.8273\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8269\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8319\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8286\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8249\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8205\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3645 - accuracy: 0.8296\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3650 - accuracy: 0.8291\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8274\n",
      "Epoch 00228: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score for fold 3: loss of 0.6952700614929199; accuracy of 48.19776713848114%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6808 - accuracy: 0.6029\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5945 - accuracy: 0.7033\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.7048\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5483 - accuracy: 0.7217\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5342 - accuracy: 0.7266\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7320\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5009 - accuracy: 0.7417\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4940 - accuracy: 0.7416\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4797 - accuracy: 0.7479\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4740 - accuracy: 0.7550\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.7544\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4610 - accuracy: 0.7624\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.7667\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.7681\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7716\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.7699\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4388 - accuracy: 0.7761\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.7701\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4339 - accuracy: 0.7779\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.7834\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7797\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7886\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4201 - accuracy: 0.7887\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4189 - accuracy: 0.7890\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4171 - accuracy: 0.7917\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.7967\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.7943\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.7968\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4100 - accuracy: 0.7980\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.7951\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8052\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4113 - accuracy: 0.7951\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4102 - accuracy: 0.7965\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4064 - accuracy: 0.7992\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4020 - accuracy: 0.8031\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4012 - accuracy: 0.8056\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3991 - accuracy: 0.8067\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3996 - accuracy: 0.8080\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4013 - accuracy: 0.8012\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4029 - accuracy: 0.8004\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3939 - accuracy: 0.8071\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3985 - accuracy: 0.8069\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8135\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3988 - accuracy: 0.8076\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3916 - accuracy: 0.8106\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3918 - accuracy: 0.8074\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3917 - accuracy: 0.8122\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8147\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3806 - accuracy: 0.8160\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3909 - accuracy: 0.8095\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3873 - accuracy: 0.8144\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.8097\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8136\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3871 - accuracy: 0.8116\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3866 - accuracy: 0.8146\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3845 - accuracy: 0.8153\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3951 - accuracy: 0.8062\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3847 - accuracy: 0.8146\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3859 - accuracy: 0.8152\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3901 - accuracy: 0.8109\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8124\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3902 - accuracy: 0.8100\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3771 - accuracy: 0.8186\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3832 - accuracy: 0.8149\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3838 - accuracy: 0.8173\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8180\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8161\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.8110\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3860 - accuracy: 0.8110\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3844 - accuracy: 0.8141\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3814 - accuracy: 0.8170\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8127\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3921 - accuracy: 0.8112\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8199\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3810 - accuracy: 0.8136\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8153\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3852 - accuracy: 0.8130\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3813 - accuracy: 0.8158\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3891 - accuracy: 0.8125\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3905 - accuracy: 0.8127\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8158\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3774 - accuracy: 0.8131\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3824 - accuracy: 0.8164\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8164\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3777 - accuracy: 0.8152\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3780 - accuracy: 0.8127\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3768 - accuracy: 0.8197\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3839 - accuracy: 0.8143\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3766 - accuracy: 0.8182\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8161\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8227\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3761 - accuracy: 0.8153\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3779 - accuracy: 0.8177\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8163\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3788 - accuracy: 0.8178\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3786 - accuracy: 0.8173\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8227\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3760 - accuracy: 0.8188\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8143\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8205\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8216\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8150\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3795 - accuracy: 0.8188\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3759 - accuracy: 0.8202\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8232\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8184\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8207\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8218\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8184\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3798 - accuracy: 0.8196\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3778 - accuracy: 0.8182\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8264\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8202\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3727 - accuracy: 0.8200\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3749 - accuracy: 0.8196\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8146\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8159\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8207\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3745 - accuracy: 0.8169\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8165\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8220\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8238\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3819 - accuracy: 0.8178\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8208\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3785 - accuracy: 0.8126\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8257\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3743 - accuracy: 0.8176\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3756 - accuracy: 0.8189\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8221\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3684 - accuracy: 0.8215\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8174\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8176\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8221\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8251\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8224\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8234\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8242\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8178\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3751 - accuracy: 0.8193\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8234\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8240\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8206\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8226\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8243\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8208\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8229\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8192\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3755 - accuracy: 0.8192\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8231\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3856 - accuracy: 0.8108\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8197\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8181\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8212\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8202\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8219\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8254\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8224\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8253\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8209\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8204\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8206\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8191\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8205\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8234\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8232\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8242\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8225\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8219\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8231\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8228\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3796 - accuracy: 0.8161\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8211\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8226\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8224\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8232\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8235\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8246\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8274\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8211\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3635 - accuracy: 0.8275\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8239\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8286\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8246\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8231\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3634 - accuracy: 0.8241\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8270\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8280\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8271\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8318\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8206\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8230\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8200\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8239\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3660 - accuracy: 0.8260\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3697 - accuracy: 0.8227\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8235\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8199\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8239\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3685 - accuracy: 0.8233\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3683 - accuracy: 0.8232\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8201\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8220\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3664 - accuracy: 0.8231\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3693 - accuracy: 0.8196\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3646 - accuracy: 0.8264\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8239\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3667 - accuracy: 0.8243\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3666 - accuracy: 0.8242\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8291\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8240\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8248\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8225\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8252\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8221\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8274\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8210\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8250\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8178\n",
      "Epoch 00218: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score for fold 4: loss of 0.6478735208511353; accuracy of 70.77217698097229%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6439 - accuracy: 0.6494\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5857 - accuracy: 0.7086\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5665 - accuracy: 0.7100\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5442 - accuracy: 0.7179\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5339 - accuracy: 0.7238\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5186 - accuracy: 0.7287\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7357\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4942 - accuracy: 0.7429\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4817 - accuracy: 0.7514\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7577\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4713 - accuracy: 0.7555\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4589 - accuracy: 0.7657\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7708\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4503 - accuracy: 0.7701\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.7778\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.7785\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.7810\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7828\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.7842\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.7898\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.7916\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.7958\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4173 - accuracy: 0.7941\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.7916\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.7999\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4075 - accuracy: 0.8021\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4087 - accuracy: 0.7996\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4048 - accuracy: 0.8032: 0s - loss: 0.4045 - accuracy: 0.80\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3989 - accuracy: 0.8069\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4007 - accuracy: 0.8028\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4034 - accuracy: 0.8038\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3991 - accuracy: 0.8045\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3952 - accuracy: 0.8101\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3980 - accuracy: 0.8094\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4016 - accuracy: 0.8021\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3995 - accuracy: 0.8072\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8164\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8130\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3960 - accuracy: 0.8117\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3950 - accuracy: 0.8092\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3917 - accuracy: 0.8151\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8118\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3877 - accuracy: 0.8158\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3854 - accuracy: 0.8168\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.8129\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3827 - accuracy: 0.8193\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3893 - accuracy: 0.8149\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8162\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8128\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3834 - accuracy: 0.8135\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8194\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.8182\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3865 - accuracy: 0.8158\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3820 - accuracy: 0.8193\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8276\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8156\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8211\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8170\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3831 - accuracy: 0.8187\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8216\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3811 - accuracy: 0.8171\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3783 - accuracy: 0.8199\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8177\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3735 - accuracy: 0.8208\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3805 - accuracy: 0.8190\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8174\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3762 - accuracy: 0.8197\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3825 - accuracy: 0.8137\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3731 - accuracy: 0.8233\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3851 - accuracy: 0.8161\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8192\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8187\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8197\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8183\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8188\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3818 - accuracy: 0.8147\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3765 - accuracy: 0.8193\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.8170\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3758 - accuracy: 0.8217\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3816 - accuracy: 0.8190\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8152\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8220\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8193\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.8182\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8170\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8137\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8178\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3720 - accuracy: 0.8217\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8216\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8213\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3750 - accuracy: 0.8200\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3744 - accuracy: 0.8199\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8180\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3878 - accuracy: 0.8107\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3724 - accuracy: 0.8236\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8257\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8247\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3837 - accuracy: 0.8153\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3679 - accuracy: 0.8284\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3721 - accuracy: 0.8181\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3701 - accuracy: 0.8226\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3704 - accuracy: 0.8226\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8245\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8237\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8241\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8237\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8217\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3723 - accuracy: 0.8190\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8195\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3694 - accuracy: 0.8242\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8226\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8279\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3747 - accuracy: 0.8179\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3710 - accuracy: 0.8250\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8231\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3716 - accuracy: 0.8195\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3775 - accuracy: 0.8184\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8237\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8223\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8203\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.8215\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3809 - accuracy: 0.8146\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8219\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8235\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8290\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3717 - accuracy: 0.8216\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3671 - accuracy: 0.8220\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3725 - accuracy: 0.8206\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8253\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8210\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3740 - accuracy: 0.8199\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8239\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8175\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8218\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3726 - accuracy: 0.8219\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8262\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8183\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3630 - accuracy: 0.8242\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8243\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8273\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3722 - accuracy: 0.8217\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3711 - accuracy: 0.8208: 0s - loss: 0.3719 - accuracy: 0.82\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8214\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3632 - accuracy: 0.8241\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8244\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3709 - accuracy: 0.8233\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3649 - accuracy: 0.8236\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3707 - accuracy: 0.8221\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8247\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8252\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8286\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.8220\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3718 - accuracy: 0.8234\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3639 - accuracy: 0.8276\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8235\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3620 - accuracy: 0.8287\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3728 - accuracy: 0.8245\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3665 - accuracy: 0.8218\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3656 - accuracy: 0.8246\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3688 - accuracy: 0.8216\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8270\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3655 - accuracy: 0.8257\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3706 - accuracy: 0.8240\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.8243\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3703 - accuracy: 0.8233\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3700 - accuracy: 0.8249\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3625 - accuracy: 0.8303\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8191\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3668 - accuracy: 0.8238\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8250\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8241\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8243\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3682 - accuracy: 0.8241\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3611 - accuracy: 0.8268\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3739 - accuracy: 0.8232\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8222\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8235\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8234\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8271\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8232\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3690 - accuracy: 0.8214\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8240\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8258\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3680 - accuracy: 0.8211\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8199\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3662 - accuracy: 0.8237\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3648 - accuracy: 0.8244\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8237\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3695 - accuracy: 0.8181\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3653 - accuracy: 0.8249\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8261\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3673 - accuracy: 0.8250\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8262\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3546 - accuracy: 0.8332\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3607 - accuracy: 0.8278\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3644 - accuracy: 0.8259\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3600 - accuracy: 0.8288\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8274\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3641 - accuracy: 0.8255\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3715 - accuracy: 0.8211\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3696 - accuracy: 0.8200\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.8276\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3681 - accuracy: 0.8229\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3677 - accuracy: 0.8234\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3636 - accuracy: 0.8230\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8254\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3631 - accuracy: 0.8274\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8276\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3615 - accuracy: 0.8282\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3658 - accuracy: 0.8254\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3642 - accuracy: 0.8250\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8228\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.8265\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8262\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8268\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8262\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3581 - accuracy: 0.8322\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.8286\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3554 - accuracy: 0.8275\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3676 - accuracy: 0.8226\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.3613 - accuracy: 0.8262\n",
      "Epoch 00221: early stopping\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                1740      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 1,761\n",
      "Trainable params: 1,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Score for fold 5: loss of 0.6237574219703674; accuracy of 69.30440068244934%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 1.0487453937530518 - Accuracy: 30.558213591575623%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.8239304423332214 - Accuracy: 27.527910470962524%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.6952700614929199 - Accuracy: 48.19776713848114%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.6478735208511353 - Accuracy: 70.77217698097229%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.6237574219703674 - Accuracy: 69.30440068244934%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 49.272093772888184 (+- 18.37236998701612)\n",
      "> Loss: 0.7679153680801392\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model2 = model_two()\n",
    "    history = model2.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model_two().evaluate(x_train_test_val[test], y_train_test_val[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model2.metrics_names[0]} of {scores[0]}; {model2.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.5906 - accuracy: 0.6104\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4341 - accuracy: 0.7092\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4487 - accuracy: 0.7083\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5493 - accuracy: 0.7017\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4332 - accuracy: 0.7093\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4983 - accuracy: 0.7050\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5323 - accuracy: 0.7028\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4902 - accuracy: 0.7055\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4889 - accuracy: 0.7056\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4631 - accuracy: 0.7073\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4268 - accuracy: 0.7097\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4960 - accuracy: 0.7052\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5613 - accuracy: 0.7009\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4572 - accuracy: 0.7077\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4963 - accuracy: 0.7051\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4758 - accuracy: 0.7065\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4266 - accuracy: 0.7097\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5029 - accuracy: 0.7047\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4733 - accuracy: 0.7067\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4782 - accuracy: 0.7063\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4923 - accuracy: 0.7054\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6371 - accuracy: 0.6959\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5325 - accuracy: 0.7028\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5584 - accuracy: 0.7011\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5592 - accuracy: 0.7010\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4497 - accuracy: 0.7082\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4875 - accuracy: 0.7057\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4632 - accuracy: 0.7073\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4760 - accuracy: 0.7065\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4466 - accuracy: 0.7084\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4256 - accuracy: 0.7098\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5312 - accuracy: 0.7029\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4965 - accuracy: 0.7051\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4769 - accuracy: 0.7064\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3927 - accuracy: 0.7119\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4669 - accuracy: 0.7071\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5055 - accuracy: 0.7045\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5678 - accuracy: 0.7005\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5161 - accuracy: 0.7038\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4668 - accuracy: 0.7071\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5030 - accuracy: 0.7047\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4622 - accuracy: 0.7074\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5159 - accuracy: 0.7039\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4355 - accuracy: 0.7091\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5206 - accuracy: 0.7035\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5608 - accuracy: 0.7009\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4462 - accuracy: 0.7084\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4629 - accuracy: 0.7073\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4361 - accuracy: 0.7091\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4218 - accuracy: 0.7100\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5450 - accuracy: 0.7020\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5488 - accuracy: 0.7017\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4724 - accuracy: 0.7067\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4999 - accuracy: 0.7049\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4892 - accuracy: 0.7056\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3425 - accuracy: 0.7152\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5205 - accuracy: 0.7036\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5814 - accuracy: 0.6996\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4524 - accuracy: 0.7080\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4917 - accuracy: 0.7054\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5463 - accuracy: 0.7019\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4859 - accuracy: 0.7058\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4830 - accuracy: 0.7060\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4950 - accuracy: 0.7052\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5393 - accuracy: 0.7023\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5863 - accuracy: 0.6992\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5104 - accuracy: 0.7042\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4798 - accuracy: 0.7062\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4725 - accuracy: 0.7067\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4886 - accuracy: 0.7057\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4782 - accuracy: 0.7063\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5131 - accuracy: 0.7040\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4281 - accuracy: 0.7096\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4755 - accuracy: 0.7065\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4773 - accuracy: 0.7064\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4137 - accuracy: 0.7106\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4644 - accuracy: 0.7072\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4954 - accuracy: 0.7052\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4700 - accuracy: 0.7069\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5116 - accuracy: 0.7041\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5331 - accuracy: 0.7027\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4711 - accuracy: 0.7068\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5172 - accuracy: 0.7038\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5145 - accuracy: 0.7040\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3507 - accuracy: 0.7147\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4850 - accuracy: 0.7059\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5257 - accuracy: 0.7032\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4955 - accuracy: 0.7052\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4688 - accuracy: 0.7069\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5049 - accuracy: 0.7046\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5222 - accuracy: 0.7034\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5055 - accuracy: 0.7045\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4027 - accuracy: 0.7113\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5491 - accuracy: 0.7017\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5005 - accuracy: 0.7049\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4880 - accuracy: 0.7057\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4663 - accuracy: 0.7071\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5769 - accuracy: 0.6999\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4838 - accuracy: 0.7060\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4932 - accuracy: 0.7053\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4524 - accuracy: 0.7080\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4590 - accuracy: 0.7076\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5255 - accuracy: 0.7032\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4521 - accuracy: 0.7080\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5216 - accuracy: 0.7035\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4673 - accuracy: 0.7070\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5563 - accuracy: 0.7012\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4770 - accuracy: 0.7064\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4659 - accuracy: 0.7071\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5013 - accuracy: 0.7048\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4851 - accuracy: 0.7059\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5112 - accuracy: 0.7042\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5526 - accuracy: 0.7015\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5156 - accuracy: 0.7039\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4960 - accuracy: 0.7052\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5040 - accuracy: 0.7046\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5382 - accuracy: 0.7024\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5286 - accuracy: 0.7030\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4340 - accuracy: 0.7092\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4973 - accuracy: 0.7051\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5005 - accuracy: 0.7049\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4750 - accuracy: 0.7065\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5335 - accuracy: 0.7027\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5222 - accuracy: 0.7034\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5696 - accuracy: 0.7003\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4901 - accuracy: 0.7056\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4260 - accuracy: 0.7098\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5041 - accuracy: 0.7046\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5376 - accuracy: 0.7024\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5123 - accuracy: 0.7041\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4760 - accuracy: 0.7065\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5134 - accuracy: 0.7040\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5363 - accuracy: 0.7025\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4968 - accuracy: 0.7051\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5338 - accuracy: 0.7027\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5249 - accuracy: 0.7033\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5415 - accuracy: 0.7022\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4494 - accuracy: 0.7082\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4832 - accuracy: 0.7060\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4573 - accuracy: 0.7077\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5344 - accuracy: 0.7026\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4555 - accuracy: 0.7078\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5718 - accuracy: 0.7002\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4621 - accuracy: 0.7074\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5486 - accuracy: 0.7017\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6244 - accuracy: 0.6967\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4655 - accuracy: 0.7072\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4653 - accuracy: 0.7072\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4609 - accuracy: 0.7075\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5097 - accuracy: 0.7043\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4877 - accuracy: 0.7057\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5180 - accuracy: 0.7037\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4530 - accuracy: 0.7080\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5369 - accuracy: 0.7025\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4728 - accuracy: 0.7067\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4958 - accuracy: 0.7052\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4685 - accuracy: 0.7070\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4446 - accuracy: 0.7085\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5519 - accuracy: 0.7015\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4812 - accuracy: 0.7061\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5029 - accuracy: 0.7047\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5441 - accuracy: 0.7020\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4687 - accuracy: 0.7070\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4554 - accuracy: 0.7078\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3966 - accuracy: 0.7117\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4604 - accuracy: 0.7075\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5345 - accuracy: 0.7026\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5178 - accuracy: 0.7037\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4724 - accuracy: 0.7067\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4648 - accuracy: 0.7072\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5306 - accuracy: 0.7029\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5740 - accuracy: 0.7000\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4871 - accuracy: 0.7057\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5080 - accuracy: 0.7044\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4960 - accuracy: 0.7052\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4377 - accuracy: 0.7090\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5882 - accuracy: 0.6991\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4015 - accuracy: 0.7114\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4382 - accuracy: 0.7090\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5214 - accuracy: 0.7035\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5999 - accuracy: 0.6983\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5370 - accuracy: 0.7025\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4342 - accuracy: 0.7092\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5499 - accuracy: 0.7016\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5050 - accuracy: 0.7046\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4995 - accuracy: 0.7049\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4737 - accuracy: 0.7066\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4979 - accuracy: 0.7050\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6619 - accuracy: 0.6943\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5023 - accuracy: 0.7047\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4557 - accuracy: 0.7078\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4707 - accuracy: 0.7068\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4959 - accuracy: 0.7052\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5364 - accuracy: 0.7025\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5164 - accuracy: 0.7038\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3748 - accuracy: 0.7131\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4742 - accuracy: 0.7066\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5018 - accuracy: 0.7048\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4377 - accuracy: 0.7090\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4594 - accuracy: 0.7076\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5079 - accuracy: 0.7044\n",
      "Epoch 00201: early stopping\n",
      "Score for fold 1: loss of 4.372908115386963; accuracy of 71.32376432418823%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.0934 - accuracy: 0.6130\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4762 - accuracy: 0.7065\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5127 - accuracy: 0.7041\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4515 - accuracy: 0.7081\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6132 - accuracy: 0.6975\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4831 - accuracy: 0.7060\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4943 - accuracy: 0.7053\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4788 - accuracy: 0.7063\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5087 - accuracy: 0.7043\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5220 - accuracy: 0.7035\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5344 - accuracy: 0.7026\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5135 - accuracy: 0.7040\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4704 - accuracy: 0.7068\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4701 - accuracy: 0.7069\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5521 - accuracy: 0.7015\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5481 - accuracy: 0.7017\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5008 - accuracy: 0.7048\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5437 - accuracy: 0.7020\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4887 - accuracy: 0.7056\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5616 - accuracy: 0.7009\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5239 - accuracy: 0.7033\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5005 - accuracy: 0.7049\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5474 - accuracy: 0.7018\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5656 - accuracy: 0.7006\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3917 - accuracy: 0.7120\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5220 - accuracy: 0.7035\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4928 - accuracy: 0.7054\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4779 - accuracy: 0.7064\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4304 - accuracy: 0.7095\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5003 - accuracy: 0.7049\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5067 - accuracy: 0.7045\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5054 - accuracy: 0.7046\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6066 - accuracy: 0.6979\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5342 - accuracy: 0.7027\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4871 - accuracy: 0.7057\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5330 - accuracy: 0.7027\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5415 - accuracy: 0.7022\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5423 - accuracy: 0.7021\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5269 - accuracy: 0.7031\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5317 - accuracy: 0.7028\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5480 - accuracy: 0.7018\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5744 - accuracy: 0.7000\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5305 - accuracy: 0.7029\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5305 - accuracy: 0.7029\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5638 - accuracy: 0.7007\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5238 - accuracy: 0.7033\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4813 - accuracy: 0.7061\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5181 - accuracy: 0.7037\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4731 - accuracy: 0.7067\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5543 - accuracy: 0.7013\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5433 - accuracy: 0.7021\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4938 - accuracy: 0.7053\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5016 - accuracy: 0.7048\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5464 - accuracy: 0.7019\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6018 - accuracy: 0.6982\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5003 - accuracy: 0.7049\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5124 - accuracy: 0.7041\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4680 - accuracy: 0.7070\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5021 - accuracy: 0.7048\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5796 - accuracy: 0.6997\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4251 - accuracy: 0.7098\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4514 - accuracy: 0.7081\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5525 - accuracy: 0.7015\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5173 - accuracy: 0.7038\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4633 - accuracy: 0.7073\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4794 - accuracy: 0.7063\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4888 - accuracy: 0.7056\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5157 - accuracy: 0.7039\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5230 - accuracy: 0.7034\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5631 - accuracy: 0.7008\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4625 - accuracy: 0.7074\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6262 - accuracy: 0.6966\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4766 - accuracy: 0.7064\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4912 - accuracy: 0.7055\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5277 - accuracy: 0.7031\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4854 - accuracy: 0.7059\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6497 - accuracy: 0.6951\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5221 - accuracy: 0.7035\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4579 - accuracy: 0.7077\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5533 - accuracy: 0.7014\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4508 - accuracy: 0.7081\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5246 - accuracy: 0.7033\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4696 - accuracy: 0.7069\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4790 - accuracy: 0.7063\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6372 - accuracy: 0.6959\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4720 - accuracy: 0.7067\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4375 - accuracy: 0.7090\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6032 - accuracy: 0.6981\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5311 - accuracy: 0.7029\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5700 - accuracy: 0.7003\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4917 - accuracy: 0.7054\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4506 - accuracy: 0.7081\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6346 - accuracy: 0.6961\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5195 - accuracy: 0.7036\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5122 - accuracy: 0.7041\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5372 - accuracy: 0.7025\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4697 - accuracy: 0.7069\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5028 - accuracy: 0.7047\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5785 - accuracy: 0.6998\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4935 - accuracy: 0.7053\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5033 - accuracy: 0.7047\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5036 - accuracy: 0.7047\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4546 - accuracy: 0.7079\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5756 - accuracy: 0.6999\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5080 - accuracy: 0.7044\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5082 - accuracy: 0.7044\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4622 - accuracy: 0.7074\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5578 - accuracy: 0.7011\n",
      "Epoch 109/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4634 - accuracy: 0.7073\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4739 - accuracy: 0.7066\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5531 - accuracy: 0.7014\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5776 - accuracy: 0.6998\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4791 - accuracy: 0.7063\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5310 - accuracy: 0.7029\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5267 - accuracy: 0.7032\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5483 - accuracy: 0.7017\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4479 - accuracy: 0.7083\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6193 - accuracy: 0.6971\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5443 - accuracy: 0.7020\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5454 - accuracy: 0.7019\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4752 - accuracy: 0.7065\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4465 - accuracy: 0.7084\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5923 - accuracy: 0.6988\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5892 - accuracy: 0.6991\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4636 - accuracy: 0.7073\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5138 - accuracy: 0.7040\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5422 - accuracy: 0.7021\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4760 - accuracy: 0.7065\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5771 - accuracy: 0.6998\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5235 - accuracy: 0.7034\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5270 - accuracy: 0.7031\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5053 - accuracy: 0.7046\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5021 - accuracy: 0.7048\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5685 - accuracy: 0.7004\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5082 - accuracy: 0.7044\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4505 - accuracy: 0.7081\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4661 - accuracy: 0.7071\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5292 - accuracy: 0.7030\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5006 - accuracy: 0.7049\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5513 - accuracy: 0.7015\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5630 - accuracy: 0.7008\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5798 - accuracy: 0.6997\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4071 - accuracy: 0.7110\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5475 - accuracy: 0.7018\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5012 - accuracy: 0.7048\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5350 - accuracy: 0.7026\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4416 - accuracy: 0.7087\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5106 - accuracy: 0.7042\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4071 - accuracy: 0.7110\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4369 - accuracy: 0.7090\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5001 - accuracy: 0.7049\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4680 - accuracy: 0.7070\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4931 - accuracy: 0.7054\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5970 - accuracy: 0.6985\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5717 - accuracy: 0.7002\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5475 - accuracy: 0.7018\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3372 - accuracy: 0.7156\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5839 - accuracy: 0.6994\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3874 - accuracy: 0.7123\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4579 - accuracy: 0.7077\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5388 - accuracy: 0.7024\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4815 - accuracy: 0.7061\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5191 - accuracy: 0.7037\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6178 - accuracy: 0.6972\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4247 - accuracy: 0.7098\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4856 - accuracy: 0.7059\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4874 - accuracy: 0.7057\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4695 - accuracy: 0.7069\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5332 - accuracy: 0.7027\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5749 - accuracy: 0.7000\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4902 - accuracy: 0.7055\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5548 - accuracy: 0.7013\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5634 - accuracy: 0.7007\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5186 - accuracy: 0.7037\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5111 - accuracy: 0.7042\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5013 - accuracy: 0.7048\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5547 - accuracy: 0.7013\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5075 - accuracy: 0.7044\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4724 - accuracy: 0.7067\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4626 - accuracy: 0.7074\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5302 - accuracy: 0.7029\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5877 - accuracy: 0.6992\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4389 - accuracy: 0.7089\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5542 - accuracy: 0.7013\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5201 - accuracy: 0.7036\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4459 - accuracy: 0.7085\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5361 - accuracy: 0.7025\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4899 - accuracy: 0.7056\n",
      "Epoch 189/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5406 - accuracy: 0.7022\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.6016 - accuracy: 0.6982\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4367 - accuracy: 0.7091\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.6121 - accuracy: 0.6976\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5055 - accuracy: 0.7045\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5280 - accuracy: 0.7031\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4432 - accuracy: 0.7086\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5011 - accuracy: 0.7048\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5537 - accuracy: 0.7014\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5195 - accuracy: 0.7036\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5394 - accuracy: 0.7023\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5475 - accuracy: 0.7018\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5398 - accuracy: 0.7023\n",
      "Epoch 00201: early stopping\n",
      "Score for fold 2: loss of 4.261033058166504; accuracy of 72.0574140548706%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.3074 - accuracy: 0.6174\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3495 - accuracy: 0.7148\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4090 - accuracy: 0.7109\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4168 - accuracy: 0.7104\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4189 - accuracy: 0.7102\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3149 - accuracy: 0.7170\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3565 - accuracy: 0.7143\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4329 - accuracy: 0.7093\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4603 - accuracy: 0.7075\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4989 - accuracy: 0.7050\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3731 - accuracy: 0.7132\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3654 - accuracy: 0.7137\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3701 - accuracy: 0.7134\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3678 - accuracy: 0.7136\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5187 - accuracy: 0.7037\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4000 - accuracy: 0.7115\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4206 - accuracy: 0.7101\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4349 - accuracy: 0.7092\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3687 - accuracy: 0.7135\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3128 - accuracy: 0.7172\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4437 - accuracy: 0.7086\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4489 - accuracy: 0.7083\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4692 - accuracy: 0.7069\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4271 - accuracy: 0.7097\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3825 - accuracy: 0.7126\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4047 - accuracy: 0.7112\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4909 - accuracy: 0.7055\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4976 - accuracy: 0.7051\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4838 - accuracy: 0.7060\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4330 - accuracy: 0.7093\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5109 - accuracy: 0.7042\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4989 - accuracy: 0.7050\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4210 - accuracy: 0.7101\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4032 - accuracy: 0.7113\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3792 - accuracy: 0.7128\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4215 - accuracy: 0.7101\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.2826 - accuracy: 0.7192\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4359 - accuracy: 0.7091\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4060 - accuracy: 0.7111\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4598 - accuracy: 0.7075\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3749 - accuracy: 0.7131\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5283 - accuracy: 0.7030\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4522 - accuracy: 0.7080\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4513 - accuracy: 0.7081\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3390 - accuracy: 0.7155\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4623 - accuracy: 0.7074\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3622 - accuracy: 0.7139\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5190 - accuracy: 0.7037\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4592 - accuracy: 0.7076\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4901 - accuracy: 0.7056\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3144 - accuracy: 0.7171\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4797 - accuracy: 0.7062\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3729 - accuracy: 0.7132\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4158 - accuracy: 0.7104\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3548 - accuracy: 0.7144\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3966 - accuracy: 0.7117\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3591 - accuracy: 0.7141\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4348 - accuracy: 0.7092\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3768 - accuracy: 0.7130\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4371 - accuracy: 0.7090\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3751 - accuracy: 0.7131\n",
      "Epoch 62/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4549 - accuracy: 0.7079\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4197 - accuracy: 0.7102\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4108 - accuracy: 0.7108\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3977 - accuracy: 0.7116\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4055 - accuracy: 0.7111\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4740 - accuracy: 0.7066\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3604 - accuracy: 0.7141\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4501 - accuracy: 0.7082\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4723 - accuracy: 0.7067\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3600 - accuracy: 0.7141\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3616 - accuracy: 0.7140\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4187 - accuracy: 0.7102\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4879 - accuracy: 0.7057\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4642 - accuracy: 0.7072\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4540 - accuracy: 0.7079\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3864 - accuracy: 0.7124\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3969 - accuracy: 0.7117\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4341 - accuracy: 0.7092\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5084 - accuracy: 0.7044\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4622 - accuracy: 0.7074\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3713 - accuracy: 0.7133\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5038 - accuracy: 0.7047\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3980 - accuracy: 0.7116\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3926 - accuracy: 0.7119\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4579 - accuracy: 0.7077\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4231 - accuracy: 0.7099\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5175 - accuracy: 0.7038\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4201 - accuracy: 0.7101\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4151 - accuracy: 0.7105\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4456 - accuracy: 0.7085\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4352 - accuracy: 0.7092\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4072 - accuracy: 0.7110\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4338 - accuracy: 0.7092\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3939 - accuracy: 0.7119\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4310 - accuracy: 0.7094\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4044 - accuracy: 0.7112\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3541 - accuracy: 0.7145\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3665 - accuracy: 0.7137\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4171 - accuracy: 0.7103\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4736 - accuracy: 0.7066\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5143 - accuracy: 0.7040\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4529 - accuracy: 0.7080\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4120 - accuracy: 0.7107\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3333 - accuracy: 0.7158\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4474 - accuracy: 0.7084\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4179 - accuracy: 0.7103\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4272 - accuracy: 0.7097\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5454 - accuracy: 0.7019\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.2190 - accuracy: 0.7233\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3867 - accuracy: 0.7123\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4713 - accuracy: 0.7068\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4020 - accuracy: 0.7113\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3833 - accuracy: 0.7126\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4703 - accuracy: 0.7069\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4292 - accuracy: 0.7095\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5292 - accuracy: 0.7030\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4723 - accuracy: 0.7067\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4939 - accuracy: 0.7053\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3655 - accuracy: 0.7137\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4049 - accuracy: 0.7111\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5006 - accuracy: 0.7049\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4086 - accuracy: 0.7109\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4317 - accuracy: 0.7094\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4225 - accuracy: 0.7100\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4056 - accuracy: 0.7111\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3786 - accuracy: 0.7129\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4859 - accuracy: 0.7058\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3736 - accuracy: 0.7132\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3651 - accuracy: 0.7137\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3797 - accuracy: 0.7128\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4786 - accuracy: 0.7063\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3575 - accuracy: 0.7143\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3420 - accuracy: 0.7153\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4557 - accuracy: 0.7078\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4389 - accuracy: 0.7089\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3736 - accuracy: 0.7132\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4837 - accuracy: 0.7060\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3697 - accuracy: 0.7134\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4404 - accuracy: 0.7088\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3607 - accuracy: 0.7140\n",
      "Epoch 142/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4623 - accuracy: 0.7074\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3865 - accuracy: 0.7123\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3958 - accuracy: 0.7117\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4774 - accuracy: 0.7064\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4687 - accuracy: 0.7070\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4565 - accuracy: 0.7078\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3386 - accuracy: 0.7155\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3363 - accuracy: 0.7156\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3667 - accuracy: 0.7136\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4925 - accuracy: 0.7054\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4642 - accuracy: 0.7073\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3991 - accuracy: 0.7115\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4869 - accuracy: 0.7058\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4368 - accuracy: 0.7091\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4088 - accuracy: 0.7109\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4645 - accuracy: 0.7072\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3569 - accuracy: 0.7143\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3984 - accuracy: 0.7116\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4234 - accuracy: 0.7099\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4146 - accuracy: 0.7105\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4733 - accuracy: 0.7067\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4701 - accuracy: 0.7069\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4814 - accuracy: 0.7061\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3217 - accuracy: 0.7166\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4076 - accuracy: 0.7110\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4843 - accuracy: 0.7059\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3693 - accuracy: 0.7135\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3920 - accuracy: 0.7120\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5219 - accuracy: 0.7035\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4233 - accuracy: 0.7099\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4030 - accuracy: 0.7113\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4774 - accuracy: 0.7064\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5230 - accuracy: 0.7034\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3754 - accuracy: 0.7131\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3659 - accuracy: 0.7137\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3332 - accuracy: 0.7158\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3424 - accuracy: 0.7152\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3639 - accuracy: 0.7138\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4937 - accuracy: 0.7053\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5399 - accuracy: 0.7023\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4122 - accuracy: 0.7107\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3938 - accuracy: 0.7119\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4293 - accuracy: 0.7095\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3397 - accuracy: 0.7154\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3865 - accuracy: 0.7123\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3276 - accuracy: 0.7162\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4322 - accuracy: 0.7093\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4226 - accuracy: 0.7100\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3978 - accuracy: 0.7116\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3675 - accuracy: 0.7136\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4308 - accuracy: 0.7094\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4195 - accuracy: 0.7102\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4093 - accuracy: 0.7108\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3751 - accuracy: 0.7131\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.2490 - accuracy: 0.7214\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3385 - accuracy: 0.7155\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3943 - accuracy: 0.7118\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3883 - accuracy: 0.7122\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3975 - accuracy: 0.7116\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4405 - accuracy: 0.7088\n",
      "Epoch 00201: early stopping\n",
      "Score for fold 3: loss of 4.664759159088135; accuracy of 69.40988898277283%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 7.1240 - accuracy: 0.4978\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4337 - accuracy: 0.7092\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4198 - accuracy: 0.7102\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5194 - accuracy: 0.7036\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4347 - accuracy: 0.7092\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4362 - accuracy: 0.7091\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4270 - accuracy: 0.7097\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4224 - accuracy: 0.7100\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4250 - accuracy: 0.7098\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4703 - accuracy: 0.7068\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3958 - accuracy: 0.7117\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4523 - accuracy: 0.7080\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5241 - accuracy: 0.7033\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4595 - accuracy: 0.7076\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4409 - accuracy: 0.7088\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5218 - accuracy: 0.7035\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3850 - accuracy: 0.7124\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4348 - accuracy: 0.7092\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4287 - accuracy: 0.7096\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4195 - accuracy: 0.7102\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4013 - accuracy: 0.7114\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4819 - accuracy: 0.7061\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4582 - accuracy: 0.7076\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5017 - accuracy: 0.7048\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3548 - accuracy: 0.7144\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4125 - accuracy: 0.7106\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4175 - accuracy: 0.7103\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4503 - accuracy: 0.7082\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3794 - accuracy: 0.7128\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4942 - accuracy: 0.7053\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4063 - accuracy: 0.7110\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4111 - accuracy: 0.7107\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3606 - accuracy: 0.7140\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3927 - accuracy: 0.7119\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3785 - accuracy: 0.7129\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4312 - accuracy: 0.7094\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4444 - accuracy: 0.7086\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4346 - accuracy: 0.7092\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4633 - accuracy: 0.7073\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4222 - accuracy: 0.7100\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4612 - accuracy: 0.7074\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4389 - accuracy: 0.7089\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4739 - accuracy: 0.7066\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3470 - accuracy: 0.7149\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4307 - accuracy: 0.7094\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4481 - accuracy: 0.7083\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4916 - accuracy: 0.7055\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3617 - accuracy: 0.7140\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4770 - accuracy: 0.7064\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3617 - accuracy: 0.7140\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5392 - accuracy: 0.7023\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3164 - accuracy: 0.7169\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4104 - accuracy: 0.7108\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3486 - accuracy: 0.7148\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4084 - accuracy: 0.7109\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4232 - accuracy: 0.7099\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3984 - accuracy: 0.7116\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4793 - accuracy: 0.7063\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3725 - accuracy: 0.7133\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4131 - accuracy: 0.7106\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4111 - accuracy: 0.7107\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4711 - accuracy: 0.7068\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4258 - accuracy: 0.7098\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3868 - accuracy: 0.7123\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3611 - accuracy: 0.7140\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4311 - accuracy: 0.7094\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4393 - accuracy: 0.7089\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5004 - accuracy: 0.7049\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3803 - accuracy: 0.7128\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4447 - accuracy: 0.7085\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4299 - accuracy: 0.7095\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4453 - accuracy: 0.7085\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4215 - accuracy: 0.7100\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3928 - accuracy: 0.7119\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4595 - accuracy: 0.7076\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4664 - accuracy: 0.7071\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4262 - accuracy: 0.7097\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4464 - accuracy: 0.7084\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4721 - accuracy: 0.7067\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3062 - accuracy: 0.7176\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4629 - accuracy: 0.7073\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4280 - accuracy: 0.7096\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4242 - accuracy: 0.7099\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4120 - accuracy: 0.7107\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4153 - accuracy: 0.7105\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4763 - accuracy: 0.7065\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4050 - accuracy: 0.7111\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5321 - accuracy: 0.7028\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4698 - accuracy: 0.7069\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3923 - accuracy: 0.7120\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4155 - accuracy: 0.7104\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3548 - accuracy: 0.7144\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4292 - accuracy: 0.7095\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4474 - accuracy: 0.7084\n",
      "Epoch 95/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3815 - accuracy: 0.7127\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3793 - accuracy: 0.7128\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4294 - accuracy: 0.7095\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4495 - accuracy: 0.7082\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3954 - accuracy: 0.7118\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4715 - accuracy: 0.7068\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4928 - accuracy: 0.7054\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4840 - accuracy: 0.7060\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4436 - accuracy: 0.7086\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3383 - accuracy: 0.7155\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3658 - accuracy: 0.7137\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3939 - accuracy: 0.7119\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4944 - accuracy: 0.7053\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4433 - accuracy: 0.7086\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4919 - accuracy: 0.7054\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3928 - accuracy: 0.7119\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4919 - accuracy: 0.7054\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4579 - accuracy: 0.7077\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4147 - accuracy: 0.7105\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5388 - accuracy: 0.7024\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4529 - accuracy: 0.7080\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4258 - accuracy: 0.7098\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4751 - accuracy: 0.7065\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3761 - accuracy: 0.7130\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4997 - accuracy: 0.7049\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3863 - accuracy: 0.7124\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4052 - accuracy: 0.7111\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4636 - accuracy: 0.7073\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4287 - accuracy: 0.7096\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4967 - accuracy: 0.7051\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4591 - accuracy: 0.7076\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5072 - accuracy: 0.7044\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3147 - accuracy: 0.7171\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4520 - accuracy: 0.7080\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4801 - accuracy: 0.7062\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3659 - accuracy: 0.7137\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3758 - accuracy: 0.7130\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4128 - accuracy: 0.7106\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4227 - accuracy: 0.7100\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4582 - accuracy: 0.7076\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4995 - accuracy: 0.7049\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3955 - accuracy: 0.7118\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4228 - accuracy: 0.7100\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3996 - accuracy: 0.7115\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3574 - accuracy: 0.7143\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3456 - accuracy: 0.7150\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3975 - accuracy: 0.7116\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3906 - accuracy: 0.7121\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4601 - accuracy: 0.7075\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4848 - accuracy: 0.7059\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3377 - accuracy: 0.7155\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5465 - accuracy: 0.7019\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4951 - accuracy: 0.7052\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4044 - accuracy: 0.7112\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5516 - accuracy: 0.7015\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4120 - accuracy: 0.7107\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3860 - accuracy: 0.7124\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5147 - accuracy: 0.7039\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5045 - accuracy: 0.7046\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4877 - accuracy: 0.7057\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3386 - accuracy: 0.7155\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4270 - accuracy: 0.7097\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4188 - accuracy: 0.7102\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4146 - accuracy: 0.7105\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4360 - accuracy: 0.7091\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3737 - accuracy: 0.7132\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4688 - accuracy: 0.7070\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3737 - accuracy: 0.7132\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4314 - accuracy: 0.7094\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3960 - accuracy: 0.7117\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3602 - accuracy: 0.7141\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5440 - accuracy: 0.7020\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4006 - accuracy: 0.7114\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4255 - accuracy: 0.7098\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5433 - accuracy: 0.7021\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4104 - accuracy: 0.7108\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3399 - accuracy: 0.7154\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4091 - accuracy: 0.7109\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4051 - accuracy: 0.7111\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4829 - accuracy: 0.7060\n",
      "Epoch 175/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3685 - accuracy: 0.7135\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4387 - accuracy: 0.7089\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4695 - accuracy: 0.7069\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5369 - accuracy: 0.7025\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4700 - accuracy: 0.7069\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4950 - accuracy: 0.7052\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4826 - accuracy: 0.7060\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4378 - accuracy: 0.7090\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4361 - accuracy: 0.7091\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4019 - accuracy: 0.7113\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4166 - accuracy: 0.7104\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4607 - accuracy: 0.7075\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3718 - accuracy: 0.7133\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3780 - accuracy: 0.7129\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4265 - accuracy: 0.7097\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4594 - accuracy: 0.7076\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4788 - accuracy: 0.7063\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3436 - accuracy: 0.7152\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4563 - accuracy: 0.7078\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3997 - accuracy: 0.7115\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4691 - accuracy: 0.7069\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3957 - accuracy: 0.7117\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4047 - accuracy: 0.7112\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4626 - accuracy: 0.7074\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4786 - accuracy: 0.7063\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3967 - accuracy: 0.7117\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4726 - accuracy: 0.7067\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3469 - accuracy: 0.7149\n",
      "Epoch 00202: early stopping\n",
      "Score for fold 4: loss of 4.408363342285156; accuracy of 71.09125852584839%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 5.8194 - accuracy: 0.6057\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3724 - accuracy: 0.7133\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4232 - accuracy: 0.7099\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4798 - accuracy: 0.7062\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5471 - accuracy: 0.7018\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4225 - accuracy: 0.7100\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4264 - accuracy: 0.7097\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4573 - accuracy: 0.7077\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4262 - accuracy: 0.7097\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5228 - accuracy: 0.7034\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4198 - accuracy: 0.7102\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3974 - accuracy: 0.7116\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4645 - accuracy: 0.7072\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3740 - accuracy: 0.7132\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3357 - accuracy: 0.7157\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4439 - accuracy: 0.7086\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5027 - accuracy: 0.7047\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4049 - accuracy: 0.7111\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4135 - accuracy: 0.7106\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3638 - accuracy: 0.7138\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4762 - accuracy: 0.7065\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 4.3368 - accuracy: 0.7156\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4291 - accuracy: 0.7096\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4856 - accuracy: 0.7058\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4747 - accuracy: 0.7066\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3732 - accuracy: 0.7132\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4915 - accuracy: 0.7055\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4662 - accuracy: 0.7071\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5556 - accuracy: 0.7013\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4579 - accuracy: 0.7077\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4478 - accuracy: 0.7083\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4366 - accuracy: 0.7091\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4871 - accuracy: 0.7058\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4634 - accuracy: 0.7073\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5248 - accuracy: 0.7033\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3818 - accuracy: 0.7127\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3245 - accuracy: 0.7164\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3724 - accuracy: 0.7133\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4708 - accuracy: 0.7068\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5238 - accuracy: 0.7033\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4376 - accuracy: 0.7090\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4372 - accuracy: 0.7090\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5487 - accuracy: 0.7017\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4136 - accuracy: 0.7106\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4636 - accuracy: 0.7073\n",
      "Epoch 46/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5152 - accuracy: 0.7039\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4211 - accuracy: 0.7101\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3694 - accuracy: 0.7135\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3955 - accuracy: 0.7118\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4659 - accuracy: 0.7071\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3788 - accuracy: 0.7129\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4555 - accuracy: 0.7078\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3899 - accuracy: 0.7121\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4370 - accuracy: 0.7090\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4649 - accuracy: 0.7072\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5013 - accuracy: 0.7048\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3979 - accuracy: 0.7116\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4028 - accuracy: 0.7113\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4477 - accuracy: 0.7083\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3772 - accuracy: 0.7130\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4976 - accuracy: 0.7051\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4946 - accuracy: 0.7053\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5297 - accuracy: 0.7030\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4682 - accuracy: 0.7070\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5576 - accuracy: 0.7011\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4616 - accuracy: 0.7074\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4930 - accuracy: 0.7054\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3921 - accuracy: 0.7120\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4440 - accuracy: 0.7086\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4536 - accuracy: 0.7079\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4532 - accuracy: 0.7080\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4915 - accuracy: 0.7055\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4018 - accuracy: 0.7113\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4221 - accuracy: 0.7100\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3808 - accuracy: 0.7127\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4881 - accuracy: 0.7057\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4444 - accuracy: 0.7086\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5106 - accuracy: 0.7042\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4196 - accuracy: 0.7102\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4287 - accuracy: 0.7096\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4007 - accuracy: 0.7114\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3771 - accuracy: 0.7130\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3093 - accuracy: 0.7174\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4272 - accuracy: 0.7097\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4195 - accuracy: 0.7102\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4440 - accuracy: 0.7086\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4368 - accuracy: 0.7090\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4645 - accuracy: 0.7072\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4128 - accuracy: 0.7106\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4667 - accuracy: 0.7071\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3759 - accuracy: 0.7130\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4181 - accuracy: 0.7103\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4164 - accuracy: 0.7104\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4037 - accuracy: 0.7112\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4409 - accuracy: 0.7088\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4793 - accuracy: 0.7063\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4393 - accuracy: 0.7089\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4524 - accuracy: 0.7080\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4832 - accuracy: 0.7060\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3810 - accuracy: 0.7127\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4202 - accuracy: 0.7101\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5985 - accuracy: 0.6984\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3535 - accuracy: 0.7145\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3814 - accuracy: 0.7127\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3827 - accuracy: 0.7126\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4603 - accuracy: 0.7075\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3125 - accuracy: 0.7172\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4139 - accuracy: 0.7106\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4637 - accuracy: 0.7073\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4349 - accuracy: 0.7092\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3685 - accuracy: 0.7135\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4239 - accuracy: 0.7099\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4229 - accuracy: 0.7100\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4041 - accuracy: 0.7112\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4652 - accuracy: 0.7072\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4200 - accuracy: 0.7101\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3403 - accuracy: 0.7154\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4499 - accuracy: 0.7082\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4238 - accuracy: 0.7099\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4277 - accuracy: 0.7096\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4227 - accuracy: 0.7100\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3456 - accuracy: 0.7150\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3836 - accuracy: 0.7125\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3485 - accuracy: 0.7148\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5216 - accuracy: 0.7035\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4546 - accuracy: 0.7079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4110 - accuracy: 0.7107\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3822 - accuracy: 0.7126\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3785 - accuracy: 0.7129\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4794 - accuracy: 0.7063\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4998 - accuracy: 0.7049\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3817 - accuracy: 0.7127\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4006 - accuracy: 0.7114\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4404 - accuracy: 0.7088\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4215 - accuracy: 0.7100\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5743 - accuracy: 0.7000\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4009 - accuracy: 0.7114\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4459 - accuracy: 0.7084\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3446 - accuracy: 0.7151\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4831 - accuracy: 0.7060\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4013 - accuracy: 0.7114\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4730 - accuracy: 0.7067\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3826 - accuracy: 0.7126\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4518 - accuracy: 0.7081\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4377 - accuracy: 0.7090\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5062 - accuracy: 0.7045\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3568 - accuracy: 0.7143\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3343 - accuracy: 0.7158\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.2918 - accuracy: 0.7186\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3683 - accuracy: 0.7135\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4044 - accuracy: 0.7112\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4653 - accuracy: 0.7072\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4466 - accuracy: 0.7084\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4090 - accuracy: 0.7109\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4546 - accuracy: 0.7079\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4340 - accuracy: 0.7092\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4303 - accuracy: 0.7095\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3464 - accuracy: 0.7150\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3934 - accuracy: 0.7119\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4373 - accuracy: 0.7090\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.5331 - accuracy: 0.7027\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4803 - accuracy: 0.7062\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4439 - accuracy: 0.7086\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3875 - accuracy: 0.7123\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4537 - accuracy: 0.7079\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4360 - accuracy: 0.7091\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4444 - accuracy: 0.7086\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4153 - accuracy: 0.7105\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4527 - accuracy: 0.7080\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4350 - accuracy: 0.7092\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4420 - accuracy: 0.7087\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5242 - accuracy: 0.7033\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4733 - accuracy: 0.7067\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.3586 - accuracy: 0.7142\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4344 - accuracy: 0.7092\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4300 - accuracy: 0.7095\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4550 - accuracy: 0.7079\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4724 - accuracy: 0.7067\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3818 - accuracy: 0.7127\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3925 - accuracy: 0.7120\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4323 - accuracy: 0.7093\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5158 - accuracy: 0.7039\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4840 - accuracy: 0.7060\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4929 - accuracy: 0.7054\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5150 - accuracy: 0.7039\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4190 - accuracy: 0.7102\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3559 - accuracy: 0.7144\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 4.4549 - accuracy: 0.7079\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4536 - accuracy: 0.7079\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3392 - accuracy: 0.7154\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4033 - accuracy: 0.7112\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4740 - accuracy: 0.7066\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4523 - accuracy: 0.7080\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3493 - accuracy: 0.7148\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4141 - accuracy: 0.7105\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3589 - accuracy: 0.7142\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5212 - accuracy: 0.7035\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.3774 - accuracy: 0.7129\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.5024 - accuracy: 0.7047\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4026 - accuracy: 0.7113\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 4.4713 - accuracy: 0.7068\n",
      "Epoch 00201: early stopping\n",
      "Score for fold 5: loss of 4.593262672424316; accuracy of 69.878751039505%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 4.372908115386963 - Accuracy: 71.32376432418823%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 4.261033058166504 - Accuracy: 72.0574140548706%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 4.664759159088135 - Accuracy: 69.40988898277283%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 4.408363342285156 - Accuracy: 71.09125852584839%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 4.593262672424316 - Accuracy: 69.878751039505%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 70.75221538543701 (+- 0.9705608834115125)\n",
      "> Loss: 4.460065269470215\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to \n",
    "    model3 = model_three()\n",
    "    history = model3.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model3.evaluate(x_train_test_val[test], y_train_test_val[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model3.metrics_names[0]} of {scores[0]}; {model3.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 cross-validation:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.7049\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6048 - accuracy: 0.7044\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7024\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5990 - accuracy: 0.7044\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5984 - accuracy: 0.7010\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5979 - accuracy: 0.6973\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5912 - accuracy: 0.7006\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.7040\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5829 - accuracy: 0.7000\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5726 - accuracy: 0.7050\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5688 - accuracy: 0.7032\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5582 - accuracy: 0.7074\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.7018\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7023\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7108\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5198 - accuracy: 0.7186\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7234\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7264\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5026 - accuracy: 0.7332\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4850 - accuracy: 0.7478\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4808 - accuracy: 0.7522\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4774 - accuracy: 0.7540\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7523\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7540\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7607\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7704\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.7678\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7634\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4476 - accuracy: 0.7711\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7675\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.7778\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4390 - accuracy: 0.7770\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.7769\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4400 - accuracy: 0.7744\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7812\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.7826\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4289 - accuracy: 0.7810\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4242 - accuracy: 0.7902\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4294 - accuracy: 0.7817\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4174 - accuracy: 0.7909\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4154 - accuracy: 0.7951\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4155 - accuracy: 0.7928\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.7909\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.7918\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4078 - accuracy: 0.7993\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4103 - accuracy: 0.7955\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7953\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4101 - accuracy: 0.7960\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4095 - accuracy: 0.7984\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4030 - accuracy: 0.7955\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4019 - accuracy: 0.8039\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4021 - accuracy: 0.8023\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4049 - accuracy: 0.8012\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4033 - accuracy: 0.8002\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3995 - accuracy: 0.8050\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3935 - accuracy: 0.8093\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8091\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4038 - accuracy: 0.8006\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8061\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8072\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4005 - accuracy: 0.8035\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3974 - accuracy: 0.8077\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3936 - accuracy: 0.8102\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8109\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3971 - accuracy: 0.8078\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3946 - accuracy: 0.8099\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8065\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4037 - accuracy: 0.8008\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8074\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3939 - accuracy: 0.8121\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3965 - accuracy: 0.8067\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8143\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8162\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8100\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3873 - accuracy: 0.8137\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3915 - accuracy: 0.8068\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8101\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8115\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3896 - accuracy: 0.8127\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3888 - accuracy: 0.8092\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8109\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8093\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3945 - accuracy: 0.8081\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8120\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8056\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8077\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8064\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3895 - accuracy: 0.8118\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8106\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8143\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8103\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8129\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8112\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8120\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8144\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.8079\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8072\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8095\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8154\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3922 - accuracy: 0.8112\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.8092\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3857 - accuracy: 0.8157\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8080\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3895 - accuracy: 0.8120\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8109\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8119\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3860 - accuracy: 0.8162\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8095\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8103\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8155\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3804 - accuracy: 0.8193\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3835 - accuracy: 0.8113\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8171\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8184\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3842 - accuracy: 0.8102\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8161\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8177\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8143\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8149\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8147\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8143\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3809 - accuracy: 0.8142\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3854 - accuracy: 0.8110\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8119\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8125\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3787 - accuracy: 0.8145\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8094\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8157\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3806 - accuracy: 0.8158\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8159\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8162\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8139\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8127\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3833 - accuracy: 0.8150\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8158\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8088\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3845 - accuracy: 0.8096\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3852 - accuracy: 0.8138\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3849 - accuracy: 0.8163\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8186\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8200\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8125\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8171\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8173\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8201\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8118\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8057\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8166\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8167\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8208\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8183\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8155\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8158\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8181\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8151\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8167\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8183\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3765 - accuracy: 0.8181\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3761 - accuracy: 0.8208\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8092\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8177\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8195\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3802 - accuracy: 0.8125\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3810 - accuracy: 0.8140\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8207\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8152\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8143\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3803 - accuracy: 0.8159\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8214\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8198\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8129\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8175\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3817 - accuracy: 0.8165\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8227\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8196\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8185\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8147\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8176\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8225\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8085\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8186\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8130\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8153\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8179\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8245\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8146\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8264\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8159\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8182\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8201\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3773 - accuracy: 0.8166\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8176\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3842 - accuracy: 0.8114\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8220\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8187\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8251\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8168\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3773 - accuracy: 0.8189\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3707 - accuracy: 0.8221\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8243\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8157\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8180\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8188\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3744 - accuracy: 0.8196\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8212\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8221\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8134\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8125\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8237\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3743 - accuracy: 0.8207\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8164\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8128\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8208\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8188\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8229\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8227\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8170\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8242\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8161\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8207\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8145\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8205\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3754 - accuracy: 0.8167\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8165\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3743 - accuracy: 0.8205\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8166\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8192\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8239\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8215\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8209\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8200\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3738 - accuracy: 0.8179\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8239\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8283\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8259\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8255\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8261\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8218\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8212\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8202\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3795 - accuracy: 0.8156\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8186\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8193\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3812 - accuracy: 0.8110\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8251\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8221\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3703 - accuracy: 0.8242\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8201\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8245\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8266\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8190\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8194\n",
      "Epoch 00252: early stopping\n",
      "Score for fold 1: loss of 0.3467637598514557; accuracy of 84.178626537323%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6066 - accuracy: 0.7115\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5974 - accuracy: 0.7117\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5903 - accuracy: 0.7167\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5913 - accuracy: 0.7120\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.7114\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5891 - accuracy: 0.7068\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5820 - accuracy: 0.7102\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5755 - accuracy: 0.7120\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5732 - accuracy: 0.7094\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5630 - accuracy: 0.7143\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5618 - accuracy: 0.7060\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5475 - accuracy: 0.7150\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7169\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5335 - accuracy: 0.7154\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7187\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5129 - accuracy: 0.7272\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5048 - accuracy: 0.7329\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4938 - accuracy: 0.7440\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7449\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7427\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7577\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7615\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4642 - accuracy: 0.7573\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7639\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4506 - accuracy: 0.7674\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4379 - accuracy: 0.7778\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4424 - accuracy: 0.7746\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.7734\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7765\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4365 - accuracy: 0.7799\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7845\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4331 - accuracy: 0.7870\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4263 - accuracy: 0.7864\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.7880\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4210 - accuracy: 0.7904\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4170 - accuracy: 0.7907\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4152 - accuracy: 0.7929\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.7953\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4066 - accuracy: 0.8005\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4121 - accuracy: 0.8012\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4063 - accuracy: 0.8028\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4099 - accuracy: 0.7982\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4057 - accuracy: 0.8021\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4081 - accuracy: 0.7995\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8103\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3964 - accuracy: 0.8089\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3969 - accuracy: 0.8100\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4023 - accuracy: 0.8056\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8099\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3962 - accuracy: 0.8121\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8122\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8104\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8119\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8085\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3943 - accuracy: 0.8073\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3893 - accuracy: 0.8157\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8149\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8156\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8148\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8132\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3860 - accuracy: 0.8178\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8145\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8120\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8202\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8168\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3830 - accuracy: 0.8154\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8098\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3807 - accuracy: 0.8211\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3941 - accuracy: 0.8079\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8194\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8111\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8167\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8161\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8152\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8173\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8173\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3909 - accuracy: 0.8091\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8073\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8140\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8219\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8202\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8174\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8224\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8235\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3829 - accuracy: 0.8151\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8132\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8193\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8172\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8192\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8235\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8275\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3836 - accuracy: 0.8136\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8193\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8180\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8175\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3799 - accuracy: 0.8195\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8227\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8216\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8226\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3848 - accuracy: 0.8171\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8173\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8227\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3760 - accuracy: 0.8201\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8140\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8225\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8204\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8253\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8199\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8200\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8178\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8281\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3751 - accuracy: 0.8229\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8193\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3778 - accuracy: 0.8177\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8156\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8228\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8273\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8166\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8181\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8194\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3786 - accuracy: 0.8162\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8220\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8241\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8276\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3668 - accuracy: 0.8250\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8104\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8256\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8203\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8260\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8128\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3686 - accuracy: 0.8255\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3806 - accuracy: 0.8153\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3723 - accuracy: 0.8249\n",
      "Epoch 134/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8260\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8203\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8260\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8172\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8255\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8219\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8267\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3683 - accuracy: 0.8234\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8222\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8253\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8151\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3642 - accuracy: 0.8261\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8266\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3680 - accuracy: 0.8261\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3687 - accuracy: 0.8261\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8262\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8250\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8261\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8230\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8177\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8271\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8142\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8196\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8235\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8206\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3576 - accuracy: 0.8316\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8297\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8270\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3642 - accuracy: 0.8301\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3660 - accuracy: 0.8275\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8266\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8300\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8217\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8265\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8278\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8251\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3656 - accuracy: 0.8259\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8245\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8203\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3649 - accuracy: 0.8277\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8222\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3634 - accuracy: 0.8262\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8234\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8272\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8260\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8199\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8248\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3602 - accuracy: 0.8319\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8252\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8314\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8239\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3688 - accuracy: 0.8228\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8244\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8292\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8258\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8297\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8251\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8257\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8239\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8272\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8255\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8222\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3566 - accuracy: 0.8310\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3621 - accuracy: 0.8296\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8259\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8169\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8256\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8230\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8209\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8280\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8242\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8242\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3612 - accuracy: 0.8258\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8232\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8172\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8302\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8281\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8264\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8221\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8235\n",
      "Epoch 214/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3541 - accuracy: 0.8307\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3650 - accuracy: 0.8235\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8240\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3617 - accuracy: 0.8292\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3570 - accuracy: 0.8312\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8295\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8189\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3665 - accuracy: 0.8253\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3575 - accuracy: 0.8307\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3686 - accuracy: 0.8252\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8264\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3557 - accuracy: 0.8314\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8303\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3601 - accuracy: 0.8263\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8245\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3609 - accuracy: 0.8274\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3642 - accuracy: 0.8264\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8228\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3594 - accuracy: 0.8284\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8261\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8287\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8272\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8268\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8302\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8251\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8284\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.8292\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3582 - accuracy: 0.8289\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8273\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8268\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3604 - accuracy: 0.8322\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3571 - accuracy: 0.8312\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3607 - accuracy: 0.8299\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3597 - accuracy: 0.8281\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3543 - accuracy: 0.8342\n",
      "Epoch 00248: early stopping\n",
      "Score for fold 2: loss of 0.390645295381546; accuracy of 81.08453154563904%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6748 - accuracy: 0.5637\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6010 - accuracy: 0.7076\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.7074\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.7080\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5876 - accuracy: 0.7131\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5861 - accuracy: 0.7108\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5823 - accuracy: 0.7108\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5790 - accuracy: 0.7090\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5729 - accuracy: 0.7110\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5676 - accuracy: 0.7110\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7146\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7159\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5428 - accuracy: 0.7174\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7143\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5266 - accuracy: 0.7181\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5175 - accuracy: 0.7249\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5067 - accuracy: 0.7332\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7380\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7460\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7455\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7546\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7561\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4632 - accuracy: 0.7623\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7648\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.7690\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.7740\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7718\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4360 - accuracy: 0.7776\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.7778\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7806\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.7809\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4267 - accuracy: 0.7860\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4265 - accuracy: 0.7820\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.7894\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8007\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4167 - accuracy: 0.7902\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4128 - accuracy: 0.7941\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.7938\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7987\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.7951\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4071 - accuracy: 0.8032\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8016\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4003 - accuracy: 0.8084\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8048\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4034 - accuracy: 0.8024\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8095\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8080\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4010 - accuracy: 0.8092\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3892 - accuracy: 0.8136\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8127\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3932 - accuracy: 0.8101\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3904 - accuracy: 0.8127\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3928 - accuracy: 0.8146\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8143\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.8122\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8168\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3912 - accuracy: 0.8148\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8135\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8146\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3918 - accuracy: 0.8134\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8172\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8088\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3897 - accuracy: 0.8130\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3880 - accuracy: 0.8113\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8222\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3890 - accuracy: 0.8122\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3884 - accuracy: 0.8111\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8213\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8191\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3882 - accuracy: 0.8123\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3832 - accuracy: 0.8155\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3864 - accuracy: 0.8185\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3870 - accuracy: 0.8144\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3890 - accuracy: 0.8122\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8183\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8157\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8192\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3851 - accuracy: 0.8148\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8156\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3819 - accuracy: 0.8184\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8125\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3790 - accuracy: 0.8210\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8189\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8248\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8212\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8205\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8201\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8208\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8201\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3767 - accuracy: 0.8205\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3826 - accuracy: 0.8137\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8221\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8174\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8200\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8225\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8196\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3781 - accuracy: 0.8199\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8122\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8175\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8199\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8221\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8195\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3756 - accuracy: 0.8198\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3791 - accuracy: 0.8175\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8228\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8218\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3778 - accuracy: 0.8201\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3770 - accuracy: 0.8206\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8237\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8250\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8219\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3784 - accuracy: 0.8183\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3752 - accuracy: 0.8212\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8213\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8222\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8268\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8263\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8227\n",
      "Epoch 119/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8259\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3822 - accuracy: 0.8182\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8272\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8214\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8244\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8195\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8163\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8278\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8226\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8203\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8248\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8231\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8201\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8194\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3760 - accuracy: 0.8188\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8261\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8217\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3624 - accuracy: 0.8322\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8217\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3708 - accuracy: 0.8251\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8254\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8243\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8262\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.8231\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8268\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8249\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8182\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8240\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3720 - accuracy: 0.8228\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8234\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8230\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3663 - accuracy: 0.8303\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8235\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8259\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8268\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8238\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3722 - accuracy: 0.8232\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8263\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8276\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8188\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3662 - accuracy: 0.8254\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8286\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8255\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8271\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8265\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8203\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3629 - accuracy: 0.8257\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8258\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8262\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8283\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8298\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8269\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8313\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8234\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3701 - accuracy: 0.8252\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8231\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8258\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3638 - accuracy: 0.8278\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8254\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8189\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8295\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8233\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8271\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3741 - accuracy: 0.8183\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8229\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8248\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8252\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3682 - accuracy: 0.8270\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8239\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8230\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8293\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8209\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8260\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8227\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8276\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8312\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8292\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8238\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3709 - accuracy: 0.8196\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3639 - accuracy: 0.8262\n",
      "Epoch 199/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8268\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8300\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8121\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8229\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8292\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8248\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8160\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3658 - accuracy: 0.8243\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8266\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8269\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8292\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3619 - accuracy: 0.8288\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8208\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3610 - accuracy: 0.8275\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8271\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3639 - accuracy: 0.8257\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8262\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3692 - accuracy: 0.8210\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8182\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3586 - accuracy: 0.8293\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8258\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8245\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8227\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8259\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8223\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3650 - accuracy: 0.8260\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3656 - accuracy: 0.8230\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8288\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3615 - accuracy: 0.8283\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3613 - accuracy: 0.8307\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8234\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8227\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3553 - accuracy: 0.8352\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3606 - accuracy: 0.8277\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3622 - accuracy: 0.8242\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8248\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8228\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3618 - accuracy: 0.8291\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8253\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8247\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8250\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3585 - accuracy: 0.8346\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.8288\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8227\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3646 - accuracy: 0.8253\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8186\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3555 - accuracy: 0.8330\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3558 - accuracy: 0.8327\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3625 - accuracy: 0.8296\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8286\n",
      "Epoch 00248: early stopping\n",
      "Score for fold 3: loss of 0.38339582085609436; accuracy of 81.75438642501831%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.5707\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6046 - accuracy: 0.7102\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6081 - accuracy: 0.7010\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6013 - accuracy: 0.7036\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5948 - accuracy: 0.7075\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5986 - accuracy: 0.6976\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5931 - accuracy: 0.6998\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5889 - accuracy: 0.6987\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5767 - accuracy: 0.7068\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5744 - accuracy: 0.7017\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7095\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.7027\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5515 - accuracy: 0.7012\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7117\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7155\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7250\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7383\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7428\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7522\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7552\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7585\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7578\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7668\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7701\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4510 - accuracy: 0.7702\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.7751\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7731\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.7783\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7822\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.7796\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4264 - accuracy: 0.7841\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4255 - accuracy: 0.7850\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.7875\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4236 - accuracy: 0.7880\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.7951\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.7906\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4151 - accuracy: 0.7910\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4112 - accuracy: 0.7914\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4085 - accuracy: 0.7996\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4093 - accuracy: 0.7979\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4052 - accuracy: 0.8043\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4020 - accuracy: 0.8027\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4057 - accuracy: 0.8051\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4023 - accuracy: 0.8040\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3987 - accuracy: 0.8070\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3978 - accuracy: 0.8078\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8082\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3931 - accuracy: 0.8088\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3992 - accuracy: 0.8087\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4041 - accuracy: 0.8065\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3908 - accuracy: 0.8126\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.8062\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8086\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8084\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3927 - accuracy: 0.8097\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8061\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3844 - accuracy: 0.8139\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3900 - accuracy: 0.8149\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3956 - accuracy: 0.8079\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8148\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3930 - accuracy: 0.8085\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8153\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3954 - accuracy: 0.8071\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3916 - accuracy: 0.8107\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3938 - accuracy: 0.8105\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8091\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8157\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8181\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8210\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4053 - accuracy: 0.8006\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3883 - accuracy: 0.8119\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8146\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3920 - accuracy: 0.8101\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8185\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8035\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3869 - accuracy: 0.8136\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8134\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8182\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3848 - accuracy: 0.8141\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3776 - accuracy: 0.8216\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8112\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8118\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8108\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3821 - accuracy: 0.8181\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3805 - accuracy: 0.8190\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8198\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3830 - accuracy: 0.8196\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3788 - accuracy: 0.8180\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8176\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8134\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8211\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3827 - accuracy: 0.8170\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8127\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3996 - accuracy: 0.8011\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8216\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8184\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3875 - accuracy: 0.8119\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3821 - accuracy: 0.8175\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3951 - accuracy: 0.8062\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8201\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3825 - accuracy: 0.8162\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8165\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8213\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8176\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3828 - accuracy: 0.8116\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8205\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8143\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8187\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3820 - accuracy: 0.8198\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8206\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8183\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3801 - accuracy: 0.8176\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8206\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3886 - accuracy: 0.8141\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8160\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8158\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3807 - accuracy: 0.8162\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8199\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8150\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8160\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3787 - accuracy: 0.8185\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3758 - accuracy: 0.8204\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3797 - accuracy: 0.8150\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8201\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3747 - accuracy: 0.8220\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3874 - accuracy: 0.8105\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8174\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8217\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8200\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3734 - accuracy: 0.8183\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8261\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8247\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3858 - accuracy: 0.8139\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3817 - accuracy: 0.8172\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8179\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8249\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3915 - accuracy: 0.8124\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8210\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8245\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3769 - accuracy: 0.8215\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8214\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8223\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8204\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.8217\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3794 - accuracy: 0.8206\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8189\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8216\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.8236\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8240\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8238\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8230\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8264\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8203\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8205\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3757 - accuracy: 0.8224\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8226\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8220\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8266\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8187\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8215\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8195\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3670 - accuracy: 0.8257\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8265\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3714 - accuracy: 0.8249\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3737 - accuracy: 0.8224\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8228\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8233\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8191\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3740 - accuracy: 0.8168\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8224\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8249\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8148\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3688 - accuracy: 0.8238\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8215\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3749 - accuracy: 0.8157\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3732 - accuracy: 0.8229\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8273\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3723 - accuracy: 0.8237\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3666 - accuracy: 0.8258\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8183\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8230\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8247\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3685 - accuracy: 0.8234\n",
      "Epoch 184/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3789 - accuracy: 0.8169\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8208\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3676 - accuracy: 0.8271\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8226\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8249\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8228\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8237\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8245\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8266\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8228\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8254\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8239\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3739 - accuracy: 0.8220\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8216\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3681 - accuracy: 0.8263\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3791 - accuracy: 0.8134\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3694 - accuracy: 0.8251\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3671 - accuracy: 0.8283\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8274\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8182\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8279\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8228\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8120\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3654 - accuracy: 0.8247\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8244\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3655 - accuracy: 0.8302\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8246\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3726 - accuracy: 0.8261\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8250\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8211\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3644 - accuracy: 0.8259\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8223\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8203\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8249\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3659 - accuracy: 0.8258\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3677 - accuracy: 0.8201\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3679 - accuracy: 0.8209\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3744 - accuracy: 0.8205\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8278\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3766 - accuracy: 0.8231\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8226\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3649 - accuracy: 0.8264\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.8269\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8230\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3707 - accuracy: 0.8205\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3698 - accuracy: 0.8242\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3664 - accuracy: 0.8236\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8255\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3662 - accuracy: 0.8242\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8281\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8183\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3675 - accuracy: 0.8296\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3661 - accuracy: 0.8275\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8231\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8244\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8291\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8232\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3729 - accuracy: 0.8223\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3721 - accuracy: 0.8228\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3635 - accuracy: 0.8262\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8279\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3637 - accuracy: 0.8249\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3605 - accuracy: 0.8325\n",
      "Epoch 00246: early stopping\n",
      "Score for fold 4: loss of 0.3600591719150543; accuracy of 82.8972578048706%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6176 - accuracy: 0.7108\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6040 - accuracy: 0.7072\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5989 - accuracy: 0.7094\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.7100\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5885 - accuracy: 0.7150\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5911 - accuracy: 0.7086\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.7097\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5843 - accuracy: 0.7078\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5785 - accuracy: 0.7084\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5700 - accuracy: 0.7120\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5713 - accuracy: 0.7039\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5587 - accuracy: 0.7112\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5498 - accuracy: 0.7120\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.7146\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5333 - accuracy: 0.7180\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7248\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7261\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7346\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7431\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4877 - accuracy: 0.7483\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7556\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4739 - accuracy: 0.7557\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7602\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7641\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7637\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4561 - accuracy: 0.7633\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7757\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.7769\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7726\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4381 - accuracy: 0.7783\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4368 - accuracy: 0.7819\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4302 - accuracy: 0.7836\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4290 - accuracy: 0.7890\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4221 - accuracy: 0.7889\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4293 - accuracy: 0.7869\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.7888\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.7885\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4098 - accuracy: 0.7963\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4185 - accuracy: 0.7911\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4149 - accuracy: 0.7965\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4166 - accuracy: 0.7969\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4109 - accuracy: 0.7967\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4088 - accuracy: 0.7989\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4051 - accuracy: 0.8031\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4024 - accuracy: 0.8029\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8051\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4085 - accuracy: 0.8013\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4036 - accuracy: 0.8071\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4047 - accuracy: 0.8044\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3987 - accuracy: 0.8091\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.8098\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3921 - accuracy: 0.8137\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3966 - accuracy: 0.8083\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3973 - accuracy: 0.8046\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3979 - accuracy: 0.8064\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4006 - accuracy: 0.8089\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3949 - accuracy: 0.8070\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.8151\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3925 - accuracy: 0.8096\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3961 - accuracy: 0.8105\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3942 - accuracy: 0.8085\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3866 - accuracy: 0.8167\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3921 - accuracy: 0.8129\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8173\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8176\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3955 - accuracy: 0.8078\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8221\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3838 - accuracy: 0.8150\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3907 - accuracy: 0.8105\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3865 - accuracy: 0.8155\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8138\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3856 - accuracy: 0.8175\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8204\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3885 - accuracy: 0.8119\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3815 - accuracy: 0.8201\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3783 - accuracy: 0.8222\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3852 - accuracy: 0.8158\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3947 - accuracy: 0.8082\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8128\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8111\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3870 - accuracy: 0.8180\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3919 - accuracy: 0.8085\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3811 - accuracy: 0.8182\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3796 - accuracy: 0.8174\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3904 - accuracy: 0.8095\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3847 - accuracy: 0.8158\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3780 - accuracy: 0.8174\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3811 - accuracy: 0.8187\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3802 - accuracy: 0.8179\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3853 - accuracy: 0.8159\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3771 - accuracy: 0.8196\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3765 - accuracy: 0.8214\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8140\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8196\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3846 - accuracy: 0.8163\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3834 - accuracy: 0.8155\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3879 - accuracy: 0.8141\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3800 - accuracy: 0.8180\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.8180\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8183\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3861 - accuracy: 0.8129\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3804 - accuracy: 0.8200\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3764 - accuracy: 0.8202\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.8159\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3792 - accuracy: 0.8203\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3808 - accuracy: 0.8181\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8234\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8186\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3862 - accuracy: 0.8113\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3814 - accuracy: 0.8188\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3755 - accuracy: 0.8218\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8202\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3818 - accuracy: 0.8137\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3754 - accuracy: 0.8190\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3800 - accuracy: 0.8175\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3762 - accuracy: 0.8191\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8197\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3809 - accuracy: 0.8165\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3788 - accuracy: 0.8164\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8190\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3777 - accuracy: 0.8194\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8241\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3863 - accuracy: 0.8160\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3799 - accuracy: 0.8173\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3721 - accuracy: 0.8222\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3834 - accuracy: 0.8165\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3730 - accuracy: 0.8224\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3732 - accuracy: 0.8225\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3840 - accuracy: 0.8135\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3764 - accuracy: 0.8170\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3785 - accuracy: 0.8193\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3850 - accuracy: 0.8187\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3704 - accuracy: 0.8237\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3779 - accuracy: 0.8185\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3735 - accuracy: 0.8213\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8165\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.8210\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3689 - accuracy: 0.8272\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3749 - accuracy: 0.8203\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8197\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3759 - accuracy: 0.8191\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8252\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8172\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3746 - accuracy: 0.8258\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8259\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3779 - accuracy: 0.8198\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3710 - accuracy: 0.8207\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3748 - accuracy: 0.8248\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8258\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3696 - accuracy: 0.8238\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3750 - accuracy: 0.8200\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3711 - accuracy: 0.8223\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3774 - accuracy: 0.8202\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3742 - accuracy: 0.8214\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8264\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8298\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3736 - accuracy: 0.8242\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3715 - accuracy: 0.8211\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8239\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8279\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3731 - accuracy: 0.8242\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.8251\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8245\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3702 - accuracy: 0.8253\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8231\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8259\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3696 - accuracy: 0.8239\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3708 - accuracy: 0.8212\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3690 - accuracy: 0.8249\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8289\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8226\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8257\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8245\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3753 - accuracy: 0.8194\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3705 - accuracy: 0.8261\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3705 - accuracy: 0.8228\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3695 - accuracy: 0.8243\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3795 - accuracy: 0.8177\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3598 - accuracy: 0.8320\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3751 - accuracy: 0.8228\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3670 - accuracy: 0.8237\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3727 - accuracy: 0.8221\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3738 - accuracy: 0.8225\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8284\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3713 - accuracy: 0.8248\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3716 - accuracy: 0.8215\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3689 - accuracy: 0.8228\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8265\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8279\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3768 - accuracy: 0.8186\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3697 - accuracy: 0.8258\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8302\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3694 - accuracy: 0.8245\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3693 - accuracy: 0.8236\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3703 - accuracy: 0.8230\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3690 - accuracy: 0.8248\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3648 - accuracy: 0.8266\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3641 - accuracy: 0.8262\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3678 - accuracy: 0.8252\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3581 - accuracy: 0.8337\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3660 - accuracy: 0.8306\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3626 - accuracy: 0.8314\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3613 - accuracy: 0.8279\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8247\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3651 - accuracy: 0.8249\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3675 - accuracy: 0.8250\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3676 - accuracy: 0.8261\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3630 - accuracy: 0.8275\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.8265\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3704 - accuracy: 0.8212\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3653 - accuracy: 0.8247\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3665 - accuracy: 0.8262\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3772 - accuracy: 0.8177\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3628 - accuracy: 0.8301\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.8256\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3706 - accuracy: 0.8213\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3599 - accuracy: 0.8272\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8181\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3627 - accuracy: 0.8284\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3620 - accuracy: 0.8265\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3621 - accuracy: 0.8284\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3560 - accuracy: 0.8284\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8290\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3868 - accuracy: 0.8153\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3666 - accuracy: 0.8253\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8304\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3633 - accuracy: 0.8278\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3687 - accuracy: 0.8262\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3724 - accuracy: 0.8218\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8263\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3641 - accuracy: 0.8285\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3699 - accuracy: 0.8248\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8174\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3700 - accuracy: 0.8266\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3673 - accuracy: 0.8262\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3677 - accuracy: 0.8253\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3728 - accuracy: 0.8239\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3583 - accuracy: 0.8320\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3684 - accuracy: 0.8241\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8277\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3614 - accuracy: 0.8266\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3667 - accuracy: 0.8259\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3745 - accuracy: 0.8222\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8265\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3619 - accuracy: 0.8282\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3640 - accuracy: 0.8256\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.3667 - accuracy: 0.8237\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3718 - accuracy: 0.8197\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3672 - accuracy: 0.8259\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3653 - accuracy: 0.8285\n",
      "Epoch 251/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3657 - accuracy: 0.8261\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.3630 - accuracy: 0.8273\n",
      "Epoch 00252: early stopping\n",
      "Score for fold 5: loss of 0.3746683895587921; accuracy of 82.06764459609985%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.3467637598514557 - Accuracy: 84.178626537323%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.390645295381546 - Accuracy: 81.08453154563904%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.38339582085609436 - Accuracy: 81.75438642501831%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.3600591719150543 - Accuracy: 82.8972578048706%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.3746683895587921 - Accuracy: 82.06764459609985%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 82.39648938179016 (+- 1.0647488265966147)\n",
      "> Loss: 0.3711064875125885\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model4 = model_four()\n",
    "    history = model4.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model4.evaluate(x_train_test_val[test] , y_train_test_val[test] , verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model4.metrics_names[0]} of {scores[0]}; {model4.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 5 cross-validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 9ms/step - loss: 1.1962 - accuracy: 0.5526\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4848 - accuracy: 0.7225\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4501 - accuracy: 0.7707\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4237 - accuracy: 0.7922\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.7891\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4044 - accuracy: 0.8046\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4024 - accuracy: 0.8084\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3947 - accuracy: 0.8108\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3957 - accuracy: 0.8152\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3926 - accuracy: 0.8113\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3871 - accuracy: 0.8119\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3918 - accuracy: 0.8153\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3923 - accuracy: 0.8097\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8124\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3848 - accuracy: 0.8150\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3807 - accuracy: 0.8138\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3871 - accuracy: 0.8103\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3865 - accuracy: 0.8107\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3734 - accuracy: 0.8208\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8240\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3821 - accuracy: 0.8124\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3768 - accuracy: 0.8208\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3744 - accuracy: 0.8199\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3817 - accuracy: 0.8182\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8143\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3645 - accuracy: 0.8225\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3701 - accuracy: 0.8177\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3604 - accuracy: 0.8276\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3688 - accuracy: 0.8153\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3600 - accuracy: 0.8300\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3602 - accuracy: 0.8301\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3598 - accuracy: 0.8262\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8268\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3631 - accuracy: 0.8252\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3540 - accuracy: 0.8313\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3494 - accuracy: 0.8311\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3686 - accuracy: 0.8198\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3526 - accuracy: 0.8285\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3575 - accuracy: 0.8283\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3547 - accuracy: 0.8222\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3520 - accuracy: 0.8280\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3467 - accuracy: 0.8312\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3541 - accuracy: 0.8285\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3520 - accuracy: 0.8361\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.8258\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3508 - accuracy: 0.8322\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3490 - accuracy: 0.8304\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3534 - accuracy: 0.8263\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3483 - accuracy: 0.8291\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3454 - accuracy: 0.8345\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3406 - accuracy: 0.8380\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3561 - accuracy: 0.8268\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8273\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8329\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.8373\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.8373\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3369 - accuracy: 0.8373\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3485 - accuracy: 0.8284\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3460 - accuracy: 0.8298\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3512 - accuracy: 0.8275\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3459 - accuracy: 0.8319\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3491 - accuracy: 0.8332\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.8298\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3435 - accuracy: 0.8314\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3412 - accuracy: 0.8362\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3420 - accuracy: 0.8357\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8290\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3454 - accuracy: 0.8307\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3515 - accuracy: 0.8232\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3439 - accuracy: 0.8301\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3402 - accuracy: 0.8346\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3370 - accuracy: 0.8348\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.8332\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3483 - accuracy: 0.8286\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3463 - accuracy: 0.8303\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.8301\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3395 - accuracy: 0.8372\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8314\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8306\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8379\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.8370\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3368 - accuracy: 0.8364\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3422 - accuracy: 0.8336\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3359 - accuracy: 0.8394\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3419 - accuracy: 0.8324\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8350\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3353 - accuracy: 0.8376\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.8331\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3422 - accuracy: 0.8341\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8405\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 0.8309\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3432 - accuracy: 0.8296\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.8391\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3359 - accuracy: 0.8337\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3321 - accuracy: 0.8419\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8295\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3346 - accuracy: 0.8364\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3328 - accuracy: 0.8358\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3310 - accuracy: 0.8382\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8339\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3369 - accuracy: 0.8364\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.8375\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8323\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8342\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3353 - accuracy: 0.8362\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3411 - accuracy: 0.8294\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3338 - accuracy: 0.8413\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3359 - accuracy: 0.8354\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3358 - accuracy: 0.8347\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3345 - accuracy: 0.8345\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8397\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.8365\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3372 - accuracy: 0.8316\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8404\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.8364\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3320 - accuracy: 0.8383\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8384\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3328 - accuracy: 0.8383\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3372 - accuracy: 0.8359\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3384 - accuracy: 0.8304\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.8380\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.8372\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.8364\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3344 - accuracy: 0.8361\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3375 - accuracy: 0.8333\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8344\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8429\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3320 - accuracy: 0.8405\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3336 - accuracy: 0.8358\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.8367\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8347\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3374 - accuracy: 0.8317\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8365\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3312 - accuracy: 0.8387\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8407\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3272 - accuracy: 0.8414\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.8388\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3274 - accuracy: 0.8408\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8373\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.8378\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.8404\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.8387\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3373 - accuracy: 0.8376\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3271 - accuracy: 0.8390\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3312 - accuracy: 0.8342\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8400\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8416\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8449\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3178 - accuracy: 0.8396\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3306 - accuracy: 0.8393\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.8395\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3276 - accuracy: 0.8391\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3310 - accuracy: 0.8373\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8438\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8386\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.8357\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8417\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3273 - accuracy: 0.8429\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3212 - accuracy: 0.8410\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8399\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8373\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8377\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3291 - accuracy: 0.8381\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8361\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8338\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3276 - accuracy: 0.8375\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3252 - accuracy: 0.8418\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.8357\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8400\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.8384\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8322\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8371\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.8396\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.8386\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3300 - accuracy: 0.8286\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3361 - accuracy: 0.8388\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.8393\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3342 - accuracy: 0.8348\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.8400\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8415\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8327\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8394\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3278 - accuracy: 0.8370\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.8372\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.8363\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3339 - accuracy: 0.8355\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.8391\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3322 - accuracy: 0.8380\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3292 - accuracy: 0.8417\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3286 - accuracy: 0.8379\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8369\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8357\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.8382\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8374\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3211 - accuracy: 0.8473\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3262 - accuracy: 0.8397\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.8381\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.8410\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3290 - accuracy: 0.8428\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8383\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.8426\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8379\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8407\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3294 - accuracy: 0.8359\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3289 - accuracy: 0.8436\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8351\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8415\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3229 - accuracy: 0.8443\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8370\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.8446\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.8378\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.8381\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8431\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8405\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.8408\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.8401\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.8349\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8419\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.8447\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3136 - accuracy: 0.8457\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3210 - accuracy: 0.8437\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3245 - accuracy: 0.8398\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.8430\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3204 - accuracy: 0.8455\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.8399\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8379\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3211 - accuracy: 0.8459\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8408\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.8390\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3180 - accuracy: 0.8471\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3226 - accuracy: 0.8430\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8367\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.8393\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3263 - accuracy: 0.8396\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3165 - accuracy: 0.8430\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.8422\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8433\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3271 - accuracy: 0.8335\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.8401\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8397\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3281 - accuracy: 0.8389\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3071 - accuracy: 0.8484\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3218 - accuracy: 0.8413\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3239 - accuracy: 0.8400\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3192 - accuracy: 0.8426\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3271 - accuracy: 0.8404\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8367\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8385\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8451\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3249 - accuracy: 0.8376\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3225 - accuracy: 0.8400\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3216 - accuracy: 0.8431\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3219 - accuracy: 0.8423\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8379\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.8457\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8388\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.8402\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3165 - accuracy: 0.8434\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3201 - accuracy: 0.8406\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3203 - accuracy: 0.8370\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8366\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8387\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8414\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.8385\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3220 - accuracy: 0.8407\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3205 - accuracy: 0.8465\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3247 - accuracy: 0.8407\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3135 - accuracy: 0.8456\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.8421\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3168 - accuracy: 0.8438\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.8433\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3158 - accuracy: 0.8446\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3276 - accuracy: 0.8397\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3218 - accuracy: 0.8418\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8340\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3251 - accuracy: 0.8428\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3210 - accuracy: 0.8438\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3147 - accuracy: 0.8457\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3242 - accuracy: 0.8423\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.8466\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3268 - accuracy: 0.8396\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8395\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8395\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3215 - accuracy: 0.8381\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.8440\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8433\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8370\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3276 - accuracy: 0.8408\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3239 - accuracy: 0.8415\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3261 - accuracy: 0.8366\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3144 - accuracy: 0.8449\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3145 - accuracy: 0.8455\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3227 - accuracy: 0.8461\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8452\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3180 - accuracy: 0.8406\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3190 - accuracy: 0.8471\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8458\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8459\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.8372\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3154 - accuracy: 0.8455\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3187 - accuracy: 0.8458\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3211 - accuracy: 0.8389\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3181 - accuracy: 0.8404\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3135 - accuracy: 0.8470\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3293 - accuracy: 0.8381\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3216 - accuracy: 0.8379\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3240 - accuracy: 0.8374\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8392\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.8385\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8421\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3147 - accuracy: 0.8453\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8425\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8406\n",
      "Epoch 314/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.8412\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3218 - accuracy: 0.8395\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3216 - accuracy: 0.8433\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.8371\n",
      "Epoch 00317: early stopping\n",
      "Score for fold 1: loss of 0.4324164092540741; accuracy of 81.40350580215454%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 9ms/step - loss: 0.7277 - accuracy: 0.6893\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.4688 - accuracy: 0.7366\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4159 - accuracy: 0.7924\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3885 - accuracy: 0.8037\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3840 - accuracy: 0.8176\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3775 - accuracy: 0.8163\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3688 - accuracy: 0.8222\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3665 - accuracy: 0.8270\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3582 - accuracy: 0.8320\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.8243\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3564 - accuracy: 0.8274\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3512 - accuracy: 0.8331\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3521 - accuracy: 0.8332\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8333\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3569 - accuracy: 0.8256\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3402 - accuracy: 0.8390\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3499 - accuracy: 0.8295\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3437 - accuracy: 0.8362\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3388 - accuracy: 0.8378\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8410\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3321 - accuracy: 0.8379\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.8355\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3400 - accuracy: 0.8350\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8388\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8440\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3340 - accuracy: 0.8431\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8388\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3378 - accuracy: 0.8329\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3261 - accuracy: 0.8402\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3350 - accuracy: 0.8354\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.8401\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8425\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3378 - accuracy: 0.8367\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8442\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3294 - accuracy: 0.8364\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8402\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8425\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3268 - accuracy: 0.8409\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8442\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3259 - accuracy: 0.8410\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8426\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.8463\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8453\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8472\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3105 - accuracy: 0.8534\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3163 - accuracy: 0.8437\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3103 - accuracy: 0.8468\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3139 - accuracy: 0.8450\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3157 - accuracy: 0.8468\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3130 - accuracy: 0.8495\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.8443\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3107 - accuracy: 0.8471\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3122 - accuracy: 0.8457\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3188 - accuracy: 0.8449\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3191 - accuracy: 0.8457\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.8505\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3220 - accuracy: 0.8430\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8443\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3153 - accuracy: 0.8480\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3082 - accuracy: 0.8522\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3129 - accuracy: 0.8513\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3071 - accuracy: 0.8538\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3126 - accuracy: 0.8460\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3059 - accuracy: 0.8539\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3087 - accuracy: 0.8476\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3100 - accuracy: 0.8524\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.8471\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.8485\n",
      "Epoch 69/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.8475\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3054 - accuracy: 0.8535\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3133 - accuracy: 0.8518\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.8493\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3033 - accuracy: 0.8574\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3029 - accuracy: 0.8539\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3070 - accuracy: 0.8497\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3049 - accuracy: 0.8526\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3020 - accuracy: 0.8563\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3059 - accuracy: 0.8516\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3029 - accuracy: 0.8527\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3019 - accuracy: 0.8528\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.8474\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3021 - accuracy: 0.8602\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3092 - accuracy: 0.8459\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2998 - accuracy: 0.8567\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3022 - accuracy: 0.8521\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3065 - accuracy: 0.8507\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3029 - accuracy: 0.8508\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.8536\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.8519\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3027 - accuracy: 0.8549\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2963 - accuracy: 0.8530\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3040 - accuracy: 0.8552\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3072 - accuracy: 0.8504\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2965 - accuracy: 0.8530\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3065 - accuracy: 0.8530\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2979 - accuracy: 0.8533\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2984 - accuracy: 0.8552\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2992 - accuracy: 0.8561\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3030 - accuracy: 0.8518\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2985 - accuracy: 0.8574\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3084 - accuracy: 0.8500\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2976 - accuracy: 0.8594\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3030 - accuracy: 0.8558\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3050 - accuracy: 0.8496\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2992 - accuracy: 0.8529\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2965 - accuracy: 0.8569\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2992 - accuracy: 0.8552\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2925 - accuracy: 0.8586\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3010 - accuracy: 0.8575\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.8574\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2956 - accuracy: 0.8534\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3068 - accuracy: 0.8534\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2941 - accuracy: 0.8592\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.8530\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3098 - accuracy: 0.8522\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8593\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2959 - accuracy: 0.8568\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3053 - accuracy: 0.8511\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2956 - accuracy: 0.8534\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2956 - accuracy: 0.8548\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2939 - accuracy: 0.8563\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2953 - accuracy: 0.8569\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2929 - accuracy: 0.8583\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2927 - accuracy: 0.8580\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2934 - accuracy: 0.8635\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3006 - accuracy: 0.8545\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2986 - accuracy: 0.8535\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2951 - accuracy: 0.8547\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.8601\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2994 - accuracy: 0.8511\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2908 - accuracy: 0.8579\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3001 - accuracy: 0.8490\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2954 - accuracy: 0.8550\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2938 - accuracy: 0.8588\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2959 - accuracy: 0.8570\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2963 - accuracy: 0.8574\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2982 - accuracy: 0.8558\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2926 - accuracy: 0.8561\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2995 - accuracy: 0.8564\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2876 - accuracy: 0.8624\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2924 - accuracy: 0.8583\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2992 - accuracy: 0.8551\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2984 - accuracy: 0.8518\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2981 - accuracy: 0.8536\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2953 - accuracy: 0.8614\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2941 - accuracy: 0.8561\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2937 - accuracy: 0.8571\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2853 - accuracy: 0.8599\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2933 - accuracy: 0.8554\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2902 - accuracy: 0.8607\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2957 - accuracy: 0.8595\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2920 - accuracy: 0.8553\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2890 - accuracy: 0.8602\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2982 - accuracy: 0.8588\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2899 - accuracy: 0.8573\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2928 - accuracy: 0.8565\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2936 - accuracy: 0.8577\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2918 - accuracy: 0.8559\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2893 - accuracy: 0.8599\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2929 - accuracy: 0.8573\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3023 - accuracy: 0.8539\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2923 - accuracy: 0.8609\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2888 - accuracy: 0.8630\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2939 - accuracy: 0.8578\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.8586\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2938 - accuracy: 0.8587\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2877 - accuracy: 0.8619\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2851 - accuracy: 0.8640\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2873 - accuracy: 0.8616\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2861 - accuracy: 0.8589\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2861 - accuracy: 0.8615\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2903 - accuracy: 0.8592\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2961 - accuracy: 0.8522\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2921 - accuracy: 0.8620\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2935 - accuracy: 0.8598\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2942 - accuracy: 0.8565\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2861 - accuracy: 0.8640\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2873 - accuracy: 0.8560\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2872 - accuracy: 0.8623\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2925 - accuracy: 0.8571\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3061 - accuracy: 0.8525\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3001 - accuracy: 0.8525\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2807 - accuracy: 0.8648\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2960 - accuracy: 0.8558\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2919 - accuracy: 0.8566\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2915 - accuracy: 0.8621\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2871 - accuracy: 0.8592\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8583\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2978 - accuracy: 0.8533\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2984 - accuracy: 0.8546\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2905 - accuracy: 0.8583\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2877 - accuracy: 0.8568\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2943 - accuracy: 0.8568\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2913 - accuracy: 0.8584\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2879 - accuracy: 0.8639\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2843 - accuracy: 0.8640\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2890 - accuracy: 0.8563\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2899 - accuracy: 0.8568\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2870 - accuracy: 0.8601\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2954 - accuracy: 0.8538\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2915 - accuracy: 0.8592\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2791 - accuracy: 0.8693\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2845 - accuracy: 0.8624\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.2917 - accuracy: 0.8605\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.2850 - accuracy: 0.8607\n",
      "Epoch 00205: early stopping\n",
      "Score for fold 2: loss of 0.4622417688369751; accuracy of 81.59489631652832%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 9ms/step - loss: 1.1884 - accuracy: 0.5752\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5081 - accuracy: 0.7412\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4583 - accuracy: 0.7570\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4347 - accuracy: 0.7612\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4134 - accuracy: 0.7930\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4042 - accuracy: 0.7983\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4029 - accuracy: 0.8010\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4002 - accuracy: 0.8000\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3830 - accuracy: 0.8136\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3867 - accuracy: 0.8097\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3857 - accuracy: 0.8126\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3783 - accuracy: 0.8111\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3782 - accuracy: 0.8133\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3790 - accuracy: 0.8163\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3709 - accuracy: 0.8257\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3750 - accuracy: 0.8234\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3688 - accuracy: 0.8226\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3667 - accuracy: 0.8212\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3613 - accuracy: 0.8270\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3683 - accuracy: 0.8166\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3606 - accuracy: 0.8265\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3592 - accuracy: 0.8229\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3647 - accuracy: 0.8248\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3587 - accuracy: 0.8208\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3603 - accuracy: 0.8236\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3459 - accuracy: 0.8320\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3575 - accuracy: 0.8266\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3570 - accuracy: 0.8282\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3560 - accuracy: 0.8289\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3442 - accuracy: 0.8319\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3528 - accuracy: 0.8252\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3536 - accuracy: 0.8265\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3405 - accuracy: 0.8347\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3507 - accuracy: 0.8280\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3518 - accuracy: 0.8241\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3493 - accuracy: 0.8314\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3479 - accuracy: 0.8283\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.8346\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3357 - accuracy: 0.8357\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3447 - accuracy: 0.8281\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3379 - accuracy: 0.8328\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3387 - accuracy: 0.8339\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3411 - accuracy: 0.8329\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8361\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8265\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3430 - accuracy: 0.8326\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3410 - accuracy: 0.8336\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.8369\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3388 - accuracy: 0.8324\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3428 - accuracy: 0.8296\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3375 - accuracy: 0.8358\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3399 - accuracy: 0.8335\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3299 - accuracy: 0.8412\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3355 - accuracy: 0.8291\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.8294\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3393 - accuracy: 0.8337\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3232 - accuracy: 0.8398\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8316\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8354\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3389 - accuracy: 0.8342\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8380\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.8400\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3296 - accuracy: 0.8380\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.8391\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.8399\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8339\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.8344\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3253 - accuracy: 0.8402\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3256 - accuracy: 0.8401\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3290 - accuracy: 0.8422\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3259 - accuracy: 0.8400\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3321 - accuracy: 0.8321\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3285 - accuracy: 0.8401\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.8324\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.8334\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 0.8394\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.8353\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3269 - accuracy: 0.8432\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8389\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3320 - accuracy: 0.8368\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3228 - accuracy: 0.8385\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3235 - accuracy: 0.8405\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3267 - accuracy: 0.8366\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8394\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3217 - accuracy: 0.8422\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8357\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.8384\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3253 - accuracy: 0.8405\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8404\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3248 - accuracy: 0.8368\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3318 - accuracy: 0.8356\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3269 - accuracy: 0.8398\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8344\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8415\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.8346\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3175 - accuracy: 0.8424\n",
      "Epoch 97/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3261 - accuracy: 0.8383\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3269 - accuracy: 0.8381\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3189 - accuracy: 0.8462\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.8427\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3189 - accuracy: 0.8385\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3215 - accuracy: 0.8389\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3217 - accuracy: 0.8399\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8413\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8417\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.8419\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3193 - accuracy: 0.8450\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8450\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.8404\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3198 - accuracy: 0.8348\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8419\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.8384\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.8412\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3266 - accuracy: 0.8402\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8381\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8393\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3227 - accuracy: 0.8451\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3211 - accuracy: 0.8409\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3112 - accuracy: 0.8467\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3130 - accuracy: 0.8460\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8477\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8416\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3230 - accuracy: 0.8429\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.8398\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3174 - accuracy: 0.8382\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3193 - accuracy: 0.8439\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.8370\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3228 - accuracy: 0.8459\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3172 - accuracy: 0.8426\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3196 - accuracy: 0.8391\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3171 - accuracy: 0.8452\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3164 - accuracy: 0.8460\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3196 - accuracy: 0.8433\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3161 - accuracy: 0.8496\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3148 - accuracy: 0.8470\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3155 - accuracy: 0.8464\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3190 - accuracy: 0.8435\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3226 - accuracy: 0.8411\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3201 - accuracy: 0.8439\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3224 - accuracy: 0.8391\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8478\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3241 - accuracy: 0.8471\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3231 - accuracy: 0.8393\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3177 - accuracy: 0.8454\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3222 - accuracy: 0.8406\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3207 - accuracy: 0.8388\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3184 - accuracy: 0.8415\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3170 - accuracy: 0.8429\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3173 - accuracy: 0.8438\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8357\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3177 - accuracy: 0.8427\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3078 - accuracy: 0.8474\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8433\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3162 - accuracy: 0.8425\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8406\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3200 - accuracy: 0.8441\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3124 - accuracy: 0.8464\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3158 - accuracy: 0.8440\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3202 - accuracy: 0.8416\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3152 - accuracy: 0.8435\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3201 - accuracy: 0.8408\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.8371\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3150 - accuracy: 0.8460\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3156 - accuracy: 0.8464\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3179 - accuracy: 0.8450\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3152 - accuracy: 0.8462\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3113 - accuracy: 0.8516\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3139 - accuracy: 0.8457\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3188 - accuracy: 0.8407\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3124 - accuracy: 0.8466\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3180 - accuracy: 0.8454\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8448\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3166 - accuracy: 0.8390\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3217 - accuracy: 0.8405\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8378\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3214 - accuracy: 0.8428\n",
      "Epoch 177/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.8457\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3143 - accuracy: 0.8426\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3232 - accuracy: 0.8402\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3148 - accuracy: 0.8463\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3174 - accuracy: 0.8415\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3161 - accuracy: 0.8442\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3110 - accuracy: 0.8463\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3157 - accuracy: 0.8440\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3139 - accuracy: 0.8463\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3131 - accuracy: 0.8461\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3141 - accuracy: 0.8428\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3111 - accuracy: 0.8455\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.8474\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3211 - accuracy: 0.8399\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3208 - accuracy: 0.8427\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3170 - accuracy: 0.8458\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3093 - accuracy: 0.8518\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.8458\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3193 - accuracy: 0.8438\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8401\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3201 - accuracy: 0.8405\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3229 - accuracy: 0.8438\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3092 - accuracy: 0.8494\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3070 - accuracy: 0.8463\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3146 - accuracy: 0.8464\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3125 - accuracy: 0.8471\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3160 - accuracy: 0.8395\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3203 - accuracy: 0.8431\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3161 - accuracy: 0.8446\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3176 - accuracy: 0.8491\n",
      "Epoch 00206: early stopping\n",
      "Score for fold 3: loss of 0.41804662346839905; accuracy of 81.49920105934143%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 10ms/step - loss: 1.2552 - accuracy: 0.5401\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6398 - accuracy: 0.7032\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5015 - accuracy: 0.7502\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4568 - accuracy: 0.7538\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4388 - accuracy: 0.7718\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.7851\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4146 - accuracy: 0.7964\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4113 - accuracy: 0.8005\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4068 - accuracy: 0.8008\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3998 - accuracy: 0.8075\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3940 - accuracy: 0.8090\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3869 - accuracy: 0.8184\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3895 - accuracy: 0.8171\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3833 - accuracy: 0.8167\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3809 - accuracy: 0.8196\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3880 - accuracy: 0.8144\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3841 - accuracy: 0.8168\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3707 - accuracy: 0.8244\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3747 - accuracy: 0.8247\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3642 - accuracy: 0.8277\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3716 - accuracy: 0.8232\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3722 - accuracy: 0.8194\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3676 - accuracy: 0.8244\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3629 - accuracy: 0.8277\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3637 - accuracy: 0.8283\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3633 - accuracy: 0.8253\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3574 - accuracy: 0.8287\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3603 - accuracy: 0.8294\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3591 - accuracy: 0.8288\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3555 - accuracy: 0.8308\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3568 - accuracy: 0.8285\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8238\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3533 - accuracy: 0.8272\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3600 - accuracy: 0.8256\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3556 - accuracy: 0.8279\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3495 - accuracy: 0.8314\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3531 - accuracy: 0.8298\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3534 - accuracy: 0.8297\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3625 - accuracy: 0.8243\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3489 - accuracy: 0.8379\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3543 - accuracy: 0.8264\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3439 - accuracy: 0.8407\n",
      "Epoch 43/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3570 - accuracy: 0.8297\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3469 - accuracy: 0.8352\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3482 - accuracy: 0.8321\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8339\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3481 - accuracy: 0.8325\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3415 - accuracy: 0.8324\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3455 - accuracy: 0.8340\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8362\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3474 - accuracy: 0.8339\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3433 - accuracy: 0.8361\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3498 - accuracy: 0.8362\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.8322\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3521 - accuracy: 0.8283\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3365 - accuracy: 0.8419\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3464 - accuracy: 0.8314\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3389 - accuracy: 0.8367\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3472 - accuracy: 0.8340\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3468 - accuracy: 0.8325\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3481 - accuracy: 0.8295\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8419\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8319\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3413 - accuracy: 0.8355\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3393 - accuracy: 0.8322\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3452 - accuracy: 0.8353\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.8343\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3378 - accuracy: 0.8356\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3413 - accuracy: 0.8346\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.8351\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3398 - accuracy: 0.8374\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3509 - accuracy: 0.8295\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3433 - accuracy: 0.8363\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3407 - accuracy: 0.8347\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3408 - accuracy: 0.8365\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3399 - accuracy: 0.8355\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.8354\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8374\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3486 - accuracy: 0.8280\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3338 - accuracy: 0.8417\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3360 - accuracy: 0.8391\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8336\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8405\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8410\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3389 - accuracy: 0.8351\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3367 - accuracy: 0.8430\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.8373\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3432 - accuracy: 0.8339\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3361 - accuracy: 0.8377\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3413 - accuracy: 0.8322\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3424 - accuracy: 0.8320\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3387 - accuracy: 0.8370\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.8335\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3392 - accuracy: 0.8344\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8395\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3378 - accuracy: 0.8385\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3298 - accuracy: 0.8447\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3407 - accuracy: 0.8334\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3296 - accuracy: 0.8416\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3393 - accuracy: 0.8336\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3385 - accuracy: 0.8355\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3405 - accuracy: 0.8358\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3312 - accuracy: 0.8414\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3416 - accuracy: 0.8339\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8431\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3408 - accuracy: 0.8356\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8388\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3410 - accuracy: 0.8381\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8370\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3394 - accuracy: 0.8281\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3366 - accuracy: 0.8353\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.8426\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3350 - accuracy: 0.8398\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8444\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3396 - accuracy: 0.8377\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8366\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.8393\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3462 - accuracy: 0.8339\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3279 - accuracy: 0.8396\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8410\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3392 - accuracy: 0.8378\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.8391\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3387 - accuracy: 0.8340\n",
      "Epoch 124/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3373 - accuracy: 0.8346\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8337\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8420\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8391\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8412\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3371 - accuracy: 0.8359\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3299 - accuracy: 0.8400\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3359 - accuracy: 0.8366\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.8447\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3356 - accuracy: 0.8391\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3314 - accuracy: 0.8373\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3294 - accuracy: 0.8453\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3334 - accuracy: 0.8400\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.8401\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3355 - accuracy: 0.8375\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3376 - accuracy: 0.8357\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3304 - accuracy: 0.8392\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3285 - accuracy: 0.8423\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3286 - accuracy: 0.8411\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8430\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3281 - accuracy: 0.8455\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.8427\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3277 - accuracy: 0.8441\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8406\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3238 - accuracy: 0.8440\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.8459\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3297 - accuracy: 0.8406\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3348 - accuracy: 0.8453\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3299 - accuracy: 0.8404\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3307 - accuracy: 0.8451\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3275 - accuracy: 0.8422\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3334 - accuracy: 0.8380\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3343 - accuracy: 0.8380\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8438\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3284 - accuracy: 0.8427\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8404\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3326 - accuracy: 0.8404\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3316 - accuracy: 0.8390\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3317 - accuracy: 0.8474\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.8360\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3270 - accuracy: 0.8464\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3281 - accuracy: 0.8424\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3244 - accuracy: 0.8454\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3297 - accuracy: 0.8451\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3291 - accuracy: 0.8392\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3243 - accuracy: 0.8386\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3349 - accuracy: 0.8333\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8379\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3402 - accuracy: 0.8373\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8427\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3283 - accuracy: 0.8421\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.8443\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.8423\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3255 - accuracy: 0.8434\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8410\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3241 - accuracy: 0.8429\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3291 - accuracy: 0.8416\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3343 - accuracy: 0.8396\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8392\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.8463\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3217 - accuracy: 0.8474\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3288 - accuracy: 0.8401\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3271 - accuracy: 0.8430\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.8334\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3301 - accuracy: 0.8414\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3324 - accuracy: 0.8407\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3315 - accuracy: 0.8358\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3276 - accuracy: 0.8382\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3237 - accuracy: 0.8447\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3332 - accuracy: 0.8372\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3341 - accuracy: 0.8371\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.8446\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.8398\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.8421\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3280 - accuracy: 0.8378\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.8392\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3356 - accuracy: 0.8334\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3329 - accuracy: 0.8362\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3251 - accuracy: 0.8433\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3286 - accuracy: 0.8406\n",
      "Epoch 204/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3302 - accuracy: 0.8429\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3337 - accuracy: 0.8349\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3305 - accuracy: 0.8436\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3269 - accuracy: 0.8433\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.8424\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3232 - accuracy: 0.8482\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3373 - accuracy: 0.8410\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3255 - accuracy: 0.8414\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3287 - accuracy: 0.8407\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3321 - accuracy: 0.8411\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3265 - accuracy: 0.8453\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3254 - accuracy: 0.8457\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3365 - accuracy: 0.8363\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3264 - accuracy: 0.8460\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3319 - accuracy: 0.8415\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.8462\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3327 - accuracy: 0.8381\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3364 - accuracy: 0.8365\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3329 - accuracy: 0.8443\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.8439\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3352 - accuracy: 0.8413\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3333 - accuracy: 0.8400\n",
      "Epoch 00225: early stopping\n",
      "Score for fold 4: loss of 0.4069898724555969; accuracy of 81.84428811073303%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 9ms/step - loss: 1.3724 - accuracy: 0.5722\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6533 - accuracy: 0.7146\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4892 - accuracy: 0.7277\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4520 - accuracy: 0.7660\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.7689\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.4227 - accuracy: 0.7868\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4152 - accuracy: 0.7912\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3968 - accuracy: 0.8116\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3935 - accuracy: 0.8087\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3934 - accuracy: 0.8018\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.4003 - accuracy: 0.8101\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3927 - accuracy: 0.8130\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3886 - accuracy: 0.8124\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3861 - accuracy: 0.8170\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3796 - accuracy: 0.8161\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.3840 - accuracy: 0.8230\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3821 - accuracy: 0.8173\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3724 - accuracy: 0.8185\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3776 - accuracy: 0.8171\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3682 - accuracy: 0.8239\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3673 - accuracy: 0.8252\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3688 - accuracy: 0.8233\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3725 - accuracy: 0.8159\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3712 - accuracy: 0.8207\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3736 - accuracy: 0.8238\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3651 - accuracy: 0.8280\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3699 - accuracy: 0.8230\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3627 - accuracy: 0.8281\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3599 - accuracy: 0.8257\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3650 - accuracy: 0.8229\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3620 - accuracy: 0.8262\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3637 - accuracy: 0.8213\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3645 - accuracy: 0.8245\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3620 - accuracy: 0.8241\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3599 - accuracy: 0.8295\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3571 - accuracy: 0.8296\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3554 - accuracy: 0.8315\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3594 - accuracy: 0.8309\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3657 - accuracy: 0.8244\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3551 - accuracy: 0.8329\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3524 - accuracy: 0.8313\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.8319\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8329\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3588 - accuracy: 0.8234\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3577 - accuracy: 0.8263\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3528 - accuracy: 0.8332\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3548 - accuracy: 0.8273\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.8291\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3562 - accuracy: 0.8253\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3465 - accuracy: 0.8329\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3496 - accuracy: 0.8334\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3495 - accuracy: 0.8361\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3444 - accuracy: 0.8326\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3493 - accuracy: 0.8317\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3476 - accuracy: 0.8349\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3510 - accuracy: 0.8279\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3519 - accuracy: 0.8271\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3489 - accuracy: 0.8296\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3433 - accuracy: 0.8342\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3554 - accuracy: 0.8260\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3479 - accuracy: 0.8304\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8364\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3377 - accuracy: 0.8350\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3464 - accuracy: 0.8323\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3428 - accuracy: 0.8324\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3467 - accuracy: 0.8346\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3434 - accuracy: 0.8362\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3440 - accuracy: 0.8355\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3380 - accuracy: 0.8388\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3408 - accuracy: 0.8340\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3456 - accuracy: 0.8342\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3462 - accuracy: 0.8290\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3465 - accuracy: 0.8341\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3452 - accuracy: 0.8307\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8332\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3411 - accuracy: 0.8351\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3453 - accuracy: 0.8325\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3399 - accuracy: 0.8333\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3426 - accuracy: 0.8298\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3412 - accuracy: 0.8316\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3401 - accuracy: 0.8322\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3370 - accuracy: 0.8369\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3391 - accuracy: 0.8366\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3411 - accuracy: 0.8384\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3379 - accuracy: 0.8335\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3414 - accuracy: 0.8317\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3390 - accuracy: 0.8299\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3427 - accuracy: 0.8289\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3362 - accuracy: 0.8356\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3415 - accuracy: 0.8327\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3322 - accuracy: 0.8420\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3381 - accuracy: 0.8402\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3371 - accuracy: 0.8372\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8329\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3425 - accuracy: 0.8312\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.8372\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3301 - accuracy: 0.8427\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3336 - accuracy: 0.8423\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.8397\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3313 - accuracy: 0.8397\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3323 - accuracy: 0.8431\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.8370\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3353 - accuracy: 0.8372\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3393 - accuracy: 0.8368\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3287 - accuracy: 0.8434\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3306 - accuracy: 0.8418\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3371 - accuracy: 0.8375\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3385 - accuracy: 0.8327\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3316 - accuracy: 0.8395\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.8402\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8403\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.8420\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3421 - accuracy: 0.8345\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3385 - accuracy: 0.8350\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3343 - accuracy: 0.8388\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3383 - accuracy: 0.8366\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3303 - accuracy: 0.8376\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3249 - accuracy: 0.8441\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3308 - accuracy: 0.8393\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8424\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8442\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.8403\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8464\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3328 - accuracy: 0.8396\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3351 - accuracy: 0.8359\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3303 - accuracy: 0.8394\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3257 - accuracy: 0.8419\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3331 - accuracy: 0.8384\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3274 - accuracy: 0.8455\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3333 - accuracy: 0.8376\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8394\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.8387\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3331 - accuracy: 0.8388\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.8433\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3315 - accuracy: 0.8440\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3340 - accuracy: 0.8408\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8445\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3246 - accuracy: 0.8456\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3183 - accuracy: 0.8517\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3315 - accuracy: 0.8417\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3337 - accuracy: 0.8400\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3257 - accuracy: 0.8451\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3347 - accuracy: 0.8367\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3242 - accuracy: 0.8400\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3292 - accuracy: 0.8417\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3243 - accuracy: 0.8473\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3237 - accuracy: 0.8493\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3236 - accuracy: 0.8444\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3293 - accuracy: 0.8394\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3340 - accuracy: 0.8372\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3298 - accuracy: 0.8424\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3252 - accuracy: 0.8443\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3282 - accuracy: 0.8413\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3281 - accuracy: 0.8397\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3283 - accuracy: 0.8392\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8390\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3312 - accuracy: 0.8413\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3278 - accuracy: 0.8392\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3290 - accuracy: 0.8416\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3289 - accuracy: 0.8413\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3162 - accuracy: 0.8457\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3246 - accuracy: 0.8460\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3250 - accuracy: 0.8418\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3238 - accuracy: 0.8451\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3235 - accuracy: 0.8434\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3210 - accuracy: 0.8434\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3305 - accuracy: 0.8406\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3279 - accuracy: 0.8385\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3301 - accuracy: 0.8449\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3245 - accuracy: 0.8447\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3248 - accuracy: 0.8432\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3222 - accuracy: 0.8520\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3289 - accuracy: 0.8418\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3169 - accuracy: 0.8467\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3213 - accuracy: 0.8482\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3290 - accuracy: 0.8405\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3314 - accuracy: 0.8408\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3253 - accuracy: 0.8394\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.8359\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.8409\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8444\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3343 - accuracy: 0.8371\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3287 - accuracy: 0.8408\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3272 - accuracy: 0.8454\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3274 - accuracy: 0.8447\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3263 - accuracy: 0.8404\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.3181 - accuracy: 0.8474\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3233 - accuracy: 0.8421\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.8418\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3203 - accuracy: 0.8452\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3288 - accuracy: 0.8416\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3175 - accuracy: 0.8432\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3239 - accuracy: 0.8430\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3282 - accuracy: 0.8355\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3207 - accuracy: 0.8445\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3204 - accuracy: 0.8463\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3229 - accuracy: 0.8436\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.8479\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3322 - accuracy: 0.8409\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8409\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3240 - accuracy: 0.8393\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3264 - accuracy: 0.8398\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3165 - accuracy: 0.8476\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3260 - accuracy: 0.8427\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3186 - accuracy: 0.8442\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3243 - accuracy: 0.8433\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3250 - accuracy: 0.8448\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3223 - accuracy: 0.8448\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3302 - accuracy: 0.8378\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3258 - accuracy: 0.8428\n",
      "Epoch 211/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3295 - accuracy: 0.8434\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3221 - accuracy: 0.8423\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.8377\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.8421\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3190 - accuracy: 0.8469\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3187 - accuracy: 0.8476\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3230 - accuracy: 0.8417\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3221 - accuracy: 0.8442\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3309 - accuracy: 0.8389\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3258 - accuracy: 0.8404\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3214 - accuracy: 0.8427\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3223 - accuracy: 0.8453\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.3269 - accuracy: 0.8379\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3234 - accuracy: 0.8402\n",
      "Epoch 00224: early stopping\n",
      "Score for fold 5: loss of 0.4573625326156616; accuracy of 81.94001317024231%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.4324164092540741 - Accuracy: 81.40350580215454%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.4622417688369751 - Accuracy: 81.59489631652832%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.41804662346839905 - Accuracy: 81.49920105934143%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.4069898724555969 - Accuracy: 81.84428811073303%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.4573625326156616 - Accuracy: 81.94001317024231%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 81.65638089179993 (+- 0.20405296174903417)\n",
      "> Loss: 0.43541144132614135\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model5= model_five()\n",
    "    history = model5.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model5.evaluate(x_train_test_val[test] , y_train_test_val[test] , verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model5.metrics_names[0]} of {scores[0]}; {model5.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your Part 4 Conclusion here\n",
    "Explain what you conclude on your models comparing preliminary results to those after cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1:\n",
    "The model's test and validation accuracy was comparable. This indicates that the model was able to generalize well with an increased accuracy of ~80%.\n",
    "\n",
    "Model 2:\n",
    "Decreasing the number of output nodes in the first layer by half performed significantly worse. The previous findings are reversed: Model 2 is too simple to address the problem.\n",
    "\n",
    "Model 3:\n",
    "The findings remain the same: by changing the activation function, the model appears to perform worse.\n",
    "\n",
    "Model 4:\n",
    "The previous findings remain the same, this model's performance is comparable to Model 1.\n",
    "\n",
    "Model 5:\n",
    "The previous findings are reversed, but with little confidence. The performance metrics are only slightly worse than Model 1.\n",
    "\n",
    "Most of these models performed significantly better than the logistic regression model, and Model 1 and 4 performed better than the random forest by 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Refining with Regularization\n",
    "We know that our biggest problem, if our models are flexibile enough, will be overfitting. Please try to regularize your best 2 models to see if you can improve their results. Look at these questions:\n",
    "\n",
    "Try regularizing each of your two best models, does the generalizability increase? of Decrease?\n",
    "Is one more sensitive than the other? Why might this happen and why?\n",
    "Please try this with all of your features and then with the reduced set of features.\n",
    "Report your precision, recall and f1 score on the train and validation sets (no cross validatio yet).\n",
    "Next carry out cross validation. Does regularization reduce under or overfitting? Why or why not?\n",
    "Hint: Try both L1 or L2 norm for regularization or dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_one_reg(reg='l2'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "\n",
    "#added hidden layer\n",
    "def model_four_reg(reg='l2'):   \n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dense(10 ,input_shape=(20,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 32ms/step - loss: 1.1653 - accuracy: 0.7094 - val_loss: 1.1372 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0602 - accuracy: 0.7054 - val_loss: 1.0810 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9819 - accuracy: 0.7102 - val_loss: 1.0171 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9149 - accuracy: 0.7131 - val_loss: 0.9788 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8631 - accuracy: 0.7155 - val_loss: 0.9316 - val_accuracy: 0.7081\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8193 - accuracy: 0.7214 - val_loss: 0.9015 - val_accuracy: 0.7088\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7721 - accuracy: 0.7336 - val_loss: 0.8571 - val_accuracy: 0.7120\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7299 - accuracy: 0.7472 - val_loss: 0.8261 - val_accuracy: 0.7139\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7025 - accuracy: 0.7468 - val_loss: 0.7948 - val_accuracy: 0.7142\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6758 - accuracy: 0.7521 - val_loss: 0.7902 - val_accuracy: 0.7139\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6457 - accuracy: 0.7544 - val_loss: 0.7568 - val_accuracy: 0.7158\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6211 - accuracy: 0.7633 - val_loss: 0.7433 - val_accuracy: 0.7158\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6088 - accuracy: 0.7601 - val_loss: 0.7078 - val_accuracy: 0.7177\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5902 - accuracy: 0.7677 - val_loss: 0.6913 - val_accuracy: 0.7187\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5745 - accuracy: 0.7684 - val_loss: 0.6877 - val_accuracy: 0.7171\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5595 - accuracy: 0.7675 - val_loss: 0.6673 - val_accuracy: 0.7209\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5449 - accuracy: 0.7769 - val_loss: 0.6568 - val_accuracy: 0.7215\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5372 - accuracy: 0.7742 - val_loss: 0.6504 - val_accuracy: 0.7215\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5302 - accuracy: 0.7723 - val_loss: 0.6512 - val_accuracy: 0.7199\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5171 - accuracy: 0.7784 - val_loss: 0.6216 - val_accuracy: 0.7238\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5070 - accuracy: 0.7818 - val_loss: 0.6231 - val_accuracy: 0.7238\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5072 - accuracy: 0.7779 - val_loss: 0.6303 - val_accuracy: 0.7228\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5031 - accuracy: 0.7739 - val_loss: 0.6114 - val_accuracy: 0.7247\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4916 - accuracy: 0.7863 - val_loss: 0.6003 - val_accuracy: 0.7285\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4883 - accuracy: 0.7825 - val_loss: 0.5986 - val_accuracy: 0.7292\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4873 - accuracy: 0.7839 - val_loss: 0.6025 - val_accuracy: 0.7266\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4789 - accuracy: 0.7833 - val_loss: 0.5888 - val_accuracy: 0.7317\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4721 - accuracy: 0.7904 - val_loss: 0.5817 - val_accuracy: 0.7343\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4708 - accuracy: 0.7922 - val_loss: 0.5741 - val_accuracy: 0.7394\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4646 - accuracy: 0.7911 - val_loss: 0.5683 - val_accuracy: 0.7419\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4681 - accuracy: 0.7897 - val_loss: 0.5664 - val_accuracy: 0.7416\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4596 - accuracy: 0.7959 - val_loss: 0.5691 - val_accuracy: 0.7407\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4567 - accuracy: 0.7956 - val_loss: 0.5659 - val_accuracy: 0.7404\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4561 - accuracy: 0.7954 - val_loss: 0.5591 - val_accuracy: 0.7435\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4582 - accuracy: 0.7961 - val_loss: 0.5611 - val_accuracy: 0.7410\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4552 - accuracy: 0.7912 - val_loss: 0.5554 - val_accuracy: 0.7439\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4524 - accuracy: 0.7965 - val_loss: 0.5609 - val_accuracy: 0.7413\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4481 - accuracy: 0.7949 - val_loss: 0.5515 - val_accuracy: 0.7502\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4547 - accuracy: 0.7942 - val_loss: 0.5564 - val_accuracy: 0.7426\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4477 - accuracy: 0.7952 - val_loss: 0.5522 - val_accuracy: 0.7432\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4483 - accuracy: 0.7985 - val_loss: 0.5472 - val_accuracy: 0.7522\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4460 - accuracy: 0.7971 - val_loss: 0.5460 - val_accuracy: 0.7496\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4439 - accuracy: 0.8019 - val_loss: 0.5460 - val_accuracy: 0.7509\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4406 - accuracy: 0.8008 - val_loss: 0.5484 - val_accuracy: 0.7442\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4422 - accuracy: 0.7974 - val_loss: 0.5436 - val_accuracy: 0.7499\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4384 - accuracy: 0.8056 - val_loss: 0.5432 - val_accuracy: 0.7499\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4454 - accuracy: 0.7935 - val_loss: 0.5444 - val_accuracy: 0.7506\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4390 - accuracy: 0.7994 - val_loss: 0.5445 - val_accuracy: 0.7509\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4402 - accuracy: 0.8039 - val_loss: 0.5414 - val_accuracy: 0.7509\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4354 - accuracy: 0.8040 - val_loss: 0.5431 - val_accuracy: 0.7506\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4352 - accuracy: 0.8025 - val_loss: 0.5457 - val_accuracy: 0.7442\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4361 - accuracy: 0.8043 - val_loss: 0.5404 - val_accuracy: 0.7531\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4452 - accuracy: 0.7976 - val_loss: 0.5443 - val_accuracy: 0.7467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4372 - accuracy: 0.8027 - val_loss: 0.5405 - val_accuracy: 0.7531\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4343 - accuracy: 0.8070 - val_loss: 0.5396 - val_accuracy: 0.7506\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4341 - accuracy: 0.8065 - val_loss: 0.5420 - val_accuracy: 0.7502\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4327 - accuracy: 0.8037 - val_loss: 0.5412 - val_accuracy: 0.7506\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4334 - accuracy: 0.8030 - val_loss: 0.5388 - val_accuracy: 0.7534\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4368 - accuracy: 0.8050 - val_loss: 0.5381 - val_accuracy: 0.7515\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4318 - accuracy: 0.8033 - val_loss: 0.5443 - val_accuracy: 0.7474\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4334 - accuracy: 0.8076 - val_loss: 0.5367 - val_accuracy: 0.7509\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4343 - accuracy: 0.8056 - val_loss: 0.5367 - val_accuracy: 0.7506\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4336 - accuracy: 0.8043 - val_loss: 0.5364 - val_accuracy: 0.7509\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4356 - accuracy: 0.8027 - val_loss: 0.5402 - val_accuracy: 0.7464\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.8044 - val_loss: 0.5355 - val_accuracy: 0.7528\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4332 - accuracy: 0.8011 - val_loss: 0.5361 - val_accuracy: 0.7537\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4256 - accuracy: 0.8096 - val_loss: 0.5371 - val_accuracy: 0.7493\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4302 - accuracy: 0.8083 - val_loss: 0.5379 - val_accuracy: 0.7499\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4347 - accuracy: 0.8052 - val_loss: 0.5373 - val_accuracy: 0.7493\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4237 - accuracy: 0.8156 - val_loss: 0.5339 - val_accuracy: 0.7553\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4268 - accuracy: 0.8092 - val_loss: 0.5416 - val_accuracy: 0.7458\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4221 - accuracy: 0.8161 - val_loss: 0.5461 - val_accuracy: 0.7416\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4291 - accuracy: 0.8099 - val_loss: 0.5361 - val_accuracy: 0.7528\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4313 - accuracy: 0.8010 - val_loss: 0.5366 - val_accuracy: 0.7467\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4311 - accuracy: 0.8030 - val_loss: 0.5328 - val_accuracy: 0.7525\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4289 - accuracy: 0.8098 - val_loss: 0.5323 - val_accuracy: 0.7522\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4303 - accuracy: 0.8049 - val_loss: 0.5311 - val_accuracy: 0.7557\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4227 - accuracy: 0.8113 - val_loss: 0.5318 - val_accuracy: 0.7544\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4254 - accuracy: 0.8106 - val_loss: 0.5333 - val_accuracy: 0.7499\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4251 - accuracy: 0.8056 - val_loss: 0.5326 - val_accuracy: 0.7506\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4237 - accuracy: 0.8119 - val_loss: 0.5314 - val_accuracy: 0.7547\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4366 - accuracy: 0.8034 - val_loss: 0.5358 - val_accuracy: 0.7477\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4280 - accuracy: 0.8081 - val_loss: 0.5341 - val_accuracy: 0.7541\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4216 - accuracy: 0.8053 - val_loss: 0.5326 - val_accuracy: 0.7544\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4308 - accuracy: 0.8057 - val_loss: 0.5300 - val_accuracy: 0.7550\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4261 - accuracy: 0.8063 - val_loss: 0.5333 - val_accuracy: 0.7537\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.8099 - val_loss: 0.5309 - val_accuracy: 0.7557\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4241 - accuracy: 0.8121 - val_loss: 0.5406 - val_accuracy: 0.7439\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4206 - accuracy: 0.8098 - val_loss: 0.5376 - val_accuracy: 0.7493\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4217 - accuracy: 0.8085 - val_loss: 0.5360 - val_accuracy: 0.7464\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.8127 - val_loss: 0.5323 - val_accuracy: 0.7483\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4185 - accuracy: 0.8156 - val_loss: 0.5302 - val_accuracy: 0.7553\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4202 - accuracy: 0.8089 - val_loss: 0.5359 - val_accuracy: 0.7483\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4209 - accuracy: 0.8129 - val_loss: 0.5319 - val_accuracy: 0.7483\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.8117 - val_loss: 0.5300 - val_accuracy: 0.7557\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.8144 - val_loss: 0.5288 - val_accuracy: 0.7537\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4212 - accuracy: 0.8090 - val_loss: 0.5321 - val_accuracy: 0.7502\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4218 - accuracy: 0.8086 - val_loss: 0.5324 - val_accuracy: 0.7486\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8199 - val_loss: 0.5282 - val_accuracy: 0.7553\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4236 - accuracy: 0.8078 - val_loss: 0.5279 - val_accuracy: 0.7563\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.8103 - val_loss: 0.5325 - val_accuracy: 0.7490\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4185 - accuracy: 0.8117 - val_loss: 0.5347 - val_accuracy: 0.7509\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4170 - accuracy: 0.8172 - val_loss: 0.5556 - val_accuracy: 0.7276\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4221 - accuracy: 0.8115 - val_loss: 0.5354 - val_accuracy: 0.7470\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4215 - accuracy: 0.8129 - val_loss: 0.5271 - val_accuracy: 0.7553\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4199 - accuracy: 0.8100 - val_loss: 0.5285 - val_accuracy: 0.7531\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4174 - accuracy: 0.8139 - val_loss: 0.5271 - val_accuracy: 0.7534\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4179 - accuracy: 0.8150 - val_loss: 0.5367 - val_accuracy: 0.7445\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.8100 - val_loss: 0.5378 - val_accuracy: 0.7445\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4176 - accuracy: 0.8125 - val_loss: 0.5625 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4188 - accuracy: 0.8095 - val_loss: 0.5265 - val_accuracy: 0.7525\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4185 - accuracy: 0.8102 - val_loss: 0.5259 - val_accuracy: 0.7566\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4146 - accuracy: 0.8180 - val_loss: 0.5349 - val_accuracy: 0.7451\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8104 - val_loss: 0.5642 - val_accuracy: 0.7238\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4190 - accuracy: 0.8077 - val_loss: 0.5270 - val_accuracy: 0.7483\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4204 - accuracy: 0.8093 - val_loss: 0.5407 - val_accuracy: 0.7442\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4190 - accuracy: 0.8119 - val_loss: 0.5329 - val_accuracy: 0.7480\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4178 - accuracy: 0.8121 - val_loss: 0.5246 - val_accuracy: 0.7566\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8121 - val_loss: 0.5298 - val_accuracy: 0.7506\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4172 - accuracy: 0.8115 - val_loss: 0.5255 - val_accuracy: 0.7553\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4137 - accuracy: 0.8138 - val_loss: 0.5267 - val_accuracy: 0.7499\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4182 - accuracy: 0.8127 - val_loss: 0.5502 - val_accuracy: 0.7330\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4174 - accuracy: 0.8135 - val_loss: 0.5293 - val_accuracy: 0.7547\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4175 - accuracy: 0.8093 - val_loss: 0.5304 - val_accuracy: 0.7502\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4147 - accuracy: 0.8144 - val_loss: 0.5613 - val_accuracy: 0.7219\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4162 - accuracy: 0.8141 - val_loss: 0.5260 - val_accuracy: 0.7483\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4203 - accuracy: 0.8122 - val_loss: 0.5239 - val_accuracy: 0.7525\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4189 - accuracy: 0.8073 - val_loss: 0.5277 - val_accuracy: 0.7506\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4143 - accuracy: 0.8169 - val_loss: 0.5348 - val_accuracy: 0.7470\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4182 - accuracy: 0.8116 - val_loss: 0.5332 - val_accuracy: 0.7461\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4156 - accuracy: 0.8140 - val_loss: 0.5488 - val_accuracy: 0.7324\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4145 - accuracy: 0.8151 - val_loss: 0.5964 - val_accuracy: 0.6938\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4161 - accuracy: 0.8137 - val_loss: 0.5244 - val_accuracy: 0.7553\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4154 - accuracy: 0.8134 - val_loss: 0.5483 - val_accuracy: 0.7346\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.8137 - val_loss: 0.5245 - val_accuracy: 0.7483\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4149 - accuracy: 0.8117 - val_loss: 0.5241 - val_accuracy: 0.7496\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8165 - val_loss: 0.5252 - val_accuracy: 0.7490\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4143 - accuracy: 0.8155 - val_loss: 0.5392 - val_accuracy: 0.7429\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4130 - accuracy: 0.8117 - val_loss: 0.5430 - val_accuracy: 0.7397\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4139 - accuracy: 0.8135 - val_loss: 0.5215 - val_accuracy: 0.7560\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4138 - accuracy: 0.8158 - val_loss: 0.5291 - val_accuracy: 0.7490\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4094 - accuracy: 0.8193 - val_loss: 0.5234 - val_accuracy: 0.7569\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4179 - accuracy: 0.8097 - val_loss: 0.5309 - val_accuracy: 0.7474\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8201 - val_loss: 0.5218 - val_accuracy: 0.7563\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.8112 - val_loss: 0.5462 - val_accuracy: 0.7352\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8109 - val_loss: 0.5586 - val_accuracy: 0.7250\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4134 - accuracy: 0.8131 - val_loss: 0.5217 - val_accuracy: 0.7563\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4147 - accuracy: 0.8075 - val_loss: 0.5381 - val_accuracy: 0.7445\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4070 - accuracy: 0.8221 - val_loss: 0.5190 - val_accuracy: 0.7576\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4129 - accuracy: 0.8114 - val_loss: 0.5216 - val_accuracy: 0.7515\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4100 - accuracy: 0.8172 - val_loss: 0.5670 - val_accuracy: 0.7158\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8105 - val_loss: 0.5201 - val_accuracy: 0.7544\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4134 - accuracy: 0.8130 - val_loss: 0.5209 - val_accuracy: 0.7563\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.8161 - val_loss: 0.5230 - val_accuracy: 0.7518\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4118 - accuracy: 0.8148 - val_loss: 0.5185 - val_accuracy: 0.7579\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4134 - accuracy: 0.8124 - val_loss: 0.5192 - val_accuracy: 0.7525\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4117 - accuracy: 0.8119 - val_loss: 0.5356 - val_accuracy: 0.7448\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8181 - val_loss: 0.5548 - val_accuracy: 0.7247\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4125 - accuracy: 0.8103 - val_loss: 0.5199 - val_accuracy: 0.7569\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4169 - accuracy: 0.8103 - val_loss: 0.5206 - val_accuracy: 0.7566\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4198 - accuracy: 0.8081 - val_loss: 0.5222 - val_accuracy: 0.7499\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4104 - accuracy: 0.8163 - val_loss: 0.5191 - val_accuracy: 0.7573\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4096 - accuracy: 0.8141 - val_loss: 0.5223 - val_accuracy: 0.7506\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4128 - accuracy: 0.8125 - val_loss: 0.5208 - val_accuracy: 0.7531\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.8162 - val_loss: 0.5248 - val_accuracy: 0.7509\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4121 - accuracy: 0.8123 - val_loss: 0.5680 - val_accuracy: 0.7148\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8113 - val_loss: 0.5335 - val_accuracy: 0.7474\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8165 - val_loss: 0.5239 - val_accuracy: 0.7541\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8143 - val_loss: 0.5187 - val_accuracy: 0.7499\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4117 - accuracy: 0.8108 - val_loss: 0.5234 - val_accuracy: 0.7515\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4117 - accuracy: 0.8162 - val_loss: 0.5233 - val_accuracy: 0.7525\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4161 - accuracy: 0.8118 - val_loss: 0.5200 - val_accuracy: 0.7490\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.8149 - val_loss: 0.5193 - val_accuracy: 0.7569\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4123 - accuracy: 0.8139 - val_loss: 0.5777 - val_accuracy: 0.7107\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4156 - accuracy: 0.8125 - val_loss: 0.5173 - val_accuracy: 0.7569\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4143 - accuracy: 0.8126 - val_loss: 0.5186 - val_accuracy: 0.7579\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4103 - accuracy: 0.8147 - val_loss: 0.5230 - val_accuracy: 0.7534\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8168 - val_loss: 0.5663 - val_accuracy: 0.7171\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4052 - accuracy: 0.8174 - val_loss: 0.5161 - val_accuracy: 0.7592\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4091 - accuracy: 0.8136 - val_loss: 0.5361 - val_accuracy: 0.7435\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4092 - accuracy: 0.8138 - val_loss: 0.5275 - val_accuracy: 0.7483\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4094 - accuracy: 0.8135 - val_loss: 0.5323 - val_accuracy: 0.7467\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4144 - accuracy: 0.8101 - val_loss: 0.5197 - val_accuracy: 0.7528\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4061 - accuracy: 0.8176 - val_loss: 0.5295 - val_accuracy: 0.7490\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8198 - val_loss: 0.5196 - val_accuracy: 0.7528\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8120 - val_loss: 0.5178 - val_accuracy: 0.7537\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8123 - val_loss: 0.5366 - val_accuracy: 0.7499\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4132 - accuracy: 0.8100 - val_loss: 0.5188 - val_accuracy: 0.7525\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4148 - accuracy: 0.8087 - val_loss: 0.5213 - val_accuracy: 0.7534\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.8182 - val_loss: 0.5184 - val_accuracy: 0.7518\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4073 - accuracy: 0.8168 - val_loss: 0.5180 - val_accuracy: 0.7541\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4055 - accuracy: 0.8170 - val_loss: 0.5242 - val_accuracy: 0.7499\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4116 - accuracy: 0.8129 - val_loss: 0.5347 - val_accuracy: 0.7432\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8160 - val_loss: 0.5189 - val_accuracy: 0.7531\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4089 - accuracy: 0.8153 - val_loss: 0.5949 - val_accuracy: 0.6941\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.8092 - val_loss: 0.5317 - val_accuracy: 0.7448\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4106 - accuracy: 0.8131 - val_loss: 0.5192 - val_accuracy: 0.7502\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8177 - val_loss: 0.5208 - val_accuracy: 0.7528\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8100 - val_loss: 0.5370 - val_accuracy: 0.7416\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4044 - accuracy: 0.8207 - val_loss: 0.5178 - val_accuracy: 0.7531\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8153 - val_loss: 0.5383 - val_accuracy: 0.7384\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4073 - accuracy: 0.8131 - val_loss: 0.5246 - val_accuracy: 0.7506\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8229 - val_loss: 0.5512 - val_accuracy: 0.7228\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4177 - accuracy: 0.8080 - val_loss: 0.5159 - val_accuracy: 0.7576\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8179 - val_loss: 0.6035 - val_accuracy: 0.6906\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.8167 - val_loss: 0.5993 - val_accuracy: 0.6938\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4102 - accuracy: 0.8123 - val_loss: 0.5424 - val_accuracy: 0.7337\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8172 - val_loss: 0.5155 - val_accuracy: 0.7553\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4147 - accuracy: 0.8106 - val_loss: 0.5359 - val_accuracy: 0.7397\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8140 - val_loss: 0.5147 - val_accuracy: 0.7576\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4115 - accuracy: 0.8117 - val_loss: 0.5432 - val_accuracy: 0.7340\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4040 - accuracy: 0.8170 - val_loss: 0.5344 - val_accuracy: 0.7429\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8205 - val_loss: 0.5282 - val_accuracy: 0.7483\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8142 - val_loss: 0.5185 - val_accuracy: 0.7534\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4052 - accuracy: 0.8182 - val_loss: 0.5264 - val_accuracy: 0.7502\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8188 - val_loss: 0.5592 - val_accuracy: 0.7196\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4070 - accuracy: 0.8137 - val_loss: 0.5304 - val_accuracy: 0.7537\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4134 - accuracy: 0.8104 - val_loss: 0.5206 - val_accuracy: 0.7560\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4064 - accuracy: 0.8134 - val_loss: 0.5385 - val_accuracy: 0.7397\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8110 - val_loss: 0.5217 - val_accuracy: 0.7515\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4089 - accuracy: 0.8137 - val_loss: 0.5401 - val_accuracy: 0.7375\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4089 - accuracy: 0.8181 - val_loss: 0.5148 - val_accuracy: 0.7537\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4056 - accuracy: 0.8160 - val_loss: 0.5404 - val_accuracy: 0.7356\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8110 - val_loss: 0.5498 - val_accuracy: 0.7250\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.8163 - val_loss: 0.5133 - val_accuracy: 0.7573\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8154 - val_loss: 0.5144 - val_accuracy: 0.7547\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.8167 - val_loss: 0.5223 - val_accuracy: 0.7557\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4073 - accuracy: 0.8068 - val_loss: 0.5492 - val_accuracy: 0.7279\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4064 - accuracy: 0.8152 - val_loss: 0.5278 - val_accuracy: 0.7461\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4125 - accuracy: 0.8101 - val_loss: 0.5328 - val_accuracy: 0.7410\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4095 - accuracy: 0.8137 - val_loss: 0.5354 - val_accuracy: 0.7413\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4107 - accuracy: 0.8124 - val_loss: 0.5662 - val_accuracy: 0.7180\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8194 - val_loss: 0.5125 - val_accuracy: 0.7601\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4106 - accuracy: 0.8107 - val_loss: 0.5149 - val_accuracy: 0.7525\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4057 - accuracy: 0.8162 - val_loss: 0.5319 - val_accuracy: 0.7426\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4043 - accuracy: 0.8193 - val_loss: 0.5706 - val_accuracy: 0.7113\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.8127 - val_loss: 0.5272 - val_accuracy: 0.7451\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8171 - val_loss: 0.5499 - val_accuracy: 0.7234\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4111 - accuracy: 0.8146 - val_loss: 0.5702 - val_accuracy: 0.7129\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8147 - val_loss: 0.5367 - val_accuracy: 0.7397\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4046 - accuracy: 0.8186 - val_loss: 0.5242 - val_accuracy: 0.7496\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4074 - accuracy: 0.8122 - val_loss: 0.5143 - val_accuracy: 0.7522\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8135 - val_loss: 0.5795 - val_accuracy: 0.7046\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8173 - val_loss: 0.5132 - val_accuracy: 0.7563\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8148 - val_loss: 0.5115 - val_accuracy: 0.7582\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4067 - accuracy: 0.8142 - val_loss: 0.5289 - val_accuracy: 0.7439\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8177 - val_loss: 0.5489 - val_accuracy: 0.7263\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4061 - accuracy: 0.8157 - val_loss: 0.5125 - val_accuracy: 0.7560\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4040 - accuracy: 0.8199 - val_loss: 0.5126 - val_accuracy: 0.7566\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8185 - val_loss: 0.5633 - val_accuracy: 0.7222\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4031 - accuracy: 0.8162 - val_loss: 0.5185 - val_accuracy: 0.7534\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4047 - accuracy: 0.8165 - val_loss: 0.5143 - val_accuracy: 0.7541\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4025 - accuracy: 0.8198 - val_loss: 0.5645 - val_accuracy: 0.7152\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8112 - val_loss: 0.5113 - val_accuracy: 0.7557\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8162 - val_loss: 0.5360 - val_accuracy: 0.7404\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4055 - accuracy: 0.8145 - val_loss: 0.5124 - val_accuracy: 0.7569\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8156 - val_loss: 0.5118 - val_accuracy: 0.7537\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4078 - accuracy: 0.8150 - val_loss: 0.5641 - val_accuracy: 0.7180\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8148 - val_loss: 0.5631 - val_accuracy: 0.7222\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4056 - accuracy: 0.8151 - val_loss: 0.6133 - val_accuracy: 0.6772\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4097 - accuracy: 0.8093 - val_loss: 0.5311 - val_accuracy: 0.7439\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4086 - accuracy: 0.8158 - val_loss: 0.5541 - val_accuracy: 0.7206\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8169 - val_loss: 0.5143 - val_accuracy: 0.7522\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4056 - accuracy: 0.8151 - val_loss: 0.5103 - val_accuracy: 0.7592\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8187 - val_loss: 0.5474 - val_accuracy: 0.7270\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8137 - val_loss: 0.5230 - val_accuracy: 0.7490\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8162 - val_loss: 0.5109 - val_accuracy: 0.7566\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4043 - accuracy: 0.8150 - val_loss: 0.5435 - val_accuracy: 0.7305\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.8133 - val_loss: 0.5210 - val_accuracy: 0.7499\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4101 - accuracy: 0.8118 - val_loss: 0.5520 - val_accuracy: 0.7206\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8158 - val_loss: 0.5488 - val_accuracy: 0.7215\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4011 - accuracy: 0.8226 - val_loss: 0.5135 - val_accuracy: 0.7544\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.8196 - val_loss: 0.5180 - val_accuracy: 0.7537\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4001 - accuracy: 0.8205 - val_loss: 0.5104 - val_accuracy: 0.7569\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8142 - val_loss: 0.5284 - val_accuracy: 0.7464\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4008 - accuracy: 0.8187 - val_loss: 0.5165 - val_accuracy: 0.7547\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4081 - accuracy: 0.8124 - val_loss: 0.5158 - val_accuracy: 0.7592\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4123 - accuracy: 0.8104 - val_loss: 0.5098 - val_accuracy: 0.7601\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4085 - accuracy: 0.8080 - val_loss: 0.5451 - val_accuracy: 0.7285\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8113 - val_loss: 0.5198 - val_accuracy: 0.7515\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4013 - accuracy: 0.8178 - val_loss: 0.5109 - val_accuracy: 0.7566\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.8071 - val_loss: 0.5451 - val_accuracy: 0.7305\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4055 - accuracy: 0.8184 - val_loss: 0.5116 - val_accuracy: 0.7576\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4014 - accuracy: 0.8170 - val_loss: 0.5157 - val_accuracy: 0.7553\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8172 - val_loss: 0.6126 - val_accuracy: 0.6801\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.8135 - val_loss: 0.5554 - val_accuracy: 0.7260\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4019 - accuracy: 0.8175 - val_loss: 0.5121 - val_accuracy: 0.7576\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8164 - val_loss: 0.5082 - val_accuracy: 0.7582\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4087 - accuracy: 0.8122 - val_loss: 0.5114 - val_accuracy: 0.7544\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3957 - accuracy: 0.8213 - val_loss: 0.5313 - val_accuracy: 0.7445\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8161 - val_loss: 0.5068 - val_accuracy: 0.7614\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.8142 - val_loss: 0.5924 - val_accuracy: 0.6941\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8158 - val_loss: 0.5280 - val_accuracy: 0.7448\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.8128 - val_loss: 0.5174 - val_accuracy: 0.7537\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4016 - accuracy: 0.8130 - val_loss: 0.5250 - val_accuracy: 0.7458\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4030 - accuracy: 0.8164 - val_loss: 0.5117 - val_accuracy: 0.7547\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4011 - accuracy: 0.8187 - val_loss: 0.5100 - val_accuracy: 0.7557\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8119 - val_loss: 0.5401 - val_accuracy: 0.7330\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.8198 - val_loss: 0.5426 - val_accuracy: 0.7305\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4010 - accuracy: 0.8177 - val_loss: 0.5587 - val_accuracy: 0.7231\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4017 - accuracy: 0.8152 - val_loss: 0.5173 - val_accuracy: 0.7560\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8165 - val_loss: 0.5594 - val_accuracy: 0.7257\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.8190 - val_loss: 0.5850 - val_accuracy: 0.7008\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8169 - val_loss: 0.5389 - val_accuracy: 0.7343\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4035 - accuracy: 0.8210 - val_loss: 0.5303 - val_accuracy: 0.7429\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.8192 - val_loss: 0.5182 - val_accuracy: 0.7522\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4109 - accuracy: 0.8078 - val_loss: 0.5387 - val_accuracy: 0.7349\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3984 - accuracy: 0.8189 - val_loss: 0.6472 - val_accuracy: 0.6498\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4115 - accuracy: 0.8065 - val_loss: 0.5299 - val_accuracy: 0.7407\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3935 - accuracy: 0.8248 - val_loss: 0.5070 - val_accuracy: 0.7617\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4041 - accuracy: 0.8126 - val_loss: 0.5121 - val_accuracy: 0.7537\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8137 - val_loss: 0.5288 - val_accuracy: 0.7419\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3981 - accuracy: 0.8232 - val_loss: 0.5241 - val_accuracy: 0.7464\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.8154 - val_loss: 0.5076 - val_accuracy: 0.7582\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4016 - accuracy: 0.8162 - val_loss: 0.5259 - val_accuracy: 0.7435\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4008 - accuracy: 0.8177 - val_loss: 0.5503 - val_accuracy: 0.7231\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4071 - accuracy: 0.8113 - val_loss: 0.5231 - val_accuracy: 0.7480\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4008 - accuracy: 0.8183 - val_loss: 0.5135 - val_accuracy: 0.7608\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4049 - accuracy: 0.8125 - val_loss: 0.5193 - val_accuracy: 0.7509\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4039 - accuracy: 0.8181 - val_loss: 0.5105 - val_accuracy: 0.7557\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4075 - accuracy: 0.8120 - val_loss: 0.6352 - val_accuracy: 0.6587\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4165 - accuracy: 0.8100 - val_loss: 0.5169 - val_accuracy: 0.7573\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4062 - accuracy: 0.8148 - val_loss: 0.5092 - val_accuracy: 0.7601\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4057 - accuracy: 0.8100 - val_loss: 0.5424 - val_accuracy: 0.7301\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 0.8166 - val_loss: 0.5455 - val_accuracy: 0.7260\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4106 - accuracy: 0.8083 - val_loss: 0.5162 - val_accuracy: 0.7537\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4018 - accuracy: 0.8162 - val_loss: 0.5108 - val_accuracy: 0.7589\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3969 - accuracy: 0.8186 - val_loss: 0.6173 - val_accuracy: 0.6766\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4106 - accuracy: 0.8152 - val_loss: 0.5185 - val_accuracy: 0.7499\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3996 - accuracy: 0.8184 - val_loss: 0.5112 - val_accuracy: 0.7633\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3971 - accuracy: 0.8179 - val_loss: 0.5215 - val_accuracy: 0.7490\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3978 - accuracy: 0.8210 - val_loss: 0.5713 - val_accuracy: 0.7081\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.8060 - val_loss: 0.5525 - val_accuracy: 0.7228\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.8192 - val_loss: 0.5174 - val_accuracy: 0.7515\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3977 - accuracy: 0.8196 - val_loss: 0.6005 - val_accuracy: 0.6884\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4059 - accuracy: 0.8176 - val_loss: 0.5470 - val_accuracy: 0.7257\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4080 - accuracy: 0.8150 - val_loss: 0.5221 - val_accuracy: 0.7512\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4025 - accuracy: 0.8177 - val_loss: 0.5427 - val_accuracy: 0.7263\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4005 - accuracy: 0.8181 - val_loss: 0.5073 - val_accuracy: 0.7582\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8010 - val_loss: 0.5304 - val_accuracy: 0.7553\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3974 - accuracy: 0.8193 - val_loss: 0.5714 - val_accuracy: 0.7091\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3988 - accuracy: 0.8142 - val_loss: 0.5241 - val_accuracy: 0.7486\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4060 - accuracy: 0.8111 - val_loss: 0.7045 - val_accuracy: 0.6121\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8100 - val_loss: 0.5427 - val_accuracy: 0.7282\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.8065 - val_loss: 0.5244 - val_accuracy: 0.7483\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4081 - accuracy: 0.8127 - val_loss: 0.5466 - val_accuracy: 0.7244\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4031 - accuracy: 0.8192 - val_loss: 0.5185 - val_accuracy: 0.7525\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3990 - accuracy: 0.8134 - val_loss: 0.5175 - val_accuracy: 0.7518\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8137 - val_loss: 0.5255 - val_accuracy: 0.7451\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4005 - accuracy: 0.8170 - val_loss: 0.5084 - val_accuracy: 0.7579\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3974 - accuracy: 0.8204 - val_loss: 0.5289 - val_accuracy: 0.7442\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4013 - accuracy: 0.8199 - val_loss: 0.7592 - val_accuracy: 0.5780\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4288 - accuracy: 0.7985 - val_loss: 0.5891 - val_accuracy: 0.6982\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3999 - accuracy: 0.8211 - val_loss: 0.5286 - val_accuracy: 0.7400\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4046 - accuracy: 0.8146 - val_loss: 0.5773 - val_accuracy: 0.7008\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3974 - accuracy: 0.8145 - val_loss: 0.5095 - val_accuracy: 0.7563\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4004 - accuracy: 0.8172 - val_loss: 0.5257 - val_accuracy: 0.7448\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.8214 - val_loss: 0.5594 - val_accuracy: 0.7209\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3971 - accuracy: 0.8208 - val_loss: 0.6241 - val_accuracy: 0.6651\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8097 - val_loss: 0.5396 - val_accuracy: 0.7515\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4081 - accuracy: 0.8107 - val_loss: 0.5824 - val_accuracy: 0.6995\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3972 - accuracy: 0.8170 - val_loss: 0.5957 - val_accuracy: 0.6900\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8107 - val_loss: 0.5523 - val_accuracy: 0.7254\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3943 - accuracy: 0.8192 - val_loss: 0.5162 - val_accuracy: 0.7525\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4031 - accuracy: 0.8146 - val_loss: 0.5382 - val_accuracy: 0.7308\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4058 - accuracy: 0.8122 - val_loss: 0.5206 - val_accuracy: 0.7493\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4030 - accuracy: 0.8134 - val_loss: 0.5045 - val_accuracy: 0.7566\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4035 - accuracy: 0.8131 - val_loss: 0.5965 - val_accuracy: 0.6931\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8173 - val_loss: 0.5504 - val_accuracy: 0.7225\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4004 - accuracy: 0.8148 - val_loss: 0.5031 - val_accuracy: 0.7598\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8174 - val_loss: 0.5087 - val_accuracy: 0.7566\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3973 - accuracy: 0.8189 - val_loss: 0.5121 - val_accuracy: 0.7563\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3964 - accuracy: 0.8194 - val_loss: 0.5091 - val_accuracy: 0.7592\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3977 - accuracy: 0.8207 - val_loss: 0.5065 - val_accuracy: 0.7598\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.8190 - val_loss: 0.5319 - val_accuracy: 0.7404\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3991 - accuracy: 0.8185 - val_loss: 0.5181 - val_accuracy: 0.7550\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4037 - accuracy: 0.8112 - val_loss: 0.5309 - val_accuracy: 0.7407\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3997 - accuracy: 0.8209 - val_loss: 0.5158 - val_accuracy: 0.7566\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4066 - accuracy: 0.8078 - val_loss: 0.5086 - val_accuracy: 0.7569\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3973 - accuracy: 0.8157 - val_loss: 0.5084 - val_accuracy: 0.7592\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8087 - val_loss: 0.5249 - val_accuracy: 0.7547\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4214 - accuracy: 0.7985 - val_loss: 0.5142 - val_accuracy: 0.7528\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8170 - val_loss: 0.5374 - val_accuracy: 0.7340\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4042 - accuracy: 0.8154 - val_loss: 0.5220 - val_accuracy: 0.7569\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4185 - accuracy: 0.7973 - val_loss: 0.5131 - val_accuracy: 0.7604\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4104 - accuracy: 0.8107 - val_loss: 0.5388 - val_accuracy: 0.7531\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4149 - accuracy: 0.8026 - val_loss: 0.5938 - val_accuracy: 0.6915\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8169 - val_loss: 0.7878 - val_accuracy: 0.5671\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4095 - accuracy: 0.8091 - val_loss: 0.5203 - val_accuracy: 0.7486\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3986 - accuracy: 0.8147 - val_loss: 0.5306 - val_accuracy: 0.7388\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3990 - accuracy: 0.8145 - val_loss: 0.6548 - val_accuracy: 0.6463\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3976 - accuracy: 0.8204 - val_loss: 0.5110 - val_accuracy: 0.7630\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4010 - accuracy: 0.8137 - val_loss: 0.5521 - val_accuracy: 0.7506\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8217 - val_loss: 0.5710 - val_accuracy: 0.7104\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8150 - val_loss: 0.7079 - val_accuracy: 0.6099\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4239 - accuracy: 0.7977 - val_loss: 0.5169 - val_accuracy: 0.7496\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3950 - accuracy: 0.8202 - val_loss: 0.5090 - val_accuracy: 0.7541\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.8180 - val_loss: 0.5043 - val_accuracy: 0.7592\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4022 - accuracy: 0.8140 - val_loss: 0.5317 - val_accuracy: 0.7394\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4043 - accuracy: 0.8132 - val_loss: 0.5323 - val_accuracy: 0.7388\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3929 - accuracy: 0.8170 - val_loss: 0.5975 - val_accuracy: 0.6903\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3986 - accuracy: 0.8199 - val_loss: 0.5210 - val_accuracy: 0.7502\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3946 - accuracy: 0.8251 - val_loss: 0.5135 - val_accuracy: 0.7573\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8107 - val_loss: 0.5734 - val_accuracy: 0.7075\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4047 - accuracy: 0.8119 - val_loss: 0.5199 - val_accuracy: 0.7483\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8151 - val_loss: 0.7355 - val_accuracy: 0.5962\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4184 - accuracy: 0.8010 - val_loss: 0.5059 - val_accuracy: 0.7553\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4005 - accuracy: 0.8134 - val_loss: 0.5448 - val_accuracy: 0.7563\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4161 - accuracy: 0.7984 - val_loss: 0.6824 - val_accuracy: 0.6351\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4047 - accuracy: 0.8132 - val_loss: 0.5060 - val_accuracy: 0.7573\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4037 - accuracy: 0.8133 - val_loss: 0.5067 - val_accuracy: 0.7592\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4037 - accuracy: 0.8158 - val_loss: 0.5048 - val_accuracy: 0.7601\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4026 - accuracy: 0.8161 - val_loss: 0.5158 - val_accuracy: 0.7563\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4195 - accuracy: 0.7973 - val_loss: 0.5221 - val_accuracy: 0.7544\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4290 - accuracy: 0.7911 - val_loss: 0.5159 - val_accuracy: 0.7525\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.8149 - val_loss: 0.5353 - val_accuracy: 0.7566\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4253 - accuracy: 0.7917 - val_loss: 0.5727 - val_accuracy: 0.7480\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4222 - accuracy: 0.7996 - val_loss: 0.6330 - val_accuracy: 0.6644\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4064 - accuracy: 0.8113 - val_loss: 0.5956 - val_accuracy: 0.6880\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4114 - accuracy: 0.8099 - val_loss: 0.5034 - val_accuracy: 0.7601\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4001 - accuracy: 0.8126 - val_loss: 0.5373 - val_accuracy: 0.7311\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3898 - accuracy: 0.8217 - val_loss: 0.6778 - val_accuracy: 0.6274\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4045 - accuracy: 0.8115 - val_loss: 0.5062 - val_accuracy: 0.7592\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4090 - accuracy: 0.8099 - val_loss: 0.5100 - val_accuracy: 0.7566\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3974 - accuracy: 0.8182 - val_loss: 0.5327 - val_accuracy: 0.7372\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4049 - accuracy: 0.8134 - val_loss: 0.5126 - val_accuracy: 0.7528\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4014 - accuracy: 0.8170 - val_loss: 0.5076 - val_accuracy: 0.7547\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.8216 - val_loss: 0.6120 - val_accuracy: 0.6797\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4068 - accuracy: 0.8109 - val_loss: 0.5446 - val_accuracy: 0.7282\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4101 - accuracy: 0.8118 - val_loss: 0.7985 - val_accuracy: 0.5620\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4227 - accuracy: 0.7972 - val_loss: 0.5108 - val_accuracy: 0.7547\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3983 - accuracy: 0.8153 - val_loss: 0.5111 - val_accuracy: 0.7550\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4019 - accuracy: 0.8144 - val_loss: 0.5085 - val_accuracy: 0.7544\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3953 - accuracy: 0.8183 - val_loss: 0.5801 - val_accuracy: 0.7021\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4098 - accuracy: 0.8114 - val_loss: 0.5142 - val_accuracy: 0.7547\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8124 - val_loss: 0.5104 - val_accuracy: 0.7550\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4064 - accuracy: 0.8145 - val_loss: 0.5033 - val_accuracy: 0.7598\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3976 - accuracy: 0.8144 - val_loss: 0.7338 - val_accuracy: 0.5943\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4052 - accuracy: 0.8102 - val_loss: 0.5036 - val_accuracy: 0.7592\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4127 - accuracy: 0.8032 - val_loss: 0.5197 - val_accuracy: 0.7477\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4023 - accuracy: 0.8143 - val_loss: 0.5191 - val_accuracy: 0.7515\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3968 - accuracy: 0.8189 - val_loss: 0.5159 - val_accuracy: 0.7518\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8106 - val_loss: 0.5158 - val_accuracy: 0.7544\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4024 - accuracy: 0.8171 - val_loss: 0.5954 - val_accuracy: 0.6893\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3954 - accuracy: 0.8202 - val_loss: 0.5606 - val_accuracy: 0.7190\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4034 - accuracy: 0.8134 - val_loss: 0.5566 - val_accuracy: 0.7193\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3976 - accuracy: 0.8185 - val_loss: 0.5464 - val_accuracy: 0.7247\n",
      "Epoch 448/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4038 - accuracy: 0.8143 - val_loss: 0.6265 - val_accuracy: 0.6648\n",
      "Epoch 449/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3985 - accuracy: 0.8162 - val_loss: 0.5016 - val_accuracy: 0.7611\n",
      "Epoch 450/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4029 - accuracy: 0.8126 - val_loss: 0.5648 - val_accuracy: 0.7107\n",
      "Epoch 451/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4083 - accuracy: 0.8077 - val_loss: 0.7224 - val_accuracy: 0.6038\n",
      "Epoch 452/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4200 - accuracy: 0.8034 - val_loss: 0.5154 - val_accuracy: 0.7585\n",
      "Epoch 453/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4081 - accuracy: 0.8109 - val_loss: 0.5564 - val_accuracy: 0.7493\n",
      "Epoch 454/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4215 - accuracy: 0.7976 - val_loss: 0.5859 - val_accuracy: 0.6976\n",
      "Epoch 455/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4004 - accuracy: 0.8161 - val_loss: 0.6513 - val_accuracy: 0.6507\n",
      "Epoch 456/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3992 - accuracy: 0.8188 - val_loss: 0.5736 - val_accuracy: 0.7049\n",
      "Epoch 457/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.8130 - val_loss: 0.5051 - val_accuracy: 0.7569\n",
      "Epoch 458/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4065 - accuracy: 0.8102 - val_loss: 0.5394 - val_accuracy: 0.7557\n",
      "Epoch 459/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4085 - accuracy: 0.8094 - val_loss: 0.9402 - val_accuracy: 0.5062\n",
      "Epoch 460/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4473 - accuracy: 0.7824 - val_loss: 0.6764 - val_accuracy: 0.6373\n",
      "Epoch 461/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8098 - val_loss: 0.5117 - val_accuracy: 0.7560\n",
      "Epoch 462/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.8065 - val_loss: 0.5114 - val_accuracy: 0.7646\n",
      "Epoch 463/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4196 - accuracy: 0.7992 - val_loss: 0.5053 - val_accuracy: 0.7585\n",
      "Epoch 464/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3998 - accuracy: 0.8134 - val_loss: 0.5185 - val_accuracy: 0.7518\n",
      "Epoch 465/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.8170 - val_loss: 0.5068 - val_accuracy: 0.7620\n",
      "Epoch 466/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4004 - accuracy: 0.8155 - val_loss: 0.5307 - val_accuracy: 0.7553\n",
      "Epoch 467/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4122 - accuracy: 0.8065 - val_loss: 0.5688 - val_accuracy: 0.7483\n",
      "Epoch 468/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4155 - accuracy: 0.8045 - val_loss: 0.5219 - val_accuracy: 0.7439\n",
      "Epoch 469/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3988 - accuracy: 0.8160 - val_loss: 0.5714 - val_accuracy: 0.7059\n",
      "Epoch 470/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3977 - accuracy: 0.8181 - val_loss: 0.5171 - val_accuracy: 0.7509\n",
      "Epoch 471/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.3969 - accuracy: 0.8200 - val_loss: 0.6776 - val_accuracy: 0.6360\n",
      "Epoch 472/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4000 - accuracy: 0.8167 - val_loss: 0.5216 - val_accuracy: 0.7455\n",
      "Epoch 473/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4084 - accuracy: 0.8110 - val_loss: 0.5100 - val_accuracy: 0.7550\n",
      "Epoch 474/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4005 - accuracy: 0.8169 - val_loss: 0.5855 - val_accuracy: 0.6979\n",
      "Epoch 475/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.8180 - val_loss: 0.6695 - val_accuracy: 0.6380\n",
      "Epoch 476/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3997 - accuracy: 0.8134 - val_loss: 0.6084 - val_accuracy: 0.6788\n",
      "Epoch 477/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.8184 - val_loss: 0.6724 - val_accuracy: 0.6373\n",
      "Epoch 478/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4113 - accuracy: 0.8072 - val_loss: 0.5957 - val_accuracy: 0.6900\n",
      "Epoch 479/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4135 - accuracy: 0.8027 - val_loss: 0.5812 - val_accuracy: 0.6979\n",
      "Epoch 480/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3988 - accuracy: 0.8168 - val_loss: 0.5693 - val_accuracy: 0.7110\n",
      "Epoch 481/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4033 - accuracy: 0.8148 - val_loss: 0.6336 - val_accuracy: 0.6632\n",
      "Epoch 482/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4051 - accuracy: 0.8066 - val_loss: 0.5155 - val_accuracy: 0.7528\n",
      "Epoch 483/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3969 - accuracy: 0.8187 - val_loss: 0.5531 - val_accuracy: 0.7215\n",
      "Epoch 484/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8113 - val_loss: 0.5087 - val_accuracy: 0.7579\n",
      "Epoch 485/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4028 - accuracy: 0.8165 - val_loss: 0.7166 - val_accuracy: 0.6073\n",
      "Epoch 486/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4291 - accuracy: 0.7917 - val_loss: 0.5051 - val_accuracy: 0.7566\n",
      "Epoch 487/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3948 - accuracy: 0.8170 - val_loss: 0.5077 - val_accuracy: 0.7601\n",
      "Epoch 488/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3978 - accuracy: 0.8182 - val_loss: 0.5029 - val_accuracy: 0.7582\n",
      "Epoch 489/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.8122 - val_loss: 0.5005 - val_accuracy: 0.7646\n",
      "Epoch 490/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3995 - accuracy: 0.8134 - val_loss: 0.5067 - val_accuracy: 0.7569\n",
      "Epoch 491/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4120 - accuracy: 0.8060 - val_loss: 0.7632 - val_accuracy: 0.7324\n",
      "Epoch 492/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4481 - accuracy: 0.7857 - val_loss: 0.5128 - val_accuracy: 0.7627\n",
      "Epoch 493/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4151 - accuracy: 0.8028 - val_loss: 0.5322 - val_accuracy: 0.7359\n",
      "Epoch 494/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4078 - accuracy: 0.8067 - val_loss: 0.5325 - val_accuracy: 0.7547\n",
      "Epoch 495/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4142 - accuracy: 0.8074 - val_loss: 0.5187 - val_accuracy: 0.7496\n",
      "Epoch 496/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4007 - accuracy: 0.8126 - val_loss: 0.5150 - val_accuracy: 0.7614\n",
      "Epoch 497/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4063 - accuracy: 0.8082 - val_loss: 0.5759 - val_accuracy: 0.7033\n",
      "Epoch 498/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4232 - accuracy: 0.8030 - val_loss: 0.5989 - val_accuracy: 0.6877\n",
      "Epoch 499/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8086 - val_loss: 0.7169 - val_accuracy: 0.6108\n",
      "Epoch 500/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4150 - accuracy: 0.8020 - val_loss: 0.6084 - val_accuracy: 0.6823\n",
      "Epoch 501/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4054 - accuracy: 0.8119 - val_loss: 0.6068 - val_accuracy: 0.6810\n",
      "Epoch 502/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4154 - accuracy: 0.8000 - val_loss: 0.6342 - val_accuracy: 0.6606\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4095 - accuracy: 0.8044 - val_loss: 0.5055 - val_accuracy: 0.7592\n",
      "Epoch 504/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3950 - accuracy: 0.8180 - val_loss: 0.5493 - val_accuracy: 0.7512\n",
      "Epoch 505/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4261 - accuracy: 0.7936 - val_loss: 0.5817 - val_accuracy: 0.7011\n",
      "Epoch 506/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4032 - accuracy: 0.8158 - val_loss: 0.5295 - val_accuracy: 0.7404\n",
      "Epoch 507/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8159 - val_loss: 0.5068 - val_accuracy: 0.7582\n",
      "Epoch 508/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4025 - accuracy: 0.8130 - val_loss: 0.5945 - val_accuracy: 0.7474\n",
      "Epoch 509/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4276 - accuracy: 0.7929 - val_loss: 0.5102 - val_accuracy: 0.7624\n",
      "Epoch 510/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4243 - accuracy: 0.7956 - val_loss: 0.6122 - val_accuracy: 0.7416\n",
      "Epoch 511/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4258 - accuracy: 0.7964 - val_loss: 0.5675 - val_accuracy: 0.7486\n",
      "Epoch 512/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8150 - val_loss: 0.8239 - val_accuracy: 0.5541\n",
      "Epoch 513/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4470 - accuracy: 0.7854 - val_loss: 0.5816 - val_accuracy: 0.7005\n",
      "Epoch 514/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4031 - accuracy: 0.8099 - val_loss: 0.5097 - val_accuracy: 0.7569\n",
      "Epoch 515/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4086 - accuracy: 0.8064 - val_loss: 0.5057 - val_accuracy: 0.7611\n",
      "Epoch 516/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4005 - accuracy: 0.8155 - val_loss: 0.5833 - val_accuracy: 0.6979\n",
      "Epoch 517/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4190 - accuracy: 0.8037 - val_loss: 0.5094 - val_accuracy: 0.7608\n",
      "Epoch 518/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4079 - accuracy: 0.8118 - val_loss: 0.5169 - val_accuracy: 0.7502\n",
      "Epoch 519/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4080 - accuracy: 0.8132 - val_loss: 0.5556 - val_accuracy: 0.7183\n",
      "Epoch 520/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4006 - accuracy: 0.8174 - val_loss: 0.5315 - val_accuracy: 0.7569\n",
      "Epoch 521/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4180 - accuracy: 0.8030 - val_loss: 0.6629 - val_accuracy: 0.6418\n",
      "Epoch 522/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4069 - accuracy: 0.8100 - val_loss: 0.5106 - val_accuracy: 0.7569\n",
      "Epoch 523/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4038 - accuracy: 0.8138 - val_loss: 0.5073 - val_accuracy: 0.7592\n",
      "Epoch 524/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4216 - accuracy: 0.8008 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 525/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3945 - accuracy: 0.8167 - val_loss: 0.5722 - val_accuracy: 0.7046\n",
      "Epoch 526/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4019 - accuracy: 0.8152 - val_loss: 0.5234 - val_accuracy: 0.7458\n",
      "Epoch 527/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4020 - accuracy: 0.8174 - val_loss: 0.5414 - val_accuracy: 0.7295\n",
      "Epoch 528/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4048 - accuracy: 0.8125 - val_loss: 0.5800 - val_accuracy: 0.7014\n",
      "Epoch 529/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4108 - accuracy: 0.8121 - val_loss: 0.5278 - val_accuracy: 0.7563\n",
      "Epoch 530/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4240 - accuracy: 0.7945 - val_loss: 0.5341 - val_accuracy: 0.7340\n",
      "Epoch 531/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3943 - accuracy: 0.8181 - val_loss: 0.5662 - val_accuracy: 0.7145\n",
      "Epoch 532/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4032 - accuracy: 0.8146 - val_loss: 0.5063 - val_accuracy: 0.7563\n",
      "Epoch 533/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3925 - accuracy: 0.8220 - val_loss: 0.5154 - val_accuracy: 0.7525\n",
      "Epoch 534/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4044 - accuracy: 0.8162 - val_loss: 0.5109 - val_accuracy: 0.7531\n",
      "Epoch 535/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4003 - accuracy: 0.8196 - val_loss: 0.5042 - val_accuracy: 0.7582\n",
      "Epoch 536/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4050 - accuracy: 0.8104 - val_loss: 0.6379 - val_accuracy: 0.6596\n",
      "Epoch 537/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4078 - accuracy: 0.8072 - val_loss: 0.6512 - val_accuracy: 0.6536\n",
      "Epoch 538/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4099 - accuracy: 0.8044 - val_loss: 0.5519 - val_accuracy: 0.7234\n",
      "Epoch 539/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4119 - accuracy: 0.8090 - val_loss: 0.5007 - val_accuracy: 0.7624\n",
      "Epoch 540/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4020 - accuracy: 0.8084 - val_loss: 0.6711 - val_accuracy: 0.7404\n",
      "Epoch 541/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4653 - accuracy: 0.7728 - val_loss: 0.5149 - val_accuracy: 0.7601\n",
      "Epoch 542/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4019 - accuracy: 0.8143 - val_loss: 0.5140 - val_accuracy: 0.7579\n",
      "Epoch 543/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3987 - accuracy: 0.8157 - val_loss: 0.5073 - val_accuracy: 0.7595\n",
      "Epoch 544/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4126 - accuracy: 0.8057 - val_loss: 0.5876 - val_accuracy: 0.7458\n",
      "Epoch 545/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4456 - accuracy: 0.7798 - val_loss: 0.5530 - val_accuracy: 0.7531\n",
      "Epoch 546/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4025 - accuracy: 0.8114 - val_loss: 0.5354 - val_accuracy: 0.7537\n",
      "Epoch 547/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4136 - accuracy: 0.8047 - val_loss: 0.5102 - val_accuracy: 0.7560\n",
      "Epoch 548/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4015 - accuracy: 0.8200 - val_loss: 0.5078 - val_accuracy: 0.7560\n",
      "Epoch 549/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4002 - accuracy: 0.8168 - val_loss: 0.5421 - val_accuracy: 0.7547\n",
      "Epoch 550/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4300 - accuracy: 0.7839 - val_loss: 0.5549 - val_accuracy: 0.7196\n",
      "Epoch 551/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3963 - accuracy: 0.8176 - val_loss: 0.5347 - val_accuracy: 0.7314\n",
      "Epoch 552/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3974 - accuracy: 0.8179 - val_loss: 0.5091 - val_accuracy: 0.7614\n",
      "Epoch 553/1000\n",
      "10/10 [==============================] - 0s 12ms/step - loss: 0.4067 - accuracy: 0.8072 - val_loss: 0.5275 - val_accuracy: 0.7579\n",
      "Epoch 554/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4029 - accuracy: 0.8116 - val_loss: 0.5744 - val_accuracy: 0.7490\n",
      "Epoch 555/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3990 - accuracy: 0.8130 - val_loss: 0.7170 - val_accuracy: 0.6054\n",
      "Epoch 556/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4283 - accuracy: 0.7921 - val_loss: 0.6993 - val_accuracy: 0.6265\n",
      "Epoch 557/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4404 - accuracy: 0.7871 - val_loss: 0.6436 - val_accuracy: 0.6568\n",
      "Epoch 558/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4033 - accuracy: 0.8138 - val_loss: 0.6258 - val_accuracy: 0.6651\n",
      "Epoch 559/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4048 - accuracy: 0.8152 - val_loss: 0.5495 - val_accuracy: 0.7247\n",
      "Epoch 560/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4012 - accuracy: 0.8141 - val_loss: 0.6703 - val_accuracy: 0.7388\n",
      "Epoch 561/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4306 - accuracy: 0.7902 - val_loss: 0.5102 - val_accuracy: 0.7541\n",
      "Epoch 562/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4070 - accuracy: 0.8088 - val_loss: 0.6209 - val_accuracy: 0.7442\n",
      "Epoch 563/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4130 - accuracy: 0.8030 - val_loss: 0.5096 - val_accuracy: 0.7569\n",
      "Epoch 564/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4032 - accuracy: 0.8158 - val_loss: 0.5312 - val_accuracy: 0.7557\n",
      "Epoch 565/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3970 - accuracy: 0.8162 - val_loss: 0.5156 - val_accuracy: 0.7512\n",
      "Epoch 566/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4041 - accuracy: 0.8126 - val_loss: 0.5040 - val_accuracy: 0.7544\n",
      "Epoch 567/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.3992 - accuracy: 0.8196 - val_loss: 0.5778 - val_accuracy: 0.7470\n",
      "Epoch 00567: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.01, verbose = 1)\n",
    "model1_reg = model_one_reg()\n",
    "history = model1_reg.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7470\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.577822744846344, 0.7470494508743286]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_reg.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 32ms/step - loss: 4.1705 - accuracy: 0.5962 - val_loss: 3.3674 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 3.1630 - accuracy: 0.7034 - val_loss: 2.5525 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2.3758 - accuracy: 0.7063 - val_loss: 1.8982 - val_accuracy: 0.7110\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.7411 - accuracy: 0.7156 - val_loss: 1.3870 - val_accuracy: 0.7132\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.2604 - accuracy: 0.7104 - val_loss: 1.0155 - val_accuracy: 0.7120\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9208 - accuracy: 0.7132 - val_loss: 0.7913 - val_accuracy: 0.7107\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7311 - accuracy: 0.7113 - val_loss: 0.7013 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6571 - accuracy: 0.7123 - val_loss: 0.6757 - val_accuracy: 0.7110\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6463 - accuracy: 0.7149 - val_loss: 0.6723 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6420 - accuracy: 0.7123 - val_loss: 0.6702 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6405 - accuracy: 0.7101 - val_loss: 0.6654 - val_accuracy: 0.7088\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6341 - accuracy: 0.7127 - val_loss: 0.6647 - val_accuracy: 0.7116\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6340 - accuracy: 0.7103 - val_loss: 0.6622 - val_accuracy: 0.7088\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6322 - accuracy: 0.7086 - val_loss: 0.6625 - val_accuracy: 0.7104\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6213 - accuracy: 0.7192 - val_loss: 0.6621 - val_accuracy: 0.7110\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6251 - accuracy: 0.7089 - val_loss: 0.6639 - val_accuracy: 0.7107\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6230 - accuracy: 0.7107 - val_loss: 0.6667 - val_accuracy: 0.7097\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6144 - accuracy: 0.7163 - val_loss: 0.6590 - val_accuracy: 0.7120\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6164 - accuracy: 0.7122 - val_loss: 0.6617 - val_accuracy: 0.7120\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6115 - accuracy: 0.7148 - val_loss: 0.6605 - val_accuracy: 0.7126\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6070 - accuracy: 0.7167 - val_loss: 0.6596 - val_accuracy: 0.7126\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6070 - accuracy: 0.7155 - val_loss: 0.6585 - val_accuracy: 0.7129\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6055 - accuracy: 0.7176 - val_loss: 0.6665 - val_accuracy: 0.7132\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6003 - accuracy: 0.7211 - val_loss: 0.6557 - val_accuracy: 0.7142\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5997 - accuracy: 0.7208 - val_loss: 0.6657 - val_accuracy: 0.7136\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5958 - accuracy: 0.7232 - val_loss: 0.6743 - val_accuracy: 0.7139\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5949 - accuracy: 0.7234 - val_loss: 0.6666 - val_accuracy: 0.7136\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5904 - accuracy: 0.7296 - val_loss: 0.6582 - val_accuracy: 0.7142\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5919 - accuracy: 0.7226 - val_loss: 0.6645 - val_accuracy: 0.7142\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5846 - accuracy: 0.7297 - val_loss: 0.6610 - val_accuracy: 0.7145\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5844 - accuracy: 0.7315 - val_loss: 0.6574 - val_accuracy: 0.7164\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5796 - accuracy: 0.7423 - val_loss: 0.6856 - val_accuracy: 0.7136\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5875 - accuracy: 0.7269 - val_loss: 0.6618 - val_accuracy: 0.7152\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5760 - accuracy: 0.7430 - val_loss: 0.6727 - val_accuracy: 0.7148\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5844 - accuracy: 0.7360 - val_loss: 0.6612 - val_accuracy: 0.7158\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5856 - accuracy: 0.7346 - val_loss: 0.6608 - val_accuracy: 0.7174\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5744 - accuracy: 0.7465 - val_loss: 0.6722 - val_accuracy: 0.7148\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5745 - accuracy: 0.7413 - val_loss: 0.6772 - val_accuracy: 0.7152\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5687 - accuracy: 0.7505 - val_loss: 0.6612 - val_accuracy: 0.7180\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5676 - accuracy: 0.7525 - val_loss: 0.6744 - val_accuracy: 0.7158\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5648 - accuracy: 0.7538 - val_loss: 0.6780 - val_accuracy: 0.7155\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5647 - accuracy: 0.7503 - val_loss: 0.6741 - val_accuracy: 0.7167\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5607 - accuracy: 0.7524 - val_loss: 0.6541 - val_accuracy: 0.7196\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5667 - accuracy: 0.7539 - val_loss: 0.6579 - val_accuracy: 0.7199\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5595 - accuracy: 0.7586 - val_loss: 0.6535 - val_accuracy: 0.7219\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5632 - accuracy: 0.7544 - val_loss: 0.6923 - val_accuracy: 0.7158\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5613 - accuracy: 0.7525 - val_loss: 0.6729 - val_accuracy: 0.7187\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5569 - accuracy: 0.7598 - val_loss: 0.6768 - val_accuracy: 0.7183\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5555 - accuracy: 0.7593 - val_loss: 0.6875 - val_accuracy: 0.7180\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5627 - accuracy: 0.7536 - val_loss: 0.6538 - val_accuracy: 0.7234\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5573 - accuracy: 0.7600 - val_loss: 0.6619 - val_accuracy: 0.7219\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5547 - accuracy: 0.7577 - val_loss: 0.6541 - val_accuracy: 0.7234\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5594 - accuracy: 0.7543 - val_loss: 0.6850 - val_accuracy: 0.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5517 - accuracy: 0.7665 - val_loss: 0.6893 - val_accuracy: 0.7183\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5515 - accuracy: 0.7648 - val_loss: 0.6518 - val_accuracy: 0.7254\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5533 - accuracy: 0.7677 - val_loss: 0.6505 - val_accuracy: 0.7266\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5520 - accuracy: 0.7682 - val_loss: 0.6649 - val_accuracy: 0.7234\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5522 - accuracy: 0.7624 - val_loss: 0.6756 - val_accuracy: 0.7215\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5478 - accuracy: 0.7726 - val_loss: 0.6947 - val_accuracy: 0.7193\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5487 - accuracy: 0.7667 - val_loss: 0.6818 - val_accuracy: 0.7215\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5455 - accuracy: 0.7690 - val_loss: 0.6674 - val_accuracy: 0.7257\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5498 - accuracy: 0.7654 - val_loss: 0.6659 - val_accuracy: 0.7257\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5469 - accuracy: 0.7690 - val_loss: 0.7104 - val_accuracy: 0.7187\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5373 - accuracy: 0.7751 - val_loss: 0.7054 - val_accuracy: 0.7193\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5413 - accuracy: 0.7730 - val_loss: 0.6748 - val_accuracy: 0.7263\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5422 - accuracy: 0.7747 - val_loss: 0.6739 - val_accuracy: 0.7270\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5423 - accuracy: 0.7737 - val_loss: 0.6997 - val_accuracy: 0.7212\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5426 - accuracy: 0.7726 - val_loss: 0.6823 - val_accuracy: 0.7257\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5450 - accuracy: 0.7712 - val_loss: 0.6868 - val_accuracy: 0.7238\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5375 - accuracy: 0.7793 - val_loss: 0.6616 - val_accuracy: 0.7295\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5401 - accuracy: 0.7799 - val_loss: 0.7154 - val_accuracy: 0.7203\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5406 - accuracy: 0.7752 - val_loss: 0.6898 - val_accuracy: 0.7260\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5351 - accuracy: 0.7849 - val_loss: 0.6903 - val_accuracy: 0.7260\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5372 - accuracy: 0.7779 - val_loss: 0.7275 - val_accuracy: 0.7203\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5345 - accuracy: 0.7786 - val_loss: 0.6845 - val_accuracy: 0.7276\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5314 - accuracy: 0.7831 - val_loss: 0.6692 - val_accuracy: 0.7298\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5373 - accuracy: 0.7803 - val_loss: 0.7014 - val_accuracy: 0.7260\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5289 - accuracy: 0.7857 - val_loss: 0.6594 - val_accuracy: 0.7340\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5329 - accuracy: 0.7811 - val_loss: 0.7340 - val_accuracy: 0.7209\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5317 - accuracy: 0.7810 - val_loss: 0.7654 - val_accuracy: 0.7190\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5416 - accuracy: 0.7761 - val_loss: 0.6671 - val_accuracy: 0.7333\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5297 - accuracy: 0.7894 - val_loss: 0.7012 - val_accuracy: 0.7273\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5325 - accuracy: 0.7893 - val_loss: 0.7202 - val_accuracy: 0.7254\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5285 - accuracy: 0.7897 - val_loss: 0.7356 - val_accuracy: 0.7234\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5280 - accuracy: 0.7896 - val_loss: 0.6551 - val_accuracy: 0.7362\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5316 - accuracy: 0.7888 - val_loss: 0.6789 - val_accuracy: 0.7330\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5267 - accuracy: 0.7915 - val_loss: 0.7589 - val_accuracy: 0.7206\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5253 - accuracy: 0.7917 - val_loss: 0.7535 - val_accuracy: 0.7215\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5276 - accuracy: 0.7890 - val_loss: 0.6603 - val_accuracy: 0.7356\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5304 - accuracy: 0.7874 - val_loss: 0.7470 - val_accuracy: 0.7238\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5195 - accuracy: 0.7992 - val_loss: 0.7540 - val_accuracy: 0.7225\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5251 - accuracy: 0.7933 - val_loss: 0.7236 - val_accuracy: 0.7273\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5286 - accuracy: 0.7903 - val_loss: 0.6929 - val_accuracy: 0.7314\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5265 - accuracy: 0.7953 - val_loss: 0.6890 - val_accuracy: 0.7330\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5230 - accuracy: 0.7959 - val_loss: 0.6934 - val_accuracy: 0.7324\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5249 - accuracy: 0.7975 - val_loss: 0.7064 - val_accuracy: 0.7317\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5278 - accuracy: 0.7940 - val_loss: 0.7957 - val_accuracy: 0.7193\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5235 - accuracy: 0.7916 - val_loss: 0.7254 - val_accuracy: 0.7289\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5246 - accuracy: 0.7943 - val_loss: 0.7385 - val_accuracy: 0.7273\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5218 - accuracy: 0.7988 - val_loss: 0.6868 - val_accuracy: 0.7333\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5186 - accuracy: 0.8008 - val_loss: 0.7231 - val_accuracy: 0.7305\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5189 - accuracy: 0.7991 - val_loss: 0.8436 - val_accuracy: 0.7174\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5246 - accuracy: 0.7965 - val_loss: 0.7299 - val_accuracy: 0.7298\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5185 - accuracy: 0.8045 - val_loss: 0.7532 - val_accuracy: 0.7266\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5170 - accuracy: 0.7998 - val_loss: 0.7184 - val_accuracy: 0.7317\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5244 - accuracy: 0.7935 - val_loss: 0.7351 - val_accuracy: 0.7305\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5173 - accuracy: 0.8019 - val_loss: 0.7042 - val_accuracy: 0.7327\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5209 - accuracy: 0.7993 - val_loss: 0.7663 - val_accuracy: 0.7263\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5216 - accuracy: 0.7959 - val_loss: 0.6888 - val_accuracy: 0.7346\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5191 - accuracy: 0.7974 - val_loss: 0.7457 - val_accuracy: 0.7289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5213 - accuracy: 0.7977 - val_loss: 0.7395 - val_accuracy: 0.7301\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5191 - accuracy: 0.8043 - val_loss: 0.8139 - val_accuracy: 0.7206\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5186 - accuracy: 0.7976 - val_loss: 0.7891 - val_accuracy: 0.7238\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5161 - accuracy: 0.7989 - val_loss: 0.7580 - val_accuracy: 0.7279\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5172 - accuracy: 0.8033 - val_loss: 0.7003 - val_accuracy: 0.7343\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5206 - accuracy: 0.8039 - val_loss: 0.7222 - val_accuracy: 0.7327\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5165 - accuracy: 0.8052 - val_loss: 0.7572 - val_accuracy: 0.7276\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5247 - accuracy: 0.7959 - val_loss: 0.7456 - val_accuracy: 0.7298\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5111 - accuracy: 0.8086 - val_loss: 0.7373 - val_accuracy: 0.7324\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5169 - accuracy: 0.8010 - val_loss: 0.7415 - val_accuracy: 0.7317\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5154 - accuracy: 0.8036 - val_loss: 0.7067 - val_accuracy: 0.7337\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.8080 - val_loss: 0.7489 - val_accuracy: 0.7301\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5254 - accuracy: 0.7972 - val_loss: 0.8254 - val_accuracy: 0.7206\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5172 - accuracy: 0.8011 - val_loss: 0.7263 - val_accuracy: 0.7324\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5111 - accuracy: 0.8075 - val_loss: 0.6943 - val_accuracy: 0.7349\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5119 - accuracy: 0.8100 - val_loss: 0.7665 - val_accuracy: 0.7279\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5132 - accuracy: 0.7984 - val_loss: 0.6827 - val_accuracy: 0.7362\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.8021 - val_loss: 0.7512 - val_accuracy: 0.7314\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5137 - accuracy: 0.8015 - val_loss: 0.7174 - val_accuracy: 0.7333\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5123 - accuracy: 0.8098 - val_loss: 0.6679 - val_accuracy: 0.7372\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5185 - accuracy: 0.8006 - val_loss: 0.7501 - val_accuracy: 0.7317\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5164 - accuracy: 0.7981 - val_loss: 0.7061 - val_accuracy: 0.7343\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5165 - accuracy: 0.8003 - val_loss: 0.6497 - val_accuracy: 0.7381\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.8031 - val_loss: 0.7250 - val_accuracy: 0.7337\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5082 - accuracy: 0.8082 - val_loss: 0.7188 - val_accuracy: 0.7333\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.8052 - val_loss: 0.6536 - val_accuracy: 0.7388\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 0.8029 - val_loss: 0.7782 - val_accuracy: 0.7270\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.8022 - val_loss: 0.6925 - val_accuracy: 0.7359\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.8051 - val_loss: 0.7792 - val_accuracy: 0.7273\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5096 - accuracy: 0.8074 - val_loss: 0.7703 - val_accuracy: 0.7285\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5131 - accuracy: 0.8006 - val_loss: 0.7911 - val_accuracy: 0.7263\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.7971 - val_loss: 0.7774 - val_accuracy: 0.7276\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5156 - accuracy: 0.8003 - val_loss: 0.8364 - val_accuracy: 0.7222\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5135 - accuracy: 0.7979 - val_loss: 0.7192 - val_accuracy: 0.7330\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5085 - accuracy: 0.8044 - val_loss: 0.7241 - val_accuracy: 0.7330\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5075 - accuracy: 0.8082 - val_loss: 0.7702 - val_accuracy: 0.7295\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5073 - accuracy: 0.8065 - val_loss: 0.6409 - val_accuracy: 0.7419\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5164 - accuracy: 0.7943 - val_loss: 0.7044 - val_accuracy: 0.7352\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5045 - accuracy: 0.8084 - val_loss: 0.6801 - val_accuracy: 0.7362\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5113 - accuracy: 0.8028 - val_loss: 0.7001 - val_accuracy: 0.7362\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.8047 - val_loss: 0.8051 - val_accuracy: 0.7257\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5084 - accuracy: 0.8020 - val_loss: 0.6534 - val_accuracy: 0.7388\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.7964 - val_loss: 0.7499 - val_accuracy: 0.7324\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5120 - accuracy: 0.8045 - val_loss: 0.7480 - val_accuracy: 0.7324\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5092 - accuracy: 0.8062 - val_loss: 0.7360 - val_accuracy: 0.7333\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5067 - accuracy: 0.8037 - val_loss: 0.6691 - val_accuracy: 0.7381\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5099 - accuracy: 0.8022 - val_loss: 0.8229 - val_accuracy: 0.7254\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.8012 - val_loss: 0.7379 - val_accuracy: 0.7333\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5097 - accuracy: 0.8047 - val_loss: 0.7835 - val_accuracy: 0.7301\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8036 - val_loss: 0.7260 - val_accuracy: 0.7346\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5108 - accuracy: 0.8029 - val_loss: 0.8157 - val_accuracy: 0.7257\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5062 - accuracy: 0.8049 - val_loss: 0.7969 - val_accuracy: 0.7276\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5028 - accuracy: 0.8074 - val_loss: 0.7184 - val_accuracy: 0.7349\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5143 - accuracy: 0.7997 - val_loss: 0.6377 - val_accuracy: 0.7426\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5104 - accuracy: 0.8017 - val_loss: 0.7303 - val_accuracy: 0.7340\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5115 - accuracy: 0.8016 - val_loss: 0.6894 - val_accuracy: 0.7368\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5091 - accuracy: 0.8043 - val_loss: 0.7443 - val_accuracy: 0.7333\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5060 - accuracy: 0.8032 - val_loss: 0.7851 - val_accuracy: 0.7295\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5099 - accuracy: 0.8013 - val_loss: 0.7356 - val_accuracy: 0.7340\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.8055 - val_loss: 0.7198 - val_accuracy: 0.7346\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5076 - accuracy: 0.8028 - val_loss: 0.6665 - val_accuracy: 0.7388\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5066 - accuracy: 0.8053 - val_loss: 0.8234 - val_accuracy: 0.7254\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5098 - accuracy: 0.7981 - val_loss: 0.7804 - val_accuracy: 0.7311\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5088 - accuracy: 0.8063 - val_loss: 0.7719 - val_accuracy: 0.7321\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5071 - accuracy: 0.8036 - val_loss: 0.7004 - val_accuracy: 0.7359\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5089 - accuracy: 0.7987 - val_loss: 0.6595 - val_accuracy: 0.7378\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5115 - accuracy: 0.8004 - val_loss: 0.7550 - val_accuracy: 0.7333\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5059 - accuracy: 0.8060 - val_loss: 0.6767 - val_accuracy: 0.7394\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4999 - accuracy: 0.8091 - val_loss: 0.7084 - val_accuracy: 0.7356\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.8084 - val_loss: 0.7864 - val_accuracy: 0.7305\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5035 - accuracy: 0.8077 - val_loss: 0.6989 - val_accuracy: 0.7365\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5091 - accuracy: 0.8049 - val_loss: 0.7250 - val_accuracy: 0.7349\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5062 - accuracy: 0.8042 - val_loss: 0.7685 - val_accuracy: 0.7321\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5033 - accuracy: 0.8069 - val_loss: 0.8107 - val_accuracy: 0.7263\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5098 - accuracy: 0.8009 - val_loss: 0.7248 - val_accuracy: 0.7349\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.8050 - val_loss: 0.8948 - val_accuracy: 0.7196\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5146 - accuracy: 0.7924 - val_loss: 0.8343 - val_accuracy: 0.7250\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5073 - accuracy: 0.8064 - val_loss: 0.7460 - val_accuracy: 0.7337\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5018 - accuracy: 0.8071 - val_loss: 0.8439 - val_accuracy: 0.7241\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5036 - accuracy: 0.8017 - val_loss: 0.7227 - val_accuracy: 0.7349\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5010 - accuracy: 0.8064 - val_loss: 0.6795 - val_accuracy: 0.7375\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5085 - accuracy: 0.8014 - val_loss: 0.8031 - val_accuracy: 0.7279\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5076 - accuracy: 0.7969 - val_loss: 0.7941 - val_accuracy: 0.7301\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5047 - accuracy: 0.8045 - val_loss: 0.8313 - val_accuracy: 0.7257\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5009 - accuracy: 0.8059 - val_loss: 0.6497 - val_accuracy: 0.7410\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5005 - accuracy: 0.8069 - val_loss: 0.6539 - val_accuracy: 0.7381\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5031 - accuracy: 0.8063 - val_loss: 0.8086 - val_accuracy: 0.7279\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5100 - accuracy: 0.7964 - val_loss: 0.6797 - val_accuracy: 0.7378\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4988 - accuracy: 0.8092 - val_loss: 0.6938 - val_accuracy: 0.7378\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5075 - accuracy: 0.7975 - val_loss: 0.6450 - val_accuracy: 0.7423\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5075 - accuracy: 0.8030 - val_loss: 0.7819 - val_accuracy: 0.7321\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5027 - accuracy: 0.8121 - val_loss: 0.7081 - val_accuracy: 0.7368\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5073 - accuracy: 0.8065 - val_loss: 0.8548 - val_accuracy: 0.7238\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4928 - accuracy: 0.8110 - val_loss: 0.7921 - val_accuracy: 0.7305\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.8025 - val_loss: 0.8260 - val_accuracy: 0.7260\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.7980 - val_loss: 0.7090 - val_accuracy: 0.7362\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8000 - val_loss: 0.7233 - val_accuracy: 0.7352\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4979 - accuracy: 0.8067 - val_loss: 0.6154 - val_accuracy: 0.7518\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5180 - accuracy: 0.7853 - val_loss: 0.7161 - val_accuracy: 0.7359\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4982 - accuracy: 0.8114 - val_loss: 0.7050 - val_accuracy: 0.7362\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5051 - accuracy: 0.8042 - val_loss: 0.7509 - val_accuracy: 0.7343\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.8118 - val_loss: 0.6496 - val_accuracy: 0.7419\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.8002 - val_loss: 0.6650 - val_accuracy: 0.7391\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.8096 - val_loss: 0.7184 - val_accuracy: 0.7365\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5014 - accuracy: 0.8089 - val_loss: 0.6637 - val_accuracy: 0.7391\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5015 - accuracy: 0.8022 - val_loss: 0.6990 - val_accuracy: 0.7378\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4987 - accuracy: 0.8063 - val_loss: 0.6877 - val_accuracy: 0.7378\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5039 - accuracy: 0.8077 - val_loss: 0.8437 - val_accuracy: 0.7254\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5053 - accuracy: 0.8001 - val_loss: 0.6849 - val_accuracy: 0.7378\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4982 - accuracy: 0.8081 - val_loss: 0.6976 - val_accuracy: 0.7368\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5063 - accuracy: 0.7981 - val_loss: 0.8417 - val_accuracy: 0.7254\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7991 - val_loss: 0.7347 - val_accuracy: 0.7349\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4995 - accuracy: 0.8048 - val_loss: 0.7151 - val_accuracy: 0.7362\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.8066 - val_loss: 0.8592 - val_accuracy: 0.7254\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4948 - accuracy: 0.8106 - val_loss: 0.8452 - val_accuracy: 0.7254\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5045 - accuracy: 0.8028 - val_loss: 0.6304 - val_accuracy: 0.7474\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5059 - accuracy: 0.7996 - val_loss: 0.6792 - val_accuracy: 0.7368\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4991 - accuracy: 0.8095 - val_loss: 0.7106 - val_accuracy: 0.7365\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5054 - accuracy: 0.8023 - val_loss: 0.7550 - val_accuracy: 0.7346\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8002 - val_loss: 0.7172 - val_accuracy: 0.7372\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8076 - val_loss: 0.6856 - val_accuracy: 0.7381\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4994 - accuracy: 0.8061 - val_loss: 0.6175 - val_accuracy: 0.7483\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5040 - accuracy: 0.7997 - val_loss: 0.6889 - val_accuracy: 0.7381\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4994 - accuracy: 0.8070 - val_loss: 0.7953 - val_accuracy: 0.7314\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.8065 - val_loss: 0.6879 - val_accuracy: 0.7400\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8067 - val_loss: 0.5928 - val_accuracy: 0.7617\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5197 - accuracy: 0.7893 - val_loss: 0.6831 - val_accuracy: 0.7404\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.8074 - val_loss: 0.7429 - val_accuracy: 0.7352\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4937 - accuracy: 0.8105 - val_loss: 0.6953 - val_accuracy: 0.7384\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5004 - accuracy: 0.8054 - val_loss: 0.7630 - val_accuracy: 0.7343\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5037 - accuracy: 0.8089 - val_loss: 0.6892 - val_accuracy: 0.7381\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4999 - accuracy: 0.8033 - val_loss: 0.8154 - val_accuracy: 0.7295\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5027 - accuracy: 0.8053 - val_loss: 0.7264 - val_accuracy: 0.7359\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.8073 - val_loss: 0.7305 - val_accuracy: 0.7356\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4943 - accuracy: 0.8102 - val_loss: 0.6540 - val_accuracy: 0.7410\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5074 - accuracy: 0.8006 - val_loss: 0.6491 - val_accuracy: 0.7426\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5036 - accuracy: 0.8047 - val_loss: 0.6128 - val_accuracy: 0.7506\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5182 - accuracy: 0.7863 - val_loss: 0.5968 - val_accuracy: 0.7576\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.8057 - val_loss: 0.6752 - val_accuracy: 0.7404\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4973 - accuracy: 0.8032 - val_loss: 0.6918 - val_accuracy: 0.7384\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.8018 - val_loss: 0.8674 - val_accuracy: 0.7254\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4996 - accuracy: 0.8025 - val_loss: 0.7036 - val_accuracy: 0.7384\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4968 - accuracy: 0.8047 - val_loss: 0.7830 - val_accuracy: 0.7337\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.8035 - val_loss: 0.6945 - val_accuracy: 0.7381\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.8028 - val_loss: 0.5960 - val_accuracy: 0.7573\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5047 - accuracy: 0.7971 - val_loss: 0.7148 - val_accuracy: 0.7372\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.8047 - val_loss: 0.7724 - val_accuracy: 0.7343\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5007 - accuracy: 0.8007 - val_loss: 0.6931 - val_accuracy: 0.7381\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4937 - accuracy: 0.8081 - val_loss: 0.7371 - val_accuracy: 0.7365\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4983 - accuracy: 0.8078 - val_loss: 0.6222 - val_accuracy: 0.7464\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5033 - accuracy: 0.7988 - val_loss: 0.6820 - val_accuracy: 0.7384\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5030 - accuracy: 0.8010 - val_loss: 0.7268 - val_accuracy: 0.7375\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5015 - accuracy: 0.8033 - val_loss: 0.6610 - val_accuracy: 0.7410\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.8064 - val_loss: 0.7068 - val_accuracy: 0.7372\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.8078 - val_loss: 0.9496 - val_accuracy: 0.7180\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4960 - accuracy: 0.8022 - val_loss: 0.6922 - val_accuracy: 0.7375\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.8009 - val_loss: 0.7159 - val_accuracy: 0.7365\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4963 - accuracy: 0.8063 - val_loss: 0.6754 - val_accuracy: 0.7400\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.8062 - val_loss: 0.8951 - val_accuracy: 0.7222\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.7920 - val_loss: 0.7344 - val_accuracy: 0.7362\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4915 - accuracy: 0.8058 - val_loss: 0.7340 - val_accuracy: 0.7356\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4949 - accuracy: 0.8047 - val_loss: 0.5939 - val_accuracy: 0.7560\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4990 - accuracy: 0.8047 - val_loss: 0.7216 - val_accuracy: 0.7368\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5016 - accuracy: 0.8079 - val_loss: 0.6635 - val_accuracy: 0.7413\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4986 - accuracy: 0.8095 - val_loss: 0.9237 - val_accuracy: 0.7215\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5039 - accuracy: 0.8031 - val_loss: 0.5908 - val_accuracy: 0.7582\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.7959 - val_loss: 0.6506 - val_accuracy: 0.7435\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4937 - accuracy: 0.8082 - val_loss: 0.9257 - val_accuracy: 0.7215\n",
      "Epoch 279/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4901 - accuracy: 0.8075 - val_loss: 0.6900 - val_accuracy: 0.7391\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4960 - accuracy: 0.8041 - val_loss: 0.8074 - val_accuracy: 0.7321\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5006 - accuracy: 0.7954 - val_loss: 0.6845 - val_accuracy: 0.7391\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.8012 - val_loss: 0.6341 - val_accuracy: 0.7464\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4958 - accuracy: 0.8062 - val_loss: 0.6674 - val_accuracy: 0.7423\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.8053 - val_loss: 0.6371 - val_accuracy: 0.7474\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4965 - accuracy: 0.8054 - val_loss: 0.6200 - val_accuracy: 0.7528\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4974 - accuracy: 0.8057 - val_loss: 0.5954 - val_accuracy: 0.7560\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5023 - accuracy: 0.7976 - val_loss: 0.7485 - val_accuracy: 0.7368\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4981 - accuracy: 0.8050 - val_loss: 0.8249 - val_accuracy: 0.7308\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4958 - accuracy: 0.8062 - val_loss: 0.7453 - val_accuracy: 0.7365\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4911 - accuracy: 0.8118 - val_loss: 0.7606 - val_accuracy: 0.7356\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4961 - accuracy: 0.8066 - val_loss: 0.7388 - val_accuracy: 0.7362\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4954 - accuracy: 0.8076 - val_loss: 0.6575 - val_accuracy: 0.7429\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5030 - accuracy: 0.7991 - val_loss: 0.6078 - val_accuracy: 0.7537\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4989 - accuracy: 0.8010 - val_loss: 0.6967 - val_accuracy: 0.7394\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4968 - accuracy: 0.8059 - val_loss: 0.6650 - val_accuracy: 0.7410\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4983 - accuracy: 0.7995 - val_loss: 0.6320 - val_accuracy: 0.7448\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4996 - accuracy: 0.7950 - val_loss: 0.6851 - val_accuracy: 0.7394\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4938 - accuracy: 0.8086 - val_loss: 0.5899 - val_accuracy: 0.7598\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5100 - accuracy: 0.7913 - val_loss: 0.6101 - val_accuracy: 0.7518\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4992 - accuracy: 0.7994 - val_loss: 0.6845 - val_accuracy: 0.7407\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.8015 - val_loss: 0.9003 - val_accuracy: 0.7250\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4985 - accuracy: 0.8022 - val_loss: 0.9017 - val_accuracy: 0.7234\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5215 - accuracy: 0.7860 - val_loss: 0.6388 - val_accuracy: 0.7455\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4943 - accuracy: 0.8011 - val_loss: 0.6324 - val_accuracy: 0.7461\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.8067 - val_loss: 0.6022 - val_accuracy: 0.7566\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.8039 - val_loss: 0.6999 - val_accuracy: 0.7388\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.8010 - val_loss: 0.7040 - val_accuracy: 0.7381\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.8128 - val_loss: 0.6229 - val_accuracy: 0.7464\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4888 - accuracy: 0.8043 - val_loss: 0.6362 - val_accuracy: 0.7432\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5085 - accuracy: 0.7971 - val_loss: 0.6898 - val_accuracy: 0.7410\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5103 - accuracy: 0.7930 - val_loss: 0.7086 - val_accuracy: 0.7384\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4871 - accuracy: 0.8132 - val_loss: 0.7526 - val_accuracy: 0.7365\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5057 - accuracy: 0.7936 - val_loss: 0.7853 - val_accuracy: 0.7349\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4927 - accuracy: 0.8071 - val_loss: 0.6704 - val_accuracy: 0.7400\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4919 - accuracy: 0.8051 - val_loss: 0.7986 - val_accuracy: 0.7340\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.7999 - val_loss: 1.0339 - val_accuracy: 0.7180\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4995 - accuracy: 0.7997 - val_loss: 0.8304 - val_accuracy: 0.7317\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4929 - accuracy: 0.8058 - val_loss: 0.8163 - val_accuracy: 0.7330\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.7989 - val_loss: 0.8275 - val_accuracy: 0.7321\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4840 - accuracy: 0.8120 - val_loss: 0.6864 - val_accuracy: 0.7404\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.8004 - val_loss: 0.6858 - val_accuracy: 0.7394\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4962 - accuracy: 0.8039 - val_loss: 0.5757 - val_accuracy: 0.7687\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5134 - accuracy: 0.7907 - val_loss: 0.6502 - val_accuracy: 0.7448\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4989 - accuracy: 0.7985 - val_loss: 0.6315 - val_accuracy: 0.7455\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.7986 - val_loss: 0.8639 - val_accuracy: 0.7295\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.7973 - val_loss: 0.8089 - val_accuracy: 0.7346\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4989 - accuracy: 0.8025 - val_loss: 0.7334 - val_accuracy: 0.7378\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4910 - accuracy: 0.8071 - val_loss: 0.6057 - val_accuracy: 0.7544\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.8023 - val_loss: 0.7093 - val_accuracy: 0.7394\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.7929 - val_loss: 0.5883 - val_accuracy: 0.7624\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5142 - accuracy: 0.7869 - val_loss: 0.8527 - val_accuracy: 0.7311\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4936 - accuracy: 0.8041 - val_loss: 0.5879 - val_accuracy: 0.7573\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5116 - accuracy: 0.7926 - val_loss: 0.5880 - val_accuracy: 0.7668\n",
      "Epoch 334/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5123 - accuracy: 0.7906 - val_loss: 0.7436 - val_accuracy: 0.7375\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4868 - accuracy: 0.8102 - val_loss: 0.6987 - val_accuracy: 0.7404\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4841 - accuracy: 0.8099 - val_loss: 0.5874 - val_accuracy: 0.7640\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4955 - accuracy: 0.8015 - val_loss: 0.6268 - val_accuracy: 0.7480\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4954 - accuracy: 0.8030 - val_loss: 0.7411 - val_accuracy: 0.7368\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4853 - accuracy: 0.8086 - val_loss: 0.5977 - val_accuracy: 0.7592\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5229 - accuracy: 0.7805 - val_loss: 0.5928 - val_accuracy: 0.7624\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5495 - accuracy: 0.7632 - val_loss: 0.5909 - val_accuracy: 0.7604\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5168 - accuracy: 0.7875 - val_loss: 0.5953 - val_accuracy: 0.7585\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5042 - accuracy: 0.7997 - val_loss: 0.6951 - val_accuracy: 0.7404\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4946 - accuracy: 0.8019 - val_loss: 0.8649 - val_accuracy: 0.7305\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4924 - accuracy: 0.8080 - val_loss: 0.7911 - val_accuracy: 0.7352\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5116 - accuracy: 0.7927 - val_loss: 0.7780 - val_accuracy: 0.7359\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5111 - accuracy: 0.7954 - val_loss: 0.8228 - val_accuracy: 0.7340\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5015 - accuracy: 0.7993 - val_loss: 0.8984 - val_accuracy: 0.7279\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5290 - accuracy: 0.7774 - val_loss: 0.9630 - val_accuracy: 0.7215\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5253 - accuracy: 0.7760 - val_loss: 0.7741 - val_accuracy: 0.7359\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5029 - accuracy: 0.8013 - val_loss: 0.6074 - val_accuracy: 0.7518\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.8017 - val_loss: 0.5999 - val_accuracy: 0.7560\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4948 - accuracy: 0.8043 - val_loss: 0.7149 - val_accuracy: 0.7384\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4901 - accuracy: 0.8077 - val_loss: 0.6279 - val_accuracy: 0.7467\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4947 - accuracy: 0.8032 - val_loss: 0.5834 - val_accuracy: 0.7636\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5159 - accuracy: 0.7906 - val_loss: 0.6197 - val_accuracy: 0.7541\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4925 - accuracy: 0.8042 - val_loss: 0.6615 - val_accuracy: 0.7419\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4938 - accuracy: 0.8077 - val_loss: 0.9609 - val_accuracy: 0.7225\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5060 - accuracy: 0.7903 - val_loss: 0.7062 - val_accuracy: 0.7413\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4933 - accuracy: 0.8047 - val_loss: 0.7012 - val_accuracy: 0.7384\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4908 - accuracy: 0.8106 - val_loss: 0.6194 - val_accuracy: 0.7490\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5028 - accuracy: 0.7919 - val_loss: 0.6790 - val_accuracy: 0.7426\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4975 - accuracy: 0.7982 - val_loss: 0.5935 - val_accuracy: 0.7585\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.7970 - val_loss: 0.6092 - val_accuracy: 0.7569\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4988 - accuracy: 0.7984 - val_loss: 0.5810 - val_accuracy: 0.7703\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5002 - accuracy: 0.7964 - val_loss: 0.6934 - val_accuracy: 0.7388\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4948 - accuracy: 0.8070 - val_loss: 0.5901 - val_accuracy: 0.7614\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4950 - accuracy: 0.8027 - val_loss: 0.5839 - val_accuracy: 0.7620\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4973 - accuracy: 0.8059 - val_loss: 0.8398 - val_accuracy: 0.7321\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.8072 - val_loss: 0.6064 - val_accuracy: 0.7541\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5073 - accuracy: 0.7953 - val_loss: 0.6499 - val_accuracy: 0.7451\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5056 - accuracy: 0.7989 - val_loss: 0.7489 - val_accuracy: 0.7375\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4918 - accuracy: 0.8051 - val_loss: 0.7554 - val_accuracy: 0.7365\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4956 - accuracy: 0.8059 - val_loss: 0.8888 - val_accuracy: 0.7289\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5054 - accuracy: 0.7926 - val_loss: 0.7371 - val_accuracy: 0.7381\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4881 - accuracy: 0.8080 - val_loss: 0.8814 - val_accuracy: 0.7301\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4998 - accuracy: 0.7970 - val_loss: 0.7836 - val_accuracy: 0.7362\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4925 - accuracy: 0.8039 - val_loss: 0.5723 - val_accuracy: 0.7665\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5100 - accuracy: 0.7930 - val_loss: 0.6360 - val_accuracy: 0.7461\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4897 - accuracy: 0.8072 - val_loss: 0.5739 - val_accuracy: 0.7732\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5454 - accuracy: 0.7653 - val_loss: 0.5718 - val_accuracy: 0.7662\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.7997 - val_loss: 0.6071 - val_accuracy: 0.7620\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5293 - accuracy: 0.7685 - val_loss: 0.6879 - val_accuracy: 0.7419\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4936 - accuracy: 0.8017 - val_loss: 0.7519 - val_accuracy: 0.7381\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4961 - accuracy: 0.8015 - val_loss: 0.5735 - val_accuracy: 0.7656\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5192 - accuracy: 0.7856 - val_loss: 0.7048 - val_accuracy: 0.7413\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4901 - accuracy: 0.8024 - val_loss: 0.6970 - val_accuracy: 0.7407\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4902 - accuracy: 0.8081 - val_loss: 0.6236 - val_accuracy: 0.7537\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5800 - accuracy: 0.7505 - val_loss: 0.5768 - val_accuracy: 0.7614\n",
      "Epoch 390/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.7919 - val_loss: 0.5894 - val_accuracy: 0.7589\n",
      "Epoch 391/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5226 - accuracy: 0.7760 - val_loss: 0.5858 - val_accuracy: 0.7620\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5081 - accuracy: 0.7992 - val_loss: 0.5820 - val_accuracy: 0.7652\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5096 - accuracy: 0.7944 - val_loss: 0.7872 - val_accuracy: 0.7365\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4903 - accuracy: 0.8043 - val_loss: 0.6451 - val_accuracy: 0.7442\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4946 - accuracy: 0.8036 - val_loss: 0.8265 - val_accuracy: 0.7343\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4879 - accuracy: 0.8120 - val_loss: 0.7745 - val_accuracy: 0.7362\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4958 - accuracy: 0.8048 - val_loss: 1.1429 - val_accuracy: 0.7174\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5246 - accuracy: 0.7837 - val_loss: 0.8046 - val_accuracy: 0.7349\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5204 - accuracy: 0.7837 - val_loss: 0.9186 - val_accuracy: 0.7276\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5131 - accuracy: 0.7899 - val_loss: 0.9645 - val_accuracy: 0.7222\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5129 - accuracy: 0.7884 - val_loss: 0.9048 - val_accuracy: 0.7301\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.8004 - val_loss: 0.7958 - val_accuracy: 0.7365\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4989 - accuracy: 0.8000 - val_loss: 0.7370 - val_accuracy: 0.7381\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.8042 - val_loss: 0.8179 - val_accuracy: 0.7346\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4822 - accuracy: 0.8128 - val_loss: 0.6480 - val_accuracy: 0.7467\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4895 - accuracy: 0.8059 - val_loss: 0.8868 - val_accuracy: 0.7285\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7981 - val_loss: 1.0465 - val_accuracy: 0.7180\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5087 - accuracy: 0.7913 - val_loss: 0.7637 - val_accuracy: 0.7368\n",
      "Epoch 409/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4853 - accuracy: 0.8102 - val_loss: 0.7876 - val_accuracy: 0.7365\n",
      "Epoch 410/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5015 - accuracy: 0.7941 - val_loss: 0.6435 - val_accuracy: 0.7458\n",
      "Epoch 411/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4903 - accuracy: 0.8086 - val_loss: 0.6025 - val_accuracy: 0.7550\n",
      "Epoch 412/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5131 - accuracy: 0.7889 - val_loss: 0.5844 - val_accuracy: 0.7646\n",
      "Epoch 413/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5321 - accuracy: 0.7763 - val_loss: 0.6580 - val_accuracy: 0.7458\n",
      "Epoch 414/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4907 - accuracy: 0.8065 - val_loss: 0.6057 - val_accuracy: 0.7576\n",
      "Epoch 415/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4966 - accuracy: 0.8016 - val_loss: 0.7883 - val_accuracy: 0.7365\n",
      "Epoch 416/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.8089 - val_loss: 0.7203 - val_accuracy: 0.7388\n",
      "Epoch 417/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4839 - accuracy: 0.8092 - val_loss: 0.6128 - val_accuracy: 0.7566\n",
      "Epoch 418/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.8113 - val_loss: 0.6530 - val_accuracy: 0.7426\n",
      "Epoch 419/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5012 - accuracy: 0.7983 - val_loss: 0.6607 - val_accuracy: 0.7455\n",
      "Epoch 420/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4896 - accuracy: 0.8045 - val_loss: 0.7335 - val_accuracy: 0.7378\n",
      "Epoch 421/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4903 - accuracy: 0.8065 - val_loss: 0.7046 - val_accuracy: 0.7400\n",
      "Epoch 422/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.8051 - val_loss: 0.8610 - val_accuracy: 0.7327\n",
      "Epoch 423/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5062 - accuracy: 0.7919 - val_loss: 1.0948 - val_accuracy: 0.7180\n",
      "Epoch 424/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5115 - accuracy: 0.7882 - val_loss: 0.5924 - val_accuracy: 0.7592\n",
      "Epoch 425/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4893 - accuracy: 0.8071 - val_loss: 0.7343 - val_accuracy: 0.7378\n",
      "Epoch 426/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4831 - accuracy: 0.8158 - val_loss: 0.6000 - val_accuracy: 0.7598\n",
      "Epoch 427/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5574 - accuracy: 0.7654 - val_loss: 0.5727 - val_accuracy: 0.7681\n",
      "Epoch 428/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7881 - val_loss: 0.6035 - val_accuracy: 0.7611\n",
      "Epoch 429/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4926 - accuracy: 0.8054 - val_loss: 0.6305 - val_accuracy: 0.7474\n",
      "Epoch 430/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4850 - accuracy: 0.8108 - val_loss: 0.6196 - val_accuracy: 0.7502\n",
      "Epoch 431/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5026 - accuracy: 0.7977 - val_loss: 0.6121 - val_accuracy: 0.7579\n",
      "Epoch 432/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.7997 - val_loss: 1.0480 - val_accuracy: 0.7183\n",
      "Epoch 433/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5210 - accuracy: 0.7775 - val_loss: 0.8460 - val_accuracy: 0.7337\n",
      "Epoch 434/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5057 - accuracy: 0.7935 - val_loss: 0.7463 - val_accuracy: 0.7384\n",
      "Epoch 435/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4881 - accuracy: 0.8110 - val_loss: 0.8083 - val_accuracy: 0.7356\n",
      "Epoch 436/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5298 - accuracy: 0.7828 - val_loss: 0.9082 - val_accuracy: 0.7301\n",
      "Epoch 437/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5067 - accuracy: 0.7928 - val_loss: 0.8414 - val_accuracy: 0.7343\n",
      "Epoch 438/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5240 - accuracy: 0.7848 - val_loss: 0.9999 - val_accuracy: 0.7219\n",
      "Epoch 439/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5106 - accuracy: 0.7914 - val_loss: 0.8541 - val_accuracy: 0.7333\n",
      "Epoch 440/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5172 - accuracy: 0.7875 - val_loss: 0.5795 - val_accuracy: 0.7675\n",
      "Epoch 441/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5083 - accuracy: 0.7907 - val_loss: 0.6050 - val_accuracy: 0.7589\n",
      "Epoch 442/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5051 - accuracy: 0.7935 - val_loss: 0.6374 - val_accuracy: 0.7470\n",
      "Epoch 443/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4991 - accuracy: 0.8010 - val_loss: 0.5762 - val_accuracy: 0.7659\n",
      "Epoch 444/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5561 - accuracy: 0.7542 - val_loss: 0.5724 - val_accuracy: 0.7697\n",
      "Epoch 445/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5196 - accuracy: 0.7851 - val_loss: 0.5846 - val_accuracy: 0.7691\n",
      "Epoch 446/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5087 - accuracy: 0.7922 - val_loss: 0.5765 - val_accuracy: 0.7700\n",
      "Epoch 447/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5468 - accuracy: 0.7661 - val_loss: 0.5736 - val_accuracy: 0.7681\n",
      "Epoch 448/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5185 - accuracy: 0.7918 - val_loss: 0.6988 - val_accuracy: 0.7416\n",
      "Epoch 449/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.8025 - val_loss: 0.8427 - val_accuracy: 0.7343\n",
      "Epoch 450/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5302 - accuracy: 0.7776 - val_loss: 0.7318 - val_accuracy: 0.7388\n",
      "Epoch 451/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4881 - accuracy: 0.8114 - val_loss: 0.7167 - val_accuracy: 0.7400\n",
      "Epoch 452/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.8107 - val_loss: 0.6298 - val_accuracy: 0.7490\n",
      "Epoch 453/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4950 - accuracy: 0.8034 - val_loss: 0.6338 - val_accuracy: 0.7474\n",
      "Epoch 454/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4918 - accuracy: 0.8089 - val_loss: 0.6107 - val_accuracy: 0.7557\n",
      "Epoch 455/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5017 - accuracy: 0.7929 - val_loss: 0.5758 - val_accuracy: 0.7678\n",
      "Epoch 456/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5381 - accuracy: 0.7690 - val_loss: 0.6436 - val_accuracy: 0.7474\n",
      "Epoch 457/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4996 - accuracy: 0.7961 - val_loss: 0.6051 - val_accuracy: 0.7569\n",
      "Epoch 458/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.7930 - val_loss: 0.5914 - val_accuracy: 0.7608\n",
      "Epoch 459/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.7962 - val_loss: 0.5698 - val_accuracy: 0.7678\n",
      "Epoch 460/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5247 - accuracy: 0.7824 - val_loss: 0.7225 - val_accuracy: 0.7397\n",
      "Epoch 461/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4831 - accuracy: 0.8149 - val_loss: 0.5841 - val_accuracy: 0.7636\n",
      "Epoch 462/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5399 - accuracy: 0.7747 - val_loss: 0.5709 - val_accuracy: 0.7671\n",
      "Epoch 463/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5017 - accuracy: 0.8018 - val_loss: 0.6979 - val_accuracy: 0.7435\n",
      "Epoch 464/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4856 - accuracy: 0.8080 - val_loss: 0.6740 - val_accuracy: 0.7435\n",
      "Epoch 465/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4909 - accuracy: 0.8044 - val_loss: 0.6075 - val_accuracy: 0.7566\n",
      "Epoch 466/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5055 - accuracy: 0.7921 - val_loss: 0.5959 - val_accuracy: 0.7566\n",
      "Epoch 467/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.7972 - val_loss: 0.6103 - val_accuracy: 0.7598\n",
      "Epoch 468/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.7537 - val_loss: 0.5802 - val_accuracy: 0.7662\n",
      "Epoch 469/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5100 - accuracy: 0.7927 - val_loss: 0.5699 - val_accuracy: 0.7726\n",
      "Epoch 470/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5098 - accuracy: 0.7901 - val_loss: 0.6774 - val_accuracy: 0.7432\n",
      "Epoch 471/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5075 - accuracy: 0.7888 - val_loss: 0.5780 - val_accuracy: 0.7627\n",
      "Epoch 472/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5118 - accuracy: 0.7897 - val_loss: 0.5791 - val_accuracy: 0.7681\n",
      "Epoch 473/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4949 - accuracy: 0.8022 - val_loss: 0.5992 - val_accuracy: 0.7569\n",
      "Epoch 474/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5017 - accuracy: 0.7962 - val_loss: 0.5731 - val_accuracy: 0.7675\n",
      "Epoch 475/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5223 - accuracy: 0.7791 - val_loss: 0.6171 - val_accuracy: 0.7512\n",
      "Epoch 476/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4860 - accuracy: 0.8087 - val_loss: 0.5704 - val_accuracy: 0.7691\n",
      "Epoch 477/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5003 - accuracy: 0.7972 - val_loss: 0.6443 - val_accuracy: 0.7534\n",
      "Epoch 478/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4921 - accuracy: 0.8039 - val_loss: 0.6596 - val_accuracy: 0.7219\n",
      "Epoch 479/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5578 - accuracy: 0.7538 - val_loss: 0.5692 - val_accuracy: 0.7684\n",
      "Epoch 480/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5064 - accuracy: 0.7934 - val_loss: 0.6432 - val_accuracy: 0.7474\n",
      "Epoch 481/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4837 - accuracy: 0.8089 - val_loss: 0.8829 - val_accuracy: 0.7321\n",
      "Epoch 482/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5178 - accuracy: 0.7869 - val_loss: 0.9029 - val_accuracy: 0.7305\n",
      "Epoch 483/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4874 - accuracy: 0.8070 - val_loss: 0.9798 - val_accuracy: 0.7234\n",
      "Epoch 484/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.7935 - val_loss: 0.8103 - val_accuracy: 0.7362\n",
      "Epoch 485/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4914 - accuracy: 0.8057 - val_loss: 0.5826 - val_accuracy: 0.7604\n",
      "Epoch 486/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5064 - accuracy: 0.7980 - val_loss: 0.7466 - val_accuracy: 0.7381\n",
      "Epoch 487/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4784 - accuracy: 0.8160 - val_loss: 0.7337 - val_accuracy: 0.7378\n",
      "Epoch 488/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4914 - accuracy: 0.8045 - val_loss: 0.8964 - val_accuracy: 0.7295\n",
      "Epoch 489/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5025 - accuracy: 0.7933 - val_loss: 1.1207 - val_accuracy: 0.7180\n",
      "Epoch 490/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5259 - accuracy: 0.7823 - val_loss: 0.7182 - val_accuracy: 0.7388\n",
      "Epoch 491/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4910 - accuracy: 0.8076 - val_loss: 0.9926 - val_accuracy: 0.7234\n",
      "Epoch 492/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5340 - accuracy: 0.7680 - val_loss: 0.8616 - val_accuracy: 0.7337\n",
      "Epoch 493/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4879 - accuracy: 0.8073 - val_loss: 0.6410 - val_accuracy: 0.7467\n",
      "Epoch 494/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4847 - accuracy: 0.8103 - val_loss: 0.7256 - val_accuracy: 0.7394\n",
      "Epoch 495/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4887 - accuracy: 0.8071 - val_loss: 0.5673 - val_accuracy: 0.7710\n",
      "Epoch 496/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5313 - accuracy: 0.7769 - val_loss: 0.6187 - val_accuracy: 0.7534\n",
      "Epoch 497/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5217 - accuracy: 0.7843 - val_loss: 0.5776 - val_accuracy: 0.7681\n",
      "Epoch 498/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.7959 - val_loss: 0.5808 - val_accuracy: 0.7627\n",
      "Epoch 499/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5089 - accuracy: 0.7907 - val_loss: 0.5868 - val_accuracy: 0.7608\n",
      "Epoch 500/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5046 - accuracy: 0.7959 - val_loss: 0.5954 - val_accuracy: 0.7662\n",
      "Epoch 501/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5075 - accuracy: 0.7891 - val_loss: 0.5675 - val_accuracy: 0.7694\n",
      "Epoch 502/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5132 - accuracy: 0.7889 - val_loss: 0.5687 - val_accuracy: 0.7707\n",
      "Epoch 503/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5205 - accuracy: 0.7884 - val_loss: 0.5720 - val_accuracy: 0.7697\n",
      "Epoch 504/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5182 - accuracy: 0.7868 - val_loss: 0.5836 - val_accuracy: 0.7633\n",
      "Epoch 505/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.8001 - val_loss: 0.7298 - val_accuracy: 0.7404\n",
      "Epoch 506/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.8082 - val_loss: 0.5807 - val_accuracy: 0.7662\n",
      "Epoch 507/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5114 - accuracy: 0.7844 - val_loss: 0.5686 - val_accuracy: 0.7694\n",
      "Epoch 508/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5079 - accuracy: 0.7895 - val_loss: 0.7142 - val_accuracy: 0.7419\n",
      "Epoch 509/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4819 - accuracy: 0.8117 - val_loss: 0.6751 - val_accuracy: 0.7442\n",
      "Epoch 510/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4823 - accuracy: 0.8105 - val_loss: 0.9738 - val_accuracy: 0.7241\n",
      "Epoch 511/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5211 - accuracy: 0.7819 - val_loss: 0.9104 - val_accuracy: 0.7308\n",
      "Epoch 512/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5017 - accuracy: 0.7948 - val_loss: 0.7250 - val_accuracy: 0.7384\n",
      "Epoch 513/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4882 - accuracy: 0.8109 - val_loss: 0.7481 - val_accuracy: 0.7375\n",
      "Epoch 514/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4992 - accuracy: 0.8020 - val_loss: 1.0001 - val_accuracy: 0.7222\n",
      "Epoch 515/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5205 - accuracy: 0.7869 - val_loss: 0.6532 - val_accuracy: 0.7458\n",
      "Epoch 516/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4864 - accuracy: 0.8090 - val_loss: 1.0374 - val_accuracy: 0.7212\n",
      "Epoch 517/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5011 - accuracy: 0.7962 - val_loss: 1.0057 - val_accuracy: 0.7215\n",
      "Epoch 518/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5025 - accuracy: 0.7961 - val_loss: 0.9138 - val_accuracy: 0.7298\n",
      "Epoch 519/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5257 - accuracy: 0.7779 - val_loss: 0.8764 - val_accuracy: 0.7321\n",
      "Epoch 520/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.7896 - val_loss: 0.9456 - val_accuracy: 0.7289\n",
      "Epoch 521/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5396 - accuracy: 0.7647 - val_loss: 0.7862 - val_accuracy: 0.7375\n",
      "Epoch 522/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5215 - accuracy: 0.7808 - val_loss: 0.6750 - val_accuracy: 0.7423\n",
      "Epoch 00522: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.01, verbose = 1)\n",
    "model1_reg = model_one_reg('l1')\n",
    "history = model1_reg.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6750 - accuracy: 0.7423\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6749976873397827, 0.7422647476196289]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_reg.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 L2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 1.4206 - accuracy: 0.5101 - val_loss: 1.2448 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.2265 - accuracy: 0.7062 - val_loss: 1.1719 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.1591 - accuracy: 0.7013 - val_loss: 1.1079 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0914 - accuracy: 0.7062 - val_loss: 1.0508 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 1.0345 - accuracy: 0.7070 - val_loss: 0.9997 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9918 - accuracy: 0.6989 - val_loss: 0.9559 - val_accuracy: 0.7085\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.9417 - accuracy: 0.7066 - val_loss: 0.9155 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.9011 - accuracy: 0.7083 - val_loss: 0.8806 - val_accuracy: 0.7085\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8659 - accuracy: 0.7092 - val_loss: 0.8494 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8312 - accuracy: 0.7138 - val_loss: 0.8217 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8083 - accuracy: 0.7098 - val_loss: 0.7977 - val_accuracy: 0.7085\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7849 - accuracy: 0.7091 - val_loss: 0.7759 - val_accuracy: 0.7085\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7645 - accuracy: 0.7084 - val_loss: 0.7571 - val_accuracy: 0.7085\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7458 - accuracy: 0.7085 - val_loss: 0.7399 - val_accuracy: 0.7085\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7294 - accuracy: 0.7080 - val_loss: 0.7260 - val_accuracy: 0.7085\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7150 - accuracy: 0.7082 - val_loss: 0.7117 - val_accuracy: 0.7085\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6995 - accuracy: 0.7107 - val_loss: 0.6999 - val_accuracy: 0.7085\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6964 - accuracy: 0.7004 - val_loss: 0.6898 - val_accuracy: 0.7085\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6820 - accuracy: 0.7060 - val_loss: 0.6802 - val_accuracy: 0.7085\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6726 - accuracy: 0.7065 - val_loss: 0.6724 - val_accuracy: 0.7085\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6656 - accuracy: 0.7051 - val_loss: 0.6648 - val_accuracy: 0.7085\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6549 - accuracy: 0.7090 - val_loss: 0.6584 - val_accuracy: 0.7085\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6492 - accuracy: 0.7083 - val_loss: 0.6529 - val_accuracy: 0.7085\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6405 - accuracy: 0.7117 - val_loss: 0.6477 - val_accuracy: 0.7085\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6415 - accuracy: 0.7046 - val_loss: 0.6434 - val_accuracy: 0.7085\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6327 - accuracy: 0.7099 - val_loss: 0.6392 - val_accuracy: 0.7085\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6320 - accuracy: 0.7053 - val_loss: 0.6358 - val_accuracy: 0.7085\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6250 - accuracy: 0.7094 - val_loss: 0.6328 - val_accuracy: 0.7085\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6208 - accuracy: 0.7109 - val_loss: 0.6299 - val_accuracy: 0.7085\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6195 - accuracy: 0.7078 - val_loss: 0.6274 - val_accuracy: 0.7085\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6146 - accuracy: 0.7103 - val_loss: 0.6255 - val_accuracy: 0.7085\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6136 - accuracy: 0.7090 - val_loss: 0.6234 - val_accuracy: 0.7085\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6167 - accuracy: 0.7022 - val_loss: 0.6220 - val_accuracy: 0.7085\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6077 - accuracy: 0.7098 - val_loss: 0.6200 - val_accuracy: 0.7085\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6054 - accuracy: 0.7105 - val_loss: 0.6187 - val_accuracy: 0.7085\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6046 - accuracy: 0.7087 - val_loss: 0.6175 - val_accuracy: 0.7085\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6059 - accuracy: 0.7050 - val_loss: 0.6164 - val_accuracy: 0.7085\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5986 - accuracy: 0.7114 - val_loss: 0.6154 - val_accuracy: 0.7085\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6012 - accuracy: 0.7050 - val_loss: 0.6151 - val_accuracy: 0.7085\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6007 - accuracy: 0.7047 - val_loss: 0.6137 - val_accuracy: 0.7085\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5946 - accuracy: 0.7100 - val_loss: 0.6133 - val_accuracy: 0.7085\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5914 - accuracy: 0.7118 - val_loss: 0.6125 - val_accuracy: 0.7085\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5913 - accuracy: 0.7076 - val_loss: 0.6125 - val_accuracy: 0.7085\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5899 - accuracy: 0.7072 - val_loss: 0.6112 - val_accuracy: 0.7085\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5865 - accuracy: 0.7107 - val_loss: 0.6132 - val_accuracy: 0.7085\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5832 - accuracy: 0.7118 - val_loss: 0.6109 - val_accuracy: 0.7088\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.7109 - val_loss: 0.6108 - val_accuracy: 0.7088\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5792 - accuracy: 0.7157 - val_loss: 0.6103 - val_accuracy: 0.7110\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5817 - accuracy: 0.7089 - val_loss: 0.6130 - val_accuracy: 0.7100\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5801 - accuracy: 0.7074 - val_loss: 0.6104 - val_accuracy: 0.7126\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5763 - accuracy: 0.7107 - val_loss: 0.6101 - val_accuracy: 0.7139\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5742 - accuracy: 0.7084 - val_loss: 0.6092 - val_accuracy: 0.7145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5691 - accuracy: 0.7150 - val_loss: 0.6084 - val_accuracy: 0.7142\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5667 - accuracy: 0.7156 - val_loss: 0.6094 - val_accuracy: 0.7142\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5628 - accuracy: 0.7174 - val_loss: 0.6127 - val_accuracy: 0.7145\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5688 - accuracy: 0.7111 - val_loss: 0.6118 - val_accuracy: 0.7142\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5580 - accuracy: 0.7218 - val_loss: 0.6074 - val_accuracy: 0.7161\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5552 - accuracy: 0.7296 - val_loss: 0.6087 - val_accuracy: 0.7152\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5594 - accuracy: 0.7246 - val_loss: 0.6133 - val_accuracy: 0.7152\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5554 - accuracy: 0.7271 - val_loss: 0.6092 - val_accuracy: 0.7164\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5525 - accuracy: 0.7341 - val_loss: 0.6137 - val_accuracy: 0.7148\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5488 - accuracy: 0.7364 - val_loss: 0.6169 - val_accuracy: 0.7152\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5452 - accuracy: 0.7399 - val_loss: 0.6096 - val_accuracy: 0.7180\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5477 - accuracy: 0.7403 - val_loss: 0.6093 - val_accuracy: 0.7183\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5445 - accuracy: 0.7430 - val_loss: 0.6185 - val_accuracy: 0.7158\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5462 - accuracy: 0.7395 - val_loss: 0.6179 - val_accuracy: 0.7167\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5395 - accuracy: 0.7435 - val_loss: 0.6072 - val_accuracy: 0.7231\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5364 - accuracy: 0.7558 - val_loss: 0.6122 - val_accuracy: 0.7187\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5380 - accuracy: 0.7501 - val_loss: 0.6113 - val_accuracy: 0.7203\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5367 - accuracy: 0.7509 - val_loss: 0.6215 - val_accuracy: 0.7174\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5417 - accuracy: 0.7409 - val_loss: 0.6083 - val_accuracy: 0.7234\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5380 - accuracy: 0.7572 - val_loss: 0.6099 - val_accuracy: 0.7225\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5359 - accuracy: 0.7577 - val_loss: 0.6126 - val_accuracy: 0.7209\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5347 - accuracy: 0.7522 - val_loss: 0.6095 - val_accuracy: 0.7238\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5321 - accuracy: 0.7598 - val_loss: 0.6141 - val_accuracy: 0.7209\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5290 - accuracy: 0.7601 - val_loss: 0.6093 - val_accuracy: 0.7241\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5251 - accuracy: 0.7663 - val_loss: 0.6116 - val_accuracy: 0.7228\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5284 - accuracy: 0.7626 - val_loss: 0.6048 - val_accuracy: 0.7257\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5329 - accuracy: 0.7611 - val_loss: 0.6051 - val_accuracy: 0.7266\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5301 - accuracy: 0.7622 - val_loss: 0.6055 - val_accuracy: 0.7257\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5269 - accuracy: 0.7636 - val_loss: 0.6102 - val_accuracy: 0.7244\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5254 - accuracy: 0.7631 - val_loss: 0.6180 - val_accuracy: 0.7219\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5256 - accuracy: 0.7622 - val_loss: 0.6148 - val_accuracy: 0.7222\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5291 - accuracy: 0.7586 - val_loss: 0.6066 - val_accuracy: 0.7254\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5270 - accuracy: 0.7678 - val_loss: 0.6101 - val_accuracy: 0.7247\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5244 - accuracy: 0.7620 - val_loss: 0.6130 - val_accuracy: 0.7234\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5232 - accuracy: 0.7685 - val_loss: 0.6029 - val_accuracy: 0.7314\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5217 - accuracy: 0.7660 - val_loss: 0.6072 - val_accuracy: 0.7241\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5190 - accuracy: 0.7704 - val_loss: 0.6052 - val_accuracy: 0.7279\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5220 - accuracy: 0.7671 - val_loss: 0.6104 - val_accuracy: 0.7247\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5167 - accuracy: 0.7720 - val_loss: 0.6012 - val_accuracy: 0.7362\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5224 - accuracy: 0.7678 - val_loss: 0.6244 - val_accuracy: 0.7225\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5159 - accuracy: 0.7674 - val_loss: 0.6027 - val_accuracy: 0.7317\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5132 - accuracy: 0.7788 - val_loss: 0.6113 - val_accuracy: 0.7244\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5152 - accuracy: 0.7687 - val_loss: 0.6069 - val_accuracy: 0.7260\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5135 - accuracy: 0.7750 - val_loss: 0.5997 - val_accuracy: 0.7343\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5122 - accuracy: 0.7822 - val_loss: 0.5998 - val_accuracy: 0.7359\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5136 - accuracy: 0.7771 - val_loss: 0.6051 - val_accuracy: 0.7257\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5114 - accuracy: 0.7749 - val_loss: 0.6012 - val_accuracy: 0.7330\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5092 - accuracy: 0.7786 - val_loss: 0.6032 - val_accuracy: 0.7295\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5103 - accuracy: 0.7788 - val_loss: 0.5985 - val_accuracy: 0.7391\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5132 - accuracy: 0.7779 - val_loss: 0.6011 - val_accuracy: 0.7333\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5132 - accuracy: 0.7784 - val_loss: 0.6002 - val_accuracy: 0.7343\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5090 - accuracy: 0.7807 - val_loss: 0.6014 - val_accuracy: 0.7333\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5125 - accuracy: 0.7743 - val_loss: 0.5978 - val_accuracy: 0.7359\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.7873 - val_loss: 0.6021 - val_accuracy: 0.7298\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7824 - val_loss: 0.6050 - val_accuracy: 0.7285\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5124 - accuracy: 0.7751 - val_loss: 0.5967 - val_accuracy: 0.7375\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5080 - accuracy: 0.7844 - val_loss: 0.6068 - val_accuracy: 0.7279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.7801 - val_loss: 0.6005 - val_accuracy: 0.7340\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5109 - accuracy: 0.7769 - val_loss: 0.6046 - val_accuracy: 0.7292\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5094 - accuracy: 0.7789 - val_loss: 0.5969 - val_accuracy: 0.7378\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5099 - accuracy: 0.7817 - val_loss: 0.5984 - val_accuracy: 0.7448\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7808 - val_loss: 0.6001 - val_accuracy: 0.7327\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5080 - accuracy: 0.7792 - val_loss: 0.6069 - val_accuracy: 0.7292\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5101 - accuracy: 0.7739 - val_loss: 0.5953 - val_accuracy: 0.7381\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5063 - accuracy: 0.7821 - val_loss: 0.5939 - val_accuracy: 0.7400\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5095 - accuracy: 0.7816 - val_loss: 0.6056 - val_accuracy: 0.7292\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.7790 - val_loss: 0.5938 - val_accuracy: 0.7404\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5034 - accuracy: 0.7866 - val_loss: 0.5999 - val_accuracy: 0.7410\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.7848 - val_loss: 0.5950 - val_accuracy: 0.7388\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4941 - accuracy: 0.7913 - val_loss: 0.5950 - val_accuracy: 0.7388\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5064 - accuracy: 0.7815 - val_loss: 0.6022 - val_accuracy: 0.7321\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5026 - accuracy: 0.7806 - val_loss: 0.6050 - val_accuracy: 0.7311\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5008 - accuracy: 0.7854 - val_loss: 0.6218 - val_accuracy: 0.7260\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.7794 - val_loss: 0.6054 - val_accuracy: 0.7311\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5023 - accuracy: 0.7826 - val_loss: 0.5982 - val_accuracy: 0.7356\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5027 - accuracy: 0.7832 - val_loss: 0.5915 - val_accuracy: 0.7445\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4991 - accuracy: 0.7885 - val_loss: 0.5982 - val_accuracy: 0.7346\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4984 - accuracy: 0.7841 - val_loss: 0.6022 - val_accuracy: 0.7317\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5019 - accuracy: 0.7802 - val_loss: 0.5933 - val_accuracy: 0.7397\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5003 - accuracy: 0.7843 - val_loss: 0.6716 - val_accuracy: 0.7174\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5189 - accuracy: 0.7662 - val_loss: 0.6001 - val_accuracy: 0.7337\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5025 - accuracy: 0.7846 - val_loss: 0.5933 - val_accuracy: 0.7404\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5009 - accuracy: 0.7867 - val_loss: 0.5921 - val_accuracy: 0.7397\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4981 - accuracy: 0.7871 - val_loss: 0.5906 - val_accuracy: 0.7426\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4934 - accuracy: 0.7931 - val_loss: 0.5922 - val_accuracy: 0.7458\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4994 - accuracy: 0.7886 - val_loss: 0.5892 - val_accuracy: 0.7439\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5095 - accuracy: 0.7740 - val_loss: 0.5953 - val_accuracy: 0.7429\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5102 - accuracy: 0.7768 - val_loss: 0.6281 - val_accuracy: 0.7254\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5092 - accuracy: 0.7711 - val_loss: 0.6003 - val_accuracy: 0.7349\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7786 - val_loss: 0.6298 - val_accuracy: 0.7254\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.7799 - val_loss: 0.6165 - val_accuracy: 0.7282\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5107 - accuracy: 0.7729 - val_loss: 0.5888 - val_accuracy: 0.7445\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4964 - accuracy: 0.7901 - val_loss: 0.5996 - val_accuracy: 0.7352\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.7816 - val_loss: 0.6185 - val_accuracy: 0.7270\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4997 - accuracy: 0.7785 - val_loss: 0.5883 - val_accuracy: 0.7432\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4905 - accuracy: 0.7913 - val_loss: 0.6034 - val_accuracy: 0.7327\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5014 - accuracy: 0.7798 - val_loss: 0.5914 - val_accuracy: 0.7404\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4888 - accuracy: 0.7937 - val_loss: 0.6072 - val_accuracy: 0.7333\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5020 - accuracy: 0.7785 - val_loss: 0.6009 - val_accuracy: 0.7343\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5044 - accuracy: 0.7796 - val_loss: 0.5887 - val_accuracy: 0.7470\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5008 - accuracy: 0.7868 - val_loss: 0.6380 - val_accuracy: 0.7244\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5043 - accuracy: 0.7796 - val_loss: 0.6062 - val_accuracy: 0.7314\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4992 - accuracy: 0.7793 - val_loss: 0.5931 - val_accuracy: 0.7397\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4992 - accuracy: 0.7800 - val_loss: 0.6271 - val_accuracy: 0.7257\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5089 - accuracy: 0.7707 - val_loss: 0.5925 - val_accuracy: 0.7451\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4936 - accuracy: 0.7956 - val_loss: 0.5915 - val_accuracy: 0.7397\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4987 - accuracy: 0.7802 - val_loss: 0.5890 - val_accuracy: 0.7470\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4953 - accuracy: 0.7883 - val_loss: 0.6154 - val_accuracy: 0.7301\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5010 - accuracy: 0.7742 - val_loss: 0.6260 - val_accuracy: 0.7273\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5136 - accuracy: 0.7686 - val_loss: 0.6877 - val_accuracy: 0.7187\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5129 - accuracy: 0.7721 - val_loss: 0.6280 - val_accuracy: 0.7260\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5006 - accuracy: 0.7732 - val_loss: 0.6156 - val_accuracy: 0.7311\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5226 - accuracy: 0.7578 - val_loss: 0.6619 - val_accuracy: 0.7222\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5233 - accuracy: 0.7646 - val_loss: 0.5940 - val_accuracy: 0.7410\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4950 - accuracy: 0.7820 - val_loss: 0.6831 - val_accuracy: 0.7193\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5053 - accuracy: 0.7825 - val_loss: 0.6589 - val_accuracy: 0.6919\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5307 - accuracy: 0.7617 - val_loss: 0.6013 - val_accuracy: 0.7388\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5214 - accuracy: 0.7682 - val_loss: 0.6791 - val_accuracy: 0.6679\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5210 - accuracy: 0.7671 - val_loss: 0.5926 - val_accuracy: 0.7451\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5004 - accuracy: 0.7882 - val_loss: 0.5869 - val_accuracy: 0.7461\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.7968 - val_loss: 0.5867 - val_accuracy: 0.7470\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4902 - accuracy: 0.7926 - val_loss: 0.5864 - val_accuracy: 0.7486\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4878 - accuracy: 0.7981 - val_loss: 0.5848 - val_accuracy: 0.7483\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4915 - accuracy: 0.7919 - val_loss: 0.5844 - val_accuracy: 0.7474\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5105 - accuracy: 0.7749 - val_loss: 0.6471 - val_accuracy: 0.7008\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5234 - accuracy: 0.7675 - val_loss: 0.6010 - val_accuracy: 0.7362\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5076 - accuracy: 0.7708 - val_loss: 0.6488 - val_accuracy: 0.7244\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5323 - accuracy: 0.7535 - val_loss: 0.7195 - val_accuracy: 0.7171\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5471 - accuracy: 0.7511 - val_loss: 0.6991 - val_accuracy: 0.7190\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5410 - accuracy: 0.7546 - val_loss: 0.5875 - val_accuracy: 0.7474\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4921 - accuracy: 0.7886 - val_loss: 0.5884 - val_accuracy: 0.7432\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4853 - accuracy: 0.7959 - val_loss: 0.6054 - val_accuracy: 0.7349\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5171 - accuracy: 0.7655 - val_loss: 0.6074 - val_accuracy: 0.7343\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4884 - accuracy: 0.7898 - val_loss: 0.6125 - val_accuracy: 0.7317\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4984 - accuracy: 0.7808 - val_loss: 0.7090 - val_accuracy: 0.7180\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5371 - accuracy: 0.7584 - val_loss: 0.6404 - val_accuracy: 0.7244\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7816 - val_loss: 0.6091 - val_accuracy: 0.7289\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5078 - accuracy: 0.7767 - val_loss: 0.6061 - val_accuracy: 0.7298\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5091 - accuracy: 0.7797 - val_loss: 0.5907 - val_accuracy: 0.7404\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.7719 - val_loss: 0.6510 - val_accuracy: 0.7247\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5143 - accuracy: 0.7691 - val_loss: 0.5882 - val_accuracy: 0.7464\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4970 - accuracy: 0.7812 - val_loss: 0.6050 - val_accuracy: 0.7311\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5144 - accuracy: 0.7780 - val_loss: 0.7115 - val_accuracy: 0.6274\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5337 - accuracy: 0.7581 - val_loss: 0.6394 - val_accuracy: 0.7094\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5130 - accuracy: 0.7799 - val_loss: 0.5870 - val_accuracy: 0.7474\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5233 - accuracy: 0.7673 - val_loss: 0.6233 - val_accuracy: 0.7187\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5071 - accuracy: 0.7809 - val_loss: 0.5952 - val_accuracy: 0.7445\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4926 - accuracy: 0.7890 - val_loss: 0.5877 - val_accuracy: 0.7464\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5024 - accuracy: 0.7814 - val_loss: 0.6798 - val_accuracy: 0.6654\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5571 - accuracy: 0.7464 - val_loss: 0.6010 - val_accuracy: 0.7362\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5000 - accuracy: 0.7884 - val_loss: 0.5898 - val_accuracy: 0.7426\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4826 - accuracy: 0.7967 - val_loss: 0.6312 - val_accuracy: 0.7279\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5376 - accuracy: 0.7546 - val_loss: 0.6451 - val_accuracy: 0.7244\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5246 - accuracy: 0.7605 - val_loss: 0.5876 - val_accuracy: 0.7432\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4866 - accuracy: 0.7949 - val_loss: 0.5860 - val_accuracy: 0.7426\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4889 - accuracy: 0.7931 - val_loss: 0.5834 - val_accuracy: 0.7483\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4891 - accuracy: 0.7902 - val_loss: 0.5846 - val_accuracy: 0.7493\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.7885 - val_loss: 0.6030 - val_accuracy: 0.7352\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5014 - accuracy: 0.7768 - val_loss: 0.6089 - val_accuracy: 0.7337\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5258 - accuracy: 0.7628 - val_loss: 0.6812 - val_accuracy: 0.7212\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5616 - accuracy: 0.7409 - val_loss: 0.6605 - val_accuracy: 0.7244\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5083 - accuracy: 0.7760 - val_loss: 0.6700 - val_accuracy: 0.7228\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5411 - accuracy: 0.7556 - val_loss: 0.6605 - val_accuracy: 0.7244\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5248 - accuracy: 0.7671 - val_loss: 0.6289 - val_accuracy: 0.7295\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5343 - accuracy: 0.7547 - val_loss: 0.6673 - val_accuracy: 0.7238\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5111 - accuracy: 0.7734 - val_loss: 0.5912 - val_accuracy: 0.7413\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.7929 - val_loss: 0.5850 - val_accuracy: 0.7480\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.7920 - val_loss: 0.7150 - val_accuracy: 0.6246\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5590 - accuracy: 0.7476 - val_loss: 0.6123 - val_accuracy: 0.7295\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7862 - val_loss: 0.5862 - val_accuracy: 0.7423\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4910 - accuracy: 0.7858 - val_loss: 0.6157 - val_accuracy: 0.7273\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5153 - accuracy: 0.7723 - val_loss: 0.6005 - val_accuracy: 0.7337\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5121 - accuracy: 0.7778 - val_loss: 0.6236 - val_accuracy: 0.7190\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5185 - accuracy: 0.7737 - val_loss: 0.6376 - val_accuracy: 0.7097\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5194 - accuracy: 0.7679 - val_loss: 0.5861 - val_accuracy: 0.7467\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4884 - accuracy: 0.7942 - val_loss: 0.5847 - val_accuracy: 0.7442\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4831 - accuracy: 0.7970 - val_loss: 0.5902 - val_accuracy: 0.7404\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4993 - accuracy: 0.7798 - val_loss: 0.6948 - val_accuracy: 0.7193\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5193 - accuracy: 0.7699 - val_loss: 0.7020 - val_accuracy: 0.7190\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5693 - accuracy: 0.7403 - val_loss: 0.6428 - val_accuracy: 0.7260\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5229 - accuracy: 0.7668 - val_loss: 0.7135 - val_accuracy: 0.7183\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5604 - accuracy: 0.7450 - val_loss: 0.6131 - val_accuracy: 0.7346\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4879 - accuracy: 0.7893 - val_loss: 0.6712 - val_accuracy: 0.7225\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5436 - accuracy: 0.7598 - val_loss: 0.6659 - val_accuracy: 0.7241\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5051 - accuracy: 0.7738 - val_loss: 0.5893 - val_accuracy: 0.7416\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.7940 - val_loss: 0.6407 - val_accuracy: 0.7254\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5433 - accuracy: 0.7486 - val_loss: 0.6153 - val_accuracy: 0.7340\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4930 - accuracy: 0.7830 - val_loss: 0.6402 - val_accuracy: 0.7254\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5149 - accuracy: 0.7610 - val_loss: 0.6168 - val_accuracy: 0.7343\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5138 - accuracy: 0.7682 - val_loss: 0.5901 - val_accuracy: 0.7413\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.7927 - val_loss: 0.6316 - val_accuracy: 0.7289\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5370 - accuracy: 0.7554 - val_loss: 0.6172 - val_accuracy: 0.7340\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4895 - accuracy: 0.7913 - val_loss: 0.5821 - val_accuracy: 0.7480\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4887 - accuracy: 0.7906 - val_loss: 0.5840 - val_accuracy: 0.7480\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4919 - accuracy: 0.7914 - val_loss: 0.5831 - val_accuracy: 0.7506\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4977 - accuracy: 0.7771 - val_loss: 0.5916 - val_accuracy: 0.7458\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4897 - accuracy: 0.7922 - val_loss: 0.6871 - val_accuracy: 0.7203\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5314 - accuracy: 0.7606 - val_loss: 0.6616 - val_accuracy: 0.7241\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5103 - accuracy: 0.7727 - val_loss: 0.6531 - val_accuracy: 0.7247\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.5207 - accuracy: 0.7610 - val_loss: 0.6158 - val_accuracy: 0.7343\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4998 - accuracy: 0.7776 - val_loss: 0.6844 - val_accuracy: 0.7215\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5659 - accuracy: 0.7429 - val_loss: 0.5973 - val_accuracy: 0.7407\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5048 - accuracy: 0.7732 - val_loss: 0.6617 - val_accuracy: 0.7244\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5020 - accuracy: 0.7796 - val_loss: 0.6007 - val_accuracy: 0.7388\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4856 - accuracy: 0.7902 - val_loss: 0.5955 - val_accuracy: 0.7397\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4978 - accuracy: 0.7856 - val_loss: 0.6046 - val_accuracy: 0.7305\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5093 - accuracy: 0.7767 - val_loss: 0.6463 - val_accuracy: 0.6986\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5279 - accuracy: 0.7666 - val_loss: 0.5901 - val_accuracy: 0.7474\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4922 - accuracy: 0.7898 - val_loss: 0.6359 - val_accuracy: 0.7075\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5607 - accuracy: 0.7501 - val_loss: 0.6854 - val_accuracy: 0.6628\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5623 - accuracy: 0.7504 - val_loss: 0.5941 - val_accuracy: 0.7419\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4788 - accuracy: 0.7952 - val_loss: 0.5839 - val_accuracy: 0.7464\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4906 - accuracy: 0.7832 - val_loss: 0.6387 - val_accuracy: 0.7266\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5184 - accuracy: 0.7675 - val_loss: 0.6245 - val_accuracy: 0.7308\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5111 - accuracy: 0.7686 - val_loss: 0.6239 - val_accuracy: 0.7308\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5118 - accuracy: 0.7677 - val_loss: 0.6338 - val_accuracy: 0.7285\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5095 - accuracy: 0.7696 - val_loss: 0.6502 - val_accuracy: 0.7247\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5176 - accuracy: 0.7648 - val_loss: 0.6794 - val_accuracy: 0.7222\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5426 - accuracy: 0.7511 - val_loss: 0.6425 - val_accuracy: 0.7266\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4966 - accuracy: 0.7813 - val_loss: 0.5875 - val_accuracy: 0.7419\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.4836 - accuracy: 0.7913 - val_loss: 0.6133 - val_accuracy: 0.7356\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4959 - accuracy: 0.7813 - val_loss: 0.6207 - val_accuracy: 0.7314\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.7730 - val_loss: 0.7426 - val_accuracy: 0.7174\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5334 - accuracy: 0.7678 - val_loss: 0.6038 - val_accuracy: 0.7378\n",
      "Epoch 277/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5030 - accuracy: 0.7766 - val_loss: 0.6014 - val_accuracy: 0.7388\n",
      "Epoch 278/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4886 - accuracy: 0.7896 - val_loss: 0.6312 - val_accuracy: 0.7292\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5327 - accuracy: 0.7585 - val_loss: 0.6364 - val_accuracy: 0.7289\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5102 - accuracy: 0.7730 - val_loss: 0.5800 - val_accuracy: 0.7496\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4804 - accuracy: 0.7985 - val_loss: 0.5798 - val_accuracy: 0.7499\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4828 - accuracy: 0.7960 - val_loss: 0.6101 - val_accuracy: 0.7301\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5182 - accuracy: 0.7750 - val_loss: 0.6991 - val_accuracy: 0.6453\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5940 - accuracy: 0.7196 - val_loss: 0.6996 - val_accuracy: 0.6463\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5217 - accuracy: 0.7703 - val_loss: 0.5828 - val_accuracy: 0.7496\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4889 - accuracy: 0.7957 - val_loss: 0.5866 - val_accuracy: 0.7496\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4883 - accuracy: 0.7902 - val_loss: 0.6531 - val_accuracy: 0.7244\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5146 - accuracy: 0.7683 - val_loss: 0.7224 - val_accuracy: 0.7180\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5586 - accuracy: 0.7472 - val_loss: 0.7432 - val_accuracy: 0.7180\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5092 - accuracy: 0.7804 - val_loss: 0.5889 - val_accuracy: 0.7419\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5117 - accuracy: 0.7760 - val_loss: 0.5945 - val_accuracy: 0.7407\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4971 - accuracy: 0.7825 - val_loss: 0.6726 - val_accuracy: 0.7234\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5505 - accuracy: 0.7471 - val_loss: 0.7136 - val_accuracy: 0.7190\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5453 - accuracy: 0.7506 - val_loss: 0.5828 - val_accuracy: 0.7486\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4842 - accuracy: 0.7976 - val_loss: 0.5825 - val_accuracy: 0.7518\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4818 - accuracy: 0.8005 - val_loss: 0.6413 - val_accuracy: 0.7018\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5240 - accuracy: 0.7643 - val_loss: 0.5798 - val_accuracy: 0.7490\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4833 - accuracy: 0.7944 - val_loss: 0.5839 - val_accuracy: 0.7423\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4953 - accuracy: 0.7839 - val_loss: 0.5973 - val_accuracy: 0.7400\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.7775 - val_loss: 0.5795 - val_accuracy: 0.7496\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4864 - accuracy: 0.7907 - val_loss: 0.6070 - val_accuracy: 0.7333\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5328 - accuracy: 0.7612 - val_loss: 0.6750 - val_accuracy: 0.6695\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5347 - accuracy: 0.7609 - val_loss: 0.5862 - val_accuracy: 0.7474\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5141 - accuracy: 0.7720 - val_loss: 0.5806 - val_accuracy: 0.7480\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4817 - accuracy: 0.7977 - val_loss: 0.5873 - val_accuracy: 0.7423\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5186 - accuracy: 0.7660 - val_loss: 0.6353 - val_accuracy: 0.7305\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5084 - accuracy: 0.7782 - val_loss: 0.6635 - val_accuracy: 0.7238\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5549 - accuracy: 0.7513 - val_loss: 0.6873 - val_accuracy: 0.7222\n",
      "Epoch 309/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5356 - accuracy: 0.7578 - val_loss: 0.5990 - val_accuracy: 0.7324\n",
      "Epoch 310/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4979 - accuracy: 0.7851 - val_loss: 0.5798 - val_accuracy: 0.7477\n",
      "Epoch 311/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4805 - accuracy: 0.7965 - val_loss: 0.5968 - val_accuracy: 0.7416\n",
      "Epoch 312/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4972 - accuracy: 0.7790 - val_loss: 0.6245 - val_accuracy: 0.7311\n",
      "Epoch 313/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5203 - accuracy: 0.7605 - val_loss: 0.6322 - val_accuracy: 0.7305\n",
      "Epoch 314/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5029 - accuracy: 0.7768 - val_loss: 0.5937 - val_accuracy: 0.7416\n",
      "Epoch 315/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4912 - accuracy: 0.7803 - val_loss: 0.6516 - val_accuracy: 0.7250\n",
      "Epoch 316/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5289 - accuracy: 0.7601 - val_loss: 0.6687 - val_accuracy: 0.7241\n",
      "Epoch 317/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5432 - accuracy: 0.7548 - val_loss: 0.5970 - val_accuracy: 0.7407\n",
      "Epoch 318/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5123 - accuracy: 0.7654 - val_loss: 0.6132 - val_accuracy: 0.7349\n",
      "Epoch 319/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5110 - accuracy: 0.7761 - val_loss: 0.6529 - val_accuracy: 0.7254\n",
      "Epoch 320/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5385 - accuracy: 0.7541 - val_loss: 0.5835 - val_accuracy: 0.7477\n",
      "Epoch 321/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4940 - accuracy: 0.7845 - val_loss: 0.6856 - val_accuracy: 0.7222\n",
      "Epoch 322/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5166 - accuracy: 0.7719 - val_loss: 0.6760 - val_accuracy: 0.7234\n",
      "Epoch 323/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5427 - accuracy: 0.7524 - val_loss: 0.6107 - val_accuracy: 0.7362\n",
      "Epoch 324/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5005 - accuracy: 0.7804 - val_loss: 0.5902 - val_accuracy: 0.7416\n",
      "Epoch 325/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4965 - accuracy: 0.7809 - val_loss: 0.5933 - val_accuracy: 0.7410\n",
      "Epoch 326/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4862 - accuracy: 0.7909 - val_loss: 0.6996 - val_accuracy: 0.6453\n",
      "Epoch 327/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5702 - accuracy: 0.7356 - val_loss: 0.5814 - val_accuracy: 0.7528\n",
      "Epoch 328/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4819 - accuracy: 0.8007 - val_loss: 0.6183 - val_accuracy: 0.7241\n",
      "Epoch 329/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5047 - accuracy: 0.7757 - val_loss: 0.6151 - val_accuracy: 0.7359\n",
      "Epoch 330/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5204 - accuracy: 0.7638 - val_loss: 0.6579 - val_accuracy: 0.7247\n",
      "Epoch 331/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5468 - accuracy: 0.7476 - val_loss: 0.5957 - val_accuracy: 0.7413\n",
      "Epoch 332/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4921 - accuracy: 0.7837 - val_loss: 0.5882 - val_accuracy: 0.7416\n",
      "Epoch 333/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5018 - accuracy: 0.7755 - val_loss: 0.6554 - val_accuracy: 0.7250\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5145 - accuracy: 0.7730 - val_loss: 0.5889 - val_accuracy: 0.7416\n",
      "Epoch 335/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4830 - accuracy: 0.7949 - val_loss: 0.6401 - val_accuracy: 0.7273\n",
      "Epoch 336/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5568 - accuracy: 0.7436 - val_loss: 0.6141 - val_accuracy: 0.7359\n",
      "Epoch 337/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5068 - accuracy: 0.7746 - val_loss: 0.6618 - val_accuracy: 0.7241\n",
      "Epoch 338/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5161 - accuracy: 0.7710 - val_loss: 0.5814 - val_accuracy: 0.7496\n",
      "Epoch 339/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5061 - accuracy: 0.7801 - val_loss: 0.6507 - val_accuracy: 0.6947\n",
      "Epoch 340/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5333 - accuracy: 0.7602 - val_loss: 0.6084 - val_accuracy: 0.7321\n",
      "Epoch 341/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4907 - accuracy: 0.7943 - val_loss: 0.5812 - val_accuracy: 0.7464\n",
      "Epoch 342/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4837 - accuracy: 0.7919 - val_loss: 0.5933 - val_accuracy: 0.7384\n",
      "Epoch 343/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5236 - accuracy: 0.7676 - val_loss: 0.6165 - val_accuracy: 0.7231\n",
      "Epoch 344/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4981 - accuracy: 0.7869 - val_loss: 0.5886 - val_accuracy: 0.7455\n",
      "Epoch 345/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4992 - accuracy: 0.7851 - val_loss: 0.7218 - val_accuracy: 0.7180\n",
      "Epoch 346/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5391 - accuracy: 0.7598 - val_loss: 0.5794 - val_accuracy: 0.7483\n",
      "Epoch 347/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4814 - accuracy: 0.7950 - val_loss: 0.5809 - val_accuracy: 0.7448\n",
      "Epoch 348/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4818 - accuracy: 0.7934 - val_loss: 0.5787 - val_accuracy: 0.7480\n",
      "Epoch 349/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4796 - accuracy: 0.7926 - val_loss: 0.5802 - val_accuracy: 0.7445\n",
      "Epoch 350/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4810 - accuracy: 0.7978 - val_loss: 0.5797 - val_accuracy: 0.7445\n",
      "Epoch 351/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.7760 - val_loss: 0.7193 - val_accuracy: 0.7187\n",
      "Epoch 352/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5921 - accuracy: 0.7358 - val_loss: 0.6743 - val_accuracy: 0.7241\n",
      "Epoch 353/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5119 - accuracy: 0.7731 - val_loss: 0.6217 - val_accuracy: 0.7343\n",
      "Epoch 354/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5383 - accuracy: 0.7580 - val_loss: 0.6196 - val_accuracy: 0.7349\n",
      "Epoch 355/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5001 - accuracy: 0.7787 - val_loss: 0.7397 - val_accuracy: 0.7180\n",
      "Epoch 356/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5212 - accuracy: 0.7744 - val_loss: 0.5923 - val_accuracy: 0.7410\n",
      "Epoch 357/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5286 - accuracy: 0.7610 - val_loss: 0.6331 - val_accuracy: 0.7305\n",
      "Epoch 358/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4876 - accuracy: 0.7890 - val_loss: 0.5795 - val_accuracy: 0.7515\n",
      "Epoch 359/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4853 - accuracy: 0.7944 - val_loss: 0.6129 - val_accuracy: 0.7372\n",
      "Epoch 360/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5082 - accuracy: 0.7711 - val_loss: 0.6533 - val_accuracy: 0.7247\n",
      "Epoch 361/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5603 - accuracy: 0.7375 - val_loss: 0.6467 - val_accuracy: 0.7276\n",
      "Epoch 362/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4963 - accuracy: 0.7804 - val_loss: 0.5798 - val_accuracy: 0.7493\n",
      "Epoch 363/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4885 - accuracy: 0.7915 - val_loss: 0.6575 - val_accuracy: 0.7244\n",
      "Epoch 364/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5027 - accuracy: 0.7816 - val_loss: 0.6915 - val_accuracy: 0.7212\n",
      "Epoch 365/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5513 - accuracy: 0.7475 - val_loss: 0.5878 - val_accuracy: 0.7423\n",
      "Epoch 366/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4843 - accuracy: 0.7889 - val_loss: 0.6173 - val_accuracy: 0.7234\n",
      "Epoch 367/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5093 - accuracy: 0.7744 - val_loss: 0.5858 - val_accuracy: 0.7474\n",
      "Epoch 368/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4999 - accuracy: 0.7817 - val_loss: 0.6800 - val_accuracy: 0.6660\n",
      "Epoch 369/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5426 - accuracy: 0.7537 - val_loss: 0.6101 - val_accuracy: 0.7270\n",
      "Epoch 370/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4945 - accuracy: 0.7868 - val_loss: 0.5785 - val_accuracy: 0.7522\n",
      "Epoch 371/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4817 - accuracy: 0.7912 - val_loss: 0.5775 - val_accuracy: 0.7525\n",
      "Epoch 372/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4781 - accuracy: 0.7969 - val_loss: 0.6148 - val_accuracy: 0.7250\n",
      "Epoch 373/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5199 - accuracy: 0.7663 - val_loss: 0.5868 - val_accuracy: 0.7448\n",
      "Epoch 374/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4789 - accuracy: 0.7965 - val_loss: 0.5852 - val_accuracy: 0.7464\n",
      "Epoch 375/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4980 - accuracy: 0.7813 - val_loss: 0.6369 - val_accuracy: 0.7033\n",
      "Epoch 376/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5220 - accuracy: 0.7650 - val_loss: 0.6138 - val_accuracy: 0.7244\n",
      "Epoch 377/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5128 - accuracy: 0.7745 - val_loss: 0.5919 - val_accuracy: 0.7381\n",
      "Epoch 378/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4834 - accuracy: 0.7902 - val_loss: 0.5811 - val_accuracy: 0.7442\n",
      "Epoch 379/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4865 - accuracy: 0.7865 - val_loss: 0.6880 - val_accuracy: 0.7215\n",
      "Epoch 380/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5692 - accuracy: 0.7407 - val_loss: 0.6451 - val_accuracy: 0.7279\n",
      "Epoch 381/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5434 - accuracy: 0.7516 - val_loss: 0.6474 - val_accuracy: 0.7279\n",
      "Epoch 382/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5649 - accuracy: 0.7389 - val_loss: 0.6271 - val_accuracy: 0.7346\n",
      "Epoch 383/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4929 - accuracy: 0.7874 - val_loss: 0.5880 - val_accuracy: 0.7419\n",
      "Epoch 384/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4781 - accuracy: 0.8002 - val_loss: 0.5784 - val_accuracy: 0.7490\n",
      "Epoch 385/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4814 - accuracy: 0.7967 - val_loss: 0.6256 - val_accuracy: 0.7132\n",
      "Epoch 386/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5237 - accuracy: 0.7651 - val_loss: 0.5882 - val_accuracy: 0.7413\n",
      "Epoch 387/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4900 - accuracy: 0.7876 - val_loss: 0.6552 - val_accuracy: 0.6893\n",
      "Epoch 388/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5385 - accuracy: 0.7548 - val_loss: 0.6105 - val_accuracy: 0.7270\n",
      "Epoch 389/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4898 - accuracy: 0.7928 - val_loss: 0.5775 - val_accuracy: 0.7509\n",
      "Epoch 390/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4871 - accuracy: 0.7910 - val_loss: 0.5889 - val_accuracy: 0.7410\n",
      "Epoch 391/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4840 - accuracy: 0.7948 - val_loss: 0.5882 - val_accuracy: 0.7413\n",
      "Epoch 392/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4835 - accuracy: 0.7882 - val_loss: 0.5986 - val_accuracy: 0.7394\n",
      "Epoch 393/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5114 - accuracy: 0.7698 - val_loss: 0.6076 - val_accuracy: 0.7384\n",
      "Epoch 394/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4823 - accuracy: 0.7850 - val_loss: 0.5793 - val_accuracy: 0.7451\n",
      "Epoch 395/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4847 - accuracy: 0.7935 - val_loss: 0.6055 - val_accuracy: 0.7308\n",
      "Epoch 396/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4893 - accuracy: 0.7925 - val_loss: 0.8469 - val_accuracy: 0.4896\n",
      "Epoch 397/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6228 - accuracy: 0.7191 - val_loss: 0.6304 - val_accuracy: 0.7107\n",
      "Epoch 398/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5247 - accuracy: 0.7709 - val_loss: 0.7014 - val_accuracy: 0.6443\n",
      "Epoch 399/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5273 - accuracy: 0.7661 - val_loss: 0.5880 - val_accuracy: 0.7413\n",
      "Epoch 400/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4884 - accuracy: 0.7916 - val_loss: 0.5768 - val_accuracy: 0.7496\n",
      "Epoch 401/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4807 - accuracy: 0.7941 - val_loss: 0.5838 - val_accuracy: 0.7480\n",
      "Epoch 402/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4879 - accuracy: 0.7886 - val_loss: 0.6108 - val_accuracy: 0.7375\n",
      "Epoch 403/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5140 - accuracy: 0.7667 - val_loss: 0.6586 - val_accuracy: 0.7244\n",
      "Epoch 404/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5162 - accuracy: 0.7710 - val_loss: 0.5939 - val_accuracy: 0.7333\n",
      "Epoch 405/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4945 - accuracy: 0.7804 - val_loss: 0.7063 - val_accuracy: 0.6370\n",
      "Epoch 406/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5222 - accuracy: 0.7690 - val_loss: 0.6657 - val_accuracy: 0.6775\n",
      "Epoch 407/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5253 - accuracy: 0.7651 - val_loss: 0.6590 - val_accuracy: 0.6871\n",
      "Epoch 408/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5336 - accuracy: 0.7650 - val_loss: 0.6177 - val_accuracy: 0.7219\n",
      "Epoch 00408: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.01, verbose = 1)\n",
    "model4_reg = model_four_reg()\n",
    "history = model4_reg.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.7219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6177325248718262, 0.7218500971794128]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_reg.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 L1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 34ms/step - loss: 4.7599 - accuracy: 0.7076 - val_loss: 3.9440 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 3.7125 - accuracy: 0.7096 - val_loss: 3.0319 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 2.8373 - accuracy: 0.7106 - val_loss: 2.2797 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 2.1241 - accuracy: 0.7076 - val_loss: 1.6759 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.5595 - accuracy: 0.7055 - val_loss: 1.2260 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.1456 - accuracy: 0.7062 - val_loss: 0.9263 - val_accuracy: 0.7085\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.8837 - accuracy: 0.7042 - val_loss: 0.7731 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7629 - accuracy: 0.7044 - val_loss: 0.7260 - val_accuracy: 0.7085\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.7197 - accuracy: 0.7065 - val_loss: 0.6939 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6854 - accuracy: 0.7119 - val_loss: 0.6728 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6704 - accuracy: 0.7082 - val_loss: 0.6633 - val_accuracy: 0.7085\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6592 - accuracy: 0.7124 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6647 - accuracy: 0.7045 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6617 - accuracy: 0.7078 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6620 - accuracy: 0.7075 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6609 - accuracy: 0.7087 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6652 - accuracy: 0.7039 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6574 - accuracy: 0.7127 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6604 - accuracy: 0.7094 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6621 - accuracy: 0.7074 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6639 - accuracy: 0.7054 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7107 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6601 - accuracy: 0.7097 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6603 - accuracy: 0.7095 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6624 - accuracy: 0.7070 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6654 - accuracy: 0.7039 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6601 - accuracy: 0.7097 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6605 - accuracy: 0.7094 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6623 - accuracy: 0.7073 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6568 - accuracy: 0.7134 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6647 - accuracy: 0.7044 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6606 - accuracy: 0.7091 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6575 - accuracy: 0.7129 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6660 - accuracy: 0.7030 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6630 - accuracy: 0.7066 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6590 - accuracy: 0.7109 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6648 - accuracy: 0.7043 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6658 - accuracy: 0.7032 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6541 - accuracy: 0.7164 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6591 - accuracy: 0.7112 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6566 - accuracy: 0.7142 - val_loss: 0.6609 - val_accuracy: 0.7085\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6672 - accuracy: 0.7016 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6655 - accuracy: 0.7035 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6659 - accuracy: 0.7034 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6601 - accuracy: 0.7096 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7107 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.6642 - accuracy: 0.7051 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6676 - accuracy: 0.7013 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6575 - accuracy: 0.7128 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6574 - accuracy: 0.7129 - val_loss: 0.6621 - val_accuracy: 0.7085\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6578 - accuracy: 0.7130 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6576 - accuracy: 0.7126 - val_loss: 0.6610 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6580 - accuracy: 0.7124 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6615 - accuracy: 0.7082 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6650 - accuracy: 0.7041 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6662 - accuracy: 0.7028 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6590 - accuracy: 0.7109 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6611 - accuracy: 0.7086 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6651 - accuracy: 0.7040 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6620 - accuracy: 0.7076 - val_loss: 0.6610 - val_accuracy: 0.7085\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6616 - accuracy: 0.7079 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6613 - accuracy: 0.7083 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6647 - accuracy: 0.7049 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6635 - accuracy: 0.7059 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6634 - accuracy: 0.7061 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6623 - accuracy: 0.7072 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6582 - accuracy: 0.7118 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6568 - accuracy: 0.7136 - val_loss: 0.6621 - val_accuracy: 0.7085\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6676 - accuracy: 0.7012 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6635 - accuracy: 0.7059 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6633 - accuracy: 0.7062 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7053 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7108 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6640 - accuracy: 0.7053 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6597 - accuracy: 0.7103 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6589 - accuracy: 0.7112 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6596 - accuracy: 0.7104 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6640 - accuracy: 0.7052 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6704 - accuracy: 0.6978 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6607 - accuracy: 0.7091 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6602 - accuracy: 0.7096 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6598 - accuracy: 0.7101 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6621 - accuracy: 0.7075 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6637 - accuracy: 0.7058 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6654 - accuracy: 0.7038 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.7099 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6624 - accuracy: 0.7071 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6636 - accuracy: 0.7060 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6584 - accuracy: 0.7116 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6640 - accuracy: 0.7054 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6618 - accuracy: 0.7080 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6579 - accuracy: 0.7122 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6605 - accuracy: 0.7093 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6582 - accuracy: 0.7120 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.7092 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6595 - accuracy: 0.7104 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6561 - accuracy: 0.7143 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6597 - accuracy: 0.7105 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6619 - accuracy: 0.7078 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6638 - accuracy: 0.7057 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6658 - accuracy: 0.7032 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6640 - accuracy: 0.7054 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6627 - accuracy: 0.7069 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6603 - accuracy: 0.7095 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6661 - accuracy: 0.7029 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6682 - accuracy: 0.7006 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6637 - accuracy: 0.7057 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6605 - accuracy: 0.7094 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6595 - accuracy: 0.7106 - val_loss: 0.6612 - val_accuracy: 0.7085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6595 - accuracy: 0.7104 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6566 - accuracy: 0.7137 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6596 - accuracy: 0.7102 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6661 - accuracy: 0.7027 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7107 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7048 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7050 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6633 - accuracy: 0.7061 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6624 - accuracy: 0.7071 - val_loss: 0.6618 - val_accuracy: 0.7085\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6645 - accuracy: 0.7049 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6647 - accuracy: 0.7050 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6588 - accuracy: 0.7113 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6609 - accuracy: 0.7090 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6615 - accuracy: 0.7083 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6638 - accuracy: 0.7057 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7050 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6696 - accuracy: 0.6990 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6654 - accuracy: 0.7040 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6562 - accuracy: 0.7139 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6616 - accuracy: 0.7079 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6635 - accuracy: 0.7062 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6569 - accuracy: 0.7132 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6610 - accuracy: 0.7090 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6604 - accuracy: 0.7093 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6633 - accuracy: 0.7061 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6614 - accuracy: 0.7085 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6627 - accuracy: 0.7068 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6631 - accuracy: 0.7064 - val_loss: 0.6621 - val_accuracy: 0.7085\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6626 - accuracy: 0.7071 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6639 - accuracy: 0.7056 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6592 - accuracy: 0.7109 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.7085 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6606 - accuracy: 0.7092 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6607 - accuracy: 0.7092 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6685 - accuracy: 0.7004 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6579 - accuracy: 0.7122 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6618 - accuracy: 0.7079 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6577 - accuracy: 0.7125 - val_loss: 0.6619 - val_accuracy: 0.7085\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6617 - accuracy: 0.7081 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6639 - accuracy: 0.7053 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6569 - accuracy: 0.7138 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6585 - accuracy: 0.7118 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6619 - accuracy: 0.7080 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6609 - accuracy: 0.7092 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6646 - accuracy: 0.7047 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.7100 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6642 - accuracy: 0.7054 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6637 - accuracy: 0.7060 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6627 - accuracy: 0.7068 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6576 - accuracy: 0.7127 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6632 - accuracy: 0.7064 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6595 - accuracy: 0.7104 - val_loss: 0.6616 - val_accuracy: 0.7085\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6682 - accuracy: 0.7008 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6562 - accuracy: 0.7140 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6599 - accuracy: 0.7102 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.7085 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6581 - accuracy: 0.7120 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.7087 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6635 - accuracy: 0.7058 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.7091 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6660 - accuracy: 0.7029 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6591 - accuracy: 0.7108 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6616 - accuracy: 0.7081 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6641 - accuracy: 0.7053 - val_loss: 0.6621 - val_accuracy: 0.7085\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6651 - accuracy: 0.7047 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6553 - accuracy: 0.7152 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.7086 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6553 - accuracy: 0.7153 - val_loss: 0.6617 - val_accuracy: 0.7085\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.7094 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6583 - accuracy: 0.7118 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6654 - accuracy: 0.7038 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6602 - accuracy: 0.7097 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 13ms/step - loss: 0.6600 - accuracy: 0.7099 - val_loss: 0.6620 - val_accuracy: 0.7085\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6631 - accuracy: 0.7065 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6634 - accuracy: 0.7060 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6621 - accuracy: 0.7075 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6615 - accuracy: 0.7082 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6595 - accuracy: 0.7104 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6610 - accuracy: 0.7088 - val_loss: 0.6615 - val_accuracy: 0.7085\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6613 - accuracy: 0.7085 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6617 - accuracy: 0.7079 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6625 - accuracy: 0.7070 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6613 - accuracy: 0.7084 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6542 - accuracy: 0.7163 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6639 - accuracy: 0.7055 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6646 - accuracy: 0.7045 - val_loss: 0.6619 - val_accuracy: 0.7085\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6563 - accuracy: 0.7147 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6644 - accuracy: 0.7049 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.7084 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6570 - accuracy: 0.7132 - val_loss: 0.6614 - val_accuracy: 0.7085\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6624 - accuracy: 0.7072 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6646 - accuracy: 0.7047 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6629 - accuracy: 0.7065 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6580 - accuracy: 0.7121 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6646 - accuracy: 0.7045 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6635 - accuracy: 0.7059 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6621 - accuracy: 0.7075 - val_loss: 0.6620 - val_accuracy: 0.7085\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6593 - accuracy: 0.7111 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6644 - accuracy: 0.7047 - val_loss: 0.6618 - val_accuracy: 0.7085\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6674 - accuracy: 0.7022 - val_loss: 0.6612 - val_accuracy: 0.7085\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6601 - accuracy: 0.7098 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6620 - accuracy: 0.7076 - val_loss: 0.6613 - val_accuracy: 0.7085\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.6594 - accuracy: 0.7107 - val_loss: 0.6611 - val_accuracy: 0.7085\n",
      "Epoch 00212: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.01, verbose = 1)\n",
    "model4_reg = model_four_reg('l1')\n",
    "history = model4_reg.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.7085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6611018776893616, 0.7084529399871826]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_reg.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that L1 is more sensitive than L2. Since L1 tends to shrink coefficients to zero, the absence of features causes a more drastic change in the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding dropout to best two models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a dropout layer\n",
    "def model_one_reg_dropout(reg='l2'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "    \n",
    "    return model1\n",
    "\n",
    "#added hidden layer\n",
    "#adding a dropout layer\n",
    "def model_four_reg_dropout(reg='l2'):   \n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(40 ,input_shape=(86,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(Dense(10 ,input_shape=(20,) ,activation='sigmoid' ,kernel_regularizer=reg))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=['accuracy'])\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 L2 dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 33ms/step - loss: 1.1350 - accuracy: 0.7027 - val_loss: 1.0779 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0509 - accuracy: 0.7099 - val_loss: 1.0056 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9863 - accuracy: 0.7078 - val_loss: 0.9540 - val_accuracy: 0.7120\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9239 - accuracy: 0.7111 - val_loss: 0.9040 - val_accuracy: 0.7136\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8675 - accuracy: 0.7199 - val_loss: 0.8638 - val_accuracy: 0.7152\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8257 - accuracy: 0.7245 - val_loss: 0.8343 - val_accuracy: 0.7282\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7848 - accuracy: 0.7285 - val_loss: 0.7924 - val_accuracy: 0.7164\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7593 - accuracy: 0.7257 - val_loss: 0.7644 - val_accuracy: 0.7199\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7201 - accuracy: 0.7349 - val_loss: 0.7417 - val_accuracy: 0.7270\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7003 - accuracy: 0.7365 - val_loss: 0.7191 - val_accuracy: 0.7215\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6795 - accuracy: 0.7370 - val_loss: 0.7026 - val_accuracy: 0.7203\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6552 - accuracy: 0.7395 - val_loss: 0.6840 - val_accuracy: 0.7337\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6327 - accuracy: 0.7493 - val_loss: 0.6683 - val_accuracy: 0.7317\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6183 - accuracy: 0.7488 - val_loss: 0.6557 - val_accuracy: 0.7276\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6066 - accuracy: 0.7462 - val_loss: 0.6434 - val_accuracy: 0.7314\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5935 - accuracy: 0.7535 - val_loss: 0.6333 - val_accuracy: 0.7311\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5836 - accuracy: 0.7533 - val_loss: 0.6242 - val_accuracy: 0.7352\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5759 - accuracy: 0.7525 - val_loss: 0.6161 - val_accuracy: 0.7343\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5695 - accuracy: 0.7513 - val_loss: 0.6092 - val_accuracy: 0.7394\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5601 - accuracy: 0.7543 - val_loss: 0.6023 - val_accuracy: 0.7359\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5486 - accuracy: 0.7544 - val_loss: 0.5975 - val_accuracy: 0.7432\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5384 - accuracy: 0.7642 - val_loss: 0.5933 - val_accuracy: 0.7340\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.7534 - val_loss: 0.5879 - val_accuracy: 0.7416\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5397 - accuracy: 0.7529 - val_loss: 0.5876 - val_accuracy: 0.7439\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5342 - accuracy: 0.7525 - val_loss: 0.5809 - val_accuracy: 0.7435\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5326 - accuracy: 0.7572 - val_loss: 0.5775 - val_accuracy: 0.7397\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5250 - accuracy: 0.7574 - val_loss: 0.5752 - val_accuracy: 0.7439\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5240 - accuracy: 0.7566 - val_loss: 0.5731 - val_accuracy: 0.7445\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.7572 - val_loss: 0.5702 - val_accuracy: 0.7410\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5160 - accuracy: 0.7550 - val_loss: 0.5681 - val_accuracy: 0.7432\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5165 - accuracy: 0.7600 - val_loss: 0.5663 - val_accuracy: 0.7429\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5102 - accuracy: 0.7593 - val_loss: 0.5674 - val_accuracy: 0.7464\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5144 - accuracy: 0.7576 - val_loss: 0.5637 - val_accuracy: 0.7451\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5153 - accuracy: 0.7544 - val_loss: 0.5624 - val_accuracy: 0.7461\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5101 - accuracy: 0.7555 - val_loss: 0.5610 - val_accuracy: 0.7439\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5148 - accuracy: 0.7562 - val_loss: 0.5618 - val_accuracy: 0.7381\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5054 - accuracy: 0.7641 - val_loss: 0.5605 - val_accuracy: 0.7410\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5022 - accuracy: 0.7610 - val_loss: 0.5589 - val_accuracy: 0.7461\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5100 - accuracy: 0.7590 - val_loss: 0.5618 - val_accuracy: 0.7455\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4992 - accuracy: 0.7662 - val_loss: 0.5576 - val_accuracy: 0.7458\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4959 - accuracy: 0.7694 - val_loss: 0.5592 - val_accuracy: 0.7470\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5079 - accuracy: 0.7591 - val_loss: 0.5567 - val_accuracy: 0.7467\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4971 - accuracy: 0.7676 - val_loss: 0.5560 - val_accuracy: 0.7423\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4999 - accuracy: 0.7671 - val_loss: 0.5564 - val_accuracy: 0.7461\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5008 - accuracy: 0.7640 - val_loss: 0.5570 - val_accuracy: 0.7467\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5034 - accuracy: 0.7598 - val_loss: 0.5549 - val_accuracy: 0.7486\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5043 - accuracy: 0.7546 - val_loss: 0.5545 - val_accuracy: 0.7480\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5002 - accuracy: 0.7614 - val_loss: 0.5549 - val_accuracy: 0.7458\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4924 - accuracy: 0.7641 - val_loss: 0.5560 - val_accuracy: 0.7477\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5026 - accuracy: 0.7633 - val_loss: 0.5567 - val_accuracy: 0.7480\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4909 - accuracy: 0.7660 - val_loss: 0.5540 - val_accuracy: 0.7496\n",
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5011 - accuracy: 0.7585 - val_loss: 0.5528 - val_accuracy: 0.7451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4967 - accuracy: 0.7661 - val_loss: 0.5555 - val_accuracy: 0.7474\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4899 - accuracy: 0.7714 - val_loss: 0.5545 - val_accuracy: 0.7486\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4960 - accuracy: 0.7608 - val_loss: 0.5545 - val_accuracy: 0.7496\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5009 - accuracy: 0.7607 - val_loss: 0.5532 - val_accuracy: 0.7486\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5020 - accuracy: 0.7671 - val_loss: 0.5560 - val_accuracy: 0.7483\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4952 - accuracy: 0.7746 - val_loss: 0.5524 - val_accuracy: 0.7477\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5006 - accuracy: 0.7597 - val_loss: 0.5545 - val_accuracy: 0.7480\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4982 - accuracy: 0.7669 - val_loss: 0.5518 - val_accuracy: 0.7470\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4893 - accuracy: 0.7653 - val_loss: 0.5563 - val_accuracy: 0.7474\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4865 - accuracy: 0.7711 - val_loss: 0.5568 - val_accuracy: 0.7455\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4980 - accuracy: 0.7635 - val_loss: 0.5509 - val_accuracy: 0.7483\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4990 - accuracy: 0.7633 - val_loss: 0.5547 - val_accuracy: 0.7470\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4900 - accuracy: 0.7756 - val_loss: 0.5574 - val_accuracy: 0.7455\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4967 - accuracy: 0.7646 - val_loss: 0.5573 - val_accuracy: 0.7455\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.4899 - accuracy: 0.7700 - val_loss: 0.5500 - val_accuracy: 0.7486\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4961 - accuracy: 0.7641 - val_loss: 0.5509 - val_accuracy: 0.7493\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4866 - accuracy: 0.7717 - val_loss: 0.5546 - val_accuracy: 0.7486\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4966 - accuracy: 0.7651 - val_loss: 0.5514 - val_accuracy: 0.7506\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4944 - accuracy: 0.7648 - val_loss: 0.5533 - val_accuracy: 0.7486\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4982 - accuracy: 0.7630 - val_loss: 0.5511 - val_accuracy: 0.7509\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4972 - accuracy: 0.7673 - val_loss: 0.5505 - val_accuracy: 0.7512\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4934 - accuracy: 0.7644 - val_loss: 0.5552 - val_accuracy: 0.7464\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4872 - accuracy: 0.7710 - val_loss: 0.5547 - val_accuracy: 0.7486\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4878 - accuracy: 0.7760 - val_loss: 0.5534 - val_accuracy: 0.7493\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4941 - accuracy: 0.7592 - val_loss: 0.5615 - val_accuracy: 0.7423\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4916 - accuracy: 0.7621 - val_loss: 0.5578 - val_accuracy: 0.7423\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5006 - accuracy: 0.7612 - val_loss: 0.5525 - val_accuracy: 0.7493\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4951 - accuracy: 0.7634 - val_loss: 0.5522 - val_accuracy: 0.7493\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4858 - accuracy: 0.7747 - val_loss: 0.5558 - val_accuracy: 0.7455\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5005 - accuracy: 0.7613 - val_loss: 0.5504 - val_accuracy: 0.7525\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4979 - accuracy: 0.7651 - val_loss: 0.5547 - val_accuracy: 0.7461\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4952 - accuracy: 0.7704 - val_loss: 0.5595 - val_accuracy: 0.7429\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4948 - accuracy: 0.7654 - val_loss: 0.5495 - val_accuracy: 0.7515\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5000 - accuracy: 0.7573 - val_loss: 0.5550 - val_accuracy: 0.7470\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5010 - accuracy: 0.7614 - val_loss: 0.5507 - val_accuracy: 0.7502\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4913 - accuracy: 0.7679 - val_loss: 0.5556 - val_accuracy: 0.7448\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4973 - accuracy: 0.7628 - val_loss: 0.5487 - val_accuracy: 0.7515\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4938 - accuracy: 0.7637 - val_loss: 0.5563 - val_accuracy: 0.7432\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4883 - accuracy: 0.7727 - val_loss: 0.5524 - val_accuracy: 0.7483\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4970 - accuracy: 0.7636 - val_loss: 0.5578 - val_accuracy: 0.7423\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4936 - accuracy: 0.7730 - val_loss: 0.5480 - val_accuracy: 0.7499\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4933 - accuracy: 0.7663 - val_loss: 0.5594 - val_accuracy: 0.7426\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4912 - accuracy: 0.7716 - val_loss: 0.5789 - val_accuracy: 0.7330\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4890 - accuracy: 0.7718 - val_loss: 0.5572 - val_accuracy: 0.7439\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4887 - accuracy: 0.7732 - val_loss: 0.5526 - val_accuracy: 0.7483\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4934 - accuracy: 0.7649 - val_loss: 0.5537 - val_accuracy: 0.7464\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4839 - accuracy: 0.7707 - val_loss: 0.5575 - val_accuracy: 0.7432\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4893 - accuracy: 0.7686 - val_loss: 0.5579 - val_accuracy: 0.7429\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4904 - accuracy: 0.7725 - val_loss: 0.5476 - val_accuracy: 0.7502\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4893 - accuracy: 0.7705 - val_loss: 0.5571 - val_accuracy: 0.7429\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4920 - accuracy: 0.7688 - val_loss: 0.5532 - val_accuracy: 0.7467\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4908 - accuracy: 0.7693 - val_loss: 0.5593 - val_accuracy: 0.7429\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4903 - accuracy: 0.7712 - val_loss: 0.5562 - val_accuracy: 0.7419\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4935 - accuracy: 0.7683 - val_loss: 0.5579 - val_accuracy: 0.7423\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4969 - accuracy: 0.7639 - val_loss: 0.5502 - val_accuracy: 0.7509\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4975 - accuracy: 0.7629 - val_loss: 0.5475 - val_accuracy: 0.7515\n",
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4868 - accuracy: 0.7684 - val_loss: 0.5593 - val_accuracy: 0.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4942 - accuracy: 0.7669 - val_loss: 0.5556 - val_accuracy: 0.7419\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4934 - accuracy: 0.7658 - val_loss: 0.5532 - val_accuracy: 0.7464\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4863 - accuracy: 0.7659 - val_loss: 0.5538 - val_accuracy: 0.7464\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.7713 - val_loss: 0.5494 - val_accuracy: 0.7512\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.7670 - val_loss: 0.5557 - val_accuracy: 0.7439\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4939 - accuracy: 0.7631 - val_loss: 0.5506 - val_accuracy: 0.7509\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4901 - accuracy: 0.7635 - val_loss: 0.5500 - val_accuracy: 0.7512\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4901 - accuracy: 0.7659 - val_loss: 0.5548 - val_accuracy: 0.7439\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4923 - accuracy: 0.7705 - val_loss: 0.5511 - val_accuracy: 0.7499\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4815 - accuracy: 0.7726 - val_loss: 0.5529 - val_accuracy: 0.7480\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.7710 - val_loss: 0.5575 - val_accuracy: 0.7423\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4937 - accuracy: 0.7697 - val_loss: 0.5565 - val_accuracy: 0.7429\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4840 - accuracy: 0.7702 - val_loss: 0.5618 - val_accuracy: 0.7419\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4877 - accuracy: 0.7667 - val_loss: 0.5495 - val_accuracy: 0.7506\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4875 - accuracy: 0.7692 - val_loss: 0.5532 - val_accuracy: 0.7455\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4883 - accuracy: 0.7622 - val_loss: 0.5558 - val_accuracy: 0.7419\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4859 - accuracy: 0.7684 - val_loss: 0.5526 - val_accuracy: 0.7467\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4904 - accuracy: 0.7682 - val_loss: 0.5567 - val_accuracy: 0.7416\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4938 - accuracy: 0.7639 - val_loss: 0.5540 - val_accuracy: 0.7426\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4845 - accuracy: 0.7759 - val_loss: 0.5534 - val_accuracy: 0.7448\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4863 - accuracy: 0.7727 - val_loss: 0.5661 - val_accuracy: 0.7394\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4866 - accuracy: 0.7724 - val_loss: 0.5583 - val_accuracy: 0.7429\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4901 - accuracy: 0.7709 - val_loss: 0.5484 - val_accuracy: 0.7518\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4878 - accuracy: 0.7681 - val_loss: 0.5558 - val_accuracy: 0.7426\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4835 - accuracy: 0.7729 - val_loss: 0.5558 - val_accuracy: 0.7416\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4859 - accuracy: 0.7724 - val_loss: 0.5550 - val_accuracy: 0.7429\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4869 - accuracy: 0.7745 - val_loss: 0.5574 - val_accuracy: 0.7432\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4914 - accuracy: 0.7638 - val_loss: 0.5557 - val_accuracy: 0.7432\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4839 - accuracy: 0.7735 - val_loss: 0.5498 - val_accuracy: 0.7483\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4911 - accuracy: 0.7677 - val_loss: 0.5501 - val_accuracy: 0.7480\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4902 - accuracy: 0.7642 - val_loss: 0.5499 - val_accuracy: 0.7480\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4845 - accuracy: 0.7679 - val_loss: 0.5592 - val_accuracy: 0.7416\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4860 - accuracy: 0.7721 - val_loss: 0.5556 - val_accuracy: 0.7435\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4920 - accuracy: 0.7649 - val_loss: 0.5634 - val_accuracy: 0.7407\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4915 - accuracy: 0.7655 - val_loss: 0.5495 - val_accuracy: 0.7499\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4861 - accuracy: 0.7700 - val_loss: 0.5499 - val_accuracy: 0.7470\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4885 - accuracy: 0.7640 - val_loss: 0.5524 - val_accuracy: 0.7445\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4859 - accuracy: 0.7784 - val_loss: 0.5658 - val_accuracy: 0.7397\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4919 - accuracy: 0.7682 - val_loss: 0.5505 - val_accuracy: 0.7477\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.7646 - val_loss: 0.5523 - val_accuracy: 0.7448\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4866 - accuracy: 0.7724 - val_loss: 0.5493 - val_accuracy: 0.7509\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4860 - accuracy: 0.7673 - val_loss: 0.5536 - val_accuracy: 0.7423\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4835 - accuracy: 0.7725 - val_loss: 0.5497 - val_accuracy: 0.7480\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4898 - accuracy: 0.7664 - val_loss: 0.5507 - val_accuracy: 0.7477\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.7715 - val_loss: 0.5484 - val_accuracy: 0.7502\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4887 - accuracy: 0.7720 - val_loss: 0.5528 - val_accuracy: 0.7429\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4910 - accuracy: 0.7701 - val_loss: 0.5503 - val_accuracy: 0.7477\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4834 - accuracy: 0.7720 - val_loss: 0.5555 - val_accuracy: 0.7435\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4875 - accuracy: 0.7672 - val_loss: 0.5560 - val_accuracy: 0.7423\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.7699 - val_loss: 0.5662 - val_accuracy: 0.7381\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4844 - accuracy: 0.7712 - val_loss: 0.5541 - val_accuracy: 0.7426\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4938 - accuracy: 0.7636 - val_loss: 0.5594 - val_accuracy: 0.7423\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4939 - accuracy: 0.7651 - val_loss: 0.5523 - val_accuracy: 0.7445\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4812 - accuracy: 0.7732 - val_loss: 0.5546 - val_accuracy: 0.7419\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4787 - accuracy: 0.7792 - val_loss: 0.5613 - val_accuracy: 0.7413\n",
      "Epoch 165/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4902 - accuracy: 0.7625 - val_loss: 0.5508 - val_accuracy: 0.7470\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4928 - accuracy: 0.7657 - val_loss: 0.5617 - val_accuracy: 0.7404\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4873 - accuracy: 0.7703 - val_loss: 0.5581 - val_accuracy: 0.7435\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4960 - accuracy: 0.7641 - val_loss: 0.5533 - val_accuracy: 0.7426\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4948 - accuracy: 0.7620 - val_loss: 0.5550 - val_accuracy: 0.7423\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4879 - accuracy: 0.7715 - val_loss: 0.5473 - val_accuracy: 0.7518\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4883 - accuracy: 0.7666 - val_loss: 0.5542 - val_accuracy: 0.7410\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4858 - accuracy: 0.7703 - val_loss: 0.5502 - val_accuracy: 0.7483\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4782 - accuracy: 0.7780 - val_loss: 0.5482 - val_accuracy: 0.7525\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4831 - accuracy: 0.7665 - val_loss: 0.5520 - val_accuracy: 0.7435\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4882 - accuracy: 0.7663 - val_loss: 0.5617 - val_accuracy: 0.7407\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4867 - accuracy: 0.7664 - val_loss: 0.5551 - val_accuracy: 0.7435\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4859 - accuracy: 0.7731 - val_loss: 0.5540 - val_accuracy: 0.7423\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4832 - accuracy: 0.7696 - val_loss: 0.5475 - val_accuracy: 0.7506\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4809 - accuracy: 0.7697 - val_loss: 0.5560 - val_accuracy: 0.7429\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4815 - accuracy: 0.7725 - val_loss: 0.5552 - val_accuracy: 0.7435\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4864 - accuracy: 0.7673 - val_loss: 0.5474 - val_accuracy: 0.7522\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4814 - accuracy: 0.7774 - val_loss: 0.5583 - val_accuracy: 0.7423\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.7737 - val_loss: 0.5523 - val_accuracy: 0.7432\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4901 - accuracy: 0.7625 - val_loss: 0.5462 - val_accuracy: 0.7512\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4894 - accuracy: 0.7654 - val_loss: 0.5533 - val_accuracy: 0.7429\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4770 - accuracy: 0.7780 - val_loss: 0.5650 - val_accuracy: 0.7391\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4877 - accuracy: 0.7652 - val_loss: 0.5476 - val_accuracy: 0.7506\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4862 - accuracy: 0.7694 - val_loss: 0.5522 - val_accuracy: 0.7432\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4805 - accuracy: 0.7716 - val_loss: 0.5494 - val_accuracy: 0.7474\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4785 - accuracy: 0.7792 - val_loss: 0.5466 - val_accuracy: 0.7509\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4795 - accuracy: 0.7741 - val_loss: 0.5508 - val_accuracy: 0.7432\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4829 - accuracy: 0.7716 - val_loss: 0.5495 - val_accuracy: 0.7477\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4788 - accuracy: 0.7676 - val_loss: 0.5456 - val_accuracy: 0.7522\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4851 - accuracy: 0.7725 - val_loss: 0.5479 - val_accuracy: 0.7480\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4819 - accuracy: 0.7744 - val_loss: 0.5491 - val_accuracy: 0.7467\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4877 - accuracy: 0.7639 - val_loss: 0.5500 - val_accuracy: 0.7442\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4888 - accuracy: 0.7659 - val_loss: 0.5455 - val_accuracy: 0.7518\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4866 - accuracy: 0.7710 - val_loss: 0.5503 - val_accuracy: 0.7432\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4844 - accuracy: 0.7674 - val_loss: 0.5523 - val_accuracy: 0.7423\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4792 - accuracy: 0.7707 - val_loss: 0.5552 - val_accuracy: 0.7429\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4760 - accuracy: 0.7744 - val_loss: 0.5475 - val_accuracy: 0.7486\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4842 - accuracy: 0.7726 - val_loss: 0.5436 - val_accuracy: 0.7512\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4827 - accuracy: 0.7726 - val_loss: 0.5608 - val_accuracy: 0.7404\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4788 - accuracy: 0.7777 - val_loss: 0.5535 - val_accuracy: 0.7416\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4825 - accuracy: 0.7677 - val_loss: 0.5470 - val_accuracy: 0.7512\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4842 - accuracy: 0.7688 - val_loss: 0.5508 - val_accuracy: 0.7419\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4824 - accuracy: 0.7737 - val_loss: 0.5457 - val_accuracy: 0.7518\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4835 - accuracy: 0.7685 - val_loss: 0.5456 - val_accuracy: 0.7525\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4744 - accuracy: 0.7749 - val_loss: 0.5544 - val_accuracy: 0.7439\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4802 - accuracy: 0.7740 - val_loss: 0.5572 - val_accuracy: 0.7429\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4837 - accuracy: 0.7724 - val_loss: 0.5519 - val_accuracy: 0.7432\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4803 - accuracy: 0.7757 - val_loss: 0.5467 - val_accuracy: 0.7496\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4803 - accuracy: 0.7721 - val_loss: 0.5496 - val_accuracy: 0.7445\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4883 - accuracy: 0.7669 - val_loss: 0.5594 - val_accuracy: 0.7413\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4864 - accuracy: 0.7700 - val_loss: 0.5515 - val_accuracy: 0.7429\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4879 - accuracy: 0.7714 - val_loss: 0.5520 - val_accuracy: 0.7429\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4889 - accuracy: 0.7680 - val_loss: 0.5507 - val_accuracy: 0.7423\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4852 - accuracy: 0.7673 - val_loss: 0.5489 - val_accuracy: 0.7458\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4868 - accuracy: 0.7638 - val_loss: 0.5470 - val_accuracy: 0.7496\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4863 - accuracy: 0.7730 - val_loss: 0.5513 - val_accuracy: 0.7432\n",
      "Epoch 221/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4832 - accuracy: 0.7732 - val_loss: 0.5500 - val_accuracy: 0.7423\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4767 - accuracy: 0.7747 - val_loss: 0.5469 - val_accuracy: 0.7493\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4809 - accuracy: 0.7683 - val_loss: 0.5435 - val_accuracy: 0.7531\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4749 - accuracy: 0.7770 - val_loss: 0.5601 - val_accuracy: 0.7416\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.4849 - accuracy: 0.7760 - val_loss: 0.5522 - val_accuracy: 0.7416\n",
      "Epoch 00225: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model1_reg_drop = model_one_reg_dropout()\n",
    "history = model1_reg_drop.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5522 - accuracy: 0.7416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.552169680595398, 0.7416267991065979]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_reg_drop.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix ,precision_recall_curve ,f1_score ,precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_v_threshold(precisions ,recalls ,thresholds):\n",
    "    plt.plot(thresholds ,precisions[:-1] ,'b--' ,label=\"Precision\")\n",
    "    plt.plot(thresholds ,recalls[:-1] ,'g-' ,label='Recall')\n",
    "    plt.xlabel('threshold')\n",
    "    plt.legend(loc='center left')\n",
    "    plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1316 1433]\n",
      " [ 503 6151]]\n",
      "0.8110495780590717\n",
      "0.9244063721070033\n",
      "0.8640258463267312\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(model1_reg_drop.predict(x_train)).astype(int)\n",
    "print(confusion_matrix(y_train_bool ,y_pred))\n",
    "print(precision_score(y_train_bool ,y_pred))\n",
    "print(recall_score(y_train_bool ,y_pred))\n",
    "print(f1_score(y_train_bool, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions ,recalls ,thresholds = precision_recall_curve(y_train_bool ,y_pred)\n",
    "plot_precision_recall_v_threshold(precisions ,recalls ,thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 L2 dropout:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "10/10 [==============================] - 1s 35ms/step - loss: 1.2881 - accuracy: 0.7085 - val_loss: 1.2315 - val_accuracy: 0.7085\n",
      "Epoch 2/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.2068 - accuracy: 0.7108 - val_loss: 1.1586 - val_accuracy: 0.7085\n",
      "Epoch 3/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.1440 - accuracy: 0.7031 - val_loss: 1.0971 - val_accuracy: 0.7085\n",
      "Epoch 4/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 1.0809 - accuracy: 0.7046 - val_loss: 1.0425 - val_accuracy: 0.7085\n",
      "Epoch 5/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 1.0233 - accuracy: 0.7074 - val_loss: 0.9926 - val_accuracy: 0.7085\n",
      "Epoch 6/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9771 - accuracy: 0.7056 - val_loss: 0.9485 - val_accuracy: 0.7085\n",
      "Epoch 7/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.9298 - accuracy: 0.7100 - val_loss: 0.9105 - val_accuracy: 0.7085\n",
      "Epoch 8/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8964 - accuracy: 0.7046 - val_loss: 0.8755 - val_accuracy: 0.7085\n",
      "Epoch 9/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.8615 - accuracy: 0.7067 - val_loss: 0.8447 - val_accuracy: 0.7085\n",
      "Epoch 10/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.8359 - accuracy: 0.7026 - val_loss: 0.8185 - val_accuracy: 0.7085\n",
      "Epoch 11/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.8079 - accuracy: 0.7042 - val_loss: 0.7952 - val_accuracy: 0.7085\n",
      "Epoch 12/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7768 - accuracy: 0.7126 - val_loss: 0.7734 - val_accuracy: 0.7085\n",
      "Epoch 13/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7636 - accuracy: 0.7043 - val_loss: 0.7542 - val_accuracy: 0.7085\n",
      "Epoch 14/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7422 - accuracy: 0.7073 - val_loss: 0.7377 - val_accuracy: 0.7085\n",
      "Epoch 15/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.7225 - accuracy: 0.7114 - val_loss: 0.7228 - val_accuracy: 0.7085\n",
      "Epoch 16/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.7116 - accuracy: 0.7070 - val_loss: 0.7110 - val_accuracy: 0.7085\n",
      "Epoch 17/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6992 - accuracy: 0.7068 - val_loss: 0.6986 - val_accuracy: 0.7085\n",
      "Epoch 18/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6870 - accuracy: 0.7076 - val_loss: 0.6881 - val_accuracy: 0.7085\n",
      "Epoch 19/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6748 - accuracy: 0.7099 - val_loss: 0.6791 - val_accuracy: 0.7085\n",
      "Epoch 20/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6670 - accuracy: 0.7090 - val_loss: 0.6711 - val_accuracy: 0.7085\n",
      "Epoch 21/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6624 - accuracy: 0.7056 - val_loss: 0.6638 - val_accuracy: 0.7085\n",
      "Epoch 22/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6497 - accuracy: 0.7100 - val_loss: 0.6581 - val_accuracy: 0.7085\n",
      "Epoch 23/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6466 - accuracy: 0.7065 - val_loss: 0.6521 - val_accuracy: 0.7085\n",
      "Epoch 24/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6380 - accuracy: 0.7094 - val_loss: 0.6477 - val_accuracy: 0.7085\n",
      "Epoch 25/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6362 - accuracy: 0.7068 - val_loss: 0.6425 - val_accuracy: 0.7085\n",
      "Epoch 26/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6287 - accuracy: 0.7095 - val_loss: 0.6386 - val_accuracy: 0.7085\n",
      "Epoch 27/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6228 - accuracy: 0.7121 - val_loss: 0.6355 - val_accuracy: 0.7085\n",
      "Epoch 28/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6209 - accuracy: 0.7070 - val_loss: 0.6323 - val_accuracy: 0.7085\n",
      "Epoch 29/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6152 - accuracy: 0.7103 - val_loss: 0.6295 - val_accuracy: 0.7085\n",
      "Epoch 30/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.7091 - val_loss: 0.6278 - val_accuracy: 0.7085\n",
      "Epoch 31/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.6091 - accuracy: 0.7114 - val_loss: 0.6249 - val_accuracy: 0.7085\n",
      "Epoch 32/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6088 - accuracy: 0.7062 - val_loss: 0.6228 - val_accuracy: 0.7085\n",
      "Epoch 33/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6097 - accuracy: 0.7037 - val_loss: 0.6218 - val_accuracy: 0.7085\n",
      "Epoch 34/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6085 - accuracy: 0.7033 - val_loss: 0.6205 - val_accuracy: 0.7085\n",
      "Epoch 35/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5992 - accuracy: 0.7100 - val_loss: 0.6181 - val_accuracy: 0.7085\n",
      "Epoch 36/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.6010 - accuracy: 0.7057 - val_loss: 0.6179 - val_accuracy: 0.7085\n",
      "Epoch 37/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5978 - accuracy: 0.7086 - val_loss: 0.6161 - val_accuracy: 0.7085\n",
      "Epoch 38/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5953 - accuracy: 0.7093 - val_loss: 0.6153 - val_accuracy: 0.7085\n",
      "Epoch 39/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5919 - accuracy: 0.7100 - val_loss: 0.6143 - val_accuracy: 0.7088\n",
      "Epoch 40/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5873 - accuracy: 0.7148 - val_loss: 0.6140 - val_accuracy: 0.7088\n",
      "Epoch 41/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5849 - accuracy: 0.7154 - val_loss: 0.6138 - val_accuracy: 0.7088\n",
      "Epoch 42/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5873 - accuracy: 0.7090 - val_loss: 0.6133 - val_accuracy: 0.7100\n",
      "Epoch 43/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5804 - accuracy: 0.7188 - val_loss: 0.6113 - val_accuracy: 0.7126\n",
      "Epoch 44/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5824 - accuracy: 0.7149 - val_loss: 0.6124 - val_accuracy: 0.7126\n",
      "Epoch 45/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5774 - accuracy: 0.7164 - val_loss: 0.6120 - val_accuracy: 0.7129\n",
      "Epoch 46/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5846 - accuracy: 0.7111 - val_loss: 0.6104 - val_accuracy: 0.7139\n",
      "Epoch 47/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5778 - accuracy: 0.7206 - val_loss: 0.6139 - val_accuracy: 0.7132\n",
      "Epoch 48/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5738 - accuracy: 0.7204 - val_loss: 0.6102 - val_accuracy: 0.7145\n",
      "Epoch 49/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5782 - accuracy: 0.7191 - val_loss: 0.6149 - val_accuracy: 0.7139\n",
      "Epoch 50/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5710 - accuracy: 0.7231 - val_loss: 0.6159 - val_accuracy: 0.7139\n",
      "Epoch 51/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5704 - accuracy: 0.7217 - val_loss: 0.6105 - val_accuracy: 0.7142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5750 - accuracy: 0.7199 - val_loss: 0.6111 - val_accuracy: 0.7142\n",
      "Epoch 53/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5624 - accuracy: 0.7270 - val_loss: 0.6098 - val_accuracy: 0.7139\n",
      "Epoch 54/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5675 - accuracy: 0.7255 - val_loss: 0.6166 - val_accuracy: 0.7145\n",
      "Epoch 55/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5726 - accuracy: 0.7232 - val_loss: 0.6155 - val_accuracy: 0.7142\n",
      "Epoch 56/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5640 - accuracy: 0.7295 - val_loss: 0.6090 - val_accuracy: 0.7152\n",
      "Epoch 57/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5625 - accuracy: 0.7327 - val_loss: 0.6127 - val_accuracy: 0.7142\n",
      "Epoch 58/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5622 - accuracy: 0.7317 - val_loss: 0.6076 - val_accuracy: 0.7167\n",
      "Epoch 59/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5639 - accuracy: 0.7376 - val_loss: 0.6107 - val_accuracy: 0.7152\n",
      "Epoch 60/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5678 - accuracy: 0.7284 - val_loss: 0.6169 - val_accuracy: 0.7139\n",
      "Epoch 61/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5607 - accuracy: 0.7352 - val_loss: 0.6125 - val_accuracy: 0.7152\n",
      "Epoch 62/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5644 - accuracy: 0.7292 - val_loss: 0.6165 - val_accuracy: 0.7152\n",
      "Epoch 63/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5570 - accuracy: 0.7415 - val_loss: 0.6128 - val_accuracy: 0.7152\n",
      "Epoch 64/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5543 - accuracy: 0.7415 - val_loss: 0.6121 - val_accuracy: 0.7158\n",
      "Epoch 65/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5536 - accuracy: 0.7368 - val_loss: 0.6154 - val_accuracy: 0.7152\n",
      "Epoch 66/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5572 - accuracy: 0.7383 - val_loss: 0.6177 - val_accuracy: 0.7152\n",
      "Epoch 67/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5587 - accuracy: 0.7340 - val_loss: 0.6180 - val_accuracy: 0.7152\n",
      "Epoch 68/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5526 - accuracy: 0.7379 - val_loss: 0.6135 - val_accuracy: 0.7164\n",
      "Epoch 69/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5628 - accuracy: 0.7314 - val_loss: 0.6192 - val_accuracy: 0.7152\n",
      "Epoch 70/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5496 - accuracy: 0.7403 - val_loss: 0.6073 - val_accuracy: 0.7183\n",
      "Epoch 71/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5540 - accuracy: 0.7443 - val_loss: 0.6078 - val_accuracy: 0.7187\n",
      "Epoch 72/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5583 - accuracy: 0.7387 - val_loss: 0.6134 - val_accuracy: 0.7174\n",
      "Epoch 73/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5578 - accuracy: 0.7394 - val_loss: 0.6118 - val_accuracy: 0.7180\n",
      "Epoch 74/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5481 - accuracy: 0.7479 - val_loss: 0.6103 - val_accuracy: 0.7180\n",
      "Epoch 75/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5581 - accuracy: 0.7378 - val_loss: 0.6136 - val_accuracy: 0.7177\n",
      "Epoch 76/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5478 - accuracy: 0.7466 - val_loss: 0.6103 - val_accuracy: 0.7180\n",
      "Epoch 77/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5442 - accuracy: 0.7495 - val_loss: 0.6130 - val_accuracy: 0.7174\n",
      "Epoch 78/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.7487 - val_loss: 0.6091 - val_accuracy: 0.7187\n",
      "Epoch 79/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5492 - accuracy: 0.7435 - val_loss: 0.6091 - val_accuracy: 0.7187\n",
      "Epoch 80/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5489 - accuracy: 0.7418 - val_loss: 0.6068 - val_accuracy: 0.7209\n",
      "Epoch 81/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5490 - accuracy: 0.7416 - val_loss: 0.6079 - val_accuracy: 0.7193\n",
      "Epoch 82/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5500 - accuracy: 0.7441 - val_loss: 0.6065 - val_accuracy: 0.7206\n",
      "Epoch 83/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5482 - accuracy: 0.7494 - val_loss: 0.6045 - val_accuracy: 0.7212\n",
      "Epoch 84/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5524 - accuracy: 0.7404 - val_loss: 0.6148 - val_accuracy: 0.7177\n",
      "Epoch 85/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5420 - accuracy: 0.7518 - val_loss: 0.6059 - val_accuracy: 0.7209\n",
      "Epoch 86/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5482 - accuracy: 0.7476 - val_loss: 0.6042 - val_accuracy: 0.7209\n",
      "Epoch 87/1000\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.5455 - accuracy: 0.7519 - val_loss: 0.6092 - val_accuracy: 0.7183\n",
      "Epoch 88/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5457 - accuracy: 0.7463 - val_loss: 0.6095 - val_accuracy: 0.7180\n",
      "Epoch 89/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5434 - accuracy: 0.7560 - val_loss: 0.6100 - val_accuracy: 0.7180\n",
      "Epoch 90/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5405 - accuracy: 0.7543 - val_loss: 0.6036 - val_accuracy: 0.7219\n",
      "Epoch 91/1000\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5384 - accuracy: 0.7526 - val_loss: 0.6033 - val_accuracy: 0.7234\n",
      "Epoch 92/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5418 - accuracy: 0.7476 - val_loss: 0.6126 - val_accuracy: 0.7180\n",
      "Epoch 93/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5430 - accuracy: 0.7478 - val_loss: 0.6034 - val_accuracy: 0.7212\n",
      "Epoch 94/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5423 - accuracy: 0.7500 - val_loss: 0.6028 - val_accuracy: 0.7225\n",
      "Epoch 95/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5430 - accuracy: 0.7538 - val_loss: 0.6069 - val_accuracy: 0.7209\n",
      "Epoch 96/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5448 - accuracy: 0.7520 - val_loss: 0.6131 - val_accuracy: 0.7183\n",
      "Epoch 97/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5542 - accuracy: 0.7428 - val_loss: 0.6002 - val_accuracy: 0.7250\n",
      "Epoch 98/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5377 - accuracy: 0.7614 - val_loss: 0.6097 - val_accuracy: 0.7187\n",
      "Epoch 99/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5395 - accuracy: 0.7491 - val_loss: 0.6037 - val_accuracy: 0.7212\n",
      "Epoch 100/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5443 - accuracy: 0.7474 - val_loss: 0.6006 - val_accuracy: 0.7241\n",
      "Epoch 101/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5455 - accuracy: 0.7492 - val_loss: 0.6064 - val_accuracy: 0.7212\n",
      "Epoch 102/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5392 - accuracy: 0.7562 - val_loss: 0.5981 - val_accuracy: 0.7260\n",
      "Epoch 103/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5362 - accuracy: 0.7575 - val_loss: 0.6098 - val_accuracy: 0.7187\n",
      "Epoch 104/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5346 - accuracy: 0.7532 - val_loss: 0.5987 - val_accuracy: 0.7257\n",
      "Epoch 105/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5388 - accuracy: 0.7531 - val_loss: 0.6088 - val_accuracy: 0.7209\n",
      "Epoch 106/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5355 - accuracy: 0.7539 - val_loss: 0.6075 - val_accuracy: 0.7215\n",
      "Epoch 107/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5430 - accuracy: 0.7503 - val_loss: 0.6058 - val_accuracy: 0.7215\n",
      "Epoch 108/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5378 - accuracy: 0.7519 - val_loss: 0.5961 - val_accuracy: 0.7273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5406 - accuracy: 0.7514 - val_loss: 0.5959 - val_accuracy: 0.7333\n",
      "Epoch 110/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5431 - accuracy: 0.7480 - val_loss: 0.5986 - val_accuracy: 0.7247\n",
      "Epoch 111/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5347 - accuracy: 0.7550 - val_loss: 0.5980 - val_accuracy: 0.7250\n",
      "Epoch 112/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5400 - accuracy: 0.7580 - val_loss: 0.6056 - val_accuracy: 0.7215\n",
      "Epoch 113/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5377 - accuracy: 0.7537 - val_loss: 0.6086 - val_accuracy: 0.7212\n",
      "Epoch 114/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5391 - accuracy: 0.7552 - val_loss: 0.6059 - val_accuracy: 0.7219\n",
      "Epoch 115/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5392 - accuracy: 0.7551 - val_loss: 0.6006 - val_accuracy: 0.7238\n",
      "Epoch 116/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5350 - accuracy: 0.7575 - val_loss: 0.6017 - val_accuracy: 0.7222\n",
      "Epoch 117/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5378 - accuracy: 0.7485 - val_loss: 0.6003 - val_accuracy: 0.7231\n",
      "Epoch 118/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5365 - accuracy: 0.7548 - val_loss: 0.5984 - val_accuracy: 0.7247\n",
      "Epoch 119/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5398 - accuracy: 0.7528 - val_loss: 0.5942 - val_accuracy: 0.7289\n",
      "Epoch 120/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5370 - accuracy: 0.7529 - val_loss: 0.6181 - val_accuracy: 0.7174\n",
      "Epoch 121/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5369 - accuracy: 0.7486 - val_loss: 0.6049 - val_accuracy: 0.7219\n",
      "Epoch 122/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5438 - accuracy: 0.7521 - val_loss: 0.6102 - val_accuracy: 0.7190\n",
      "Epoch 123/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5345 - accuracy: 0.7559 - val_loss: 0.6065 - val_accuracy: 0.7215\n",
      "Epoch 124/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5339 - accuracy: 0.7514 - val_loss: 0.5982 - val_accuracy: 0.7238\n",
      "Epoch 125/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5361 - accuracy: 0.7530 - val_loss: 0.5992 - val_accuracy: 0.7241\n",
      "Epoch 126/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5341 - accuracy: 0.7565 - val_loss: 0.5944 - val_accuracy: 0.7263\n",
      "Epoch 127/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5309 - accuracy: 0.7531 - val_loss: 0.5956 - val_accuracy: 0.7247\n",
      "Epoch 128/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5313 - accuracy: 0.7584 - val_loss: 0.5925 - val_accuracy: 0.7346\n",
      "Epoch 129/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5318 - accuracy: 0.7607 - val_loss: 0.5920 - val_accuracy: 0.7349\n",
      "Epoch 130/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5318 - accuracy: 0.7641 - val_loss: 0.5934 - val_accuracy: 0.7273\n",
      "Epoch 131/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5266 - accuracy: 0.7624 - val_loss: 0.5921 - val_accuracy: 0.7321\n",
      "Epoch 132/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5358 - accuracy: 0.7547 - val_loss: 0.6040 - val_accuracy: 0.7231\n",
      "Epoch 133/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5315 - accuracy: 0.7520 - val_loss: 0.5953 - val_accuracy: 0.7250\n",
      "Epoch 134/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5380 - accuracy: 0.7529 - val_loss: 0.5958 - val_accuracy: 0.7250\n",
      "Epoch 135/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5273 - accuracy: 0.7602 - val_loss: 0.5914 - val_accuracy: 0.7321\n",
      "Epoch 136/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5319 - accuracy: 0.7564 - val_loss: 0.5913 - val_accuracy: 0.7327\n",
      "Epoch 137/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5321 - accuracy: 0.7537 - val_loss: 0.5913 - val_accuracy: 0.7349\n",
      "Epoch 138/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5318 - accuracy: 0.7545 - val_loss: 0.6116 - val_accuracy: 0.7199\n",
      "Epoch 139/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5342 - accuracy: 0.7561 - val_loss: 0.5967 - val_accuracy: 0.7244\n",
      "Epoch 140/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5400 - accuracy: 0.7527 - val_loss: 0.6005 - val_accuracy: 0.7228\n",
      "Epoch 141/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5309 - accuracy: 0.7527 - val_loss: 0.5936 - val_accuracy: 0.7257\n",
      "Epoch 142/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5291 - accuracy: 0.7553 - val_loss: 0.5922 - val_accuracy: 0.7279\n",
      "Epoch 143/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5309 - accuracy: 0.7525 - val_loss: 0.5937 - val_accuracy: 0.7254\n",
      "Epoch 144/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5331 - accuracy: 0.7500 - val_loss: 0.5901 - val_accuracy: 0.7346\n",
      "Epoch 145/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5315 - accuracy: 0.7549 - val_loss: 0.5911 - val_accuracy: 0.7282\n",
      "Epoch 146/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5372 - accuracy: 0.7511 - val_loss: 0.5994 - val_accuracy: 0.7228\n",
      "Epoch 147/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5305 - accuracy: 0.7635 - val_loss: 0.5899 - val_accuracy: 0.7311\n",
      "Epoch 148/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5201 - accuracy: 0.7626 - val_loss: 0.6046 - val_accuracy: 0.7231\n",
      "Epoch 149/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5275 - accuracy: 0.7626 - val_loss: 0.5909 - val_accuracy: 0.7289\n",
      "Epoch 150/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5272 - accuracy: 0.7602 - val_loss: 0.5887 - val_accuracy: 0.7349\n",
      "Epoch 151/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5271 - accuracy: 0.7579 - val_loss: 0.5887 - val_accuracy: 0.7333\n",
      "Epoch 152/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5386 - accuracy: 0.7602 - val_loss: 0.5883 - val_accuracy: 0.7352\n",
      "Epoch 153/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5341 - accuracy: 0.7568 - val_loss: 0.5925 - val_accuracy: 0.7254\n",
      "Epoch 154/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5259 - accuracy: 0.7568 - val_loss: 0.5883 - val_accuracy: 0.7349\n",
      "Epoch 155/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5308 - accuracy: 0.7569 - val_loss: 0.5887 - val_accuracy: 0.7327\n",
      "Epoch 156/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5286 - accuracy: 0.7608 - val_loss: 0.5887 - val_accuracy: 0.7372\n",
      "Epoch 157/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5329 - accuracy: 0.7574 - val_loss: 0.5912 - val_accuracy: 0.7276\n",
      "Epoch 158/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5278 - accuracy: 0.7579 - val_loss: 0.5923 - val_accuracy: 0.7250\n",
      "Epoch 159/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5267 - accuracy: 0.7613 - val_loss: 0.5958 - val_accuracy: 0.7254\n",
      "Epoch 160/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5298 - accuracy: 0.7565 - val_loss: 0.6088 - val_accuracy: 0.7206\n",
      "Epoch 161/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5285 - accuracy: 0.7589 - val_loss: 0.5957 - val_accuracy: 0.7250\n",
      "Epoch 162/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5311 - accuracy: 0.7620 - val_loss: 0.5889 - val_accuracy: 0.7327\n",
      "Epoch 163/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5293 - accuracy: 0.7548 - val_loss: 0.5915 - val_accuracy: 0.7260\n",
      "Epoch 164/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5276 - accuracy: 0.7502 - val_loss: 0.5941 - val_accuracy: 0.7241\n",
      "Epoch 165/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5288 - accuracy: 0.7561 - val_loss: 0.5871 - val_accuracy: 0.7340\n",
      "Epoch 166/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5237 - accuracy: 0.7574 - val_loss: 0.5994 - val_accuracy: 0.7228\n",
      "Epoch 167/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5348 - accuracy: 0.7502 - val_loss: 0.5867 - val_accuracy: 0.7352\n",
      "Epoch 168/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5257 - accuracy: 0.7621 - val_loss: 0.5976 - val_accuracy: 0.7254\n",
      "Epoch 169/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5247 - accuracy: 0.7586 - val_loss: 0.5907 - val_accuracy: 0.7270\n",
      "Epoch 170/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.7568 - val_loss: 0.5870 - val_accuracy: 0.7327\n",
      "Epoch 171/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5279 - accuracy: 0.7592 - val_loss: 0.5982 - val_accuracy: 0.7241\n",
      "Epoch 172/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5217 - accuracy: 0.7639 - val_loss: 0.5883 - val_accuracy: 0.7301\n",
      "Epoch 173/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5253 - accuracy: 0.7566 - val_loss: 0.5961 - val_accuracy: 0.7257\n",
      "Epoch 174/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5279 - accuracy: 0.7541 - val_loss: 0.5863 - val_accuracy: 0.7340\n",
      "Epoch 175/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5254 - accuracy: 0.7555 - val_loss: 0.5854 - val_accuracy: 0.7368\n",
      "Epoch 176/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5195 - accuracy: 0.7649 - val_loss: 0.5922 - val_accuracy: 0.7263\n",
      "Epoch 177/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5319 - accuracy: 0.7526 - val_loss: 0.5853 - val_accuracy: 0.7352\n",
      "Epoch 178/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5285 - accuracy: 0.7582 - val_loss: 0.5852 - val_accuracy: 0.7346\n",
      "Epoch 179/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5254 - accuracy: 0.7602 - val_loss: 0.5848 - val_accuracy: 0.7352\n",
      "Epoch 180/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5275 - accuracy: 0.7575 - val_loss: 0.5869 - val_accuracy: 0.7327\n",
      "Epoch 181/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5280 - accuracy: 0.7543 - val_loss: 0.6019 - val_accuracy: 0.7228\n",
      "Epoch 182/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5357 - accuracy: 0.7534 - val_loss: 0.5941 - val_accuracy: 0.7375\n",
      "Epoch 183/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5302 - accuracy: 0.7572 - val_loss: 0.5918 - val_accuracy: 0.7260\n",
      "Epoch 184/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5297 - accuracy: 0.7520 - val_loss: 0.6090 - val_accuracy: 0.7209\n",
      "Epoch 185/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5344 - accuracy: 0.7532 - val_loss: 0.5864 - val_accuracy: 0.7324\n",
      "Epoch 186/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5262 - accuracy: 0.7565 - val_loss: 0.5848 - val_accuracy: 0.7340\n",
      "Epoch 187/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5233 - accuracy: 0.7648 - val_loss: 0.5871 - val_accuracy: 0.7314\n",
      "Epoch 188/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5249 - accuracy: 0.7599 - val_loss: 0.5908 - val_accuracy: 0.7250\n",
      "Epoch 189/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5249 - accuracy: 0.7587 - val_loss: 0.5921 - val_accuracy: 0.7397\n",
      "Epoch 190/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5323 - accuracy: 0.7539 - val_loss: 0.5921 - val_accuracy: 0.7257\n",
      "Epoch 191/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5233 - accuracy: 0.7678 - val_loss: 0.5845 - val_accuracy: 0.7407\n",
      "Epoch 192/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5271 - accuracy: 0.7572 - val_loss: 0.5875 - val_accuracy: 0.7308\n",
      "Epoch 193/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5243 - accuracy: 0.7554 - val_loss: 0.5847 - val_accuracy: 0.7330\n",
      "Epoch 194/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5261 - accuracy: 0.7531 - val_loss: 0.5834 - val_accuracy: 0.7384\n",
      "Epoch 195/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5243 - accuracy: 0.7582 - val_loss: 0.5888 - val_accuracy: 0.7270\n",
      "Epoch 196/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5244 - accuracy: 0.7561 - val_loss: 0.5843 - val_accuracy: 0.7400\n",
      "Epoch 197/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5160 - accuracy: 0.7705 - val_loss: 0.5830 - val_accuracy: 0.7359\n",
      "Epoch 198/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5249 - accuracy: 0.7594 - val_loss: 0.5828 - val_accuracy: 0.7388\n",
      "Epoch 199/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5232 - accuracy: 0.7623 - val_loss: 0.5871 - val_accuracy: 0.7461\n",
      "Epoch 200/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5236 - accuracy: 0.7578 - val_loss: 0.5936 - val_accuracy: 0.7257\n",
      "Epoch 201/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5250 - accuracy: 0.7592 - val_loss: 0.5824 - val_accuracy: 0.7368\n",
      "Epoch 202/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5246 - accuracy: 0.7630 - val_loss: 0.5855 - val_accuracy: 0.7321\n",
      "Epoch 203/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5254 - accuracy: 0.7548 - val_loss: 0.5827 - val_accuracy: 0.7346\n",
      "Epoch 204/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5269 - accuracy: 0.7544 - val_loss: 0.5876 - val_accuracy: 0.7295\n",
      "Epoch 205/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5202 - accuracy: 0.7614 - val_loss: 0.5854 - val_accuracy: 0.7317\n",
      "Epoch 206/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5214 - accuracy: 0.7591 - val_loss: 0.5908 - val_accuracy: 0.7263\n",
      "Epoch 207/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5133 - accuracy: 0.7626 - val_loss: 0.5835 - val_accuracy: 0.7340\n",
      "Epoch 208/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5279 - accuracy: 0.7588 - val_loss: 0.5964 - val_accuracy: 0.7381\n",
      "Epoch 209/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5295 - accuracy: 0.7572 - val_loss: 0.5822 - val_accuracy: 0.7410\n",
      "Epoch 210/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5190 - accuracy: 0.7619 - val_loss: 0.5880 - val_accuracy: 0.7273\n",
      "Epoch 211/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5299 - accuracy: 0.7518 - val_loss: 0.5866 - val_accuracy: 0.7439\n",
      "Epoch 212/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5271 - accuracy: 0.7626 - val_loss: 0.5858 - val_accuracy: 0.7321\n",
      "Epoch 213/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5186 - accuracy: 0.7692 - val_loss: 0.5916 - val_accuracy: 0.7400\n",
      "Epoch 214/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5285 - accuracy: 0.7560 - val_loss: 0.6100 - val_accuracy: 0.7212\n",
      "Epoch 215/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5306 - accuracy: 0.7524 - val_loss: 0.5825 - val_accuracy: 0.7337\n",
      "Epoch 216/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5272 - accuracy: 0.7530 - val_loss: 0.5917 - val_accuracy: 0.7263\n",
      "Epoch 217/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5218 - accuracy: 0.7620 - val_loss: 0.5840 - val_accuracy: 0.7327\n",
      "Epoch 218/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5177 - accuracy: 0.7657 - val_loss: 0.5843 - val_accuracy: 0.7317\n",
      "Epoch 219/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5212 - accuracy: 0.7611 - val_loss: 0.5808 - val_accuracy: 0.7404\n",
      "Epoch 220/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5188 - accuracy: 0.7649 - val_loss: 0.5812 - val_accuracy: 0.7407\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5166 - accuracy: 0.7642 - val_loss: 0.5820 - val_accuracy: 0.7333\n",
      "Epoch 222/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5261 - accuracy: 0.7598 - val_loss: 0.5918 - val_accuracy: 0.7423\n",
      "Epoch 223/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5292 - accuracy: 0.7538 - val_loss: 0.5813 - val_accuracy: 0.7407\n",
      "Epoch 224/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5218 - accuracy: 0.7608 - val_loss: 0.5842 - val_accuracy: 0.7451\n",
      "Epoch 225/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5267 - accuracy: 0.7604 - val_loss: 0.5867 - val_accuracy: 0.7305\n",
      "Epoch 226/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5242 - accuracy: 0.7584 - val_loss: 0.5880 - val_accuracy: 0.7279\n",
      "Epoch 227/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5194 - accuracy: 0.7666 - val_loss: 0.5821 - val_accuracy: 0.7426\n",
      "Epoch 228/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5241 - accuracy: 0.7571 - val_loss: 0.5875 - val_accuracy: 0.7282\n",
      "Epoch 229/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5205 - accuracy: 0.7623 - val_loss: 0.5809 - val_accuracy: 0.7356\n",
      "Epoch 230/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5178 - accuracy: 0.7648 - val_loss: 0.5802 - val_accuracy: 0.7384\n",
      "Epoch 231/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5240 - accuracy: 0.7591 - val_loss: 0.5813 - val_accuracy: 0.7340\n",
      "Epoch 232/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5259 - accuracy: 0.7552 - val_loss: 0.5851 - val_accuracy: 0.7317\n",
      "Epoch 233/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5188 - accuracy: 0.7647 - val_loss: 0.5826 - val_accuracy: 0.7445\n",
      "Epoch 234/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5273 - accuracy: 0.7536 - val_loss: 0.5815 - val_accuracy: 0.7413\n",
      "Epoch 235/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5199 - accuracy: 0.7596 - val_loss: 0.5850 - val_accuracy: 0.7321\n",
      "Epoch 236/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5258 - accuracy: 0.7590 - val_loss: 0.5943 - val_accuracy: 0.7257\n",
      "Epoch 237/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5227 - accuracy: 0.7628 - val_loss: 0.6032 - val_accuracy: 0.7231\n",
      "Epoch 238/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5187 - accuracy: 0.7627 - val_loss: 0.5797 - val_accuracy: 0.7388\n",
      "Epoch 239/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5257 - accuracy: 0.7561 - val_loss: 0.5807 - val_accuracy: 0.7343\n",
      "Epoch 240/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5205 - accuracy: 0.7571 - val_loss: 0.5849 - val_accuracy: 0.7317\n",
      "Epoch 241/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5171 - accuracy: 0.7666 - val_loss: 0.5797 - val_accuracy: 0.7384\n",
      "Epoch 242/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5157 - accuracy: 0.7656 - val_loss: 0.5803 - val_accuracy: 0.7359\n",
      "Epoch 243/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5246 - accuracy: 0.7636 - val_loss: 0.5837 - val_accuracy: 0.7327\n",
      "Epoch 244/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5240 - accuracy: 0.7595 - val_loss: 0.5815 - val_accuracy: 0.7445\n",
      "Epoch 245/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5206 - accuracy: 0.7606 - val_loss: 0.5794 - val_accuracy: 0.7391\n",
      "Epoch 246/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5147 - accuracy: 0.7671 - val_loss: 0.5947 - val_accuracy: 0.7254\n",
      "Epoch 247/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5134 - accuracy: 0.7685 - val_loss: 0.5809 - val_accuracy: 0.7442\n",
      "Epoch 248/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5165 - accuracy: 0.7632 - val_loss: 0.5792 - val_accuracy: 0.7381\n",
      "Epoch 249/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5155 - accuracy: 0.7653 - val_loss: 0.5943 - val_accuracy: 0.7250\n",
      "Epoch 250/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5209 - accuracy: 0.7536 - val_loss: 0.5793 - val_accuracy: 0.7388\n",
      "Epoch 251/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5209 - accuracy: 0.7622 - val_loss: 0.5920 - val_accuracy: 0.7397\n",
      "Epoch 252/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5252 - accuracy: 0.7593 - val_loss: 0.5825 - val_accuracy: 0.7333\n",
      "Epoch 253/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5171 - accuracy: 0.7661 - val_loss: 0.5931 - val_accuracy: 0.7404\n",
      "Epoch 254/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5229 - accuracy: 0.7636 - val_loss: 0.5813 - val_accuracy: 0.7337\n",
      "Epoch 255/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5162 - accuracy: 0.7605 - val_loss: 0.5800 - val_accuracy: 0.7346\n",
      "Epoch 256/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5244 - accuracy: 0.7588 - val_loss: 0.6025 - val_accuracy: 0.7231\n",
      "Epoch 257/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5272 - accuracy: 0.7528 - val_loss: 0.5805 - val_accuracy: 0.7340\n",
      "Epoch 258/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5218 - accuracy: 0.7586 - val_loss: 0.5790 - val_accuracy: 0.7413\n",
      "Epoch 259/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5213 - accuracy: 0.7594 - val_loss: 0.5836 - val_accuracy: 0.7451\n",
      "Epoch 260/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5135 - accuracy: 0.7706 - val_loss: 0.5831 - val_accuracy: 0.7330\n",
      "Epoch 261/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5194 - accuracy: 0.7614 - val_loss: 0.5782 - val_accuracy: 0.7388\n",
      "Epoch 262/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5153 - accuracy: 0.7663 - val_loss: 0.6209 - val_accuracy: 0.7244\n",
      "Epoch 263/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5368 - accuracy: 0.7559 - val_loss: 0.5941 - val_accuracy: 0.7266\n",
      "Epoch 264/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5280 - accuracy: 0.7552 - val_loss: 0.5785 - val_accuracy: 0.7375\n",
      "Epoch 265/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5215 - accuracy: 0.7627 - val_loss: 0.5788 - val_accuracy: 0.7419\n",
      "Epoch 266/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5214 - accuracy: 0.7531 - val_loss: 0.5864 - val_accuracy: 0.7400\n",
      "Epoch 267/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5179 - accuracy: 0.7655 - val_loss: 0.5850 - val_accuracy: 0.7423\n",
      "Epoch 268/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5172 - accuracy: 0.7693 - val_loss: 0.5930 - val_accuracy: 0.7397\n",
      "Epoch 269/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5291 - accuracy: 0.7576 - val_loss: 0.5780 - val_accuracy: 0.7432\n",
      "Epoch 270/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5185 - accuracy: 0.7629 - val_loss: 0.5864 - val_accuracy: 0.7416\n",
      "Epoch 271/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5225 - accuracy: 0.7563 - val_loss: 0.5780 - val_accuracy: 0.7397\n",
      "Epoch 272/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5136 - accuracy: 0.7731 - val_loss: 0.5836 - val_accuracy: 0.7311\n",
      "Epoch 273/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5173 - accuracy: 0.7617 - val_loss: 0.5778 - val_accuracy: 0.7394\n",
      "Epoch 274/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5241 - accuracy: 0.7610 - val_loss: 0.5830 - val_accuracy: 0.7439\n",
      "Epoch 275/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5264 - accuracy: 0.7543 - val_loss: 0.5813 - val_accuracy: 0.7464\n",
      "Epoch 276/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5187 - accuracy: 0.7612 - val_loss: 0.5787 - val_accuracy: 0.7429\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5120 - accuracy: 0.7675 - val_loss: 0.5788 - val_accuracy: 0.7435\n",
      "Epoch 278/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5233 - accuracy: 0.7652 - val_loss: 0.5776 - val_accuracy: 0.7423\n",
      "Epoch 279/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5126 - accuracy: 0.7676 - val_loss: 0.5776 - val_accuracy: 0.7397\n",
      "Epoch 280/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5166 - accuracy: 0.7682 - val_loss: 0.5839 - val_accuracy: 0.7426\n",
      "Epoch 281/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5188 - accuracy: 0.7554 - val_loss: 0.6097 - val_accuracy: 0.7222\n",
      "Epoch 282/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5345 - accuracy: 0.7497 - val_loss: 0.5775 - val_accuracy: 0.7394\n",
      "Epoch 283/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5128 - accuracy: 0.7626 - val_loss: 0.5818 - val_accuracy: 0.7340\n",
      "Epoch 284/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5166 - accuracy: 0.7674 - val_loss: 0.5773 - val_accuracy: 0.7400\n",
      "Epoch 285/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5232 - accuracy: 0.7601 - val_loss: 0.5916 - val_accuracy: 0.7260\n",
      "Epoch 286/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5360 - accuracy: 0.7529 - val_loss: 0.5856 - val_accuracy: 0.7301\n",
      "Epoch 287/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5162 - accuracy: 0.7612 - val_loss: 0.5784 - val_accuracy: 0.7356\n",
      "Epoch 288/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5230 - accuracy: 0.7563 - val_loss: 0.5774 - val_accuracy: 0.7372\n",
      "Epoch 289/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5179 - accuracy: 0.7620 - val_loss: 0.5968 - val_accuracy: 0.7247\n",
      "Epoch 290/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5278 - accuracy: 0.7593 - val_loss: 0.5768 - val_accuracy: 0.7407\n",
      "Epoch 291/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5150 - accuracy: 0.7651 - val_loss: 0.5782 - val_accuracy: 0.7356\n",
      "Epoch 292/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5192 - accuracy: 0.7620 - val_loss: 0.5853 - val_accuracy: 0.7305\n",
      "Epoch 293/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5303 - accuracy: 0.7544 - val_loss: 0.6178 - val_accuracy: 0.7206\n",
      "Epoch 294/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5230 - accuracy: 0.7607 - val_loss: 0.5803 - val_accuracy: 0.7343\n",
      "Epoch 295/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5129 - accuracy: 0.7639 - val_loss: 0.5808 - val_accuracy: 0.7333\n",
      "Epoch 296/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5205 - accuracy: 0.7605 - val_loss: 0.5803 - val_accuracy: 0.7337\n",
      "Epoch 297/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5201 - accuracy: 0.7645 - val_loss: 0.5768 - val_accuracy: 0.7416\n",
      "Epoch 298/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5196 - accuracy: 0.7587 - val_loss: 0.5769 - val_accuracy: 0.7391\n",
      "Epoch 299/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5184 - accuracy: 0.7650 - val_loss: 0.5771 - val_accuracy: 0.7426\n",
      "Epoch 300/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5111 - accuracy: 0.7707 - val_loss: 0.5810 - val_accuracy: 0.7337\n",
      "Epoch 301/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5232 - accuracy: 0.7576 - val_loss: 0.5782 - val_accuracy: 0.7461\n",
      "Epoch 302/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5184 - accuracy: 0.7673 - val_loss: 0.5912 - val_accuracy: 0.7407\n",
      "Epoch 303/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5248 - accuracy: 0.7608 - val_loss: 0.5798 - val_accuracy: 0.7458\n",
      "Epoch 304/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5169 - accuracy: 0.7608 - val_loss: 0.5778 - val_accuracy: 0.7359\n",
      "Epoch 305/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5213 - accuracy: 0.7661 - val_loss: 0.6167 - val_accuracy: 0.7247\n",
      "Epoch 306/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5351 - accuracy: 0.7534 - val_loss: 0.5917 - val_accuracy: 0.7391\n",
      "Epoch 307/1000\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.5149 - accuracy: 0.7642 - val_loss: 0.5773 - val_accuracy: 0.7432\n",
      "Epoch 308/1000\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.5143 - accuracy: 0.7603 - val_loss: 0.5779 - val_accuracy: 0.7352\n",
      "Epoch 00308: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "model4_reg_drop = model_four_reg_dropout()\n",
    "history = model4_reg_drop.fit(x_train ,y_train_bool ,epochs = 1000 ,validation_data=(x_val, y_val_bool)\n",
    "              ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "#Plot train vs test accuracy per epoch\n",
    "plt.figure()\n",
    "# Use the history metrics\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "# Make it pretty\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5779 - accuracy: 0.7352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5778772234916687, 0.7352471947669983]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_reg_drop.evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 919 1830]\n",
      " [ 296 6358]]\n",
      "0.7765021983390328\n",
      "0.9555154794108807\n",
      "0.8567578493464493\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(model4_reg_drop.predict(x_train)).astype(int)\n",
    "print(confusion_matrix(y_train_bool ,y_pred))\n",
    "print(precision_score(y_train_bool ,y_pred))\n",
    "print(recall_score(y_train_bool ,y_pred))\n",
    "print(f1_score(y_train_bool, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precisions ,recalls ,thresholds = precision_recall_curve(y_train_bool ,y_pred)\n",
    "plot_precision_recall_v_threshold(precisions ,recalls ,thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1 cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1785 - accuracy: 0.6047\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0380 - accuracy: 0.7048\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9486 - accuracy: 0.7154\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8828 - accuracy: 0.7172\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8185 - accuracy: 0.7228\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7711 - accuracy: 0.7306\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7239 - accuracy: 0.7385\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6943 - accuracy: 0.7402\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6561 - accuracy: 0.7515\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6287 - accuracy: 0.7577\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6057 - accuracy: 0.7571\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.7610\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5697 - accuracy: 0.7605\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5548 - accuracy: 0.7659\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.7639\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7675\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5267 - accuracy: 0.7659\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7695\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5133 - accuracy: 0.7684\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7708\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7699\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4941 - accuracy: 0.7763\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7711\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7736\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4841 - accuracy: 0.7734\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7778\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7807\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7808\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7659\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7750\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7825\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7737\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7823\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7534\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7762\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4732 - accuracy: 0.7785\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7570\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7731\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7789\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4897 - accuracy: 0.7709\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7816\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4925 - accuracy: 0.7722\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7731\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7739\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4803 - accuracy: 0.7722\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4601 - accuracy: 0.7864\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7758\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7782\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5179 - accuracy: 0.7581\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7752\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4830 - accuracy: 0.7718\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7818\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7899\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4837 - accuracy: 0.7731\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7813\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7742\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7783\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4630 - accuracy: 0.7850\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7726\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7820\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7723\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7586\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7848\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5004 - accuracy: 0.7684\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7886\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7653\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7772\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7928\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7829\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4779 - accuracy: 0.7791\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7777\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7810\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7882\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7798\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7937\n",
      "Epoch 76/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7886\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5277 - accuracy: 0.7497\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7718\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7822\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7929\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7891\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.7911\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7845\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7765\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7959\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7944\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5116 - accuracy: 0.7549\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7857\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7732\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7838\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7772\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7842\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7770\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7855\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4658 - accuracy: 0.7859\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7797\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7728\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4761 - accuracy: 0.7796\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7744\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7971\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4695 - accuracy: 0.7845\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4814 - accuracy: 0.7748\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7960\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7947\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7895\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4967 - accuracy: 0.7690\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4966 - accuracy: 0.7676\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7871\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7827\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7969\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7770\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7794\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7996\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7656\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7924\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7948\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4794 - accuracy: 0.7767\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7609\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7782\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7928\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4826 - accuracy: 0.7780\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4881 - accuracy: 0.7670\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7977\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7919\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7610\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4769 - accuracy: 0.7797\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7942\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7877\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7900\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7858\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7974\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7863\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7737\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8037\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7922\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7861\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7729\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7966\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7986\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7835\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5111 - accuracy: 0.7580\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.7893\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7738\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.7926\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.7904\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.7602\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8004\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7930\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7636\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4400 - accuracy: 0.8065\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7586\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.7935\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7784\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7883\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7796\n",
      "Epoch 156/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7741\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8052\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7786\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7871\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4756 - accuracy: 0.7763\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.7958\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4605 - accuracy: 0.7917\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7930\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4772 - accuracy: 0.7757\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7736\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.8031\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7891\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7747\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7773\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7806\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7839\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4677 - accuracy: 0.7828\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7859\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.8039\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7858\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7801\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4453 - accuracy: 0.7962\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.7986\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7899\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7679\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7945\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7817\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.7985\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7944\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7693\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4583 - accuracy: 0.7931\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7892\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8072\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7932\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7838\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4652 - accuracy: 0.7888\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4834 - accuracy: 0.7752\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8025\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8002\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7915\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7655\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7970\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7723\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4848 - accuracy: 0.7717\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.7985\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7684\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.7861\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4399 - accuracy: 0.8075\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7782\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7887\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7889\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4422 - accuracy: 0.7990\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7708\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7886\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.7991\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4656 - accuracy: 0.7834\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.7939\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7874\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.7871\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7725\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4644 - accuracy: 0.7871\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4650 - accuracy: 0.7877\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8026\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7698\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8051\n",
      "Epoch 00220: early stopping\n",
      "Score for fold 1: loss of 0.4340762794017792;     accuracy of 81.08453154563904%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1644 - accuracy: 0.6018\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0123 - accuracy: 0.7072\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9341 - accuracy: 0.7084\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8639 - accuracy: 0.7164\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8072 - accuracy: 0.7211\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7585 - accuracy: 0.7265\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7104 - accuracy: 0.7393\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6761 - accuracy: 0.7515\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6498 - accuracy: 0.7526\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6237 - accuracy: 0.7559\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6017 - accuracy: 0.7556\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5809 - accuracy: 0.7586\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7605\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7659\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5394 - accuracy: 0.7686\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7660\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7659\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5242 - accuracy: 0.7617\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.7694\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4959 - accuracy: 0.7735\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7726\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7756\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7774\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7811\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7691\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7609\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4887 - accuracy: 0.7746\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4995 - accuracy: 0.7668\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7845\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7645\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4946 - accuracy: 0.7678\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7777\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7491\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.7804\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7658\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7856\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5334 - accuracy: 0.7496\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7771\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4800 - accuracy: 0.7806\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7693\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4932 - accuracy: 0.7665\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7732\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7843\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7694\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5030 - accuracy: 0.7666\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7549\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4691 - accuracy: 0.7834\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5022 - accuracy: 0.7605\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4705 - accuracy: 0.7826\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7826\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4763 - accuracy: 0.7746\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7695\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7745\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4669 - accuracy: 0.7821\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7696\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4638 - accuracy: 0.7861\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7687\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7880\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7784\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4820 - accuracy: 0.7714\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4687 - accuracy: 0.7783\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4551 - accuracy: 0.7906\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7843\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7664\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4919 - accuracy: 0.7660\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7974\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7772\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7768\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7852\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4623 - accuracy: 0.7911\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5184 - accuracy: 0.7667\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7801\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7722\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.7861\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7803\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7901\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7799\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7845\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7676\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.7705\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7905\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7703\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4882 - accuracy: 0.7694\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7958\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4508 - accuracy: 0.7946\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5422 - accuracy: 0.7523\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7809\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4608 - accuracy: 0.7836\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7922\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.7992\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4940 - accuracy: 0.7675\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7928\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7594\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7987\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7618\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7790\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4733 - accuracy: 0.7778\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7854\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7841\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7805\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7970\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7734\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7973\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7799\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7694\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7851\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4796 - accuracy: 0.7729\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4598 - accuracy: 0.7895\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4697 - accuracy: 0.7803\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7954\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4657 - accuracy: 0.7855\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7789\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7686\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4557 - accuracy: 0.7966\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7886\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5054 - accuracy: 0.7615\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7815\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7758\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7909\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4498 - accuracy: 0.7975\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7707\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7904\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7929\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7813\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7740\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7683\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7885\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4451 - accuracy: 0.8003\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7743\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7840\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7861\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7771\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.7928\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7844\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7802\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4889 - accuracy: 0.7680\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.7986\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7837\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7965\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8037\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.7747\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7775\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7801\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4586 - accuracy: 0.7869\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8011\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7642\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8051\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7731\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7889\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5046 - accuracy: 0.7657\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7830\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8065\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4899 - accuracy: 0.7731\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7912\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.7950\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7702\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.7980\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7780\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8023\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4371 - accuracy: 0.8060\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5209 - accuracy: 0.7513\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.7838\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4460 - accuracy: 0.8032\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4920 - accuracy: 0.7697\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4517 - accuracy: 0.7924\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7626\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4569 - accuracy: 0.7923\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7912\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4749 - accuracy: 0.7778\n",
      "Epoch 170/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7750\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4466 - accuracy: 0.8019\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.7617\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4591 - accuracy: 0.7860\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7778\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4574 - accuracy: 0.7935\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7625\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7901\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7914\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7747\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.7807\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7822\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4468 - accuracy: 0.8042\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8076\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.7914\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.7680\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7838\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7978\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7764\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7800\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7841\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7951\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7960\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.7726\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7926\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7738\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7993\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4655 - accuracy: 0.7814\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7844\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7936\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7854\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7827\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8033\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4614 - accuracy: 0.7874\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7797\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7801\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4464 - accuracy: 0.7985\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7760\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7765\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4679 - accuracy: 0.7821\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8016\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.7643\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7992\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7912\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7743\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4353 - accuracy: 0.8097\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7849\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4900 - accuracy: 0.7729\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7914\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8002\n",
      "Epoch 00219: early stopping\n",
      "Score for fold 2: loss of 0.5138887763023376;     accuracy of 75.50238966941833%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1724 - accuracy: 0.6109\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0235 - accuracy: 0.7077\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.9379 - accuracy: 0.7134\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8740 - accuracy: 0.7148\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8099 - accuracy: 0.7248\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7601 - accuracy: 0.7348\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7207 - accuracy: 0.7382\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6849 - accuracy: 0.7449\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6542 - accuracy: 0.7449\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6256 - accuracy: 0.7522\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6018 - accuracy: 0.7584\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5849 - accuracy: 0.7590\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5695 - accuracy: 0.7621\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5506 - accuracy: 0.7653\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.7614\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7636\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7730\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5132 - accuracy: 0.7703\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7780\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7724\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4956 - accuracy: 0.7758\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7735\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7749\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7819\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4811 - accuracy: 0.7776\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7654\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7823\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7746\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4799 - accuracy: 0.7753\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7694\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7827\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7762\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4931 - accuracy: 0.7709\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7814\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4923 - accuracy: 0.7634\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7651\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7817\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5036 - accuracy: 0.7643\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7814\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4762 - accuracy: 0.7784\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7633\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4566 - accuracy: 0.7896\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4870 - accuracy: 0.7772\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7811\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7680\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.7773\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4978 - accuracy: 0.7630\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4633 - accuracy: 0.7850\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.7702\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.7888\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7754\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7808\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7540\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7830\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7793\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7749\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7814\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5123 - accuracy: 0.7627\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7922\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7653\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4565 - accuracy: 0.7921\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7798\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7915\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7675\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7757\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4851 - accuracy: 0.7694\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7927\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4755 - accuracy: 0.7756\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7805\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4611 - accuracy: 0.7861\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7717\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7678\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7879\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7754\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7945\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5063 - accuracy: 0.7635\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7874\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4668 - accuracy: 0.7848\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7946\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4514 - accuracy: 0.7978\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7463\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4590 - accuracy: 0.7866\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4737 - accuracy: 0.7795\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7898\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7885\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.7574\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4609 - accuracy: 0.7883\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7812\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.7499\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4581 - accuracy: 0.7928\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7885\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4790 - accuracy: 0.7772\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7581\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.7942\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7802\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4972 - accuracy: 0.7690\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4620 - accuracy: 0.7915\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.7954\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7842\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7873\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7711\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7969\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4740 - accuracy: 0.7788\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7886\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4476 - accuracy: 0.7931\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4719 - accuracy: 0.7812\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7805\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7993\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7961\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4603 - accuracy: 0.7925\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4934 - accuracy: 0.7662\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7714\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4618 - accuracy: 0.7877\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4571 - accuracy: 0.7920\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7748\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8010\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7885\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7911\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7539\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7946\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7966\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4700 - accuracy: 0.7837\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5083 - accuracy: 0.7585\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7990\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7968\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.7795\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7751\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7891\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7951\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.7992\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7610\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7746\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7904\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4594 - accuracy: 0.7904\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7938\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4479 - accuracy: 0.7952\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7937\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7692\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.7993\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4585 - accuracy: 0.7913\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5461 - accuracy: 0.7422\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4694 - accuracy: 0.7830\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4577 - accuracy: 0.7918\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4428 - accuracy: 0.8001\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7914\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7657\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7986\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7897\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4598 - accuracy: 0.7883\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4832 - accuracy: 0.7704\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4872 - accuracy: 0.7695\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7935\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7906\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7859\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5051 - accuracy: 0.7587\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7888\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7629\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7992\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4359 - accuracy: 0.8102\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5142 - accuracy: 0.7596\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.7940\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8010\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7545\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7879\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.7900\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7707\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7916\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4751 - accuracy: 0.7749\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4547 - accuracy: 0.7941\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4596 - accuracy: 0.7893\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4699 - accuracy: 0.7844\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7798\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8069\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7723\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.7919\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7555\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.8021\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5100 - accuracy: 0.7611\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8002\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7981\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4922 - accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4483 - accuracy: 0.7995\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7823\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7816\n",
      "Epoch 185/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.7977\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7945\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4646 - accuracy: 0.7895\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4511 - accuracy: 0.8008\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7732\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.7976\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4690 - accuracy: 0.7868\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4626 - accuracy: 0.7882\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7996\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.7604\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7977\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.7998\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7622\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.7871\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8007\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7723\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4584 - accuracy: 0.7940\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4894 - accuracy: 0.7763\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.7943\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4393 - accuracy: 0.8076\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.7588\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4706 - accuracy: 0.7850\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8014\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7639\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4482 - accuracy: 0.7932\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4744 - accuracy: 0.7773\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.7971\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4619 - accuracy: 0.7836\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7903\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4776 - accuracy: 0.7764\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8040\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.7960\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4809 - accuracy: 0.7783\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4348 - accuracy: 0.8080\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4805 - accuracy: 0.7735\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7910\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7957\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.7814\n",
      "Epoch 00222: early stopping\n",
      "Score for fold 3: loss of 0.44942787289619446;     accuracy of 79.45773601531982%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1496 - accuracy: 0.7090\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0418 - accuracy: 0.7122\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9602 - accuracy: 0.7060\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8889 - accuracy: 0.7106\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8189 - accuracy: 0.7261\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7747 - accuracy: 0.7215\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7292 - accuracy: 0.7320\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6890 - accuracy: 0.7395\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6595 - accuracy: 0.7458\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6276 - accuracy: 0.7542\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6065 - accuracy: 0.7550\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5875 - accuracy: 0.7583\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7615\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7646\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.7702\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5364 - accuracy: 0.7646\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7685\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7667\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5038 - accuracy: 0.7751\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4990 - accuracy: 0.7745\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4950 - accuracy: 0.7748\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4906 - accuracy: 0.7743\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7731\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7785\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4814 - accuracy: 0.7759\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7785\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4678 - accuracy: 0.7835\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7823\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4786 - accuracy: 0.7816\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7779\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7608\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4998 - accuracy: 0.7683\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7704\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7554\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7753\n",
      "Epoch 36/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4628 - accuracy: 0.7846\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4831 - accuracy: 0.7706\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4621 - accuracy: 0.7841\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7639\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4812 - accuracy: 0.7787\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4704 - accuracy: 0.7835\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4789 - accuracy: 0.7811\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4922 - accuracy: 0.7669\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4951 - accuracy: 0.7702\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7844\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5217 - accuracy: 0.7525\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4525 - accuracy: 0.7894\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7729\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4701 - accuracy: 0.7849\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7735\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7905\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7632\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4838 - accuracy: 0.7742\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7770\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7704\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4773 - accuracy: 0.7807\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4526 - accuracy: 0.8005\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4683 - accuracy: 0.7798\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4909 - accuracy: 0.7767\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7848\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7755\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7816\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4775 - accuracy: 0.7728\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7900\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7852\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4877 - accuracy: 0.7776\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7647\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.7868\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4784 - accuracy: 0.7753\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4561 - accuracy: 0.7915\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7699\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7873\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.7651\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.7907\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7978\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.7946\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4766 - accuracy: 0.7799\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7703\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.7970\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4676 - accuracy: 0.7859\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4634 - accuracy: 0.7848\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7932\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4667 - accuracy: 0.7884\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5155 - accuracy: 0.7530\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7990\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.7979\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.7712\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7750\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4725 - accuracy: 0.7800\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7831\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.7681\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7884\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.7981\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.7776\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4544 - accuracy: 0.7904\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7700\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.7846\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7803\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4530 - accuracy: 0.7899\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7969\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7844\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4757 - accuracy: 0.7843\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7941\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.7991\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4865 - accuracy: 0.7771\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7817\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7849\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7832\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7835\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7915\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4760 - accuracy: 0.7748\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.7876\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4709 - accuracy: 0.7830\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4886 - accuracy: 0.7673\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7854\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.7789\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.7962\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7868\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4875 - accuracy: 0.7735\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7971\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7756\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4521 - accuracy: 0.7938\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4383 - accuracy: 0.8041\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4970 - accuracy: 0.7648\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.7826\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.7998\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8048\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.7664\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4607 - accuracy: 0.7876\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8029\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4819 - accuracy: 0.7767\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4673 - accuracy: 0.7874\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4716 - accuracy: 0.7821\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8031\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7843\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.7891\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7961\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7799\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8027\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7798\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.7616\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7960\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4647 - accuracy: 0.7849\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7775\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8004\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4921 - accuracy: 0.7655\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.7776\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7784\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4518 - accuracy: 0.7929\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8021\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7926\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.7886\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4570 - accuracy: 0.7922\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.7998\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7918\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.7995\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4730 - accuracy: 0.7793\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8029\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4739 - accuracy: 0.7836\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7859\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4395 - accuracy: 0.8058\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4439 - accuracy: 0.8013\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7860\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8042\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7630\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4446 - accuracy: 0.8018\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4937 - accuracy: 0.7638\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8059\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4554 - accuracy: 0.7956\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7985\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7858\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7658\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7907\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7921\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7869\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.7773\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.7968\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7851\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4469 - accuracy: 0.8006\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4858 - accuracy: 0.7667\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4401 - accuracy: 0.8052\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7995\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7594\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.7963\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4712 - accuracy: 0.7784\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4367 - accuracy: 0.8021\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4717 - accuracy: 0.7873\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7922\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4397 - accuracy: 0.8020\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4653 - accuracy: 0.7843\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.7868\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7676\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.7962\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4563 - accuracy: 0.7912\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.8055\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.7802\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7878\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4497 - accuracy: 0.7929\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.7778\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4588 - accuracy: 0.7911\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7906\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.7986\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4797 - accuracy: 0.7734\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7975\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.7971\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4414 - accuracy: 0.8010\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.7974\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4817 - accuracy: 0.7714\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.7974\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4555 - accuracy: 0.7922\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4829 - accuracy: 0.7749\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4467 - accuracy: 0.7997\n",
      "Epoch 00212: early stopping\n",
      "Score for fold 4: loss of 0.5143822431564331;     accuracy of 75.65411329269409%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 3,521\n",
      "Trainable params: 3,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.2218 - accuracy: 0.6113\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0241 - accuracy: 0.7086\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9422 - accuracy: 0.7126\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8728 - accuracy: 0.7133\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8144 - accuracy: 0.7206\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7615 - accuracy: 0.7299\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7151 - accuracy: 0.7413\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6846 - accuracy: 0.7445\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6530 - accuracy: 0.7496\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6280 - accuracy: 0.7496\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6092 - accuracy: 0.7542\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5835 - accuracy: 0.7572\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5681 - accuracy: 0.7610\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7632\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7655\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7662\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7656\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5146 - accuracy: 0.7702\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7744\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5012 - accuracy: 0.7726\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4987 - accuracy: 0.7752\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4928 - accuracy: 0.7757\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4910 - accuracy: 0.7771\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4867 - accuracy: 0.7774\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7606\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.7746\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7754\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7760\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7654\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4902 - accuracy: 0.7692\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4711 - accuracy: 0.7806\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7714\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4662 - accuracy: 0.7843\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4904 - accuracy: 0.7734\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5045 - accuracy: 0.7605\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.7719\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7624\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7659\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4627 - accuracy: 0.7874\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7548\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.7639\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7649\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7768\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7883\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7770\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7534\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4685 - accuracy: 0.7853\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5041 - accuracy: 0.7616\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4914 - accuracy: 0.7640\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4696 - accuracy: 0.7838\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7857\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4816 - accuracy: 0.7720\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7768\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4778 - accuracy: 0.7818\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5027 - accuracy: 0.7691\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4629 - accuracy: 0.7930\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4846 - accuracy: 0.7726\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7689\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5078 - accuracy: 0.7535\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4616 - accuracy: 0.7881\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7790\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7875\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4924 - accuracy: 0.7689\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4859 - accuracy: 0.7702\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4589 - accuracy: 0.7875\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4552 - accuracy: 0.7927\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4988 - accuracy: 0.7668\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4999 - accuracy: 0.7660\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.7876\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4689 - accuracy: 0.7798\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4793 - accuracy: 0.7766\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7722\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7923\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4742 - accuracy: 0.7829\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4765 - accuracy: 0.7831\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7849\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.7894\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.7698\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7768\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4916 - accuracy: 0.7633\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4747 - accuracy: 0.7773\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7963\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7640\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4540 - accuracy: 0.7897\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4936 - accuracy: 0.7676\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7803\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4674 - accuracy: 0.7819\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4682 - accuracy: 0.7895\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7726\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4613 - accuracy: 0.7947\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7949\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4870 - accuracy: 0.7756\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8030\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4954 - accuracy: 0.7686\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8000\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4506 - accuracy: 0.7980\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7382\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.7953\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4795 - accuracy: 0.7806\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4631 - accuracy: 0.7894\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8004\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4964 - accuracy: 0.7713\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.7892\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7906\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4821 - accuracy: 0.7752\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4854 - accuracy: 0.7747\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.7942\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.7814\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4770 - accuracy: 0.7805\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.7929\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4849 - accuracy: 0.7766\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7905\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4942 - accuracy: 0.7666\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7938\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4599 - accuracy: 0.7921\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.7666\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4693 - accuracy: 0.7828\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7762\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4564 - accuracy: 0.7897\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4738 - accuracy: 0.7877\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7647\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7793\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8006\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5069 - accuracy: 0.7609\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4615 - accuracy: 0.7893\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.7980\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7728\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4777 - accuracy: 0.7764\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7863\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4801 - accuracy: 0.7765\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4539 - accuracy: 0.7990\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4579 - accuracy: 0.7890\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5071 - accuracy: 0.7653\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8060\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4839 - accuracy: 0.7785\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7949\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4612 - accuracy: 0.7861\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.7755\n",
      "Epoch 139/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4684 - accuracy: 0.7884\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7924\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.7915\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4903 - accuracy: 0.7725\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8016\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.7560\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4448 - accuracy: 0.8038\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5029 - accuracy: 0.7637\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4575 - accuracy: 0.7965\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.7913\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7992\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.7700\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.7961\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4912 - accuracy: 0.7734\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7945\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4758 - accuracy: 0.7805\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.7951\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4984 - accuracy: 0.7677\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8012\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4686 - accuracy: 0.7840\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4592 - accuracy: 0.7949\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.7771\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4723 - accuracy: 0.7796\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4507 - accuracy: 0.7984\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.7943\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7534\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4542 - accuracy: 0.7945\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.7989\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.7740\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4746 - accuracy: 0.7805\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.7984\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.7846\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.8074\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7963\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7604\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4384 - accuracy: 0.8065\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4735 - accuracy: 0.7829\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7797\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4444 - accuracy: 0.8022\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.7723\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4698 - accuracy: 0.7850\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.7978\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4578 - accuracy: 0.7915\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4651 - accuracy: 0.7850\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8069\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4715 - accuracy: 0.7806\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4666 - accuracy: 0.7824\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.7998\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4718 - accuracy: 0.7852\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7588\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4764 - accuracy: 0.7837\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4427 - accuracy: 0.8079\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4449 - accuracy: 0.8023\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4604 - accuracy: 0.7952\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4660 - accuracy: 0.7866\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4861 - accuracy: 0.7758\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8058\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4791 - accuracy: 0.7785\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.7864\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4537 - accuracy: 0.7986\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.7952\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4748 - accuracy: 0.7793\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.8037\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4754 - accuracy: 0.7790\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.7888\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.4434 - accuracy: 0.8016\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4576 - accuracy: 0.7910\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4680 - accuracy: 0.7870\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.7974\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4816 - accuracy: 0.7816\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4901 - accuracy: 0.7634\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4421 - accuracy: 0.8057\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4587 - accuracy: 0.7953\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4639 - accuracy: 0.7880\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4767 - accuracy: 0.7814\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.7920\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8061\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5060 - accuracy: 0.7626\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8055\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8031\n",
      "Epoch 219/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7655\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4440 - accuracy: 0.8028\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.7835\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4509 - accuracy: 0.7975\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.7838\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4560 - accuracy: 0.7894\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4549 - accuracy: 0.7979\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.7925\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.7988\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.7831\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8029\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4815 - accuracy: 0.7760\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4671 - accuracy: 0.7868\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4357 - accuracy: 0.8057\n",
      "Epoch 00232: early stopping\n",
      "Score for fold 5: loss of 0.4789304733276367;     accuracy of 77.12188959121704%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.4340762794017792 - Accuracy: 81.08453154563904%\n",
      "> Fold 1 - Confusion Matrix: [[1869 1811]\n",
      " [ 626 8232]]     - Precision: 0.8196753957980683%     - Recall: 0.9293294197335742%     - F1: 0.8710650230146553%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.5138887763023376 - Accuracy: 75.50238966941833%\n",
      "> Fold 2 - Confusion Matrix: [[2908  774]\n",
      " [2413 6443]]     - Precision: 0.8927532215602051%     - Recall: 0.7275293586269196%     - F1: 0.8017171654327133%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.44942787289619446 - Accuracy: 79.45773601531982%\n",
      "> Fold 3 - Confusion Matrix: [[1656 2019]\n",
      " [ 523 8340]]     - Precision: 0.8050970170865913%     - Recall: 0.9409906352250931%     - F1: 0.8677556965976485%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.5143822431564331 - Accuracy: 75.65411329269409%\n",
      "> Fold 4 - Confusion Matrix: [[ 953 2703]\n",
      " [ 224 8659]]     - Precision: 0.7621017426509418%     - Recall: 0.9747832939322301%     - F1: 0.8554210916275624%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.4789304733276367 - Accuracy: 77.12188959121704%\n",
      "> Fold 5 - Confusion Matrix: [[ 991 2688]\n",
      " [ 217 8643]]     - Precision: 0.7627746889065395%     - Recall: 0.975507900677201%     - F1: 0.8561240156505374%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 77.76413202285767 (+- 2.1851077927714493)\n",
      "> Loss: 0.4781411290168762\n",
      "> Precision: 0.8084804132004692\n",
      "> Recall: 0.9096281216390036\n",
      "> F1: 0.8504165984646234\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "conf_mat_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "f1_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy'\n",
    "                                                  ,patience=200\n",
    "                                                  ,min_delta = 0.05, verbose = 1)\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model1_reg = model_one_reg()\n",
    "    history = model1_reg.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model1_reg.evaluate(x_train_test_val[test] , y_train_test_val[test] , verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model1_reg.metrics_names[0]} of {scores[0]}; \\\n",
    "    {model1_reg.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    y_pred = np.round(model1_reg.predict(x_train_test_val[train])).astype(int)\n",
    "    conf_mat_per_fold.append(confusion_matrix(y_train_test_val[train]  ,y_pred))\n",
    "    precision_per_fold.append(precision_score(y_train_test_val[train] ,y_pred))\n",
    "    recall_per_fold.append(recall_score(y_train_test_val[train] ,y_pred))\n",
    "    f1_per_fold.append(f1_score(y_train_test_val[train], y_pred))\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print(f'> Fold {i+1} - Confusion Matrix: {conf_mat_per_fold[i]} \\\n",
    "    - Precision: {precision_per_fold[i]}% \\\n",
    "    - Recall: {recall_per_fold[i]}% \\\n",
    "    - F1: {f1_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)}')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)}')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4 Cross Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 6ms/step - loss: 1.3022 - accuracy: 0.7117\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1952 - accuracy: 0.7056\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1050 - accuracy: 0.7088\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0319 - accuracy: 0.7074\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9702 - accuracy: 0.7057\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9115 - accuracy: 0.7109\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8671 - accuracy: 0.7096\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8266 - accuracy: 0.7108\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7893 - accuracy: 0.7152\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7646 - accuracy: 0.7112\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7370 - accuracy: 0.7142\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7225 - accuracy: 0.7071\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7019 - accuracy: 0.7109\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6870 - accuracy: 0.7098\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6787 - accuracy: 0.7045\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6602 - accuracy: 0.7125\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6537 - accuracy: 0.7103\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.7157\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.7084\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6330 - accuracy: 0.7086\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6238 - accuracy: 0.7123\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6236 - accuracy: 0.7077\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6218 - accuracy: 0.7047\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6131 - accuracy: 0.7097\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6123 - accuracy: 0.7073\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6074 - accuracy: 0.7101\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6083 - accuracy: 0.7063\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.7036\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6037 - accuracy: 0.7051\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.7017\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6005 - accuracy: 0.7055\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.7057\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5909 - accuracy: 0.7116\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5851 - accuracy: 0.7156\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5935 - accuracy: 0.7064\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5877 - accuracy: 0.7103\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5859 - accuracy: 0.7109\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5810 - accuracy: 0.7131\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5791 - accuracy: 0.7149\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5755 - accuracy: 0.7172\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5748 - accuracy: 0.7154\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5745 - accuracy: 0.7174\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5721 - accuracy: 0.7180\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7210\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5656 - accuracy: 0.7225\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5679 - accuracy: 0.7230\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7294\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5619 - accuracy: 0.7293\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5583 - accuracy: 0.7337\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5589 - accuracy: 0.7328\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7365\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5511 - accuracy: 0.7433\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7427\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7419\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5460 - accuracy: 0.7492\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5481 - accuracy: 0.7466\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7495\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7466\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5467 - accuracy: 0.7493\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7484\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5429 - accuracy: 0.7556\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7488\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.7548\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5388 - accuracy: 0.7556\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7612\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7537\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5339 - accuracy: 0.7621\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7601\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5302 - accuracy: 0.7592\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7628\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7608\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7595\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5288 - accuracy: 0.7643\n",
      "Epoch 74/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7613\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7705\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7588\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5282 - accuracy: 0.7637\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5343 - accuracy: 0.7589\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5254 - accuracy: 0.7689\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7668\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7669\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7646\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5286 - accuracy: 0.7669\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5287 - accuracy: 0.7627\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7738\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5359 - accuracy: 0.7656\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7751\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7715\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7725\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7673\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5334 - accuracy: 0.7648\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7659\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7743\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7704\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7774\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7667\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5281 - accuracy: 0.7638\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5307 - accuracy: 0.7703\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5329 - accuracy: 0.7593\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7681\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7587\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7743\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7674\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7816\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5507 - accuracy: 0.7478\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7577\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7734\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5289 - accuracy: 0.7759\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7718\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7626\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7579\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5151 - accuracy: 0.7727\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5688 - accuracy: 0.7413\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7675\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7616\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5525 - accuracy: 0.7569\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5463 - accuracy: 0.7531\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5332 - accuracy: 0.7727\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7642\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7744\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.7557\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7623\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5410 - accuracy: 0.7631\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7718\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7590\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5762 - accuracy: 0.7417\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7543\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7718\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5088 - accuracy: 0.7805\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.7552\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7671\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7643\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5233 - accuracy: 0.7721\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7654\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7733\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5781 - accuracy: 0.7336\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7768\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5478 - accuracy: 0.7572\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7738\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7725\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5625 - accuracy: 0.7462\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7669\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7654\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7731\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5354 - accuracy: 0.7579\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5230 - accuracy: 0.7701\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5471 - accuracy: 0.7571\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7646\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5433 - accuracy: 0.7583\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5440 - accuracy: 0.7614\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5119 - accuracy: 0.7735\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7686\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7465\n",
      "Epoch 154/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7687\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7729\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7615\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5742 - accuracy: 0.7468\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7682\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5671 - accuracy: 0.7498\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7787\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7522\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7509\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7636\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5164 - accuracy: 0.7717\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7797\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5530 - accuracy: 0.7547\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.7331\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7669\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.7756\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5416 - accuracy: 0.7578\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5435 - accuracy: 0.7610\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7632\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5061 - accuracy: 0.7759\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5724 - accuracy: 0.7431\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.7771\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5140 - accuracy: 0.7777\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5064 - accuracy: 0.7756\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5927 - accuracy: 0.7332\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5577 - accuracy: 0.7562\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7655\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7582\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7683\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7751\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5034 - accuracy: 0.7796\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5157 - accuracy: 0.7757\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.7303\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5585 - accuracy: 0.7418\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5358 - accuracy: 0.7694\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7753\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5178 - accuracy: 0.7757\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7553\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5802 - accuracy: 0.7400\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.7714\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5773 - accuracy: 0.7458\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5231 - accuracy: 0.7701\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.7604\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5361 - accuracy: 0.7621\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5674 - accuracy: 0.7488\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5139 - accuracy: 0.7724\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7454\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5154 - accuracy: 0.7699\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5447 - accuracy: 0.7674\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5459 - accuracy: 0.7544\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5363 - accuracy: 0.7652\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7622\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5352 - accuracy: 0.7640\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7652\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5756 - accuracy: 0.7410\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7616\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5309 - accuracy: 0.7668\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7507\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5124 - accuracy: 0.7729\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5750 - accuracy: 0.7469\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7679\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5534 - accuracy: 0.7530\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7765\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5491 - accuracy: 0.7506\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5419 - accuracy: 0.7611\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5342 - accuracy: 0.7619\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7827\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7715\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7396\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7705\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7747\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5542 - accuracy: 0.7588\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5347 - accuracy: 0.7621\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7634\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5158 - accuracy: 0.7704\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5340 - accuracy: 0.7667\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7657\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5375 - accuracy: 0.7649\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7478\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7570\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5323 - accuracy: 0.7678\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5211 - accuracy: 0.7686\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5148 - accuracy: 0.7810\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7744\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5822 - accuracy: 0.7374\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7521\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5270 - accuracy: 0.7675\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5590 - accuracy: 0.7530\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7768\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7664\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7672\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7567\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5430 - accuracy: 0.7604\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5262 - accuracy: 0.7697\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5691 - accuracy: 0.7446\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5541 - accuracy: 0.7567\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5504 - accuracy: 0.7546\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4992 - accuracy: 0.7806\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7731\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5866 - accuracy: 0.7350\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7664\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5487 - accuracy: 0.7542\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5117 - accuracy: 0.7733\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5486 - accuracy: 0.7564\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.7512\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5082 - accuracy: 0.7764\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7681\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5421 - accuracy: 0.7612\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7471\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5580 - accuracy: 0.7526\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7695\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7557\n",
      "Epoch 00265: early stopping\n",
      "Score for fold 1: loss of 0.5321862101554871;     accuracy of 78.81977558135986%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 6ms/step - loss: 1.3012 - accuracy: 0.7025\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.1827 - accuracy: 0.7116\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0970 - accuracy: 0.7111\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0241 - accuracy: 0.7102\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9651 - accuracy: 0.7062\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9064 - accuracy: 0.7124\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8668 - accuracy: 0.7058\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8283 - accuracy: 0.7054\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7950 - accuracy: 0.7060\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7636 - accuracy: 0.7092\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7407 - accuracy: 0.7084\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7185 - accuracy: 0.7102\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7016 - accuracy: 0.7092\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6907 - accuracy: 0.7042\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6728 - accuracy: 0.7105\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6642 - accuracy: 0.7079\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.7079\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6487 - accuracy: 0.7054\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.7059\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6323 - accuracy: 0.7079\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6278 - accuracy: 0.7083\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7091\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6213 - accuracy: 0.7056\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6090 - accuracy: 0.7147\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.7096\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6117 - accuracy: 0.7036\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6067 - accuracy: 0.7071\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6041 - accuracy: 0.7077\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6010 - accuracy: 0.7078\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6001 - accuracy: 0.7064\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.7141\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5919 - accuracy: 0.7119\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5976 - accuracy: 0.7030\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5909 - accuracy: 0.7102\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5923 - accuracy: 0.7071\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.7133\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5808 - accuracy: 0.7173\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5839 - accuracy: 0.7112\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5774 - accuracy: 0.7172\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.7105\n",
      "Epoch 41/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5775 - accuracy: 0.7142\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.7145\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5703 - accuracy: 0.7231\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5737 - accuracy: 0.7175\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.7218\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7305\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7258\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.7300\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.7324\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7386\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5541 - accuracy: 0.7381\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5532 - accuracy: 0.7413\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5557 - accuracy: 0.7371\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5565 - accuracy: 0.7374\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5521 - accuracy: 0.7421\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5469 - accuracy: 0.7477\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5465 - accuracy: 0.7438\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5502 - accuracy: 0.7447\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7499\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5456 - accuracy: 0.7576\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5444 - accuracy: 0.7498\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7526\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5389 - accuracy: 0.7555\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5409 - accuracy: 0.7550\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.7557\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7567\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5404 - accuracy: 0.7531\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5440 - accuracy: 0.7507\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5382 - accuracy: 0.7544\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7559\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.7546\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5336 - accuracy: 0.7547\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7622\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.7571\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7635\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5348 - accuracy: 0.7567\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7654\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7629\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7599\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5293 - accuracy: 0.7658\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5317 - accuracy: 0.7619\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5247 - accuracy: 0.7660\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5349 - accuracy: 0.7592\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7643\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7674\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7628\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5186 - accuracy: 0.7713\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5378 - accuracy: 0.7576\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5275 - accuracy: 0.7745\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7656\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5237 - accuracy: 0.7677\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7580\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.7781\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5241 - accuracy: 0.7652\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5490 - accuracy: 0.7499\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5328 - accuracy: 0.7665\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5237 - accuracy: 0.7711\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5595 - accuracy: 0.7451\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7708\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7695\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7596\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5453 - accuracy: 0.7590\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5265 - accuracy: 0.7660\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5176 - accuracy: 0.7694\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5205 - accuracy: 0.7686\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5612 - accuracy: 0.7534\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5226 - accuracy: 0.7684\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.7732\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.7467\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7705\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5108 - accuracy: 0.7773\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7699\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6031 - accuracy: 0.7242\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.7662\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7686\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7651\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5575 - accuracy: 0.7528\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7630\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7690\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5155 - accuracy: 0.7674\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5571 - accuracy: 0.7524\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5246 - accuracy: 0.7706\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7595\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5480 - accuracy: 0.7598\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5130 - accuracy: 0.7702\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5136 - accuracy: 0.7717\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5948 - accuracy: 0.7364\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7673\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7754\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5351 - accuracy: 0.7591\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7534\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5251 - accuracy: 0.7670\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7752\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7664\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5696 - accuracy: 0.7418\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7662\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7721\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.7696\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.7395\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7605\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5175 - accuracy: 0.7677\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7573\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7582\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5606 - accuracy: 0.7484\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5235 - accuracy: 0.7741\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7633\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7543\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7682\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5434 - accuracy: 0.7647\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7540\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7720\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.7511\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7536\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5159 - accuracy: 0.7709\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7653\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5602 - accuracy: 0.7614\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7570\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5093 - accuracy: 0.7729\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7721\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5686 - accuracy: 0.7507\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7716\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5492 - accuracy: 0.7554\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7678\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7525\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7725\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5448 - accuracy: 0.7635\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5121 - accuracy: 0.7730\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5072 - accuracy: 0.7723\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5641 - accuracy: 0.7518\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7727\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5259 - accuracy: 0.7699\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5576 - accuracy: 0.7515\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7598\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7534\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5362 - accuracy: 0.7719\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7784\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5636 - accuracy: 0.7481\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5497 - accuracy: 0.7559\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5629 - accuracy: 0.7532\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7586\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5440 - accuracy: 0.7569\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7641\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5678 - accuracy: 0.7509\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5296 - accuracy: 0.7664\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5446 - accuracy: 0.7607\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5939 - accuracy: 0.7278\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.7660\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5601 - accuracy: 0.7435\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5221 - accuracy: 0.7672\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7565\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5258 - accuracy: 0.7693\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5555 - accuracy: 0.7518\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5624 - accuracy: 0.7492\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7702\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5705 - accuracy: 0.7429\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7669\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7479\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5115 - accuracy: 0.7749\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5377 - accuracy: 0.7640\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5411 - accuracy: 0.7647\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7726\n",
      "Epoch 202/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5292 - accuracy: 0.7669\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5543 - accuracy: 0.7490\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5147 - accuracy: 0.7746\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5415 - accuracy: 0.7633\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5482 - accuracy: 0.7568\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5283 - accuracy: 0.7658\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5574 - accuracy: 0.7551\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7672\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5451 - accuracy: 0.7562\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5571 - accuracy: 0.7529\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5225 - accuracy: 0.7685\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5206 - accuracy: 0.7706\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7513\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7479\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5308 - accuracy: 0.7683\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.7680\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.7594\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7635\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5404 - accuracy: 0.7655\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5310 - accuracy: 0.7671\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5815 - accuracy: 0.7395\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7752\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5077 - accuracy: 0.7744\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5707 - accuracy: 0.7446\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7501\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5547 - accuracy: 0.7548\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5165 - accuracy: 0.7706\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5529 - accuracy: 0.7547\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5370 - accuracy: 0.7580\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.7529\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5462 - accuracy: 0.7564\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7787\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5822 - accuracy: 0.7411\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5075 - accuracy: 0.7810\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7601\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5253 - accuracy: 0.7713\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7617\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.7589\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5993 - accuracy: 0.7277\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5200 - accuracy: 0.7648\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5475 - accuracy: 0.7575\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7583\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5407 - accuracy: 0.7651\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5223 - accuracy: 0.7683\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7661\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7583\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5076 - accuracy: 0.7782\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5478 - accuracy: 0.7541\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.7766\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7495\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5341 - accuracy: 0.7659\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5230 - accuracy: 0.7678\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5598 - accuracy: 0.7581\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7609\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5127 - accuracy: 0.7815\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5215 - accuracy: 0.7654\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5909 - accuracy: 0.7360\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5567 - accuracy: 0.7520\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5381 - accuracy: 0.7661\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7714\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7847\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7634\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5747 - accuracy: 0.7430\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7725\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.7691\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5575 - accuracy: 0.7539\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7623\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7509\n",
      "Epoch 00269: early stopping\n",
      "Score for fold 2: loss of 0.5504798889160156;     accuracy of 76.65071487426758%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 6ms/step - loss: 1.3992 - accuracy: 0.5414\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.1799 - accuracy: 0.7105\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0970 - accuracy: 0.7069\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0221 - accuracy: 0.7091\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9647 - accuracy: 0.7039\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9086 - accuracy: 0.7072\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8604 - accuracy: 0.7108\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8230 - accuracy: 0.7095\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7935 - accuracy: 0.7051\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7645 - accuracy: 0.7068\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7390 - accuracy: 0.7079\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7182 - accuracy: 0.7092\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7011 - accuracy: 0.7082\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.7046\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6758 - accuracy: 0.7051\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6628 - accuracy: 0.7079\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6489 - accuracy: 0.7123\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6449 - accuracy: 0.7075\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6357 - accuracy: 0.7104\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.7108\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6254 - accuracy: 0.7089\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.7016\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6161 - accuracy: 0.7097\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6141 - accuracy: 0.7077\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6167 - accuracy: 0.7011\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6099 - accuracy: 0.7056\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6023 - accuracy: 0.7112\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6004 - accuracy: 0.7097\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5979 - accuracy: 0.7127\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5985 - accuracy: 0.7066\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5934 - accuracy: 0.7120\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.7138\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5896 - accuracy: 0.7120\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5854 - accuracy: 0.7169\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.7097\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5832 - accuracy: 0.7157\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5823 - accuracy: 0.7149\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5795 - accuracy: 0.7152\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5721 - accuracy: 0.7222\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5766 - accuracy: 0.7188\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5718 - accuracy: 0.7215\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5702 - accuracy: 0.7185\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5616 - accuracy: 0.7309\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5661 - accuracy: 0.7261\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5649 - accuracy: 0.7278\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5650 - accuracy: 0.7271\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.7341\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5568 - accuracy: 0.7372\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5627 - accuracy: 0.7290\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5556 - accuracy: 0.7372\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5533 - accuracy: 0.7420\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5560 - accuracy: 0.7394\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.7453\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5455 - accuracy: 0.7470\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5510 - accuracy: 0.7431\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5477 - accuracy: 0.7476\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5458 - accuracy: 0.7459\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5438 - accuracy: 0.7489\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5401 - accuracy: 0.7475\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5468 - accuracy: 0.7462\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5439 - accuracy: 0.7503\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7542\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5393 - accuracy: 0.7567\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5367 - accuracy: 0.7580\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7576\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5380 - accuracy: 0.7539\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5346 - accuracy: 0.7565\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5366 - accuracy: 0.7593\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7530\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7585\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7562\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5274 - accuracy: 0.7648\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7653\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7619\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5272 - accuracy: 0.7648\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7688\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7663\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7682\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.7643\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5245 - accuracy: 0.7657\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5381 - accuracy: 0.7665\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.7661\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5263 - accuracy: 0.7675\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5239 - accuracy: 0.7648\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7621\n",
      "Epoch 86/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5276 - accuracy: 0.7632\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7658\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5225 - accuracy: 0.7666\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7666\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5198 - accuracy: 0.7706\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5191 - accuracy: 0.7718\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.7596\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7646\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7749\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5224 - accuracy: 0.7664\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.7734\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7722\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5842 - accuracy: 0.7428\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7647\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5376 - accuracy: 0.7605\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7627\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5403 - accuracy: 0.7599\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5402 - accuracy: 0.7641\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7681\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.7491\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5284 - accuracy: 0.7650\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5567 - accuracy: 0.7527\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5172 - accuracy: 0.7681\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7665\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5426 - accuracy: 0.7612\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.7612\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5170 - accuracy: 0.7701\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5181 - accuracy: 0.7716\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7582\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5428 - accuracy: 0.7567\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5257 - accuracy: 0.7709\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.7612\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5101 - accuracy: 0.7752\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7696\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5607 - accuracy: 0.7491\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5554 - accuracy: 0.7605\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5491 - accuracy: 0.7529\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5152 - accuracy: 0.7690\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5677 - accuracy: 0.7475\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5465 - accuracy: 0.7553\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5384 - accuracy: 0.7650\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.7640\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5122 - accuracy: 0.7765\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5324 - accuracy: 0.7670\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5344 - accuracy: 0.7594\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5655 - accuracy: 0.7444\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7669\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5320 - accuracy: 0.7703\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5351 - accuracy: 0.7591\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5279 - accuracy: 0.7675\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5546 - accuracy: 0.7599\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5500 - accuracy: 0.7595\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7620\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7759\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5271 - accuracy: 0.7631\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5693 - accuracy: 0.7390\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5286 - accuracy: 0.7646\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5412 - accuracy: 0.7682\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5269 - accuracy: 0.7615\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5218 - accuracy: 0.7706\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.7595\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5545 - accuracy: 0.7553\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5430 - accuracy: 0.7558\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5194 - accuracy: 0.7744\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7694\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5187 - accuracy: 0.7701\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5719 - accuracy: 0.7461\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7691\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5663 - accuracy: 0.7422\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5471 - accuracy: 0.7494\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5131 - accuracy: 0.7752\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5385 - accuracy: 0.7576\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.7687\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5399 - accuracy: 0.7666\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5436 - accuracy: 0.7564\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5473 - accuracy: 0.7572\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5325 - accuracy: 0.7655\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5052 - accuracy: 0.7819\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.7617\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5301 - accuracy: 0.7662\n",
      "Epoch 166/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5456 - accuracy: 0.7628\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5156 - accuracy: 0.7750\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5878 - accuracy: 0.7350\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5112 - accuracy: 0.7796\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5079 - accuracy: 0.7738\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5297 - accuracy: 0.7662\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5727 - accuracy: 0.7522\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5867 - accuracy: 0.7361\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5493 - accuracy: 0.7566\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5288 - accuracy: 0.7697\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5311 - accuracy: 0.7647\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5527 - accuracy: 0.7560\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5608 - accuracy: 0.7446\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7744\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5252 - accuracy: 0.7703\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7751\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5564 - accuracy: 0.7497\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5388 - accuracy: 0.7674\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5243 - accuracy: 0.7677\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.5651 - accuracy: 0.7467\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5562 - accuracy: 0.7490\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5075 - accuracy: 0.7819\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5174 - accuracy: 0.7716\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5903 - accuracy: 0.7294\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5538 - accuracy: 0.7554\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7656\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5229 - accuracy: 0.7702\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5177 - accuracy: 0.7712\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7683\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5443 - accuracy: 0.7604\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5452 - accuracy: 0.7618\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5408 - accuracy: 0.7575\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5374 - accuracy: 0.7680\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5433 - accuracy: 0.7563\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.7739\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5306 - accuracy: 0.7623\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5304 - accuracy: 0.7605\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5526 - accuracy: 0.7611\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5313 - accuracy: 0.7665\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5422 - accuracy: 0.76 - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7617\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.7543\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5431 - accuracy: 0.7634\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5326 - accuracy: 0.7674\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7772\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5203 - accuracy: 0.7749\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5303 - accuracy: 0.7678\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5845 - accuracy: 0.7383\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.7755\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5663 - accuracy: 0.7464\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5537 - accuracy: 0.7510\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5312 - accuracy: 0.7697\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5768 - accuracy: 0.7356\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5380 - accuracy: 0.7630\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5392 - accuracy: 0.7648\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5300 - accuracy: 0.7714\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5517 - accuracy: 0.7555\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5342 - accuracy: 0.7652\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5580 - accuracy: 0.7494\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5253 - accuracy: 0.7751\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7507\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5162 - accuracy: 0.7739\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5757 - accuracy: 0.7431\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5204 - accuracy: 0.7700\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5233 - accuracy: 0.7713\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5464 - accuracy: 0.7595\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5539 - accuracy: 0.7545\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5065 - accuracy: 0.7760\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5687 - accuracy: 0.7484\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5353 - accuracy: 0.7574\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5358 - accuracy: 0.7647\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5565 - accuracy: 0.7516\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5092 - accuracy: 0.7799\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5712 - accuracy: 0.7461\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5365 - accuracy: 0.7644\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 5s 366ms/step - loss: 0.5090 - accuracy: 0.7724\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.5235 - accuracy: 0.7676\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.5390 - accuracy: 0.7599 0s - loss: 0.5599 - accura\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.5373 - accuracy: 0.7677\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5256 - accuracy: 0.7721\n",
      "Epoch 245/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 24ms/step - loss: 0.5309 - accuracy: 0.7697\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.5484 - accuracy: 0.7524\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.5587 - accuracy: 0.7490\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5182 - accuracy: 0.7709\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.5263 - accuracy: 0.7700\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5803 - accuracy: 0.7386\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5270 - accuracy: 0.7720\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5127 - accuracy: 0.7740\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5598 - accuracy: 0.7469\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5062 - accuracy: 0.7813\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5328 - accuracy: 0.7684\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5636 - accuracy: 0.7482\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5414 - accuracy: 0.7561\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.5243 - accuracy: 0.7736\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5654 - accuracy: 0.7530\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.5129 - accuracy: 0.7726\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.5410 - accuracy: 0.7601\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.5790 - accuracy: 0.7405\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5502 - accuracy: 0.7576\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.5312 - accuracy: 0.7688\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.5195 - accuracy: 0.7737\n",
      "Epoch 00265: early stopping\n",
      "Score for fold 3: loss of 0.6151961088180542;     accuracy of 72.1531093120575%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 12ms/step - loss: 1.3138 - accuracy: 0.7088\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.1937 - accuracy: 0.7118\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 1.1063 - accuracy: 0.7115\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 1.0397 - accuracy: 0.7024\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.9663 - accuracy: 0.7135\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.9182 - accuracy: 0.7070\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.8699 - accuracy: 0.7094\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.8340 - accuracy: 0.7054\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.8007 - accuracy: 0.7056\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.7715 - accuracy: 0.7059\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.7470 - accuracy: 0.7057\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.7288 - accuracy: 0.7025\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.7022 - accuracy: 0.7132\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6923 - accuracy: 0.7067\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6796 - accuracy: 0.7064\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6701 - accuracy: 0.7047\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6589 - accuracy: 0.7064\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6509 - accuracy: 0.7059\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6381 - accuracy: 0.7123\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6393 - accuracy: 0.7045\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6271 - accuracy: 0.7120\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6347 - accuracy: 0.6990\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.6205 - accuracy: 0.7105\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6211 - accuracy: 0.7061\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6187 - accuracy: 0.7056\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.6156 - accuracy: 0.7057\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6141 - accuracy: 0.7059\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6112 - accuracy: 0.7070\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.6126 - accuracy: 0.7031\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6073 - accuracy: 0.7071\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6059 - accuracy: 0.7079\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6040 - accuracy: 0.7085\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6036 - accuracy: 0.7070\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.6044 - accuracy: 0.7045\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5973 - accuracy: 0.7113\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5998 - accuracy: 0.7073\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5961 - accuracy: 0.7112\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5992 - accuracy: 0.7064\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5949 - accuracy: 0.7093\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5992 - accuracy: 0.7039\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5961 - accuracy: 0.7054\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5942 - accuracy: 0.7061\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5942 - accuracy: 0.7050\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5940 - accuracy: 0.7054\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5944 - accuracy: 0.7022\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5847 - accuracy: 0.7138\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5869 - accuracy: 0.7092\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5885 - accuracy: 0.7072\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5820 - accuracy: 0.7122\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5797 - accuracy: 0.7133\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5746 - accuracy: 0.7166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5776 - accuracy: 0.7132\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5729 - accuracy: 0.7181\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5771 - accuracy: 0.7129\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5710 - accuracy: 0.7197\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5669 - accuracy: 0.7240\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5636 - accuracy: 0.7280\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5636 - accuracy: 0.7277\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5684 - accuracy: 0.7249\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5665 - accuracy: 0.7269\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5576 - accuracy: 0.7350\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5568 - accuracy: 0.7392\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5562 - accuracy: 0.7402\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5547 - accuracy: 0.7409\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5577 - accuracy: 0.7391\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5530 - accuracy: 0.7419\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5544 - accuracy: 0.7414\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.7460\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5503 - accuracy: 0.7432\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5473 - accuracy: 0.7493\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5449 - accuracy: 0.7494\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5469 - accuracy: 0.7485\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5467 - accuracy: 0.7480\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5486 - accuracy: 0.7508\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5457 - accuracy: 0.7487\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5368 - accuracy: 0.7568\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5440 - accuracy: 0.7513\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5360 - accuracy: 0.7586\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5350 - accuracy: 0.7599\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5394 - accuracy: 0.7532\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5359 - accuracy: 0.7593\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5350 - accuracy: 0.7593\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5322 - accuracy: 0.7577\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5384 - accuracy: 0.7558\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5372 - accuracy: 0.7551\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5365 - accuracy: 0.7568\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5422 - accuracy: 0.7549\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5316 - accuracy: 0.7607\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5378 - accuracy: 0.7618\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5291 - accuracy: 0.7651\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5281 - accuracy: 0.7652\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5317 - accuracy: 0.7599\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5277 - accuracy: 0.7621\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5300 - accuracy: 0.7624\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5231 - accuracy: 0.7636\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.5397 - accuracy: 0.7619\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5294 - accuracy: 0.7664\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5351 - accuracy: 0.7615\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5351 - accuracy: 0.7618\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5253 - accuracy: 0.7641\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5439 - accuracy: 0.7561\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5250 - accuracy: 0.7650 0s - loss: 0.5252 - accuracy: 0.\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5246 - accuracy: 0.7687\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5247 - accuracy: 0.7646 0s - loss: 0.5242 - accuracy: 0.\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5592 - accuracy: 0.7472\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5311 - accuracy: 0.7623\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5517 - accuracy: 0.7513\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5306 - accuracy: 0.7645\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5420 - accuracy: 0.7600\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5209 - accuracy: 0.7726\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5246 - accuracy: 0.7754\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5188 - accuracy: 0.7649 0s - loss: 0.5117 - accu\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5862 - accuracy: 0.7339\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5271 - accuracy: 0.7685\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5287 - accuracy: 0.7629\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5273 - accuracy: 0.7656\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5628 - accuracy: 0.7484\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5304 - accuracy: 0.7681\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5289 - accuracy: 0.7666\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5114 - accuracy: 0.7740\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5405 - accuracy: 0.7623\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5650 - accuracy: 0.7515\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5392 - accuracy: 0.7631\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5296 - accuracy: 0.7650\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5356 - accuracy: 0.7668\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5712 - accuracy: 0.7437\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5730 - accuracy: 0.7362\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5295 - accuracy: 0.7620\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.5246 - accuracy: 0.7699\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5206 - accuracy: 0.7711\n",
      "Epoch 131/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5329 - accuracy: 0.7649\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5484 - accuracy: 0.7558\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5284 - accuracy: 0.7673\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5139 - accuracy: 0.7756\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5131 - accuracy: 0.7716\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5954 - accuracy: 0.7341\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5254 - accuracy: 0.7680\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5299 - accuracy: 0.7670\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5798 - accuracy: 0.7295\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5378 - accuracy: 0.7598\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5627 - accuracy: 0.7451\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5248 - accuracy: 0.7708\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 1s 43ms/step - loss: 0.5239 - accuracy: 0.7676\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5595 - accuracy: 0.7572\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5503 - accuracy: 0.7592\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5261 - accuracy: 0.7629\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5681 - accuracy: 0.7499\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5343 - accuracy: 0.7575\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5332 - accuracy: 0.7707\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5592 - accuracy: 0.7510\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5123 - accuracy: 0.7770\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5487 - accuracy: 0.7611\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.5795 - accuracy: 0.73 - 1s 46ms/step - loss: 0.5771 - accuracy: 0.7386\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5406 - accuracy: 0.7606\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.5330 - accuracy: 0.7628\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5124 - accuracy: 0.7720\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.5963 - accuracy: 0.7290\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5449 - accuracy: 0.7558 0s - loss: 0.5479 - accuracy: 0.\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5203 - accuracy: 0.7662 0s - loss: 0.5220 - accura\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5334 - accuracy: 0.7694\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5539 - accuracy: 0.7485\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5220 - accuracy: 0.7738\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5187 - accuracy: 0.7738\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5275 - accuracy: 0.7662 0s - loss: 0.5265 - accuracy: 0.\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5677 - accuracy: 0.7505\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5346 - accuracy: 0.7633\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5243 - accuracy: 0.7708\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5087 - accuracy: 0.7734\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5139 - accuracy: 0.7749\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5910 - accuracy: 0.7353\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5767 - accuracy: 0.7414\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5438 - accuracy: 0.7632\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5407 - accuracy: 0.7606\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5458 - accuracy: 0.7592\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5330 - accuracy: 0.7663\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5688 - accuracy: 0.7484\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5202 - accuracy: 0.7722\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5076 - accuracy: 0.7736\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5385 - accuracy: 0.7668\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.5730 - accuracy: 0.7508\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.5467 - accuracy: 0.7578\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5518 - accuracy: 0.7602\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5482 - accuracy: 0.7529\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5411 - accuracy: 0.7622\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5657 - accuracy: 0.7435\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5153 - accuracy: 0.7737\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5739 - accuracy: 0.7386\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5478 - accuracy: 0.7576\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5111 - accuracy: 0.7750\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5556 - accuracy: 0.7494\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.5660 - accuracy: 0.7470\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.5126 - accuracy: 0.7726\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5155 - accuracy: 0.7730\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5579 - accuracy: 0.7615\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5253 - accuracy: 0.7718\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5418 - accuracy: 0.7664\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5509 - accuracy: 0.7553\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5554 - accuracy: 0.7534\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5144 - accuracy: 0.7709\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5154 - accuracy: 0.7769\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5733 - accuracy: 0.7431\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5138 - accuracy: 0.7698\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5137 - accuracy: 0.7689\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5319 - accuracy: 0.7676\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5482 - accuracy: 0.7594\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5358 - accuracy: 0.7611\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5439 - accuracy: 0.7671\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5816 - accuracy: 0.7360\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5088 - accuracy: 0.7721\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5712 - accuracy: 0.7476\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5538 - accuracy: 0.7516\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5402 - accuracy: 0.7615\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5606 - accuracy: 0.7486\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5771 - accuracy: 0.7435\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5090 - accuracy: 0.7738\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5115 - accuracy: 0.7744\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5746 - accuracy: 0.7406\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5211 - accuracy: 0.7710\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5476 - accuracy: 0.7595\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5232 - accuracy: 0.7688\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5910 - accuracy: 0.7421\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.5223 - accuracy: 0.7712\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5912 - accuracy: 0.7301\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5105 - accuracy: 0.7762\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5177 - accuracy: 0.7714\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.5324 - accuracy: 0.7613\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5724 - accuracy: 0.7375\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.5092 - accuracy: 0.7775\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5441 - accuracy: 0.7612 0s - loss: 0.5347 - ac\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5689 - accuracy: 0.7452\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5079 - accuracy: 0.7747\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5073 - accuracy: 0.7778\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5478 - accuracy: 0.7544\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5808 - accuracy: 0.7451\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5455 - accuracy: 0.7648\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5358 - accuracy: 0.7560\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5320 - accuracy: 0.7696\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5379 - accuracy: 0.7626\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5355 - accuracy: 0.7672\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5897 - accuracy: 0.7343\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5352 - accuracy: 0.7614\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5723 - accuracy: 0.7379\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 1s 57ms/step - loss: 0.5081 - accuracy: 0.7737\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.5253 - accuracy: 0.7670\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5954 - accuracy: 0.7330\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5396 - accuracy: 0.7637\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5408 - accuracy: 0.7555\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.5102 - accuracy: 0.7757\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5637 - accuracy: 0.7504\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5295 - accuracy: 0.7695\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5320 - accuracy: 0.7595\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5668 - accuracy: 0.7503 0s - loss: 0.5655 - accuracy: \n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5341 - accuracy: 0.7633\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5213 - accuracy: 0.7752\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5554 - accuracy: 0.7531\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 1s 55ms/step - loss: 0.5368 - accuracy: 0.7668\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5123 - accuracy: 0.7781\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5804 - accuracy: 0.7396\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5343 - accuracy: 0.7713\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5199 - accuracy: 0.7736\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5469 - accuracy: 0.7599\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.5649 - accuracy: 0.7503\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5254 - accuracy: 0.7616\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5705 - accuracy: 0.7438\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5305 - accuracy: 0.7726 0s - loss: 0.5329 - ac\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 1s 51ms/step - loss: 0.5130 - accuracy: 0.7757\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.5564 - accuracy: 0.7549\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5506 - accuracy: 0.7603\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5689 - accuracy: 0.7483\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5254 - accuracy: 0.7720\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5699 - accuracy: 0.7427\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5241 - accuracy: 0.7730\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.5347 - accuracy: 0.7618\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5498 - accuracy: 0.7546\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.5089 - accuracy: 0.7752\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5594 - accuracy: 0.7516\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 1s 49ms/step - loss: 0.5649 - accuracy: 0.7506\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.5088 - accuracy: 0.7799\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 1s 44ms/step - loss: 0.5124 - accuracy: 0.7744\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.5527 - accuracy: 0.7527\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.5699 - accuracy: 0.7426\n",
      "Epoch 00281: early stopping\n",
      "Score for fold 4: loss of 0.5105152130126953;     accuracy of 76.6751766204834%\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 40)                3480      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,901\n",
      "Trainable params: 3,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 3s 52ms/step - loss: 1.3172 - accuracy: 0.6971\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 1.1915 - accuracy: 0.7054\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 1.1059 - accuracy: 0.7050\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 1.0347 - accuracy: 0.7024\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 1s 52ms/step - loss: 0.9719 - accuracy: 0.7027\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 1s 58ms/step - loss: 0.9214 - accuracy: 0.6989\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 1s 56ms/step - loss: 0.8747 - accuracy: 0.7004\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 1s 54ms/step - loss: 0.8332 - accuracy: 0.7031\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 1s 53ms/step - loss: 0.7981 - accuracy: 0.7054\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.7703 - accuracy: 0.7048\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.7441 - accuracy: 0.7066\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.7252 - accuracy: 0.7044\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 1s 46ms/step - loss: 0.7077 - accuracy: 0.7042\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6953 - accuracy: 0.7009\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6780 - accuracy: 0.7062\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6693 - accuracy: 0.7030\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6573 - accuracy: 0.7056\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.6468 - accuracy: 0.7082\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6453 - accuracy: 0.7011\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.6397 - accuracy: 0.7013\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6373 - accuracy: 0.6981\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6299 - accuracy: 0.7007\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.6190 - accuracy: 0.7086\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6177 - accuracy: 0.7060\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6156 - accuracy: 0.7056\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6143 - accuracy: 0.7032\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6129 - accuracy: 0.7024\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6053 - accuracy: 0.7073\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.7083\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6051 - accuracy: 0.7029\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.7098\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5997 - accuracy: 0.7038\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6032 - accuracy: 0.6984\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5948 - accuracy: 0.7071\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5953 - accuracy: 0.7057\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5892 - accuracy: 0.7109\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5887 - accuracy: 0.7112\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5885 - accuracy: 0.7108\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5873 - accuracy: 0.7088\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5821 - accuracy: 0.7103\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5779 - accuracy: 0.7152\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5796 - accuracy: 0.7125\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5818 - accuracy: 0.7085\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5732 - accuracy: 0.7172\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5742 - accuracy: 0.7179\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5691 - accuracy: 0.7243\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7224\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5649 - accuracy: 0.7232\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.7312\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5591 - accuracy: 0.7341\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7336\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5605 - accuracy: 0.7350\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5584 - accuracy: 0.7342\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5540 - accuracy: 0.7429\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5521 - accuracy: 0.7426\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5483 - accuracy: 0.7460\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5553 - accuracy: 0.7435\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5461 - accuracy: 0.7481\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5463 - accuracy: 0.7499\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.7531\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7491\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5472 - accuracy: 0.7479\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5429 - accuracy: 0.7601\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5447 - accuracy: 0.7525\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5442 - accuracy: 0.7528\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5365 - accuracy: 0.7567\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5397 - accuracy: 0.7535\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7531\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7590\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5346 - accuracy: 0.7603\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5317 - accuracy: 0.7633\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5371 - accuracy: 0.7555\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5361 - accuracy: 0.7586\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5280 - accuracy: 0.7639\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5277 - accuracy: 0.7671\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5363 - accuracy: 0.7608\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5333 - accuracy: 0.7624\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5285 - accuracy: 0.7673\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5284 - accuracy: 0.7640\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7641\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5290 - accuracy: 0.7671\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7720\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5320 - accuracy: 0.7631\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5265 - accuracy: 0.7686\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5231 - accuracy: 0.7714\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.7621\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5366 - accuracy: 0.7606\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7674\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5267 - accuracy: 0.7623\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5283 - accuracy: 0.7664\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5235 - accuracy: 0.7698\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5551 - accuracy: 0.7518\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5280 - accuracy: 0.7718\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5306 - accuracy: 0.7613\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7587\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5211 - accuracy: 0.7709\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5572 - accuracy: 0.7523\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5527 - accuracy: 0.7533\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5160 - accuracy: 0.7722\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5331 - accuracy: 0.7697\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5399 - accuracy: 0.7585\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5308 - accuracy: 0.7606\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5185 - accuracy: 0.7684\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5473 - accuracy: 0.7595\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5190 - accuracy: 0.7711\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5160 - accuracy: 0.7726\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5379 - accuracy: 0.7600\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5451 - accuracy: 0.7565\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5559 - accuracy: 0.7496\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5390 - accuracy: 0.7574\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7705\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5433 - accuracy: 0.7634\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5220 - accuracy: 0.7672\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5295 - accuracy: 0.7630\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5379 - accuracy: 0.7641\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7559\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5253 - accuracy: 0.7729\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5290 - accuracy: 0.7696\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5328 - accuracy: 0.7663\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5264 - accuracy: 0.7719\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5628 - accuracy: 0.7463\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5205 - accuracy: 0.7745\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5375 - accuracy: 0.7628\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5344 - accuracy: 0.7645\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5128 - accuracy: 0.7776\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5432 - accuracy: 0.7589\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5438 - accuracy: 0.7561\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5170 - accuracy: 0.7773\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5403 - accuracy: 0.7630\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.7671\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5372 - accuracy: 0.7673\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5347 - accuracy: 0.7651\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5322 - accuracy: 0.7676\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5560 - accuracy: 0.7476\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5352 - accuracy: 0.7640\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5174 - accuracy: 0.7729\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5758 - accuracy: 0.7411\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5648 - accuracy: 0.7418\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5138 - accuracy: 0.7729\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5261 - accuracy: 0.7708\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5321 - accuracy: 0.7602\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7552\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5195 - accuracy: 0.7693\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5655 - accuracy: 0.7513\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5306 - accuracy: 0.7631\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5138 - accuracy: 0.7799\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5300 - accuracy: 0.7692\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5769 - accuracy: 0.7414\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5187 - accuracy: 0.7743\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7685\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5491 - accuracy: 0.7623\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5401 - accuracy: 0.7618\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5323 - accuracy: 0.7640\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5524 - accuracy: 0.7572\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5382 - accuracy: 0.7566\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5169 - accuracy: 0.7768\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5118 - accuracy: 0.7733\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6047 - accuracy: 0.7272\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7679\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5364 - accuracy: 0.7640\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5569 - accuracy: 0.7563\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5439 - accuracy: 0.7521\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5266 - accuracy: 0.7678\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5208 - accuracy: 0.7696\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5445 - accuracy: 0.7654\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5570 - accuracy: 0.7490\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5415 - accuracy: 0.7632\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5467 - accuracy: 0.7562\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5298 - accuracy: 0.7612\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5173 - accuracy: 0.7758\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5187 - accuracy: 0.7759\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5586 - accuracy: 0.7512\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5464 - accuracy: 0.7615\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 4s 299ms/step - loss: 0.5378 - accuracy: 0.7619\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5257 - accuracy: 0.7732\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5388 - accuracy: 0.7653\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5314 - accuracy: 0.7640\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5298 - accuracy: 0.7687\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5501 - accuracy: 0.7591\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5304 - accuracy: 0.7671\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.7758\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5662 - accuracy: 0.7447\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5413 - accuracy: 0.7641\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5428 - accuracy: 0.7617\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5611 - accuracy: 0.7483\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5339 - accuracy: 0.7614\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5096 - accuracy: 0.7778\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5234 - accuracy: 0.7695\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5769 - accuracy: 0.7395\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5407 - accuracy: 0.7610\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5610 - accuracy: 0.7532\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5159 - accuracy: 0.7727\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5503 - accuracy: 0.7563\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5726 - accuracy: 0.7410\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5448 - accuracy: 0.7572\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5283 - accuracy: 0.7667\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5425 - accuracy: 0.7598\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5133 - accuracy: 0.7787\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5709 - accuracy: 0.7460\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5239 - accuracy: 0.7713\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5563 - accuracy: 0.7525\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5192 - accuracy: 0.7766\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5156 - accuracy: 0.7741\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5655 - accuracy: 0.7431\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5043 - accuracy: 0.7764\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5329 - accuracy: 0.7674\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5735 - accuracy: 0.7451\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5069 - accuracy: 0.7764\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5199 - accuracy: 0.7762\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5640 - accuracy: 0.7538\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5181 - accuracy: 0.7740\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5469 - accuracy: 0.7651\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7462\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5501 - accuracy: 0.7616\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5571 - accuracy: 0.7505\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5305 - accuracy: 0.7717\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5676 - accuracy: 0.7420\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5116 - accuracy: 0.7754\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5454 - accuracy: 0.7595\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5287 - accuracy: 0.7662\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5585 - accuracy: 0.7466\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5304 - accuracy: 0.7628\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5975 - accuracy: 0.7293\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5215 - accuracy: 0.7671\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.7750\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5352 - accuracy: 0.7637\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5038 - accuracy: 0.7835\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.5806 - accuracy: 0.7383\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.5714 - accuracy: 0.7439\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.5154 - accuracy: 0.7734\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.5808 - accuracy: 0.7422\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.5162 - accuracy: 0.7736\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.5653 - accuracy: 0.7456\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.5527 - accuracy: 0.7508\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.5064 - accuracy: 0.7820\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5311 - accuracy: 0.7692\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5911 - accuracy: 0.7321\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.5275 - accuracy: 0.7691\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5311 - accuracy: 0.7646\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 14ms/step - loss: 0.5528 - accuracy: 0.7576\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5333 - accuracy: 0.7590\n",
      "Epoch 242/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5498 - accuracy: 0.7626\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5213 - accuracy: 0.7729\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5366 - accuracy: 0.7613\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.5432 - accuracy: 0.7582\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.5329 - accuracy: 0.7699\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5113 - accuracy: 0.7728\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.5522 - accuracy: 0.7601\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5404 - accuracy: 0.7580\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5376 - accuracy: 0.7640\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5868 - accuracy: 0.7400\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5087 - accuracy: 0.7850\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7736\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5338 - accuracy: 0.7706\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5396 - accuracy: 0.7633\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.7426\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.5276 - accuracy: 0.7679\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5312 - accuracy: 0.7692\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5405 - accuracy: 0.7565\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5459 - accuracy: 0.7673\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.5203 - accuracy: 0.7750\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.7746\n",
      "Epoch 00262: early stopping\n",
      "Score for fold 5: loss of 0.5928738713264465;     accuracy of 73.86726140975952%\n",
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 0.5321862101554871 - Accuracy: 78.81977558135986%\n",
      "> Fold 1 - Confusion Matrix: [[ 995 2677]\n",
      " [ 214 8652]]     - Precision: 0.7637037690881808%     - Precision: 0.9758628468305888%     - Precision: 0.85684575389948%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 0.5504798889160156 - Accuracy: 76.65071487426758%\n",
      "> Fold 2 - Confusion Matrix: [[ 997 2663]\n",
      " [ 226 8652]]     - Precision: 0.7646486964206806%     - Precision: 0.9745438161748141%     - Precision: 0.8569306195216164%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 0.6151961088180542 - Accuracy: 72.1531093120575%\n",
      "> Fold 3 - Confusion Matrix: [[ 991 2667]\n",
      " [ 207 8673]]     - Precision: 0.7648148148148148%     - Precision: 0.9766891891891892%     - Precision: 0.8578635014836795%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 0.5105152130126953 - Accuracy: 76.6751766204834%\n",
      "> Fold 4 - Confusion Matrix: [[ 974 2703]\n",
      " [ 221 8641]]     - Precision: 0.7617242595204513%     - Precision: 0.9750620627397879%     - Precision: 0.8552905077699693%\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 0.5928738713264465 - Accuracy: 73.86726140975952%\n",
      "> Fold 5 - Confusion Matrix: [[1027 2678]\n",
      " [ 232 8602]]     - Precision: 0.7625886524822695%     - Precision: 0.9737378311070862%     - Precision: 0.8553246494978621%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Accuracy: 75.63320755958557 (+- 2.345416211815193)\n",
      "> Loss: 0.5602502584457397\n",
      "> Precision: 0.7634960384652795\n",
      "> Recall: 0.9751791492082933\n",
      "> F1: 0.8564510064345214\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del history\n",
    "except:\n",
    "    pass\n",
    "\n",
    "conf_mat_per_fold = []\n",
    "precision_per_fold = []\n",
    "recall_per_fold = []\n",
    "f1_per_fold = []\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "fold_no = 1\n",
    "\n",
    "for train, test in kfold.split(x_train_test_val, y_train_test_val):\n",
    "    # Fit data to model\n",
    "    model4_reg = model_four_reg()\n",
    "    history = model4_reg.fit(x_train_test_val[train] ,y_train_test_val[train] \n",
    "            ,epochs = 1000 ,batch_size=1000 ,callbacks = [early_stopping])\n",
    "\n",
    "    # Generate generalization metrics\n",
    "    scores = model4_reg.evaluate(x_train_test_val[test] , y_train_test_val[test] , verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model4_reg.metrics_names[0]} of {scores[0]}; \\\n",
    "    {model4_reg.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    y_pred = np.round(model1_reg.predict(x_train_test_val[train])).astype(int)\n",
    "    conf_mat_per_fold.append(confusion_matrix(y_train_test_val[train]  ,y_pred))\n",
    "    precision_per_fold.append(precision_score(y_train_test_val[train] ,y_pred))\n",
    "    recall_per_fold.append(recall_score(y_train_test_val[train] ,y_pred))\n",
    "    f1_per_fold.append(f1_score(y_train_test_val[train], y_pred))\n",
    "\n",
    "    # Increase fold number\n",
    "    fold_no = fold_no + 1\n",
    "    \n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print(f'> Fold {i+1} - Confusion Matrix: {conf_mat_per_fold[i]} \\\n",
    "    - Precision: {precision_per_fold[i]}% \\\n",
    "    - Precision: {recall_per_fold[i]}% \\\n",
    "    - Precision: {f1_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print(f'> Precision: {np.mean(precision_per_fold)}')\n",
    "print(f'> Recall: {np.mean(recall_per_fold)}')\n",
    "print(f'> F1: {np.mean(f1_per_fold)}')\n",
    "print('--------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in your part 5 conclusions here\n",
    "Explain what you conclude from your regularization analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1 with L2 regularization and a dropout layer performed the best. All other models increased in complexity. This may indicate that Model 1 could be simplified by removing columns, increasing the dropout percentage, or reducing the number of nodes, in order to improve performance.\n",
    "\n",
    "Although these conclusisions were drawn from the models above, in a real application they should not be used as they exist now. Their precision and recall curves did not intersect although they appear to be on track to. This indicates that there are still adjustments to be made to the model in order to achieve optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Grid Search\n",
    "Please read this article on using Grid Search CV with Keras. Be very very careful. Grid Search is very very slow. Given your above experiments you should have a pretty good idea of what your prameters should be before you run grid search. Run some small gridsearch runs (much smaller or more widely spaced) than you want to estimate time. Remember google colab will end after a limited amount of time so build slowly. Try to pin down the best parameters for:\n",
    "\n",
    "1. The number of layers (please don't go deeper than 10 hidden layers)\n",
    "2. The number of nodes per layer\n",
    "3. The type of regularization to use\n",
    "4. The type of weight initialization to use.\n",
    "5. The type of activation function.\n",
    "6. The metric to evaluate with, although logloss is standard, try using other metrics of accuracy.\n",
    "\n",
    "You may even try multiple and averaging or taking the harmonic weight of multiple metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping as early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_pipeline(X_train_data, X_test_data, y_train_data, y_test_data, \n",
    "                       model, param_grid, cv=10, scoring_fit='neg_mean_squared_error',\n",
    "                       do_probabilities = False):\n",
    "    gs = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid, \n",
    "        cv=cv, \n",
    "        n_jobs=-1, \n",
    "        scoring=scoring_fit,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    early_stopping = early(monitor='val_loss'\n",
    "              ,patience=200\n",
    "              ,min_delta = 0.05, verbose = 1)\n",
    "\n",
    "    fitted_model = gs.fit(X_train_data, y_train_data ,callbacks = [early_stopping])\n",
    "\n",
    "    if do_probabilities:\n",
    "        pred = fitted_model.predict_proba(X_test_data)\n",
    "    else:\n",
    "        pred = fitted_model.predict(X_test_data)\n",
    "\n",
    "    return fitted_model, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding a dropout layer\n",
    "def model_one_param(activat='relu'\n",
    "                    ,drop=.2\n",
    "                    ,layrs=1\n",
    "                    ,metric='accuracy'\n",
    "                    ,nods=30\n",
    "                    ,optimizer='sgd'\n",
    "                   ):\n",
    "    tf.keras.backend.clear_session()\n",
    "    model1 = Sequential()\n",
    "    for i in range(0 ,layrs):\n",
    "        model1.add(Dense(nods ,input_shape=(86,) ,activation=activat ,kernel_regularizer='l2'))\n",
    "    model1.add(Dropout(drop))\n",
    "    model1.add(Dense(1 ,activation='sigmoid'))\n",
    "    model1.compile(optimizer='sgd' ,loss='binary_crossentropy' ,metrics=metric)\n",
    "    K.set_value(model1.optimizer.learning_rate, .3)\n",
    "    model1.summary()\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   14.5s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   46.3s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.5min\n",
      "/usr/lib/python3/dist-packages/joblib/externals/loky/process_executor.py:703: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 70)                6090      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 6,161\n",
      "Trainable params: 6,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/busybeeze/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4150206870519127\n",
      "{'activat': 'tanh', 'drop': 0.2, 'metric': 'accuracy', 'nods': 70, 'optimizer': 'sgd'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'nods': [70 ,40 ,15],\n",
    "                'drop' :    [0.2 ,.5, 0.8],\n",
    "              'activat' : ['sigmoid', 'tanh'],\n",
    "              'optimizer' : ['adam', 'nadam' ,'sgd'],\n",
    "              'metric' : ['accuracy', 'val_loss'],\n",
    "             }\n",
    "\n",
    "model = KerasClassifier(build_fn = model_one_param, verbose=0)\n",
    "\n",
    "model, pred = algorithm_pipeline(x_train, x_test, y_train_bool, y_test_bool, model, \n",
    "                                        param_grid, cv=5, scoring_fit='neg_log_loss')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 70)                6090      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 6,161\n",
      "Trainable params: 6,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "98/98 [==============================] - 1s 3ms/step - loss: 1.6626 - accuracy: 0.3034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6667776107788086, 0.3001594841480255]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one_param(**model.best_params_).evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   47.6s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                2610      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,641\n",
      "Trainable params: 2,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "-0.20589065345504315\n",
      "{'activat': 'tanh', 'drop': 0.6, 'metric': 'accuracy', 'nods': 30, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'nods': [20 ,30 ,120],\n",
    "                'drop' :    [0.6 ,.2, 0.4],\n",
    "              'activat' : ['sigmoid','tanh'],\n",
    "              'optimizer' : ['adam', 'nadam' ,'sgd'],\n",
    "              'metric' : ['accuracy', 'val_loss'],\n",
    "             }\n",
    "\n",
    "model = KerasClassifier(build_fn = model_one_param, verbose=0)\n",
    "\n",
    "model, pred = algorithm_pipeline(x_train, x_test, y_train_bool, y_test_bool, model, \n",
    "                                        param_grid, cv=5, scoring_fit='neg_mean_squared_error')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 30)                2610      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 31        \n",
      "=================================================================\n",
      "Total params: 2,641\n",
      "Trainable params: 2,641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "98/98 [==============================] - 1s 3ms/step - loss: 1.1217 - accuracy: 0.5904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1211373805999756, 0.5926634669303894]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one_param(**model.best_params_).evaluate(x_val ,y_val_bool)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 624 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 989 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1080 out of 1080 | elapsed:  4.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 140)               12180     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 32,061\n",
      "Trainable params: 32,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "-0.20068348660173968\n",
      "{'activat': 'tanh', 'drop': 0.6, 'layrs': 2, 'metric': 'accuracy', 'nods': 140, 'optimizer': 'nadam'}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { 'nods': [100 ,120 ,140],\n",
    "                'drop' :    [0.6 ,.8, 0.9],\n",
    "              'activat' : ['sigmoid','tanh'],\n",
    "              'optimizer' : ['adam', 'nadam' ,'sgd'],\n",
    "              'metric' : ['accuracy', 'val_loss'],\n",
    "              'layrs' : [1 ,2]\n",
    "             }\n",
    "\n",
    "model = KerasClassifier(build_fn = model_one_param, verbose=0)\n",
    "\n",
    "model, pred = algorithm_pipeline(x_train, x_test, y_train_bool, y_test_bool, model, \n",
    "                                        param_grid, cv=5, scoring_fit='neg_mean_squared_error')\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 140)               12180     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 140)               19740     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 141       \n",
      "=================================================================\n",
      "Total params: 32,061\n",
      "Trainable params: 32,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "98/98 [==============================] - 1s 3ms/step - loss: 3.1834 - accuracy: 0.4152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.183027982711792, 0.4149920344352722]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_one_param(**model.best_params_).evaluate(x_val ,y_val_bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put your grid search conclusion for part 6 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I appears that only 1 layer with a larger amount of output nodes than features is an optimal model. With a dropout greater than half, indicates that a majority of the features aren't important for generating the best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Conclusion\n",
    "Conclude with a full report here on what we know now about this problem. How well it does verses baseline, what the best Keras archtecture is, what features should be used, how the data should be cleaned etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after paramater investigation, these models did not perform significantly better than a regular random forest. This could mean that these models are either not complex enough to beat the machine learning approach, or that the problem is simple enough that it doesn't require a neural network approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
